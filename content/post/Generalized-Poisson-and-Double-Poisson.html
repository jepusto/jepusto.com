---
title: Implementing Consul's generalized Poisson distribution in Stan
authors:
- admin
date: '2023-12-04'
draft: true
codefolding_show: 'show'
slug: generalized-poisson-in-Stan
categories: []
tags:
  - Bayes
  - simulation
  - distribution-theory
  - generalized linear model
  - programming
  - Rstats
header:
  caption: ''
  image: ''
---



<p><span class="math display">\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]</span></p>
<p>For a project I am working on, we are using <a href="https://mc-stan.org/">Stan</a> to fit generalized random effects location-scale models to a bunch of count data.
In <a href="/double-poisson-in-Stan/">a previous post</a>, I walked through our implementation of <a href="https://doi.org/10.2307/2289002">Efron’s (1986)</a> double-Poisson distribution, which we are interested in using because it allows for both over- and under-dispersion relative to the Poisson distribution.
Another distribution with these properties is the generalized Poisson distribution described by <a href="https://doi.org/10.1080/00401706.1973.10489112">Consul and Jain (1973)</a>.</p>
<p>In this post, I’ll walk through my implementation of the GPO in Stan.
The <a href="https://cran.r-project.org/package=gamlss.dist"><code>gamlss.dist</code> package</a> provides a full set of distributional functions for the generalized Poisson distribution, including a sampler, but the functions are configured to only allow for over-dispersion. Since I’m interested in allowing for under-dispersion as well, I’ll need to write my own functions. As in my previous post, I can validate my Stan functions against the functions from <code>gamlss.dist</code> (although only for over-dispersion scenarios).</p>
<pre class="r"><code>library(tidyverse)
library(patchwork)   # composing figures
library(gamlss.dist) # DPO distribution functions
library(rstan)       # Stan interface to R
library(brms)        # fitting generalized linear models
library(bayesplot)   # Examine fitted models
library(loo)         # Model fit measures</code></pre>
<div id="the-generalized-poisson" class="section level2">
<h2>The generalized Poisson</h2>
<p>Consul and Jain’s generalized Poisson distribution is a discrete distribution for non-negative counts, with support <span class="math inline">\(\mathcal{S}_X = \{0, 1, 2, 3, ...\}\)</span>.
The mean-variance relationship of the generalized Poisson is constant; for <span class="math inline">\(X \sim GPO(\mu, \phi)\)</span>, <span class="math inline">\(\text{E}(X) = \mu\)</span> and <span class="math inline">\(\text{Var}(X) = \mu / \phi\)</span> for <span class="math inline">\(0 &lt; \phi &lt; 1\)</span>; the expectation and variance are not exact but are close approximations when there is underdispersion, so <span class="math inline">\(\phi &gt; 1\)</span>. Thus, like the double-Poisson distribution, the generalized Poisson satisfies the assumptions of a quasi-Poisson generalized linear model (at least approximately).</p>
<p>The density of the generalized Poisson distribution with mean <span class="math inline">\(\mu\)</span> and inverse-disperson <span class="math inline">\(\phi\)</span> is:
<span class="math display">\[
f(x | \mu, \phi) = \mu \sqrt{\phi} \left( x + \sqrt{\phi}(\mu - x) \right)^{x-1} \frac{\exp \left[-\left( x + \sqrt{\phi}(\mu - x)\right)\right]}{x!}.
\]</span>
We then have
<span class="math display">\[
\ln f(x | \mu, \phi) = \frac{1}{2} \ln \phi + \ln \mu + (x - 1) \ln \left( x + \sqrt{\phi}(\mu - x) \right) - \left( x + \sqrt{\phi}(\mu - x) \right) - \ln \left(x!\right).
\]</span>
Using the GPO with under-dispersed data is a little bit more controversial (by statistical standards) than using the DPO.
This is because, for parameter values corresponding to under-dispersion, its probability mass function becomes negative for large counts. In particular, note that for values <span class="math inline">\(x &gt; \frac{\mu\sqrt\phi}{\sqrt\phi - 1}\)</span>, the quantity <span class="math inline">\(x + \sqrt{\phi}(\mu - x)\)</span> becomes negative, and so <span class="math inline">\(f(x| \mu, \phi)\)</span> is no longer a proper probability.
Consul suggested handling this situation by truncating the distribution at <span class="math inline">\(m = \left\lfloor \frac{\mu\sqrt\phi}{\sqrt\phi - 1}\right\rfloor\)</span>. However, doing so makes the distribution only an approximation, such that <span class="math inline">\(\mu\)</span> is no longer exactly the mean and <span class="math inline">\(\phi\)</span> is no longer exactly the inverse dispersion.
For modest under-dispersion of no less than 60% of the mean, <span class="math inline">\(1 &lt; \phi &lt; 5 / 3\)</span> and the truncation point is fairly extreme, with <span class="math inline">\(m \approx 4.4 \mu\)</span>, so I’m not too worried about this issue.
We’ll see how it plays out in application, of course.</p>
</div>
<div id="log-of-the-probability-mass-function" class="section level1">
<h1>Log of the probability mass function</h1>
<p>Here’s a Stan function implementing the lpmf, with the truncation bit:</p>
<pre class="r"><code>stancode_lpmf &lt;- &quot;
real gpo_lpmf(int X, real mu, real phi) {
  real ans;
  real m = mu / (1 - inv(sqrt(phi)));
  real z = X + sqrt(phi) * (mu - X);
  if (phi &gt; 1 &amp;&amp; X &gt; m)
    ans = negative_infinity();
  else 
    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);
  return ans;
}
&quot;</code></pre>
<p>To check that this is accurate, I’ll compare the Stan function to the corresponding function from <code>gamlss.dist</code> for a couple of different parameter values and for <span class="math inline">\(x = 0,...,100\)</span>. If my function is accurate, my calculated log-probabilities should be equal to the results from <code>gamlss.dist::dGPO</code>. Note that the <code>gamlss.dist</code> function uses a different parameterization for the dispersion, with <span class="math inline">\(\sigma = \frac{\phi^{-1/2} - 1}{\mu}\)</span>.</p>
<pre class="r"><code>writeLines(paste(&quot;functions {&quot;, stancode_lpmf, &quot;}&quot;, sep = &quot;\n&quot;), &quot;GPO-lpmf.stan&quot;)
expose_stan_functions(&quot;GPO-lpmf.stan&quot;)

test_lpmf &lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
    X = 0:100
  ) %&gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    gamlss_lpmf = dGPO(x = X, mu = mu, sigma = sigma, log = TRUE),
    my_lpmf = pmap_dbl(.l = list(X = X, mu = mu, phi = phi), .f = gpo_lpmf),
    diff = my_lpmf - gamlss_lpmf
  )</code></pre>
<pre class="r"><code>ggplot(test_lpmf, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &quot;label_both&quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &quot;phi&quot;) + 
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Checks out. Onward!</p>
</div>
<div id="quantile-function" class="section level1">
<h1>Quantile function</h1>
<p>I’ll next implement the generalized Poisson quantile function, taking advantage of a simple recurrence relationship for sequential values. Note that
<span class="math display">\[
\begin{aligned}
f(0 | \mu, \phi) &amp;= \exp \left(-\mu \sqrt{\phi}\right) \\
f(x | \mu, \phi) &amp;= f(x - 1 | \mu, \phi) \times \frac{\left(x + \sqrt{\phi}(\mu - x)\right)^{x - 1}}{\left(x - 1 + \sqrt{\phi}(\mu - (x - 1))\right)^{x - 2}} \times \frac{\exp(\sqrt{\phi} - 1)}{x}
\end{aligned}
\]</span>
where the second expression holds for <span class="math inline">\(x \geq 1\)</span>.</p>
<p>The function below computes the quantile given a value <span class="math inline">\(p\)</span> by computing the cumulative distribution function until <span class="math inline">\(p\)</span> is exceeded:</p>
<pre class="r"><code>stancode_quantile &lt;- &quot; 
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &lt; p &amp;&amp; q &lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}
&quot;</code></pre>
<p>If my quantile function is accurate, it should match the value computed from <code>gamlss.dist::qDPO()</code> exactly.</p>
<pre class="r"><code>writeLines(paste(&quot;functions {&quot;, stancode_quantile, &quot;}&quot;, sep = &quot;\n&quot;), &quot;GPO-quantile.stan&quot;)
expose_stan_functions(&quot;GPO-quantile.stan&quot;)

test_quantile &lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
  ) %&gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    p = map(1:n(), ~ runif(100)),
  ) %&gt;%
  unnest(p) %&gt;%
  mutate(
    my_q = pmap_dbl(list(p = p, mu = mu, phi = phi), .f = gpo_quantile),
    gamlss_q = qGPO(p, mu = mu, sigma = sigma),
    diff = my_q - gamlss_q
  )</code></pre>
<pre class="r"><code>ggplot(test_quantile, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &quot;label_both&quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &quot;phi&quot;) + 
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/check-quantile-plot-1.png" width="672" /></p>
<p>I should enter this figure in the competition for the world’s most boring statistical graphic.</p>
</div>
<div id="sampler" class="section level1">
<h1>Sampler</h1>
<p>The last thing I’ll need is a sampler, which I’ll implement by generating random points from a uniform distribution, then computing the generalized Poisson quantiles of these random points. My implementation just generates a single random variate:</p>
<pre class="r"><code>stancode_qr &lt;- &quot;
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &lt; p &amp;&amp; q &lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}

int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&quot;</code></pre>
<p>To check this function, I’ll generate some large samples from the generalized Poisson with a few different parameter sets. If the sampler is working properly, the empirical cumulative distribution should line up closely with the cumulative distribution computed using <code>gamlss.dist::pGPO()</code>.</p>
<pre class="r"><code>writeLines(paste(&quot;functions {&quot;, stancode_qr, &quot;}&quot;, sep = &quot;\n&quot;), &quot;GPO-rng.stan&quot;)
expose_stan_functions(&quot;GPO-rng.stan&quot;)

gpo_rng_sampler &lt;- function(N, mu, phi) {
  replicate(N, gpo_rng(mu = mu, phi = phi))
}

test_rng &lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
  ) %&gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    x = pmap(.l = list(N = 10000, mu = mu, phi = phi), .f = gpo_rng_sampler),
    tb = map(x, ~ as.data.frame(table(.x)))
  ) %&gt;%
  dplyr::select(-x) %&gt;%
  group_by(mu, phi) %&gt;%
  unnest(tb) %&gt;%
  mutate(
    .x = as.integer(levels(.x))[.x],
    Freq_cum = cumsum(Freq) / 10000,
    gamlss_F = pGPO(q = .x, mu = mu, sigma = sigma)
  )</code></pre>
<pre class="r"><code>ggplot(test_rng, aes(gamlss_F, Freq_cum, color = factor(phi))) + 
  geom_abline(slope = 1, color = &quot;blue&quot;, linetype = &quot;dashed&quot;) + 
  geom_point() + geom_line() +  
  facet_grid(phi ~ mu, labeller = &quot;label_both&quot;) + 
  theme_minimal() + 
  labs(x = &quot;Theoretical cdf (gamlss.dist)&quot;, y = &quot;Empirical cdf (my function)&quot;) + 
  theme(legend.position = &quot;none&quot;) </code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/check-rng-plot-1.png" width="672" />
Another approach to checking the sampler is to simulate a bunch of observations and check whether the empirical mean and variance match the theoretical moments. I’ll do this as well, using some values of <span class="math inline">\(phi &gt; 1\)</span> to test whether the sampler still works when there’s under-dispersion.</p>
<pre class="r"><code>test_moments &lt;- 
  expand_grid(
    mu = c(5, 10, 20, 40, 60),
    phi = seq(1, 2, 0.1),
  ) %&gt;%
  mutate(
    x = pmap(.l = list(N = 1e5, mu = mu, phi = phi), .f = gpo_rng_sampler),
    M = map_dbl(x, mean),
    S = map_dbl(x, sd),
    M_ratio = M / mu,
    S_ratio = S / sqrt(mu / phi)
  ) %&gt;%
  dplyr::select(-x) %&gt;%
  pivot_longer(ends_with(&quot;_ratio&quot;),names_to = &quot;moment&quot;,values_to = &quot;ratio&quot;) %&gt;%
  mutate(
    moment = factor(moment, levels = c(&quot;M_ratio&quot;, &quot;S_ratio&quot;), labels = c(&quot;Sample mean&quot;, &quot;Standard deviation&quot;)),
    mu = factor(mu)
  )

ggplot(test_moments, aes(phi, ratio, color = mu)) + 
  geom_point() + geom_line() + 
  facet_wrap(~ moment) + 
  theme_minimal()</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/test-sample-moments-1.png" width="768" />
Looks like the sample moments closely match the parameter values, with deviations that look pretty much like random error. Nice!</p>
</div>
<div id="using-the-custom-distribution-functions" class="section level1">
<h1>Using the custom distribution functions</h1>
<p>To finish out my tests of these functions, I’ll try out a small simulation. Following my <a href="/Double-Poisson-in-Stan/">previous post</a>, I’ll generate data based on a generalized linear model with a single predictor <span class="math inline">\(X\)</span>, where the outcome <span class="math inline">\(Y\)</span> follows a generalized Poisson distribution conditional on <span class="math inline">\(X\)</span>. The data-generating process is:</p>
<p><span class="math display">\[
\begin{aligned}
X &amp;\sim N(0, 1) \\
Y|X &amp;\sim GPO(\mu(X), \phi) \\
\log \mu(X) &amp;= 2 + 0.3 \times X
\end{aligned}
\]</span>
with dispersion parameter to <span class="math inline">\(1 / \phi = 0.7\)</span> so that the outcome is <em>under</em>-dispersed.</p>
<p>The following code generates a large sample from the data-generating process:</p>
<pre class="r"><code>set.seed(20231204)
N &lt;- 600
X &lt;- rnorm(N)
mu &lt;- exp(2 + 0.3 * X)
phi_inv &lt;- 0.7
Y &lt;- map_dbl(mu, gpo_rng, phi = 1 / phi_inv)
dat &lt;- data.frame(X = X, Y = Y)</code></pre>
<p>Here’s what the sample looks like, along with a smoothed regression estimated using a basic cubic spline:</p>
<pre class="r"><code>ggplot(dat, aes(X, Y)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = &#39;gam&#39;, formula = y ~ s(x, bs = &quot;cs&quot;)) + 
  theme_minimal()</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/glm-scatterplot-1.png" width="576" />
Here is a fit using quasi-likelihood estimation of a log-linear model:</p>
<pre class="r"><code>quasi_fit &lt;- glm(Y ~ X, family = quasipoisson(link = &quot;log&quot;), data = dat)
summary(quasi_fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Y ~ X, family = quasipoisson(link = &quot;log&quot;), data = dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.8059  -0.5958  -0.0308   0.5275   2.8044  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.99558    0.01273  156.71   &lt;2e-16 ***
## X            0.30081    0.01174   25.61   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 0.6689639)
## 
##     Null deviance: 852.98  on 599  degrees of freedom
## Residual deviance: 413.94  on 598  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>This approach recovers the data-generating parameters quite well, with a dispersion estimate of 0.669 compared to the true dispersion parameter of 0.7.</p>
<div id="candidate-models" class="section level2">
<h2>Candidate models</h2>
<p>Now let me fit the same generalized linear model but assuming that the outcome follow a couple of different distributions, including a true Poisson (with unit dispersion), a negative binomial, the double-Poisson distribution from the previous post, and the generalized Poisson distribution. Here goes!</p>
<pre class="r"><code>Poisson_fit &lt;- 
  brm(
    Y ~ X, family = poisson(link = &quot;log&quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )</code></pre>
<pre class="r"><code>negbin_fit &lt;- 
  brm(
    Y ~ X, family = negbinomial(link = &quot;log&quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )</code></pre>
<pre class="r"><code>stancode_dpo &lt;- &quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
int dpo_quantile(real p, real mu, real phi, int maxval) {
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int q = 0;
  while (cdf_vec[q + 1] &lt; p) {
      q += 1;
    }
  return q;
}
int dpo_rng(real mu, real phi, int maxval) {
  real p = uniform_rng(0,1);
  int x = dpo_quantile(p, mu, phi, maxval);
  return x;
}
&quot;
double_Poisson &lt;- custom_family(
  &quot;dpo&quot;, dpars = c(&quot;mu&quot;,&quot;phi&quot;),
  links = c(&quot;log&quot;,&quot;log&quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &quot;int&quot;
)

double_Poisson_stanvars &lt;- stanvar(scode = stancode_dpo, block = &quot;functions&quot;)

phi_prior &lt;- prior(exponential(1), class = &quot;phi&quot;)

DPO_fit &lt;- 
  brm(
    Y ~ X, family = double_Poisson,
    prior = phi_prior,
    stanvars = double_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )

expose_functions(DPO_fit, vectorize = TRUE)

log_lik_dpo &lt;- function(i, prep) {
  mu &lt;- brms::get_dpar(prep, &quot;mu&quot;, i = i)
  phi &lt;- brms::get_dpar(prep, &quot;phi&quot;, i = i)
  y &lt;- prep$data$Y[i]
  dpo_lpmf(y, mu, phi)
}

posterior_predict_dpo &lt;- function(i, prep, maxval = NULL, ...) {
  mu &lt;- brms::get_dpar(prep, &quot;mu&quot;, i = i)
  phi &lt;- brms::get_dpar(prep, &quot;phi&quot;, i = i)
  if (is.null(maxval)) maxval &lt;- 20 * mu / min(phi, 1)
  dpo_rng(mu, phi, maxval = maxval)
}</code></pre>
<pre class="r"><code>stancode_gpo &lt;- &quot;
real gpo_lpmf(int X, real mu, real phi) {
  real ans;
  real m = mu / (1 - inv(sqrt(phi)));
  real z = X + sqrt(phi) * (mu - X);
  if (phi &gt; 1 &amp;&amp; X &gt; m)
    ans = negative_infinity();
  else 
    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);
  return ans;
}
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &lt; p &amp;&amp; q &lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}
int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&quot;
generalized_Poisson &lt;- custom_family(
  &quot;gpo&quot;, dpars = c(&quot;mu&quot;,&quot;phi&quot;),
  links = c(&quot;log&quot;,&quot;log&quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &quot;int&quot;
)

generalized_Poisson_stanvars &lt;- stanvar(scode = stancode_gpo, block = &quot;functions&quot;)

phi_prior &lt;- prior(exponential(1), class = &quot;phi&quot;)

GPO_fit &lt;- 
  brm(
    Y ~ X, family = generalized_Poisson,
    prior = phi_prior,
    stanvars = generalized_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )

expose_functions(GPO_fit, vectorize = TRUE)

log_lik_gpo &lt;- function(i, prep) {
  mu &lt;- brms::get_dpar(prep, &quot;mu&quot;, i = i)
  phi &lt;- brms::get_dpar(prep, &quot;phi&quot;, i = i)
  y &lt;- prep$data$Y[i]
  gpo_lpmf(y, mu, phi)
}

posterior_predict_gpo &lt;- function(i, prep, maxval = NULL, ...) {
  mu &lt;- brms::get_dpar(prep, &quot;mu&quot;, i = i)
  phi &lt;- brms::get_dpar(prep, &quot;phi&quot;, i = i)
  gpo_rng(mu, phi)
}</code></pre>
</div>
<div id="model-comparison" class="section level2">
<h2>Model comparison</h2>
<p>Here is a comparison of LOOIC for all of the models:</p>
<pre class="r"><code>loo(Poisson_fit, negbin_fit, DPO_fit, GPO_fit)</code></pre>
<pre><code>## Output of model &#39;Poisson_fit&#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1358.1 12.4
## p_loo         1.6  0.2
## looic      2716.2 24.9
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;negbin_fit&#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1361.1 12.1
## p_loo         1.5  0.2
## looic      2722.1 24.2
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;DPO_fit&#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1341.1 17.5
## p_loo         3.2  0.3
## looic      2682.2 35.1
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;GPO_fit&#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1337.5 18.0
## p_loo         3.3  0.4
## looic      2675.0 36.1
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Model comparisons:
##             elpd_diff se_diff
## GPO_fit       0.0       0.0  
## DPO_fit      -3.6       1.7  
## Poisson_fit -20.6       6.1  
## negbin_fit  -23.6       6.5</code></pre>
<p>Unsurprisingly, the model based on the true data-generating process clearly fits better than the models involving other outcome distributions.</p>
<p>Here’s the posterior for the dispersion (i.e., <span class="math inline">\(1 / \phi\)</span>) based on the GPO and DPO models:</p>
<pre class="r"><code>color_scheme_set(&quot;green&quot;)
GPO_dispersion &lt;- 
  mcmc_areas(GPO_fit, pars = &quot;phi&quot;, transformations = \(x) 1 / x) + 
  scale_x_continuous(limits = c(0.55, 0.95)) + 
  theme_minimal() + 
  ggtitle(&quot;Generalized Poisson&quot;)

color_scheme_set(&quot;brightblue&quot;)
DPO_dispersion &lt;- 
  mcmc_areas(DPO_fit, pars = &quot;phi&quot;, transformations = \(x) 1 / x) + 
  scale_x_continuous(limits = c(0.55, 0.95)) + 
  theme_minimal() + 
  ggtitle(&quot;Double Poisson&quot;)

DPO_dispersion / GPO_dispersion</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/dispersion-comparison-1.png" width="480" /></p>
<p>It looks like the estimated dispersion from the double Poisson model is biased upwards (towards one) a little bit). To get a better sense of this, I’ll run some posterior predictive checks, using the quasi-likelihood dispersion as a summary statistic:</p>
<pre class="r"><code>Yrep_Poisson &lt;- posterior_predict(Poisson_fit, ndraws = 500) 
Yrep_negbin &lt;- posterior_predict(negbin_fit, ndraws = 500)
Yrep_dpo &lt;- posterior_predict(DPO_fit, ndraws = 500)
Yrep_gpo &lt;- posterior_predict(GPO_fit, ndraws = 500)

dispersion_coef &lt;- function(y) {
  quasi_fit &lt;- glm(y ~ dat$X, family = quasipoisson(link = &quot;log&quot;))
  sum(residuals(quasi_fit, type = &quot;pearson&quot;)^2) / quasi_fit$df.residual
}

color_scheme_set(&quot;blue&quot;)
Poisson_disp &lt;- ppc_stat(dat$Y, Yrep_Poisson, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &quot;Poisson&quot;)

color_scheme_set(&quot;purple&quot;)
negbin_disp &lt;- ppc_stat(dat$Y, Yrep_negbin, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &quot;Negative-binomial&quot;)

color_scheme_set(&quot;brightblue&quot;)
dpo_disp &lt;- ppc_stat(dat$Y, Yrep_dpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &quot;Double Poisson&quot;)

color_scheme_set(&quot;green&quot;)
gpo_disp &lt;- ppc_stat(dat$Y, Yrep_gpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &quot;Generalized Poisson&quot;)

Poisson_disp / negbin_disp / dpo_disp / gpo_disp &amp;
  theme_minimal() &amp; 
  xlim(c(0.45, 1.3))</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/ppc-dispersion-1.png" width="768" />
Both the double Poisson and the generalized Poisson models generate data with levels of dispersion similar to the observed data. Squinting pretty hard, it looks like perhaps the double Poisson model is indeed a bit biased.</p>
</div>
<div id="marginal-posterior-predictive-densities" class="section level2">
<h2>Marginal posterior predictive densities</h2>
<p>Here’s some rootograms for the posterior predictive density of the raw outcomes:</p>
<pre class="r"><code>color_scheme_set(&quot;blue&quot;)
Poisson_root &lt;- ppc_rootogram(dat$Y, Yrep_Poisson, style = &quot;hanging&quot;) + labs(title = &quot;Poisson&quot;)
color_scheme_set(&quot;purple&quot;)
negbin_root &lt;- ppc_rootogram(dat$Y, Yrep_negbin, style = &quot;hanging&quot;) + labs(title = &quot;Negative-binomial&quot;)
color_scheme_set(&quot;brightblue&quot;)
dpo_root &lt;- ppc_rootogram(dat$Y, Yrep_dpo, style = &quot;hanging&quot;) + labs(title = &quot;Double Poisson&quot;)
color_scheme_set(&quot;green&quot;)
gpo_root &lt;- ppc_rootogram(dat$Y, Yrep_gpo, style = &quot;hanging&quot;) + labs(title = &quot;Generalized Poisson&quot;)

Poisson_root / negbin_root / dpo_root / gpo_root &amp;
  theme_minimal()</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/ppd-1.png" width="672" />
You can see from these that the Poisson and negative-binomial models expect more low-frequency counts than are present in the observed data. However, the figure doesn’t really capture the degree of mis-fit that is apparent with the dispersion summary statistics. I think this is because the distribution of <span class="math inline">\(Y\)</span> changes so much depending on the value of the predictor <span class="math inline">\(X\)</span>.</p>
</div>
<div id="posterior-predictive-residual-densities" class="section level2">
<h2>Posterior predictive residual densities</h2>
<p>One way to focus in on the distributional assumption is to examine the distribution of residuals rather than raw outcomes. I’ll do that here by looking the deviance residuals from the quasi-Poisson GLM model, treating the calculation of the residuals as merely as transformation of the raw data. Here are some posterior predictive density plots of these deviance residuals:</p>
<pre class="r"><code># quasi-Poisson deviance residuals
dat$resid &lt;- residuals(quasi_fit)

# function to calculate quasi-Poisson deviance residuals
quasi_residuals &lt;- function(y) as.numeric(residuals(glm(y ~ dat$X, family = quasipoisson(link = &quot;log&quot;))))

# transform posterior predictive data into residuals
R &lt;- 50
resid_Poisson &lt;- apply(Yrep_Poisson[1:R,], 1, quasi_residuals) |&gt; t()
resid_negbin &lt;- apply(Yrep_negbin[1:R,], 1, quasi_residuals) |&gt; t()
resid_dpo &lt;- apply(Yrep_dpo[1:R,], 1, quasi_residuals) |&gt; t()
resid_gpo &lt;- apply(Yrep_gpo[1:R,], 1, quasi_residuals) |&gt; t()

# make density plots
color_scheme_set(&quot;blue&quot;)
Poisson_resid_density &lt;- ppc_dens_overlay(dat$resid, resid_Poisson) + labs(title = &quot;Poisson&quot;)

color_scheme_set(&quot;purple&quot;)
negbin_resid_density &lt;- ppc_dens_overlay(dat$resid, resid_negbin) + labs(title = &quot;Negative-binomial&quot;)

color_scheme_set(&quot;brightblue&quot;)
dpo_resid_density &lt;- ppc_dens_overlay(dat$resid, resid_dpo) + labs(title = &quot;Double Poisson&quot;)

color_scheme_set(&quot;green&quot;)
gpo_resid_density &lt;- ppc_dens_overlay(dat$resid, resid_gpo) + labs(title = &quot;Generalized Poisson&quot;)

Poisson_resid_density / negbin_resid_density / dpo_resid_density / gpo_resid_density &amp;
  theme_minimal() &amp; 
  xlim(c(-3, 3))</code></pre>
<p><img src="/post/Generalized-Poisson-and-Double-Poisson_files/figure-html/ppd-residuals-1.png" width="576" /></p>
<p>It’s quite a bit clearer from these plots that the DPO and GPO models are closer to replicating the distribution of the data than are the Poisson or negative binomial models.</p>
</div>
<div id="a-fancy-hierarchical-model" class="section level2">
<h2>A fancy hierarchical model</h2>
<p>The research project for which we need these distributions involves models that are quite a bit more involved than the simple GLM that I simulated above. We’re especially interested in hierarchical models that allow for cluster-level heterogeneity in both the mean and the dispersion parameter of the distribution. These models go under the heading of generalized additive models for location, scale, and shape (GAMLSS) and have been developed in the likelihood framework with the <a href="https://www.gamlss.com/">gamlss package</a> and in the Bayesian framework with the [bamlss package].</p>
<p>I’ll test out my generalized Poisson implementation by simulating data from a model that has random variation in the means and in the variances. The data-generating process is as follows:
<span class="math display">\[
\begin{aligned}
N_j &amp;\sim 1 + Pois(15) \\
\ln \mu_j &amp;\sim N(3.5, \ 1) \\
\ln \phi_j &amp;\sim N(0.15, \ 0.15) \\
Y_{ij} &amp;\sim GPO(\mu_j, \phi_j) \quad \text{for} \quad i = 1,...,N_j
\end{aligned}
\]</span></p>
<p>all for <span class="math inline">\(j = 1,...,J\)</span>. The specified distribution of <span class="math inline">\(\phi_j\)</span>’s leads to dispersions ranging from about 0.61 to 1.21, with a median of 0.86 and and IQR of 0.77 to 0.95.</p>
<p>Here’s a simulation from the model with <span class="math inline">\(J = 80\)</span>:</p>
<pre class="r"><code>set.seed(20231205)
J &lt;- 80

dat &lt;- 
  tibble(
    ID = 1:J, 
    N = 1L + rpois(J, lambda = 15), 
    log_mu = rnorm(J, mean = 3.5, sd = 1), 
    log_phi = rnorm(J, mean = 0.15, sd = 0.15)
  ) %&gt;%
  mutate(
    Y = pmap(list(N = N, mu = exp(log_mu), phi = exp(log_phi)), gpo_rng_sampler)
  ) %&gt;%
  unnest(Y)</code></pre>
<p>Now let me try fitting some models. I’ll first try fitting some GLMMs, which include random intercepts on the mean term but not on the dispersions. Just for kicks, I’ll use both the generalized Poisson (i.e., the true distribution) and the double Poisson (which is mis-specified).</p>
<pre class="r"><code># Fit GPO model with mean random effects
glmm_gpo &lt;- brm(
  Y ~ 1 + (1 | ID),
  data = dat,
  family = generalized_Poisson,
  stanvars = generalized_Poisson_stanvars,
  prior = phi_prior,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4,
  control = list(adapt_delta = 0.80)
)

summary(glmm_gpo)</code></pre>
<pre><code>##  Family: gpo 
##   Links: mu = log; phi = identity 
## Formula: Y ~ 1 + (1 | ID) 
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.05      0.09     0.89     1.25 1.05       79      215
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     3.32      0.12     3.08     3.57 1.10       57      149
## 
## Family Specific Parameters: 
##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## phi     1.14      0.05     1.05     1.24 1.00     2638     3744
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># Fit DPO model with mean random effects
glmm_dpo &lt;- brm(
  Y ~ 1 + (1 | ID),
  data = dat,
  family = double_Poisson,
  stanvars = double_Poisson_stanvars,
  prior = phi_prior,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4,
  control = list(adapt_delta = 0.80)
)

summary(glmm_dpo)</code></pre>
<pre><code>##  Family: dpo 
##   Links: mu = log; phi = identity 
## Formula: Y ~ 1 + (1 | ID) 
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.03      0.09     0.90     1.24 1.02      214      295
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     3.33      0.13     3.11     3.58 1.06       66      203
## 
## Family Specific Parameters: 
##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## phi     1.11      0.05     1.02     1.21 1.00     2895     4498
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>I’ll now fit the actual data-generating model, which has random dispersion terms in addition to the random intercepts on the mean. I’ll also try out the same model specification, but with the double Poisson distribution:</p>
<pre class="r"><code># Fit GPO model with mean and dispersion random effects
gamlss_gpo &lt;- brm(
  bf(
    Y ~ 1 + (1 | a | ID),
    phi ~ 1 + (1 | a | ID)
  ),
  data = dat,
  family = generalized_Poisson,
  stanvars = generalized_Poisson_stanvars,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4
)

summary(gamlss_gpo)</code></pre>
<pre><code>##  Family: gpo 
##   Links: mu = log; phi = log 
## Formula: Y ~ 1 + (1 | a | ID) 
##          phi ~ 1 + (1 | a | ID)
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##                              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)                    2.04      1.72     0.90     5.31 1.61        7
## sd(phi_Intercept)                1.52      2.12     0.16     5.46 1.60        7
## cor(Intercept,phi_Intercept)     0.13      0.51    -0.48     0.96 1.59        7
##                              Tail_ESS
## sd(Intercept)                      11
## sd(phi_Intercept)                  11
## cor(Intercept,phi_Intercept)       11
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept         2.88      0.75     1.60     3.51 1.61        7       19
## phi_Intercept    -0.27      0.75    -1.57     0.27 1.59        7       11
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># Fit DPO model with mean and dispersion random effects
gamlss_dpo &lt;- brm(
  bf(
    Y ~ 1 + (1 | a | ID),
    phi ~ 1 + (1 | a | ID)
  ),
  data = dat,
  family = double_Poisson,
  stanvars = double_Poisson_stanvars,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4
)

summary(gamlss_dpo)</code></pre>
<pre><code>##  Family: dpo 
##   Links: mu = log; phi = log 
## Formula: Y ~ 1 + (1 | a | ID) 
##          phi ~ 1 + (1 | a | ID)
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##                              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)                    1.06      0.09     0.90     1.24 1.01      489
## sd(phi_Intercept)                0.31      0.07     0.17     0.45 1.00     2530
## cor(Intercept,phi_Intercept)    -0.06      0.17    -0.39     0.28 1.00     6434
##                              Tail_ESS
## sd(Intercept)                     849
## sd(phi_Intercept)                3243
## cor(Intercept,phi_Intercept)     5791
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept         3.32      0.12     3.09     3.57 1.02      191      300
## phi_Intercept     0.15      0.06     0.03     0.26 1.00     5576     6152
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We get some rather odd results. The simpler GLMMs have better fit (as indicated by LOOIC) than the GAMLSS models:</p>
<pre class="r"><code>loo(glmm_gpo, glmm_dpo, gamlss_gpo, gamlss_dpo)</code></pre>
<pre><code>## Output of model &#39;glmm_gpo&#39;:
## 
## Computed from 8000 by 1213 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -3671.2 32.1
## p_loo        78.9  3.5
## looic      7342.3 64.2
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;glmm_dpo&#39;:
## 
## Computed from 8000 by 1213 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -3672.7 31.5
## p_loo        76.9  3.3
## looic      7345.3 63.1
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;gamlss_gpo&#39;:
## 
## Computed from 8000 by 1213 log-likelihood matrix
## 
##              Estimate         SE
## elpd_loo -178472079.4 17043794.6
## p_loo     178468202.3 17043790.9
## looic     356944158.9 34087589.2
## ------
## Monte Carlo SE of elpd_loo is NA.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     700   57.7%   0         
##  (0.5, 0.7]   (ok)         2    0.2%   0         
##    (0.7, 1]   (bad)        1    0.1%   0         
##    (1, Inf)   (very bad) 510   42.0%   0         
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;gamlss_dpo&#39;:
## 
## Computed from 8000 by 1213 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -3663.0 31.5
## p_loo       104.5  5.0
## looic      7326.0 62.9
## ------
## Monte Carlo SE of elpd_loo is 0.2.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     1203  99.2%   1133      
##  (0.5, 0.7]   (ok)         10   0.8%   334       
##    (0.7, 1]   (bad)         0   0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)    0   0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Model comparisons:
##            elpd_diff    se_diff     
## gamlss_dpo          0.0          0.0
## glmm_gpo           -8.2          4.3
## glmm_dpo           -9.7          4.1
## gamlss_gpo -178468416.4   17043790.8</code></pre>
<p>All of the models also estimate some degree of over-dispersion (<span class="math inline">\(\phi &lt; 1\)</span>) on average. Curious.</p>
</div>
</div>
<div id="colophon" class="section level1">
<h1>Colophon</h1>
<pre><code>## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 22621)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] loo_2.5.1           bayesplot_1.10.0    brms_2.18.0        
##  [4] Rcpp_1.0.10         rstan_2.26.23       StanHeaders_2.26.28
##  [7] gamlss.dist_6.0-5   MASS_7.3-58.1       patchwork_1.1.2    
## [10] forcats_0.5.2       stringr_1.5.0       dplyr_1.1.3        
## [13] purrr_1.0.2         readr_2.1.3         tidyr_1.3.0        
## [16] tibble_3.2.1        ggplot2_3.4.3       tidyverse_1.3.2    
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.4.1         backports_1.4.1      RcppEigen_0.3.3.9.2 
##   [4] plyr_1.8.7           igraph_1.3.5         splines_4.2.2       
##   [7] crosstalk_1.2.0      TH.data_1.1-2        rstantools_2.2.0    
##  [10] inline_0.3.19        digest_0.6.31        htmltools_0.5.4     
##  [13] fansi_1.0.4          BH_1.78.0-0          magrittr_2.0.3      
##  [16] checkmate_2.1.0      googlesheets4_1.0.1  tzdb_0.3.0          
##  [19] modelr_0.1.9         RcppParallel_5.1.5   matrixStats_0.63.0  
##  [22] xts_0.12.2           sandwich_3.0-2       timechange_0.2.0    
##  [25] prettyunits_1.1.1    colorspace_2.1-0     rvest_1.0.3         
##  [28] haven_2.5.1          xfun_0.40            callr_3.7.3         
##  [31] crayon_1.5.2         jsonlite_1.8.4       survival_3.4-0      
##  [34] zoo_1.8-12           glue_1.6.2           gtable_0.3.4        
##  [37] gargle_1.3.0         emmeans_1.8.2        distributional_0.3.1
##  [40] pkgbuild_1.4.0       abind_1.4-5          scales_1.2.1        
##  [43] mvtnorm_1.1-3        DBI_1.1.3            miniUI_0.1.1.1      
##  [46] xtable_1.8-4         stats4_4.2.2         DT_0.26             
##  [49] htmlwidgets_1.6.2    httr_1.4.5           threejs_0.3.3       
##  [52] posterior_1.3.1      ellipsis_0.3.2       pkgconfig_2.0.3     
##  [55] farver_2.1.1         sass_0.4.5           dbplyr_2.2.1        
##  [58] utf8_1.2.3           labeling_0.4.3       tidyselect_1.2.0    
##  [61] rlang_1.1.1          reshape2_1.4.4       later_1.3.0         
##  [64] munsell_0.5.0        cellranger_1.1.0     tools_4.2.2         
##  [67] cachem_1.0.6         cli_3.6.1            generics_0.1.3      
##  [70] ggridges_0.5.4       broom_1.0.1          evaluate_0.20       
##  [73] fastmap_1.1.0        yaml_2.3.7           processx_3.7.0      
##  [76] knitr_1.42           fs_1.6.1             nlme_3.1-160        
##  [79] mime_0.12            xml2_1.3.3           compiler_4.2.2      
##  [82] shinythemes_1.2.0    rstudioapi_0.14      reprex_2.0.2        
##  [85] bslib_0.4.2          stringi_1.7.12       highr_0.10          
##  [88] ps_1.7.1             blogdown_1.13        Brobdingnag_1.2-9   
##  [91] lattice_0.20-45      Matrix_1.6-3         markdown_1.8        
##  [94] shinyjs_2.1.0        tensorA_0.36.2       vctrs_0.6.3         
##  [97] pillar_1.9.0         lifecycle_1.0.3      jquerylib_0.1.4     
## [100] bridgesampling_1.1-2 estimability_1.4.1   httpuv_1.6.8        
## [103] QuickJSR_1.0.6       R6_2.5.1             bookdown_0.29       
## [106] promises_1.2.0.1     gridExtra_2.3        codetools_0.2-18    
## [109] colourpicker_1.2.0   gtools_3.9.4         assertthat_0.2.1    
## [112] withr_2.5.0          shinystan_2.6.0      multcomp_1.4-25     
## [115] mgcv_1.8-41          parallel_4.2.2       hms_1.1.2           
## [118] grid_4.2.2           coda_0.19-4          rmarkdown_2.20      
## [121] googledrive_2.0.0    shiny_1.7.2          lubridate_1.9.2     
## [124] base64enc_0.1-3      dygraphs_1.1.1.6</code></pre>
</div>
