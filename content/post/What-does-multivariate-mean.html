---
title: What do meta-analysts mean by 'multivariate' meta-analysis?
authors:
- admin
date: '2020-06-27'
number_sections: false
codefolding_nobutton: false
disable_codefolding: true
draft: true
slug: what-does-multivariate-mean
bibliography: [meta-references.bib]
csl: apa.csl
link-citations: true
categories: []
tags:
  - meta-analysis
  - multivariate
  - dependent effect sizes
header:
  caption: ''
  image: ''
---



<p>If you’ve ever had class with me or attended one of my presentations, you’ve probably heard me grouse about how statisticians are mostly awful about naming things.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> A lot of the terminology in our field is pretty bad and ineloquent. As a leading example, look no further than Rubin and Little’s classification of missing data mechanisms as missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR). Clear as mud, and the last one sounds like something you’d see on a handmade sign with a picture of someone’s pet puppy who wandered off last week.</p>
<p><img src="https://petkey.blob.core.windows.net/resource/images/940000/949000/949340_500W.jpg" /><!-- --></p>
<p>As another example, consider that introductory statistics students always struggle to distinguish between no less than <strong><em>three</em></strong> different concepts that are all called “variance”: population variance, sample variance, and sampling variance.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Unless the instructor also took diction training from the Royal Shakespeare Company, it’s no wonder that a fair number of students are left confused.</p>
<p><img src="/img/Hamlet-z-transform.jpg" />
In this post, I will try to clarify (at least a little bit) another mess of terminology that crops up a lot in my work on meta-analysis: what do we mean when we say a model or method is “multivariate”? In the context of meta-analysis methods, I think there are at least three distinct senses in which this term is used:</p>
<ul>
<li>As an umbrella term for models/methods where there is more than one effect size estimate per study,</li>
<li>As a description for a class of methods within that broad umbrella, where certain aspects of the model are treated as known, or</li>
<li>As a description for a class of models for multivariate effect size estimates, where each effect size estimate from a study falls into one of a set of distinct categories.</li>
</ul>
<p>Let me explain what I mean by each of these.</p>
<div id="multivariate-handwaving" class="section level2">
<h2>Multivariate handwaving</h2>
<p>In the context of meta-analysis, the broadest meaning of “multivariate” is any method used for modeling data that includes more than one effect size estimate in some or all of the included studies. Formally, the term would apply to any model appropriate for a set of <span class="math inline">\(k\)</span> studies, where study <span class="math inline">\(j\)</span> includes <span class="math inline">\(n_j\)</span> effect size estimates, and where the effect size estimates would be denoted <span class="math inline">\(T_{ij}\)</span>, for <span class="math inline">\(i = 1,...,n_j\)</span> and <span class="math inline">\(j = 1,...,k\)</span>.</p>
<p>As it is used here, “multivariate” is really an umbrella term that could encompass a wide variety of methods and models, including multi-level meta-analysis or meta-regression models, multivariate methods in the narrower senses I will describe subsequently, and even robust variance estimation methods. It would also encompass techniques for handling this sort of data structure that aren’t strictly models, such as aggregating effect size estimates to the level of the study or using Harris Cooper’s “shifting unit-of-analysis” method <span class="citation">(Cooper, <a href="#ref-Cooper1998synthesizing" role="doc-biblioref">1998</a>)</span>.
This usage of “multivariate” involves a bit too much hand-waving for my taste (although I’ve been guilty of using the term this way in the past). I think a better, clearer term for this broad class of methods would be to call them methods for <strong><em>meta-analysis of dependent effect sizes</em></strong>.</p>
</div>
<div id="multivariate-sampling-errors" class="section level2">
<h2>Multivariate sampling errors</h2>
<p>Another sense in which “multivariate” is used pertains to a certain class of models for dependent effect sizes. In particular, “multivariate meta-analysis” sometimes means a model where the sampling variances and covariances of the effect size estimates are treated as fully known. Say that each effect size estimate <span class="math inline">\(T_{ij}\)</span> has a corresponding true effect size parameter <span class="math inline">\(\theta_{ij}\)</span>, so that the sampling error is <span class="math inline">\(e_{ij} = T_{ij} - \theta_{ij}\)</span>, or
<span class="math display">\[
T_{ij} = \theta_{ij} + e_{ij}.
\]</span>
Typically, meta-analysis techniques treat the sampling errors as having known variances, <span class="math inline">\(\text{Var}(e_{ij}) = \sigma_{ij}^2\)</span> for known <span class="math inline">\(\sigma_{ij}^2\)</span>.
Here, a multivariate meta-analysis would go a step further and make assumptions that <span class="math inline">\(\text{Cov}(e_{hj}, e_{ij}) = \rho_{hij}\sigma_{hj} \sigma_{ij}\)</span> for <em>known</em> correlations <span class="math inline">\(\rho_{hij}\)</span>, <span class="math inline">\(h,i = 1,...,n_j\)</span> and <span class="math inline">\(j=1,...,k\)</span>.
Typically, the sampling variances and covariances would play into how the model is estimated and how one conducts inference and gets standard errors on things, etc.</p>
<p><span class="citation">Becker (<a href="#ref-Becker2000multivariate" role="doc-biblioref">2000</a>)</span> and <span class="citation">Gleser &amp; Olkin (<a href="#ref-Gleser2009stochastically" role="doc-biblioref">2009</a>)</span> describe a whole slew of different situations where meta-analysts will encounter multiple effect size estimates within a given study, and both provide formulas for the covariances between those effect sizes.
In some situations, these covariances can be calculated just based on primary study sample sizes or other information readily available from study reports.
In other situations (such as when one calculates <a href="/correlations-between-smds/">standardized mean differences for each of several outcomes on a common set of participants</a>), the information needed to calculate covariances might not be available, which is where methods like robust variance estimation come in.
With this meaning of the term, multivariate meta-analysis methods are those that both directly model the dependent effects structure and that treat the sampling covariances as known. They are therefore distinct from methods, such as robust variance estimation, that do not rely on knowing the exact variance-covariance structure of the sampling errors.
In my own work, I find it helpful to be able to draw this distinction, so I rather like this usage of “multivariate.” This will surely irritate some statisticians, though, who prefer the third, stricter meaning of the term.</p>
</div>
<div id="strictly-multivariate-models" class="section level2">
<h2>Strictly multivariate models</h2>
<p>A third meaning of multivariate is to denote a class of models for multivariate data, meaning data where each unit is measured on several dimensions or characteristics. In the meta-analysis context, multivariate effect sizes are ones where, for each included study or sample, we have effect sizes describing outcomes (e.g., treatment effects) on one or more dimensions.
For example, say that we have a bunch of studies examining some sort of educational intervention, and each study reports effect sizes describing the intervention’s impact on a) reading performance, b) social studies achievement, and/or c) language arts achievement. What differentiates this sort of multivariate data from the first, “umbrella” sense of the term is that with strictly multivariate data, no study has more than one effect size within a given dimension. In contrast, meta-analysis of dependent effect sizes deal with data structures that are not necessarily so tidy and organized, such that we might not be able to classify each effect size into one of a finite and exhaustive set of categories.</p>
<p>When working with strictly multivariate data like this, a multivariate meta-analysis (or meta-regression) model would entail estimating average effects (or regression coefficients) <em>for each dimension</em> rather than aggregating across dimensions. This class of models was discussed extensively in an excellent article by <span class="citation">Jackson et al. (<a href="#ref-Jackson2011multivariate" role="doc-biblioref">2011</a>)</span>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> With my example of educational intervention studies, we would estimate average impacts on reading performance, social studies achievement, and language arts achievement. Estimating an overall aggregate effect on academic achievement would make little sense here, because we’d be mixing apples, oranges, and kiwis.</p>
<p>Formally, this sort of data structure and model can be described as follows. As previously, say that we have a set of <span class="math inline">\(k\)</span> studies, where study <span class="math inline">\(j\)</span> has <span class="math inline">\(n_j\)</span> effect sizes, <span class="math inline">\(T_{ij}\)</span>, and correspoding sampling variances <span class="math inline">\(\sigma_{ij}^2\)</span>, both for <span class="math inline">\(i = 1,...,n_j\)</span> and <span class="math inline">\(j = 1,...k\)</span>. Effect size <span class="math inline">\(i\)</span> from study <span class="math inline">\(j\)</span> can be classified into one of <span class="math inline">\(C\)</span> dimensions. Let <span class="math inline">\(d^c_{ij}\)</span> be an indicator for whether effect <span class="math inline">\(i\)</span> falls into dimension <span class="math inline">\(c\)</span>, for <span class="math inline">\(c = 1,...,C\)</span>. With a strictly multivariate structure, there is never more than one effect per category, so <span class="math inline">\(\sum_{i=1}^{n_j} d^c_{ij} \leq 1\)</span> for each <span class="math inline">\(c = 1,...,C\)</span> and <span class="math inline">\(j = 1,...,k\)</span>. A typical multivariate random effects model would then be
<span class="math display">\[
T_{ij} = \sum_{c=1}^C \left(\mu_c + v_{cj}\right) d^c_{ij} + e_{ij},
\]</span>
where <span class="math inline">\(\mu_c\)</span> is the average effect size for category <span class="math inline">\(c\)</span>, <span class="math inline">\(v_{cj}\)</span> is a random effect for category <span class="math inline">\(c\)</span> in study <span class="math inline">\(j\)</span>, and <span class="math inline">\(e_{ij}\)</span> is the sampling error term. The classic assumption about the random effects is that they are dependent within study, so
<span class="math display">\[
\text{Var}(v_{cj}) = \tau^2_c \qquad \text{and} \qquad \text{Cov}(v_{bj}, v_{cj}) = \tau_{bc}
\]</span>
for <span class="math inline">\(b,c = 1,...,C\)</span>. Typically, these sorts of models would also rely on assumptions about the correlations between the sampling errors, just as with the second meaning of multivariate. Thus, to complete the model, we would have <span class="math inline">\(\text{Cov}(e_{hj}, e_{ij}) = \rho_{hij}\sigma_{hj}\sigma_{ij}\)</span> for known <span class="math inline">\(\rho_{hij}\)</span>. In practice, we might want to impose some common structure to the correlations across studies, such as using <span class="math inline">\(\rho_{hij}\)</span>’s that depend on the dimensions being correlated but are common across studies. Formally, we would have
<span class="math display">\[
\rho_{hij} = \sum_{b=1}^C \sum_{c=1}^C d^b_{ij} \ d^c_{ij} \ \rho_{bc}.
\]</span>
Of course, even getting this level of detail about correlations between effect sizes might often be pretty challenging.</p>
<p>In a strictly multivariate meta-regression model, we would also allow the coefficients for each predictor to be specific to each category, so that
<span class="math display">\[
T_{ij} = \sum_{c=1}^C \left(\mathbf{x}_{ij}\boldsymbol\beta_c + v_{cj}\right) d^c_{ij} + e_{ij},
\]</span>
In my example of educational intervention impact studies, say that are interested in whether the effects differ between quasi-experimental studies and true randomized control trials, and whether the effects differ based on the proportion of the sample that was economically disadvantaged. The strictly multivariate model would always involve interacting these predictors with the outcome category. In R’s equation notation, the meta-regression specification would be</p>
<pre class="r"><code>ES ~ 0 + Cat + Cat:RCT + Cat:disadvantaged_pct</code></pre>
<p>In contrast, in a generic meta-regression for dependent effect sizes, we might not include all of the interactions, and instead assume that the associations of the predictors were constant across outcome dimensions, as in</p>
<pre class="r"><code>ES ~ 0 + outcome_cat + RCT + college_pct</code></pre>
<p>In the strict sense of the term, the model without interactions is no longer really a multivariate meta-regression.</p>
</div>
<div id="remarks" class="section level2">
<h2>Remarks</h2>
<p>An interesting property of strict multivariate meta-analysis models is that they involve partial pooling—or “borrowing of strength”—across dimensions <span class="citation">(Riley et al., <a href="#ref-riley_evaluation_2007" role="doc-biblioref">2007</a>, <a href="#ref-riley_multivariate_2017" role="doc-biblioref">2017</a>)</span>. Even though the model has separate coefficients for each dimension, the estimates for a given dimension are influenced by the available effect sizes for <em>all</em> dimensions. For instance, in the meta-analysis of educational intervention studies, the average impact on reading performance outcomes is based in part on the effect size estimates for the social studies and language arts performance. This happens because the model treats all of the dimensions as <em>correlated</em>—through the correlated sampling errors and, potentially, through the correlated random effects structure. <span class="citation">Copas et al. (<a href="#ref-copas_role_2018" role="doc-biblioref">2018</a>)</span> examine how this works and propose a diagnostic plot to understand how it happens in application. <span class="citation">Kirkham et al. (<a href="#ref-kirkham_multivariate_2012" role="doc-biblioref">2012</a>)</span> also show that the borrowing of strength phenomenon can partially mitigate bias from selective outcome reporting. These concepts could be quite relevant even beyond the “strict” multivariate meta-analysis context in which they have been explored. It strikes me that it would be useful to investigate them in the more general context of meta-analysis with dependent effect sizes—that is, multivariate meta-analysis in the first, broadest sense.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-Becker2000multivariate">
<p>Becker, B. J. (2000). Multivariate meta-analysis. In S. D. Brown &amp; H. E. A. Tinsley (Eds.), <em>Handbook of applied multivariate statistics and mathematical modeling</em> (pp. 499–525). Academic Press. <a href="https://doi.org/10.1016/B978-012691360-6/50018-5">https://doi.org/10.1016/B978-012691360-6/50018-5</a></p>
</div>
<div id="ref-Cooper1998synthesizing">
<p>Cooper, H. M. (1998). <em>Synthesizing Research: A Guide for Literature Reviews</em> (3rd ed.). Sage Publications, Inc.</p>
</div>
<div id="ref-copas_role_2018">
<p>Copas, J. B., Jackson, D., White, I. R., &amp; Riley, R. D. (2018). The role of secondary outcomes in multivariate meta-analysis. <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em>, <em>67</em>(5), 1177–1205. <a href="https://doi.org/10.1111/rssc.12274">https://doi.org/10.1111/rssc.12274</a></p>
</div>
<div id="ref-Gleser2009stochastically">
<p>Gleser, L. J., &amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp; J. C. Valentine (Eds.), <em>The handbook of research synthesis and meta-analysis</em> (2nd ed., pp. 357–376). Russell Sage Foundation.</p>
</div>
<div id="ref-Jackson2011multivariate">
<p>Jackson, D., Riley, R. D., &amp; White, I. R. (2011). Multivariate meta-analysis: Potential and promise. <em>Statistics in Medicine</em>. <a href="https://doi.org/10.1002/sim.4172">https://doi.org/10.1002/sim.4172</a></p>
</div>
<div id="ref-kirkham_multivariate_2012">
<p>Kirkham, J. J., Riley, R. D., &amp; Williamson, P. R. (2012). A multivariate meta-analysis approach for reducing the impact of outcome reporting bias in systematic reviews. <em>Statistics in Medicine</em>, <em>31</em>(20), 2179–2195. <a href="https://doi.org/10.1002/sim.5356">https://doi.org/10.1002/sim.5356</a></p>
</div>
<div id="ref-riley_evaluation_2007">
<p>Riley, R. D., Abrams, K. R., Lambert, P. C., Sutton, A. J., &amp; Thompson, J. R. (2007). An evaluation of bivariate random-effects meta-analysis for the joint synthesis of two correlated outcomes. <em>Statistics in Medicine</em>, <em>26</em>(1), 78–97. <a href="https://doi.org/10.1002/sim.2524">https://doi.org/10.1002/sim.2524</a></p>
</div>
<div id="ref-riley_multivariate_2017">
<p>Riley, R. D., Jackson, D., Salanti, G., Burke, D. L., Price, M., Kirkham, J., &amp; White, I. R. (2017). Multivariate and network meta-analysis of multiple outcomes and multiple treatments: Rationale, concepts, and examples. <em>BMJ</em>, j3932. <a href="https://doi.org/10.1136/bmj.j3932">https://doi.org/10.1136/bmj.j3932</a></p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>“Mostly” rather than “uniformly” due to exceptions like Brad Efron (a.k.a. Mr. Bootstrap) and Rob Tibshirani (a.k.a. Mr. Lasso).<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>And then consider the square roots of these quantities, respectively: population standard deviation, sample standard deviation, and <strong><em>standard error</em></strong>. WTF?<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Read this article! It’s essential. And it comes with pages and pages of commentary by other statisticans.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
