---
title: Computing covariance matrices for meta-analysis of dependent effect size estimates
authors:
- admin
date: '2024-05-18'
draft: true
slug: computing-covariance-matrices
categories: []
tags:
  - effect size
  - distribution theory
  - meta-analysis
header:
  caption: ''
  image: ''
---

[A while back](/correlations-between-SMDs/), I wrote up formulas for the sampling covariances between standardized mean differences that are calculated from multi-arm experiments, including experiments with multiple outcomes. Along with the sampling variances of effect size estimates, the covariances are also needed for conducting a meta-analysis of dependent effect size data. However, it's often hard to get all the information you need to actually apply the formulas in practice, and so we end up relying on simplified, rough approximations (and sensitivity analysis) for the covariance terms. A few years after the post above, [I sketched out some functions](/imputing-covariance-matrices-for-multi-variate-meta-analysis/) for building these sort of quick-and-dirty covariance matrices, and eventually added them to the `clubSandwich package` as `impute_covariance_matrix()` and `pattern_covariance_matrix()`. Although they're certainly convenient, and can handle situations where you'd like to assume different correlations for different pairs of outcomes, the covariance matrices you can generate with these functions don't really handle the situation where you've got effect size estimates from multi-arm experiments.

Then a few years ago, Wolfgang Viechtbauer added a function called `vcalc()` to the `metafor` package, which does everything that `impute_covariance_matrix()` and `pattern_covariance_matrix()` can do, but with even more features and nuance. The `vcalc()` doesn't implement the exact formulas for covariances between standardized mean differences, but it does implement a close approximation that also generalizes readily to other effect size metrics. Consequently, I think it's really time to retire (or at least deprecate) the clubSandwich functions. To mark the occasion (and hopefully encourage users of `clubSandwich::impute_covariance_matrix()` to make the switch), I'm going to use this post to demonstrate some of the nice features of `metafor::vcalc()`.

## Multi-arm trials

Here's some made-up datasets from two hypothetical studies, where the first study has three treatment arms and the second has two treatment arms:
```{r}
library(tidyverse)

# Kaplan (2011)

Kaplan_dat <- tibble(
  Condition = c("Business as usual", "Social media diet","Social media encouragement"),
  N = c(36, 49, 72),
  FOMO_Mean = c(39.7, 40.7,48.6),
  FOMO_SD = c(17.2, 13.5, 14.9),
  CESD_Mean = c(10.1, 9.8, 11.2),
  CESD_SD = c(5.7,7.1,8.3)
)

# Pre-process for effect size calculations

Kaplan_long <-
  Kaplan_dat %>%
  pivot_longer(
    FOMO_Mean:CESD_SD, 
    names_to = c("outcome",".value"),
    names_pattern = c("(.+)_(.+)")
  )

Kaplan_BAU <- 
  Kaplan_long %>%
  filter(Condition == "Business as usual") 

Kaplan_ES <-
  Kaplan_long %>%
  filter(Condition != "Business as usual") %>%
  inner_join(Kaplan_BAU, by = "outcome", suffix = c("_T","_C")) %>%
  mutate(study = "Kaplan (2011)")


# Kim & Wollack (2013)
Kim_dat <- tibble(
  Condition = c("Business as usual", "Social media diet"),
  N = c(14, 34),
  FOMO_Mean = c(22.83, 20.22),
  FOMO_SD = c(8.3, 9.7),
  BDI_Mean = c(34.28, 35.55),
  BDI_SD = c(12.1, 13.3)
)

Kim_ES <- 
  Kim_dat %>%
  mutate(
    study = "Kim (2011)",
    arm = c("C","T")
  ) %>%
  pivot_longer(
    FOMO_Mean:BDI_SD, 
    names_to = c("outcome",".value"),
    names_pattern = c("(.+)_(.+)")
  ) %>%
  pivot_wider(
    names_from = arm,
    values_from = c(Condition, N, Mean, SD)
  )
  
```
We can compute effect size estimates[^pooling] and variances from the summary statistics as follows:
```{r}
library(metafor)

ES_dat <-
  bind_rows(Kaplan_ES, Kim_ES) %>%
  escalc(
    data = .,
    measure = "SMD",
    n1i = N_T, n2i = N_C,
    m1i = Mean_T, m2i = Mean_C,
    sd1i = SD_T, sd2i = SD_C
  )

ES_dat
```

[^pooling]: Detail-oriented readers might note that the standardized mean differences calculated here are from multi-arm trials, but the effects are calculated using denominator standard deviations that only pool across pairs of arms, rather than across _all_ arms in the sample. The latter is usually better (because it keeps the scaling of the outcome constant across all the effects from the sample), but I'm too lazy to handle this particular wrinkle right now.

Using `impute_covariance_matrix()` on this dataset will return a set of covariance matrices for each sample, where there is a constant correlation between pairs of effect sizes from the same study (here I use a correlation of 0.7):
```{r}
library(clubSandwich)

V_icm <- with(ES_dat, 
  impute_covariance_matrix(
    vi = vi,
    cluster = study,
    r = 0.7
  )
)

V_icm
lapply(V_icm, cov2cor)
```
That degree of correlation isn't really right---it's too high, for one, and it shouldn't be constant across all three pairs of effects from study 1 because the treatment groups have different sample sizes. In fact, the covariances among these effects can be [calculated based on the available information](/correlations-between-SMDs/), without the need to impute anything. A closer approximation is possible with `vcalc()`. 

To use `vcalc()`, we'll need to provide a bit of additional information about the structure of the arms within each study (in the arguments `grp1` and `grp2`) and the sample sizes of each arm (in the arguments `w1` and `w2`):
```{r}
V_vcalc <- vcalc(
  data = ES_dat,        # dataset
  vi = vi,              # sampling variances
  cluster = study,      # identifier for each unique sample
  obs = outcome,        # identifier for each unique outcome within a study
  grp1 = Condition_T,   # identifier for unique treatment arms
  w1 = N_T,             # effective sample size of each treatment arm
  grp2 = Condition_C,   # identifier for unique contro arms
  w2 = N_C,             # effective sample size of each control arm
  rho = 0.7,            # assumed correlation between outcomes within a study
  sparse = TRUE         # return a sparse matrix
)

# look at the blocks for each sample
V_vcalc_list <- blsplit(V_vcalc, ES_dat$study) 
V_vcalc_list
```
These covariances have smaller correlations between effect sizes for different arms (closer to 0.5 or less):
```{r}
blsplit(V_vcalc, ES_dat$study) |> 
  lapply(cov2cor)
```

What's going on here? The code inside `metafor::vcalc()` contains one of the hairiest messes of `ifelse` statements I've ever encountered, but I think the gist of it is that the covariance terms are calculated differently depending on whether different rows within a cluster share the same `grp1`  or `grp2` identifier. Say that study $j$ has $k_j$ effect sizes, indexed by $i=1,...,k_j$, that the covariance between effects $h$ and $i$ is $V_{hi,j}$, that the weights corresponding to effect $i$ are $\eta_{1ij}$ and $\eta_{2ij}$, and that the group identifiers are $g_{1ij}$ and $g_{2ij}$. Assuming that the set of `grp1` identifiers does not overlap with the set of `grp2` identifiers, then the covariance between effect sizes $h$ and $i$ in study $j$ is taken to be
$$
V_{hi,j} = \left(I(g_{1hj} = g_{1ij}) \sqrt{\frac{\frac{1}{\eta_{1hj}}}{\frac{1}{\eta_{1hj}} + \frac{1}{\eta_{2hj}}} \times \frac{\frac{1}{\eta_{1ij}}}{\frac{1}{\eta_{1ij}} + \frac{1}{\eta_{2ij}}}} + I(g_{2hj} = g_{2ij}) \sqrt{\frac{\frac{1}{\eta_{2hj}}}{\frac{1}{\eta_{2hj}} + \frac{1}{\eta_{2hj}}} \times \frac{\frac{1}{\eta_{1ij}}}{\frac{1}{\eta_{1ij}} + \frac{1}{\eta_{2ij}}}}\right) \times \sqrt{V_{hh,j}  V_{ii,j}}.
$$
For many effect size metrics, the sampling variance has a form like
$V_{ii,j} = \frac{\sigma_{1ij}}{\eta_{1ij}} + \frac{\sigma_{2ij}{\eta_{2ij}}$, and so the covariance formula above will effectively pull off the part of the sampling variance that corresponds to a group shared in common by effect sizes $h$ and $i$, and will end up reducing to the sampling variance when $h = i$. 

The formula for the sampling variance of a standardized mean difference (based on a simple comparison of group means) is 
$$\text{Var}(d_{ij}) \approx V_{ii,j} = \frac{1}{n_{C,ij}} + \frac{1}{n_{T,ij}} + \frac{d_{ij}^2}{2 \nu},$$
where $n_{C,ij}$ and $n_{T,ij}$ are the sample sizes in the two groups being compared and $\nu$ is the degrees of freedom of the denominator standard deviation. This doesn't exactly have the proportional form above, but unless $\nu$ is really small, $V_{ii,j}$ is going to be very close to $\frac{1}{n_{C,ij}} + \frac{1}{n_{T,ij}}$. Taking $\eta_{1,ij} = n_{T,ij}$ and $\eta_{2,ij} = n_{C,ij}$, the covariance formula implemented in `vcalc` ends up giving something quite close to
$$V_{hi,j} \approx \frac{I(g_{2hj} = g_{2ij})}{n_{C,ij}} + \frac{I(g_{1hj} = g_{1ij})}{n_{T,ij}}.$$
Since the covariance formulas I reviewed in my old post are approximations anyways, this further simplification seems pretty much okay. 

Here's a "by-hand" implementation of the covariance formula from my old post:
```{r}
library(dplyr)
V_hand <- 
  A_dat %>% 
  mutate(df = n_T + n_C - 2) %>%
  group_by(sampleID) %>% 
  group_map(~ (diag(1 / .x$n_T) + 1 / .x$n_C + tcrossprod(.x$yi / sqrt(.x$df))) * (1 - 3 / (4 * .x$df - 1))^2)
```
The `vcalc()` approximation gets very close:
```{r}
round(V_hand[[1]] - V_vcalc_list[[1]], 4)
round(V_hand[[2]] - V_vcalc_list[[2]], 4)
```


## Now with multiple outcomes

