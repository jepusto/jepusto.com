<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Presentations &amp; Posters | James E. Pustejovsky</title>
    <link>https://www.jepusto.com/talk/</link>
      <atom:link href="https://www.jepusto.com/talk/index.xml" rel="self" type="application/rss+xml" />
    <description>Presentations &amp; Posters</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2023</copyright><lastBuildDate>Fri, 29 Sep 2023 16:30:00 +0000</lastBuildDate>
    <image>
      <url>https://www.jepusto.com/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Presentations &amp; Posters</title>
      <link>https://www.jepusto.com/talk/</link>
    </image>
    
    <item>
      <title>Discussion of Stabilizing measures to reconcile accuracy and equity in performance measurement</title>
      <link>https://www.jepusto.com/talk/sree-2023-stabilizing-performance-measures-discussion/</link>
      <pubDate>Fri, 29 Sep 2023 16:30:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sree-2023-stabilizing-performance-measures-discussion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Equity-related moderator analysis in syntheses of dependent effect sizes: Conceptual and statistical considerations</title>
      <link>https://www.jepusto.com/talk/sree-2023-equity-related-moderator-analysis/</link>
      <pubDate>Wed, 27 Sep 2023 16:15:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sree-2023-equity-related-moderator-analysis/</guid>
      <description>&lt;h1 id=&#34;backgroundcontext&#34;&gt;Background/Context&lt;/h1&gt;
&lt;p&gt;In meta-analyses examining educational interventions, researchers seek to understand the distribution of intervention impacts, in order to draw generalizations about what works, for whom, and under what conditions. One common way to examine equity implications in such reviews is through moderator analysis, which involves modeling how intervention effect sizes vary depending on the characteristics of primary study participants. For example, one might estimate associations between effect size and the percentage of the primary study participants who were from a rural school, from a low-income family, identified as a specific racial or ethnic group, or designated as an English Language Learner. Such moderator analyses can provide insights about the populations and contexts where an intervention is more or less effective—that is, they can address questions of who benefits and how the effects of an educational intervention are distributed.&lt;/p&gt;
&lt;p&gt;Meta-analyses of educational interventions often include primary studies that report multiple relevant effect size estimates, such for more than one measure of an outcome construct, at multiple time-points, for multiple versions of an intervention, or for different sub-groups of participants. This leads to a data structure where the effects from a given study are correlated, necessitating the use of statistical methods that are appropriate for dependent observations. Methodological research in this area has provided estimation and inference methods that which can handle dependent effect sizes, including multi-level meta-analyses (Van den Noortgate et al., 2013, 2015), robust variance estimation (Hedges et al., 2010), and combinations thereof (Fernández-Castilla et al., 2020; Pustejovsky &amp;amp; Tipton, 2022). However, there has been much less attention to the specific forms of moderator analysis that are of interest in practice.&lt;/p&gt;
&lt;h1 id=&#34;purposeobjectiveresearch-question&#34;&gt;Purpose/Objective/Research Question&lt;/h1&gt;
&lt;p&gt;We aim to identify conceptual and statistical considerations for moderator analysis of equity-related variables in meta-analyses involving dependent effect sizes. Specifically, we distinguish between direct evidence and contextual evidence about equity of impacts and show that the choice of meta-analytic model can be consequential for analyses involving direct evidence. We then examine how meta-analysts currently conduct equity-related moderator analyses, by reviewing completed research synthesis projects funded by the Institute of Education Sciences (IES) over the period of 2002 to 2018. We find that most projects do not distinguish between direct and contextual evidence and use analytic approaches that are inefficient for synthesizing direct evidence.
Conceptual Considerations&lt;/p&gt;
&lt;p&gt;Moderator analyses of equity-related variables can be carried out by regressing effect size estimates on predictors encoding participant characteristics. Consider a synthesis in which some primary studies contribute multiple effect sizes. In this data structure, a predictor might represent a study-level characteristic or one that varies across the effects within a given study. The level of variation is especially salient for analysis of equity-related variables because study-level characteristics and effect-level characteristics represent qualitatively different types of evidence. For study-level predictors, associations with effect size pertain to the study’s context and are not necessarily indicative of individual-level variation in impacts. Thus, interpretation is challenging because studies vary in many ways, with many possible sources of confounding. For effect-level predictors, within-study variation represents direct evidence about individual-level moderation (e.g., a comparison of impacts between low-income and higher-income participants in the same study), unconfounded by study-level characteristics.&lt;/p&gt;
&lt;p&gt;We describe different strategies for separately investing direct and contextual evidence about moderation, including a) decomposing the predictor into study-level average and within-study centered components or b) inclusion of the raw predictor and the study-level average in a meta-regression. Although strategy (a) has been recommended previously in the context of meta-analysis of dependent effects (Tanner-Smith &amp;amp; Tipton, 2014), our presentation makes explicit the connection to equity-related moderator analysis and specifies the data requirements for applying it.&lt;/p&gt;
&lt;h1 id=&#34;statistical-considerations&#34;&gt;Statistical Considerations&lt;/h1&gt;
&lt;p&gt;Meta-regression with dependent effect sizes involves choosing a working model for the dependence structure, which determines the set of weights used for estimating the meta-regression. Several different working models have been proposed, including correlated effects and hierarchical effects models (Hedges et al., 2010), a correlated-and-hierarchical effects model (Pustejovsky &amp;amp; Tipton, 2022) and the multi-level meta-analysis model (Van den Noortgate et al., 2013, 2015). Ad hoc strategies, such as aggregating effects to the study level or ignoring dependence, can also be understood as working models.&lt;/p&gt;
&lt;p&gt;Previous research and guidance about the choice of working model has argued that the choice of working model is fairly inconsequential so long as the working model is roughly similar the true dependence structure (Hedges et al., 2010; Tanner-Smith et al., 2016; Tanner-Smith &amp;amp; Tipton, 2014). In the appendix, we examine the exact weights assigned by a variety of different working models to studies with direct evidence and contextual evidence. Contrary to past guidance, we find that different working models can lead to quite different weighting—particularly for direct evidence (i.e., study mean-centered predictors).&lt;/p&gt;
&lt;h1 id=&#34;current-practice&#34;&gt;Current Practice&lt;/h1&gt;
&lt;p&gt;To understand current practices for analysis of equity-related moderator variables, we reviewed completed meta-analysis projects funded by IES over the period of 2002 to 2018. We identified grants that (a) had journal articles reporting a meta-analysis, (b) were not methodological, and (c) were not training programs. A search of the IES website for project descriptions that included the word “meta-analysis” returned 80 results, of which 25 met inclusion criteria. Table 1 summarizes the approaches to moderator analyses used in these projects. Most projects reported some form of meta-regression analysis, but very few described a centering strategy and only one project used study-mean centering. Notably, the correlated effects and hierarchical effects working models were commonly used, yet these models involve inefficient weighting of direct evidence.&lt;/p&gt;
&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;In light of this review of current practice, the conceptual and statistical considerations that we describe suggest that there is substantial room for improvement in how meta-analysts conduct moderation analysis, particularly for equity-related variables where individual-level variation is of primary interest. Even under this simple—simplistic, even—conception of equity, bringing systematic review and meta-analysis methods to bear to address inequities in the education system will require not only improving analytic practices, but also changing how primary investigations frame questions, collect data, and report findings.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Determining the Timing of Phase Changes: Some Statistical Perspective</title>
      <link>https://www.jepusto.com/talk/wiscc-2023/</link>
      <pubDate>Thu, 18 May 2023 09:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/wiscc-2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Calculating Effect Sizes for Single-Case Research: An Introduction to the SingleCaseES and scdhlm Web Applications and R Packages</title>
      <link>https://www.jepusto.com/talk/small-is-beautiful-2023-workshop/</link>
      <pubDate>Wed, 26 Apr 2023 11:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/small-is-beautiful-2023-workshop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect size measures for single-case research: Conceptual, practical, and statistical considerations</title>
      <link>https://www.jepusto.com/talk/small-is-beautiful-2023-keynote/</link>
      <pubDate>Tue, 25 Apr 2023 08:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/small-is-beautiful-2023-keynote/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Empirical benchmarks for between-case standardized mean differences from single-case multiple baseline designs examining academic interventions.</title>
      <link>https://www.jepusto.com/talk/aera-2023-bcsmd-benchmarks/</link>
      <pubDate>Sun, 16 Apr 2023 11:40:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2023-bcsmd-benchmarks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Discussion of ‘Moving from What Works to What Replicates: Promoting the Systematic Replication of Results.’</title>
      <link>https://www.jepusto.com/talk/aera-2023-replication-discussion/</link>
      <pubDate>Sat, 15 Apr 2023 14:50:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2023-replication-discussion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Clustered bootstrapping for selective reporting models in meta-analysis with dependent effects</title>
      <link>https://www.jepusto.com/talk/esmarconf2023-clustered-bootstrap-selection-model/</link>
      <pubDate>Thu, 30 Mar 2023 08:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/esmarconf2023-clustered-bootstrap-selection-model/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A matter of emphasis: Comparison of working models for meta-analysis of dependent effect sizes</title>
      <link>https://www.jepusto.com/talk/srsm-2022-matter-of-emphasis/</link>
      <pubDate>Wed, 20 Jul 2022 14:50:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/srsm-2022-matter-of-emphasis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The state of single case synthesis: Premises, tools, and possibilities</title>
      <link>https://www.jepusto.com/talk/sscc-2022-state-of-scd-synthesis/</link>
      <pubDate>Thu, 19 May 2022 13:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sscc-2022-state-of-scd-synthesis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Selective reporting in meta-analysis of dependent effect size estimates</title>
      <link>https://www.jepusto.com/talk/stanford-qsu-2022-selective-reporting/</link>
      <pubDate>Tue, 08 Feb 2022 18:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/stanford-qsu-2022-selective-reporting/</guid>
      <description>&lt;p&gt;Publication bias and other forms of selective outcome reporting are important threats to the validity of findings from research syntheses—even undermining their special status for informing evidence-based practice and policy guidance. An array of methods have been proposed for detecting selective outcome reporting, but nearly all of the available statistical tests are premised on the assumption that each study contributes a single effect size, which is statistically independent of the other effect sizes in the analysis. In practice, however, it is very common for meta-analyses to include studies that contribute multiple, statistically dependent effect sizes (e.g., effect sizes for multiple, related outcome measures, effect sizes at different follow-up times, or effect sizes from multiple replications based on a common protocol). In this talk, I will review these issues and describe the range of methods that synthesists currently use to examine selective reporting issues under effect size dependence. I then describe a new test for diagnosing selective reporting by comparing the observed number of statistically significant effect sizes to the number expected based on the power of included studies to detect the estimated average effect. This test generalizes the Test of Excess Significance (TES; Ioannidis &amp;amp; Trikalinos, 2007) and is closely related to the score test under a simple version of the Vevea and Hedges (1995) selection model. It uses cluster-robust sandwich estimation methods to handle dependence of effect sizes nested within studies. I report some simulation evidence on the power of this new test relative to existing alternatives and discuss further directions for investigating selective reporting issues in meta-analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Easy, cluster-robust standard errors with the clubSandwich package</title>
      <link>https://www.jepusto.com/talk/oslorug-2022-clubsandwich/</link>
      <pubDate>Thu, 03 Feb 2022 10:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/oslorug-2022-clubsandwich/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Four things every quantitative social scientist should know about meta-analysis</title>
      <link>https://www.jepusto.com/talk/edpsych-colloquium-2021-four-things/</link>
      <pubDate>Mon, 27 Sep 2021 10:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/edpsych-colloquium-2021-four-things/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Synthesis of dependent effect sizes: Robust variance estimation with clubSandwich</title>
      <link>https://www.jepusto.com/talk/oslorug-2021-rve-with-metafor-and-clubsandwich/</link>
      <pubDate>Thu, 02 Sep 2021 10:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/oslorug-2021-rve-with-metafor-and-clubsandwich/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Statistical frontiers for selective reporting and publication bias</title>
      <link>https://www.jepusto.com/talk/sips-2021-statistical-frontiers-for-selective-reporting/</link>
      <pubDate>Wed, 23 Jun 2021 12:30:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sips-2021-statistical-frontiers-for-selective-reporting/</guid>
      <description>&lt;p&gt;This workshop will cover methods to investigate selective reporting in meta-analysis of statistically dependent effect sizes, which are a common feature of systematic reviews in psychology. The workshop is organized into two sections. In the first section, we will describe situations where dependent effect sizes occur and review methods for summarizing findings in the presence of dependent effects. We will then describe methods for creating and interpreting funnel plots, including tests of asymmetry, with dependent effect sizes. In the second section, we will present new statistical sensitivity analyses for publication bias, which perform well in small meta-analyses, those with non-normal or dependent effect sizes, and those with heterogeneity. The sensitivity analyses enable statements such as &amp;ldquo;For publication bias to shift the observed point estimate to the null, &amp;lsquo;significant&amp;rsquo; results would need to be at least 10-fold more likely to be published than negative or &amp;lsquo;non-significant&amp;rsquo; results&amp;rdquo; or &amp;ldquo;no amount of publication bias could explain away the average effect.&amp;rdquo; In both sections, we will demonstrate methods using R code and examples from real meta-analyses.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Synthesis of dependent effect sizes: Versatile models through metafor and clubSandwich</title>
      <link>https://www.jepusto.com/talk/esmarconf2021-rve-with-metafor-and-clubsandwich/</link>
      <pubDate>Thu, 21 Jan 2021 09:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/esmarconf2021-rve-with-metafor-and-clubsandwich/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A generalized excess significance test for selective outcome reporting with dependent effect sizes</title>
      <link>https://www.jepusto.com/talk/srsm-2019-generalized-excess-significance-test/</link>
      <pubDate>Mon, 22 Jul 2019 13:30:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/srsm-2019-generalized-excess-significance-test/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Log response ratio effect sizes: Rationale and methods for single case designs with behavioral outcomes</title>
      <link>https://www.jepusto.com/talk/abai-2019-log-response-ratios/</link>
      <pubDate>Sun, 26 May 2019 17:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/abai-2019-log-response-ratios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evaluating meta-analytic methods to detect outcome reporting bias in the presence of dependent effect sizes</title>
      <link>https://www.jepusto.com/talk/aera-2019-orb-dependence/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2019-orb-dependence/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An examination of measurement procedures and baseline behavioral outcomes in single-case research</title>
      <link>https://www.jepusto.com/talk/aera-2019-outcome-measurement-procedures/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2019-outcome-measurement-procedures/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The impact of response-guided designs on count outcomes in single-case design baselines</title>
      <link>https://www.jepusto.com/talk/aera-2019-response-guided-algorithms/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2019-response-guided-algorithms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small-sample cluster-robust variance estimators for two-stage least squares models</title>
      <link>https://www.jepusto.com/talk/sree-2019-2sls-crve/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sree-2019-2sls-crve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Combining robust variance estimation with models for dependent effect sizes</title>
      <link>https://www.jepusto.com/talk/utaustin-2018-combining-rve-with-models/</link>
      <pubDate>Mon, 01 Oct 2018 12:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/utaustin-2018-combining-rve-with-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Combining robust variance estimation with models for dependent effect sizes</title>
      <link>https://www.jepusto.com/talk/srsm-2018-combining-rve-with-models/</link>
      <pubDate>Wed, 18 Jul 2018 09:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/srsm-2018-combining-rve-with-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meta-analysis of dependent effects: A review and consolidation of methods</title>
      <link>https://www.jepusto.com/talk/aera-2018-dependent-effects/</link>
      <pubDate>Sun, 15 Apr 2018 08:15:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2018-dependent-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meta-analysis of single-case research: A brief and breezy tour</title>
      <link>https://www.jepusto.com/talk/aera-2018-meta-analysis-of-single-case-research/</link>
      <pubDate>Sun, 15 Apr 2018 08:15:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2018-meta-analysis-of-single-case-research/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A gradual effects model for single case designs</title>
      <link>https://www.jepusto.com/talk/ies-2018-gradual-effects-model/</link>
      <pubDate>Wed, 10 Jan 2018 08:15:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/ies-2018-gradual-effects-model/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Randomization inference for single-case experimental designs</title>
      <link>https://www.jepusto.com/talk/ies-2018-randomization-inference/</link>
      <pubDate>Wed, 10 Jan 2018 08:15:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/ies-2018-randomization-inference/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Heteroskedasticity-robust tests in linear regression: A review and evaluation of small-sample corrections</title>
      <link>https://www.jepusto.com/talk/aera-2017-hc-t-tests/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2017-hc-t-tests/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A nonlinear intervention analysis model for treatment reversal single-case designs</title>
      <link>https://www.jepusto.com/talk/aera-2017-intervention-analysis/</link>
      <pubDate>Fri, 28 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2017-intervention-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Using response ratios for meta-analyzing single-case designs with behavioral outcomes</title>
      <link>https://www.jepusto.com/talk/aera-2017-response-ratios/</link>
      <pubDate>Fri, 28 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2017-response-ratios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small sample corrections for use of cluster-robust standard errors in the analysis of school-based experiments</title>
      <link>https://www.jepusto.com/talk/sree-2017-small-sample-corrections/</link>
      <pubDate>Thu, 02 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sree-2017-small-sample-corrections/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect sizes for single-case research</title>
      <link>https://www.jepusto.com/talk/ies-2016-single-case-effect-sizes/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/ies-2016-single-case-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small-sample methods for cluster-robust variance estimation and hypothesis testing in fixed effects models</title>
      <link>https://www.jepusto.com/talk/jsm-2016-small-sample-crve/</link>
      <pubDate>Sun, 31 Jul 2016 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/jsm-2016-small-sample-crve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>When large samples act small: The importance of small-sample adjustments for cluster-robust inference in impact evaluations</title>
      <link>https://www.jepusto.com/talk/air-2016-when-large-samples-act-small/</link>
      <pubDate>Mon, 18 Jul 2016 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/air-2016-when-large-samples-act-small/</guid>
      <description></description>
    </item>
    
    <item>
      <title>When large samples act small: Cluster-robust variance estimation and hypothesis testing with few clusters</title>
      <link>https://www.jepusto.com/talk/prc-2016-when-large-samples-act-small/</link>
      <pubDate>Fri, 19 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/prc-2016-when-large-samples-act-small/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small-sample adjustments for multiple-contrast hypothesis tests of meta-regressions using robust variance estimation</title>
      <link>https://www.jepusto.com/talk/srsm-2015-small-sample-adjustments/</link>
      <pubDate>Wed, 08 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/srsm-2015-small-sample-adjustments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Operational sensitivities of non-overlap effect sizes for single-case experimental designs</title>
      <link>https://www.jepusto.com/talk/aera-2015-operational-sensitivities/</link>
      <pubDate>Sun, 19 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2015-operational-sensitivities/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small-sample adjustments for F-tests using robust variance estimation in meta-regression</title>
      <link>https://www.jepusto.com/talk/aera-2015-small-sample-adjustments/</link>
      <pubDate>Sat, 18 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2015-small-sample-adjustments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Observation procedures and Markov Chain models for estimating the prevalence and incidence of a state behavior</title>
      <link>https://www.jepusto.com/talk/aera-2015-observation-procedures/</link>
      <pubDate>Thu, 16 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2015-observation-procedures/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small-sample adjustments for tests of moderators and model fit using robust variance estimation in meta-regression</title>
      <link>https://www.jepusto.com/talk/sree-2015-small-sample-adjustments/</link>
      <pubDate>Fri, 06 Mar 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sree-2015-small-sample-adjustments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Four methods of analyzing partial interval recording data, with application to single-case research</title>
      <link>https://www.jepusto.com/talk/aera-2014-four-methods-for-pir/</link>
      <pubDate>Fri, 04 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2014-four-methods-for-pir/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Addressing construct invalidity in partial interval recording data</title>
      <link>https://www.jepusto.com/talk/tuesap-2014-construct-invalidity-of-pir/</link>
      <pubDate>Fri, 21 Mar 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/tuesap-2014-construct-invalidity-of-pir/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On internal validity in multiple baseline designs</title>
      <link>https://www.jepusto.com/talk/sree-2014-internal-validity-of-mbd/</link>
      <pubDate>Thu, 06 Mar 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sree-2014-internal-validity-of-mbd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Some Markov models for direct observation of behavior</title>
      <link>https://www.jepusto.com/talk/nu-stats-2013-markov-models-for-direct-observation/</link>
      <pubDate>Wed, 29 May 2013 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/nu-stats-2013-markov-models-for-direct-observation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect sizes and measurement comparability for meta-analysis of single-case research</title>
      <link>https://www.jepusto.com/talk/abai-2013-effect-sizes/</link>
      <pubDate>Tue, 28 May 2013 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/abai-2013-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Observation procedures and Markov chain models for estimating the prevalence and incidence of a behavior</title>
      <link>https://www.jepusto.com/talk/aera-2013-observation-procedures/</link>
      <pubDate>Tue, 30 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/aera-2013-observation-procedures/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Operationally comparable effect sizes for meta-analysis of single-case research</title>
      <link>https://www.jepusto.com/talk/sree-2013-operationally-comparable-effect-sizes/</link>
      <pubDate>Thu, 07 Mar 2013 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/sree-2013-operationally-comparable-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Some implications of behavioral observation procedures for meta-analysis of single-case research</title>
      <link>https://www.jepusto.com/talk/ut-austin-2012-meta-analysis-of-single-case-research/</link>
      <pubDate>Wed, 14 Nov 2012 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/ut-austin-2012-meta-analysis-of-single-case-research/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Question-order effects in social network name generators</title>
      <link>https://www.jepusto.com/talk/issna-2008-question-order-effects/</link>
      <pubDate>Wed, 23 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/talk/issna-2008-question-order-effects/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
