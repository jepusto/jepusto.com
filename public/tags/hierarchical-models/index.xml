<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hierarchical models | James E. Pustejovsky</title>
    <link>/tags/hierarchical-models/</link>
      <atom:link href="/tags/hierarchical-models/index.xml" rel="self" type="application/rss+xml" />
    <description>hierarchical models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2021</copyright><lastBuildDate>Sat, 20 Nov 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>hierarchical models</title>
      <link>/tags/hierarchical-models/</link>
    </image>
    
    <item>
      <title>Variance component estimates in meta-analysis with mis-specified sampling correlation</title>
      <link>/variance-components-with-misspecified-correlation/</link>
      <pubDate>Sat, 20 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/variance-components-with-misspecified-correlation/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In a recent paper with Beth Tipton, we proposed &lt;a href=&#34;/publication/rve-meta-analysis-expanding-the-range/&#34;&gt;new working models&lt;/a&gt; for meta-analyses involving dependent effect sizes. The central idea of our approach is to use a working model that captures the main features of the effect size data, such as by allowing for both between- and within-study heterogeneity in the true effect sizes (rather than only between-study heterogeneity). Doing so will lead to more precise estimates of overall average effects or, in models that include predictor variables, more precise estimates of meta-regression coefficients. Further, one can combine this working model with robust variance estimation methods to provide protection against the possibility that some of the model’s assumptions could be mis-specified.&lt;/p&gt;
&lt;p&gt;In order to estimate these new working models, the analyst must first make some assumption about the degree of correlation between effect size estimates that come from the same sample. In typical applications, it can be difficult to obtain good empirical information about the correlation between effect size estimates, and so it is common to impose some simplifying assumptions and use rough guesses about the degree of correlation. There’s a sense that this might not matter much—particularly because robust variance estimation should protect the inferences if the assumptions about the correlation are wrong. However, I still wonder about the extent to which these assumptions about the correlation structure matter for anything.&lt;/p&gt;
&lt;p&gt;There’s a few reasons to wonder about how much the correlation matters. One is that the analyst might actually care about the variance component estimates from the working model, if they’re substantively interested in the extent of heterogeneity or if they’re trying to make predictions about the distribution of effect sizes that could be expected in a new study. Compared to earlier working models, the variance component estimates of the models that we proposed in the paper seem to be relatively more sensitive to the assumed correlation. Second, one alternative analytic strategy that’s been proposed (and applied) for meta-analysis of dependent effect sizes is to use a multi-level meta-analysis (MLMA) model. The MLMA is a special case of the correlated-and-hierarchical effects model that we described in the paper, the main difference being that MLMA &lt;em&gt;ignores&lt;/em&gt; the possibility of correlation between effect size estimates, or equivalently, assumes that the correlation is zero. Thus, MLMA is one specific way that this correlation assumption might be mis-specified. There’s some simulation evidence that inferences based on MLMA may be robust (even without using robust variance estimation), but it’s not clear how general this robustness property might be.&lt;/p&gt;
&lt;p&gt;In this post, I’m going to look at the implications of using a mis-specified assumption about the sampling correlation for the variance components in the correlated-and-hierarchical effects working model. As in &lt;a href=&#34;/weighting-in-multivariate-meta-analysis/&#34;&gt;my previous post on weights in multivariate meta-analysis&lt;/a&gt;, I’m going to mostly limit consideration to the simple (but important!) case of an intercept-only model, without any further predictors of effect size, to see what can be learned about how the variance components can go wrong.&lt;/p&gt;
&lt;div id=&#34;the-correlated-and-hierarchical-effects-che-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The correlated-and-hierarchical effects (CHE) model&lt;/h1&gt;
&lt;p&gt;Consider a meta-analytic dataset with effect size estimates &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,k_j\)&lt;/span&gt; indexes effect size estimates within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes studies, for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;. Say that effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; has sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{ij}\)&lt;/span&gt;, and there is some sampling correlation between effect sizes &lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, denoted &lt;span class=&#34;math inline&#34;&gt;\(\phi_{hij}\)&lt;/span&gt;.
The correlated-and-hierarchical effects (or CHE) model describes the distribution of effect sizes using random effects to capture between-study heterogeneity (as in the basic random effects model) and within-study heterogeneity in true effect sizes. In hierarchical notation, the model is
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
T_{ij} &amp;amp;= \theta_j + \nu_{ij} + e_{ij} \\
\theta_j &amp;amp;= \mu + \eta_j
\end{align}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\Var(e_{ij}) = \sigma^2_{ij}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\Var(\nu_{ij}) = \omega^2\)&lt;/span&gt; is the within-study variance, and &lt;span class=&#34;math inline&#34;&gt;\(\Var(\eta_j) = \tau^2\)&lt;/span&gt; is the between-study variance.
To simplify things, let us also assume that the effect size estimates from a given study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; all have equal sampling variance, so &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{1j} = \sigma^2_{2j} = \cdots = \sigma^2_{k_jj} = \sigma^2_j\)&lt;/span&gt;, and that there is a common correlation between any pair of effect size estimates from the same study, so &lt;span class=&#34;math inline&#34;&gt;\(\Cov(e_{hj}, e_{ij}) = \phi \sigma^2_j\)&lt;/span&gt; for some correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Typically, the analyst would estimate this working model using restricted maximum likelihood (REML) estimation to obtain estimates of the variance components &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;, after specifying a value of &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. With an adequately large sample of studies, the REML estimators should be close-to-unbiased and accurate. But what if the assumed correlation is wrong? Let’s suppose that the analyst estimates (via REML) the CHE working model but uses the assumption that there is a common correlation between effect size estimates of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, which is not necessarily equal to the true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. What are the consequences for estimating &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mis-specified-reml&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mis-specified REML&lt;/h1&gt;
&lt;p&gt;To figure out what’s going on here, we need to know something about how REML estimators behave under mis-specified models. For starters, I’ll work with a more general case than the CHE model described above. Suppose that we have a vector of multi-variate normal outcomes &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, explained by a set of covariates &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt;, and with true variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi_j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_j \ \sim \ N\left( \mathbf{X}_j \beta, \boldsymbol\Phi_j \right)
\]&lt;/span&gt;
However, suppose that we posit a variance structure &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega_j(\boldsymbol\theta)\)&lt;/span&gt;, which is a function of a &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;-dimensional variance component parameter &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt;, and where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi_j\)&lt;/span&gt; is not necessarily conformable to &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega_j(\boldsymbol\theta)\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; denote the full vector of outcomes and the full (stacked) predictor matrix for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega\)&lt;/span&gt; denote the corresponding block-diagonal variance-covariance matrices.&lt;/p&gt;
&lt;p&gt;We estimate &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt; by REML, which maximizes the log likelihood
&lt;span class=&#34;math display&#34;&gt;\[
2 l_R(\boldsymbol\theta) = c -\log \left|\boldsymbol\Omega_j(\boldsymbol\theta)\right| - \log \left|\mathbf{X}&amp;#39; \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X}\right| - \mathbf{T}&amp;#39;\mathbf{Q}(\boldsymbol\theta)\mathbf{T},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Q}(\boldsymbol\theta) = \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) - \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X} \left(\mathbf{X}&amp;#39; \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X}\right)^{-1} \mathbf{X}&amp;#39;\boldsymbol\Omega^{-1}_j(\boldsymbol\theta)\)&lt;/span&gt;. Equivalently, the REML estimators solve the score equations
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial l_R(\boldsymbol\theta)}{\partial \theta_q} = 0, \qquad \text{for} \qquad q = 1,...,v.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Under mis-specification, the REML estimators converge (as &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; increases) to the values that minimize the Kullback-Liebler divergence between the posited model and the true data-generating process. For the restricted likelihood, the Kullback-Liebler divergence is given by
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathcal{KL}(\theta, \theta_0) &amp;amp;= \E\left[l_R(\theta_0) - l_R(\theta)\right] \\
&amp;amp;= c + \log \left| \boldsymbol\Omega(\boldsymbol\theta) \right| + \log \left| \mathbf{X}&amp;#39;\boldsymbol\Omega^{-1}(\boldsymbol\theta) \mathbf{X} \right| + \text{tr}\left(\mathbf{Q}(\boldsymbol\theta) \boldsymbol\Phi\right),
\end{aligned}
\]&lt;/span&gt;
where the expectation in the first line is taken with respect to the true data-generating process and where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; (in the second line) is a constant that does not depend on &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;back-to-che&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Back to CHE&lt;/h1&gt;
&lt;p&gt;Let me now jump back to the special case of the CHE model for a meta-analysis with no predictors. Let &lt;span class=&#34;math inline&#34;&gt;\(\tau_*^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega_*^2\)&lt;/span&gt; denote the variance components in the true data-generating process. Let &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; denote the asymptotic limits of the REML estimators under the mis-specified model. In this model, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j = \mathbf{1}_j\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\boldsymbol\Phi_j &amp;amp;= \left(\tau_*^2 + \phi \sigma_j^2\right) \mathbf{1}_j \mathbf{1}_j&amp;#39; + \left(\omega_*^2 + (1 - \phi) \sigma_j^2\right) \mathbf{I}_j \\
\boldsymbol\Omega_j &amp;amp;= \left(\tilde\tau^2 + \rho \sigma_j^2\right) \mathbf{1}_j \mathbf{1}_j&amp;#39; + \left(\tilde\omega^2 + (1 - \rho) \sigma_j^2\right) \mathbf{I}_j \\
\boldsymbol\Omega_j^{-1} &amp;amp;= \frac{1}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\left[\mathbf{I}_j - \frac{\tilde\tau^2 + \rho \sigma_j^2}{k_j \tilde\tau^2 + k_j \rho \sigma_j^2 + \tilde\omega^2 + (1 - \rho)\sigma_j^2} \mathbf{1}_j \mathbf{1}_j&amp;#39; \right].
\end{aligned}
\]&lt;/span&gt;
Let &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{\tilde{w}_j = \frac{k_j}{k_j \tilde\tau^2 + k_j \rho \sigma_j^2 + \tilde\omega^2 + (1 - \rho)\sigma_j^2}}\)&lt;/span&gt; denote the weight assigned to study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under the mis-specified model, with the total weight denoted as &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{\tilde{W} = \sum_{j=1}^J \tilde{w}_j}\)&lt;/span&gt;. Similarly, let &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{w^*_j = \frac{k_j}{k_j \tau_*^2 + k_j \phi \sigma_j^2 + \omega_*^2 + (1 - \phi)\sigma_j^2}}\)&lt;/span&gt; denote the weight that &lt;em&gt;should&lt;/em&gt; be assigned to study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under the true model, with total &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{W^* = \sum_{j=1}^J w^*_j}\)&lt;/span&gt;. Then we have that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{tr}\left(\mathbf{Q} \boldsymbol\Phi\right) &amp;amp;= \text{tr}\left(\boldsymbol\Omega^{-1} \boldsymbol\Phi\right) - \text{tr}\left[\left(\mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \mathbf{1}\right)^{-1} \mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \boldsymbol\Phi \boldsymbol\Omega^{-1} \mathbf{1}\right] \\
&amp;amp;= \sum_{j=1}^J \text{tr}\left(\boldsymbol\Omega^{-1}_j \boldsymbol\Phi_j\right) - \frac{1}{\tilde{W}}\sum_{j=1}^J \mathbf{1}_j&amp;#39;\boldsymbol\Omega^{-1}_j \boldsymbol\Phi_j \boldsymbol\Omega_j^{-1} \mathbf{1}_j \\
&amp;amp;= \sum_{j=1}^J \frac{k_j}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\left[\tau_*^2 + \omega_*^2 + \sigma_j^2 - \left(\tilde\tau^2 + \rho \sigma_j^2\right) \frac{\tilde{w}_j}{w^*_j}\right] - \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j},
\end{aligned}
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\log \left| \boldsymbol\Omega \right| = \sum_{j=1}^J\log \left| \boldsymbol\Omega_j \right| = \sum_{j=1}^J\left[ \left(k_j - 1\right) \log\left(\tilde\omega^2 + (1 - \rho)\sigma_j^2\right) - \log \left(\frac{\tilde{w}_j}{k_j}\right)\right]
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\log \left|\mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \mathbf{1}\right| = \log \left(\tilde{W}\right),
\]&lt;/span&gt;
It follows that the REML estimators converge to the values &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; that minimize
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathcal{KL}\left(\tilde\tau^2, \tilde\omega^2, \rho, \tau_*^2, \omega_*^2, \phi\right) &amp;amp;= \sum_{j=1}^J \frac{k_j}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\left[\tau_*^2 + \omega_*^2 + \sigma_j^2 - \left(\tilde\tau^2 + \rho \sigma_j^2\right) \frac{\tilde{w}_j}{w^*_j}\right]- \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j} \\
&amp;amp; \qquad \qquad + \sum_{j=1}^J\left(k_j - 1\right) \log\left(\tilde\omega^2 + (1 - \rho)\sigma_j^2\right) - \sum_{j=1}^J \log \left(\frac{\tilde{w}_j}{k_j}\right) + \log(\tilde{W})
\end{aligned}
\]&lt;/span&gt;
This is a complicated non-linear objective function, but it can be minimized numerically using standard techniques.&lt;/p&gt;
&lt;p&gt;Here are some heatmaps of the function for &lt;span class=&#34;math inline&#34;&gt;\(\tau = 0.2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\omega = 0.1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi = 0.4\)&lt;/span&gt;, and some simulated values for &lt;span class=&#34;math inline&#34;&gt;\(k_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j^2\)&lt;/span&gt;, for three different assumed correlations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
set.seed(20211124)

CHE_KL &amp;lt;- function(t, o, tau, omega, phi, rho, k_j, sigmasq_j) {
  
  trs_j &amp;lt;- t^2 + rho * sigmasq_j
  ors_j &amp;lt;- o^2 + (1 - rho) * sigmasq_j
  w_j &amp;lt;- k_j / (k_j * trs_j + ors_j)
  W &amp;lt;- sum(w_j)
  
  tausq_ps_j &amp;lt;- tau^2 + phi * sigmasq_j
  omegasq_ps_j &amp;lt;- omega^2 + (1 - phi) * sigmasq_j
  wj_star &amp;lt;- k_j / (k_j * tausq_ps_j + omegasq_ps_j)
  
  A1 &amp;lt;- sum(k_j * (tausq_ps_j + omegasq_ps_j - trs_j * w_j / wj_star) / ors_j)
  A2 &amp;lt;- sum(w_j^2 / wj_star) / W
  B &amp;lt;- sum((k_j - 1) * log(ors_j) - log(w_j / k_j))
  C &amp;lt;- log(W)
  
  A1 - A2 + B + C
  
}

tau &amp;lt;- 0.2
omega &amp;lt;- 0.1
phi &amp;lt;- 0.4
J &amp;lt;- 20
k_j &amp;lt;- 1 + rpois(J, 5)
sigmasq_j &amp;lt;- 4 / pmax(rgamma(J, 3, scale = 30), 20)


KL_dat &amp;lt;- 
  cross_df(list(t = seq(0,0.4,0.01),
                o = seq(0,0.2,0.005),
                rho = c(0, 0.4, 0.8))) %&amp;gt;%
  mutate(
    KL = pmap_dbl(., .f = CHE_KL, 
                       tau = tau, omega = omega,
                       phi = phi, k_j = k_j, sigmasq_j = sigmasq_j),
    rho = paste(&amp;quot;rho ==&amp;quot;, rho)
  ) %&amp;gt;%
  group_by(rho)

KL_min &amp;lt;- 
  KL_dat %&amp;gt;%
  filter(KL == min(KL))

KL_dat %&amp;gt;%
  mutate(KL = -pmin(0.25, (KL - min(KL)) / (max(KL) - min(KL)))) %&amp;gt;%
ggplot() + 
  facet_wrap(~ rho, scales = &amp;quot;free&amp;quot;, labeller = &amp;quot;label_parsed&amp;quot;) + 
  geom_contour_filled(aes(x = t, y = o, z = KL), bins = 30) + 
  geom_point(x = tau, y = omega, color = &amp;quot;white&amp;quot;, size = 2) + 
  geom_point(data = KL_min, aes(x = t, y = o), color = &amp;quot;red&amp;quot;, size = 2) + 
  theme_minimal() + 
  labs(x = expression(tau), y = expression(omega)) + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Variance-component-estimation-in-misspecified-CHE_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The white points correspond to the true parameter values, while the red points correspond with the values that minimized the K-L divergence. In the middle plot, where &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.4\)&lt;/span&gt; corresponds to the true sampling correlation, the function is minimized at the true values of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;. In the left-hand plot, assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.0\)&lt;/span&gt; leads to an upwardly biased value of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and a downwardly biased value of &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;. In the right-hand plot, assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.8\)&lt;/span&gt; leads to a smaller value of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and a larger value of &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;completely-balanced-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Completely balanced designs&lt;/h2&gt;
&lt;p&gt;The equalities simplify a bit in the special case that the sample of studies is completely balanced, such that &lt;span class=&#34;math inline&#34;&gt;\(k_1 = k_2 = \cdots = k_J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2 = \sigma_2^2 = \cdots = \sigma_J^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Woodbury identity</title>
      <link>/woodbury-identity/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/woodbury-identity/</guid>
      <description>


&lt;p&gt;As in many parts of life, statistics is full of little bits of knowledge that are useful if you happen to know them, but which hardly anybody ever bothers to mention. You would think, if something is so useful, perhaps your professors would spend a fair bit of time explaining it to you. But maybe the stuff seems trivial, obvious, or simple to them, so they don’t bother.&lt;/p&gt;
&lt;p&gt;One example of this is Excel keyboard shortcuts. In a previous life, I was an Excel jockey so I learned all the keyboard shortcuts, such as how to move the cursor to the last cell in a continuous block of entries (&lt;code&gt;ctrl&lt;/code&gt; + an arrow key). Whenever I do this while sharing a screen in a meeting, someone is invariably astounded and wants to know what dark sorcery I’m conjuring. It’s a simple trick, but a useful one—especially if you’re working with a really large dataset with thousands of rows. But it’s also something that there’s no reason to expect anyone to figure out on their own, and that no stats or quant methods professor is going to spend class time demonstrating.&lt;/p&gt;
&lt;p&gt;Let me explain another, slightly more involved example, involving one of my favorite pieces of matrix algebra. There’s a thing called the Woodbury identity, also known as the Sherman-Morrison-Woodbury identity, that is a little life hack for inverting certain types of matrices. It has a &lt;a href=&#34;https://en.wikipedia.org/wiki/Woodbury_matrix_identity&#34;&gt;Wikipedia page&lt;/a&gt;, which I have visited many times. It is a very handy bit of math, if you happen to be a statistics student working with hierarchical models (such as meta-analytic models). I’ll give a statement of the identity, then explain a bit about the connection to hierarchical models.&lt;/p&gt;
&lt;div id=&#34;the-woodbury-identity&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Woodbury identity&lt;/h1&gt;
&lt;p&gt;Say that you’ve got four matrices, an &lt;span class=&#34;math inline&#34;&gt;\(n \times n\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{A}\)&lt;/span&gt;, a &lt;span class=&#34;math inline&#34;&gt;\(k \times k\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{C}\)&lt;/span&gt;, an &lt;span class=&#34;math inline&#34;&gt;\(n \times k\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{U}\)&lt;/span&gt;, and a &lt;span class=&#34;math inline&#34;&gt;\(k \times n\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}\)&lt;/span&gt;. Assume that &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{A}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{C}\)&lt;/span&gt; are invertible. The Woodbury identity tells you how to get the inverse of a certain combination of these matrices:
&lt;span class=&#34;math display&#34;&gt;\[
\left(\mathbf{A} + \mathbf{U} \mathbf{C} \mathbf{V}\right)^{-1} = \mathbf{A}^{-1} - \mathbf{A}^{-1} \mathbf{U} \left(\mathbf{C}^{-1} + \mathbf{V} \mathbf{A}^{-1} \mathbf{U} \right)^{-1} \mathbf{V} \mathbf{A}^{-1}.
\]&lt;/span&gt;
Admit it, you’re impressed. “Dude! Mind. Blown.” you’re probably saying to yourself right now.&lt;/p&gt;
&lt;p&gt;Or perhaps you’re still a touch skeptical that this formula is worth knowing. Let me explain the connection to hierarchical models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hierarchical models&lt;/h1&gt;
&lt;p&gt;Hierarchical linear models are a mainstay of statistical analysis in many, many areas of application, including education research, where we often deal with data collected on individuals (students, teachers) nested within larger aggregate units (like schools). In meta-analysis, these models come up if we’re dealing with samples that have more than one relevant outcome, so that we have multiple effect size estimates nested within a given sample or study.&lt;/p&gt;
&lt;p&gt;Suppose we have a hierarchical structure with &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; clusters, where cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; has &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; individual observations. A quite general way of expressing a hierarchical model for such a data structure is
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{Y}_j = \mathbf{X}_j \boldsymbol\beta + \mathbf{Z}_j \boldsymbol\eta_j + \boldsymbol\epsilon_j,
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, where, for cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times 1\)&lt;/span&gt; vector of outcomes,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times p\)&lt;/span&gt; design matrix for the fixed effects,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(p \times 1\)&lt;/span&gt; vector of fixed effect coefficients,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Z}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times q\)&lt;/span&gt; design matrix for the random effects,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\eta_j\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(q \times 1\)&lt;/span&gt; vector of random effects, and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\epsilon_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times 1\)&lt;/span&gt; vector of level-1 errors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this model, we assume that the random effects have mean zero and unknown variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt;, often assumed to be an unstructured, symmetric and invertible matrix; we assume that the level-1 errors are also mean zero with variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j\)&lt;/span&gt;; and we assume that &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\eta_j\)&lt;/span&gt; is independent of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\epsilon_j\)&lt;/span&gt;. In many instances, we might assume that the entries of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{e}_j\)&lt;/span&gt; are all independent, so &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j\)&lt;/span&gt; will be a multiple of an identity matrix, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j = \sigma^2 \mathbf{I}_j\)&lt;/span&gt;. In other instances (such as models for longitudinal data), &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma\)&lt;/span&gt; might be a patterned matrix that includes off-diagonal terms, such as an auto-regressive structure.&lt;/p&gt;
&lt;p&gt;What is the marginal variance of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_j | \mathbf{X}_j\)&lt;/span&gt; in this model? In other words, if we combine the variance due to the random effects and the variance of the level-1 errors, what do we get? We get
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(\mathbf{Y}_j | \mathbf{X}_j \right) = \mathbf{V}_j = \mathbf{Z}_j \mathbf{T} \mathbf{Z}_j&amp;#39; + \boldsymbol\Sigma_j,
\]&lt;/span&gt;
a matrix that, if you reverse the terms, looks like
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{V}_j = \boldsymbol\Sigma_j + \mathbf{Z}_j \mathbf{T} \mathbf{Z}_j&amp;#39;
\]&lt;/span&gt;
a simple form of the combination of matrices in the left-hand side of the Woodbury identity. Thus, the identity tells us how we can invert this matrix.&lt;/p&gt;
&lt;p&gt;But why would we care about inverting this variance-covariance matrix, you might ask? One good reason is that the fixed effect coefficients in the hierarchical model are estimated by weighted least squares, where the weight matrices are the inverse of an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;. Thus, to understand how the weights in a hierarchical model work, it’s quite useful to be able to invert &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;. Another good (related) reason is that the sampling variance of the fixed effect estimates is approximately
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\boldsymbol{\hat\beta}) \approx \left(\sum_{j=1}^J \mathbf{X}_j&amp;#39;\mathbf{V}_j^{-1} \mathbf{X}_j \right)^{-1}
\]&lt;/span&gt;
(it would be exact if we knew the parameters of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt; with certainty). So if we want to understand the precision of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\hat\beta}\)&lt;/span&gt; or the power of a hypothesis test involving &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\hat\beta}\)&lt;/span&gt;, then we we won’t be able to get very far without inverting &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Directly applying the identity, we get
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{V}_j^{-1} = \boldsymbol\Sigma_j^{-1} - \boldsymbol\Sigma_j^{-1} \mathbf{Z}_j \left(\mathbf{T}^{-1} + \mathbf{Z}_j&amp;#39;\boldsymbol\Sigma_j^{-1}\mathbf{Z}_j \right)^{-1} \mathbf{Z}_j&amp;#39; \boldsymbol\Sigma_j^{-1}
\]&lt;/span&gt;
This expression looks like a bit of a mess, I’ll admit, but it can be useful. Things simplify quite a bit of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j^{-1}\)&lt;/span&gt; has a form that is easy to invert (like a multiple of an identity matrix) and if the dimension of the random effects &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; is small. Under these conditions, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j^{-1}\)&lt;/span&gt; is easy to work with, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}^{-1}\)&lt;/span&gt; is manageable because it has small dimensions, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Z}_j&amp;#39;\boldsymbol\Sigma_j^{-1}\mathbf{Z}_j\)&lt;/span&gt; becomes manageable because it also has small dimensions (&lt;span class=&#34;math inline&#34;&gt;\(q \times q\)&lt;/span&gt;, in both cases).&lt;/p&gt;
&lt;div id=&#34;random-intercepts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Random intercepts&lt;/h2&gt;
&lt;p&gt;As an example, consider a very simple model that includes only random intercepts, so &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Z}_j = \mathbf{1}_j\)&lt;/span&gt;, an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times 1\)&lt;/span&gt; vector with every entry equal to 1, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt; is simply &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, the variance of the random intercepts. For simplicity, let’s also assume that the level-1 errors are independent, so &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j = \sigma^2 \mathbf{I}_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j^{-1} = \sigma^{-2} \mathbf{I}_j\)&lt;/span&gt;. Applying the Woodbury identity,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathbf{V}_j^{-1} &amp;amp;= \boldsymbol\Sigma_j^{-1} - \boldsymbol\Sigma_j^{-1} \mathbf{1}_j \left(\mathbf{T}^{-1} + \mathbf{1}_j&amp;#39;\boldsymbol\Sigma_j^{-1}\mathbf{1}_j \right)^{-1} \mathbf{1}_j&amp;#39; \boldsymbol\Sigma_j^{-1} \\
&amp;amp;= \sigma^{-2} \mathbf{I}_j - \sigma^{-4} \mathbf{1}_j \left(\tau^{-2} + \sigma^{-2} \mathbf{1}_j&amp;#39;\mathbf{1}_j \right)^{-1} \mathbf{1}_j&amp;#39; \\
&amp;amp;= \sigma^{-2} \mathbf{I}_j - \sigma^{-4} \left(\tau^{-2} + \sigma^{-2} n_j \right)^{-1} \mathbf{1}_j \mathbf{1}_j&amp;#39; \\
&amp;amp;= \sigma^{-2} \left(\mathbf{I}_j - \frac{\tau^2} {\sigma^2 + n_j \tau^2} \mathbf{1}_j \mathbf{1}_j&amp;#39;\right).
\end{aligned}
\]&lt;/span&gt;
Try checking this for yourself by carrying through the matrix algebra for &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j \mathbf{V}_j^{-1}\)&lt;/span&gt;, which should come out equal to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{I}_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now suppose that the design matrix is also quite simple, consisting of just an intercept term &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j = \mathbf{1}_j\)&lt;/span&gt;, so that &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta = \beta\)&lt;/span&gt; is simply a population mean. How precise is the estimate of the population mean from this hierarchical model? Well, the sampling variance of the estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta\)&lt;/span&gt; is approximately
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{Var}(\hat\beta) &amp;amp;\approx \left(\sum_{j=1}^J \mathbf{1}_j&amp;#39;\mathbf{V}_j^{-1} \mathbf{1}_j \right)^{-1} \\
&amp;amp;= \left(\sigma^{-2}\sum_{j=1}^J \mathbf{1}_j&amp;#39; \left(\mathbf{I}_j - \frac{\tau^2} {\sigma^2 + n_j \tau^2} \mathbf{1}_j \mathbf{1}_j&amp;#39;\right) \mathbf{1}_j \right)^{-1} \\
&amp;amp;= \left(\sigma^{-2} \sum_{j=1}^J n_j \left(1 - \frac{n_j \tau^2} {\sigma^2 + n_j \tau^2} \right)  \right)^{-1} \\ 
&amp;amp;= \left( \sigma^{-2} \sum_{j=1}^J \frac{n_j \sigma^2} {\sigma^2 + n_j \tau^2} \right)^{-1} \\ 
&amp;amp;= \left(\sum_{j=1}^J \frac{n_j} {\sigma^2 + n_j \tau^2} \right)^{-1} \\
&amp;amp;= \left(\sigma^2 + \tau^2\right) \left(\sum_{j=1}^J \frac{n_j} {1 + (n_j - 1) \rho} \right)^{-1},
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\rho = \tau^2 / (\tau^2 + \sigma^2)\)&lt;/span&gt; is the intra-class correlation. Squint at this expression for a bit and you can see how the ICC influences the varince. If &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is near zero, then the sampling variance will be close to &lt;span class=&#34;math inline&#34;&gt;\(\left(\sigma^2 + \tau^2\right) / N\)&lt;/span&gt;, which is what you would get if you treated every observation as independent. If &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is near 1, then the sampling variance ends up being nearly &lt;span class=&#34;math inline&#34;&gt;\(\left(\sigma^2 + \tau^2\right) / J\)&lt;/span&gt;, which is what you would get if you treated every cluster as a single observation. For intermediate ICCs, the sample size from cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (in the numerator of the fraction inside the summation) gets cut down to size accordingly.&lt;/p&gt;
&lt;p&gt;The estimator of the population mean is a weighted average of the outcomes. Specifically,
&lt;span class=&#34;math display&#34;&gt;\[
\hat\beta = \left(\sum_{j=1}^J \mathbf{1}_j&amp;#39;\mathbf{\hat{V}}_j^{-1} \mathbf{1}_j \right)^{-1} \sum_{j=1}^J \mathbf{1}_j&amp;#39;\mathbf{\hat{V}}_j^{-1} \mathbf{Y}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\hat{V}}_j\)&lt;/span&gt; is an estimator of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;. If you carry through the matrix algebra, you’ll find that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\hat\beta &amp;amp;= \left(\sum_{j=1}^J \frac{n_j} {\sigma^2 + n_j \tau^2} \right)^{-1} \sum_{j=1}^J \frac{\mathbf{1}_j&amp;#39;\mathbf{Y}_j}{\sigma^2 + n_j \tau^2} \\
&amp;amp;= \frac{1}{W} \sum_{j=1}^J \sum_{i=1}^{n_j} w_j y_{ij},
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(w_j = \frac{1}{1 + (n_j - 1) \rho}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{W = \sum_{j=1}^J n_j w_j}\)&lt;/span&gt;. From this, we can see that the weight of a given observation depends on the ICC and the size of the cluster. If the ICC is low, then weights will all be close to 1. For higher ICCs, observations in smaller clusters get proportionately &lt;em&gt;more&lt;/em&gt; weight than observations in larger clusters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-meta-analysis-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A meta-analysis example&lt;/h2&gt;
&lt;p&gt;In a &lt;a href=&#34;/weighting-in-multivariate-meta-analysis/&#34;&gt;previous post&lt;/a&gt; on multi-variate meta-analysis, I examined how weighting works in some multi-variate meta-analysis models, where you have multiple effect size estimates nested within a study. Letting &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; denote effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;. The first model I considered in the previous post was
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \mu + \eta_j + \nu_{ij} + e_{ij},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\nu_{ij}) = \omega^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(e_{ij}) = V_j\)&lt;/span&gt;, treated as known, and &lt;span class=&#34;math inline&#34;&gt;\(\text{cor}(e_{hj}, e_{ij}) = \rho\)&lt;/span&gt; for some specified value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; This model makes the simplifying assumptions that the effect sizes within a given study all have the same sampling variance, &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;, and that there is a single correlation between pairs of outcomes from the same study, that is constant across all pairs of outcomes and across all studies.&lt;/p&gt;
&lt;p&gt;You can write this model in matrix form as
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_j = \mu \mathbf{1}_j + \eta_j \mathbf{1}_j + \boldsymbol\nu_j + \mathbf{e}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\boldsymbol\nu_j) = \omega^2 \mathbf{I}_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{e}_j) = V_j \left[\rho \mathbf{1}_j \mathbf{1}_j&amp;#39; + (1 - \rho) \mathbf{I}_j\right]\)&lt;/span&gt;. It follows that
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\mathbf{T}_j) = (\tau^2 + V_j\rho) \mathbf{1}_j \mathbf{1}_j&amp;#39; + [\omega^2 + V_j (1 - \rho)] \mathbf{I}_j.
\]&lt;/span&gt;
The Woodbury identity comes in handy here again, if we want to examine the weights implied by this model or the sampling variance of the overall average effect size estimator.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; I’ll leave it as an exercise to find an expression for the weight assigned to effect size &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; under this model.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; You could also try finding an expression for the variance of the overall average effect size estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu\)&lt;/span&gt;, based on inverse-variance weighting, when the model is correctly specified.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-meta-analysis-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Another meta-analysis example&lt;/h2&gt;
&lt;p&gt;In the &lt;a href=&#34;/weighting-in-multivariate-meta-analysis/&#34;&gt;previous post&lt;/a&gt;, I also covered weighting in a bit more general model, where the sampling variances and correlations are no longer quite so constrained. As before, we have
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_j = \mu \mathbf{1}_j + \eta_j \mathbf{1}_j + \boldsymbol\nu_j + \mathbf{e}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\boldsymbol\nu_j) = \omega^2 \mathbf{I}_j\)&lt;/span&gt;. But now let &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{e}_j) = \boldsymbol\Sigma_j\)&lt;/span&gt; for some arbitrary, symmetric, invertible matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j\)&lt;/span&gt;. The marginal variance of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_j\)&lt;/span&gt; is therefore
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\mathbf{T}_j) = \tau^2\mathbf{1}_j \mathbf{1}_j&amp;#39; + \omega^2 \mathbf{I}_j + \boldsymbol\Sigma_j.
\]&lt;/span&gt;
Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_j = \left(\omega^2 \mathbf{I}_j + \boldsymbol\Sigma_j\right)^{-1}\)&lt;/span&gt;. Try applying the Woodbury identity to invert &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{T}_j)\)&lt;/span&gt; in terms of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_j\)&lt;/span&gt;. Then see if you can derive the weight assigned to effect &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under this model. See the previous post for the solution.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;This model is what we call the “correlated-and-hierarchical effects model” in my paper (with Beth Tipton) on &lt;a href=&#34;/publication/rve-meta-analysis-expanding-the-range/&#34;&gt;extending working models for robust variance estimation&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Or squint hard at the formula for the variance of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_j\)&lt;/span&gt;, and you’ll see that it has the same form as the random intercepts model in the previous example. Just replace the &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; in that model with &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 + V_j \rho\)&lt;/span&gt; and replace the &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; in that model with &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 + V_j (1 - \rho)\)&lt;/span&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;See the &lt;a href=&#34;/weighting-in-multivariate-meta-analysis/&#34;&gt;previous post&lt;/a&gt; for the answer.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;In the previous post, I expressed the weights in terms of &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt;, the sum of the entries in row &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; of the &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_j\)&lt;/span&gt; matrix. In vector form, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{s}_j = \left(s_{1j} \ s_{2j} \ \cdots \ s_{n_j j}\right)&amp;#39; = \mathbf{S}_j \mathbf{1}_j\)&lt;/span&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Centering categorical predictors in meta-regression</title>
      <link>/centering-categorical-predictors/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/centering-categorical-predictors/</guid>
      <description>


&lt;p&gt;Meta-analyses of dependent effect size estimates involve a hierarchical data structure, where you’ve got multiple independent samples (or experiments or studies, you might call them) and one or more effect size estimates are drawn from each sample.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(fastDummies)
library(clubSandwich)
library(metafor)

tmp &amp;lt;- tempfile(fileext = &amp;quot;.rds&amp;quot;)
download.file(&amp;quot;https://jepusto.com/data/Tanner-Smith-Lipsey-2015-subset.rds&amp;quot;, tmp)

TSL15 &amp;lt;- 
  readRDS(file = tmp) %&amp;gt;%
  # exclude observations missing control variables
  filter(!is.na(percoll), !is.na(attrition_all), !is.na(permale))

# Shorten dv category labels
levels(TSL15$dv_cat) &amp;lt;- c(&amp;quot;freq&amp;quot;,&amp;quot;heavy&amp;quot;,&amp;quot;quantity&amp;quot;,&amp;quot;peak&amp;quot;,&amp;quot;BAC&amp;quot;,&amp;quot;combined&amp;quot;)

# Center control variables

TSL15_cent &amp;lt;- 
  TSL15 %&amp;gt;%
  mutate(
    postwks_c = pmin(postwks, 26) - 12,
    postwks_long = as.numeric(postwks &amp;gt; 26),
    percoll_c = percoll - 1,
    permale_c = permale - 0.5,
    attrition_c = attrition_all - median(attrition_all),
    study_dv = paste(studyid, dv_cat, sep = &amp;quot;-&amp;quot;),
    study_ctype = paste(studyid, Ctype, sep = &amp;quot;-&amp;quot;)
  ) %&amp;gt;%
  # make dummies
  dummy_cols(&amp;quot;dv_cat&amp;quot;) %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  # group center, group means
  mutate(across(starts_with(&amp;quot;dv_cat_&amp;quot;), list(gc = ~ .x - mean(.x), gm = ~ mean(.x)))) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(
    # center group means
    across(matches(&amp;quot;dv_cat_.+_gm&amp;quot;), ~ .x - mean(.x)),
    # add grand means to group-centered
    across(matches(&amp;quot;dv_cat_.+_gc&amp;quot;), ~ .x + mean(.x), .names = &amp;quot;{.col}g&amp;quot;)
  )

# constant sampling correlation assumption
rho &amp;lt;- 0.6

# constant sampling correlation working model
V_mat &amp;lt;- impute_covariance_matrix(TSL15_cent$V, 
                                  cluster = TSL15_cent$studyid, 
                                  r = rho, 
                                  smooth_vi = TRUE)

# fit random effects working model in metafor
dv_multilevel &amp;lt;- rma.mv(yi = es,
                        mods = ~ 0 + dv_cat,
                        V = V_mat, 
                        random = ~ 1 | studyid / esid,
                        data = TSL15_cent, sparse = TRUE)
dv_multilevel

dv_A &amp;lt;- update(dv_multilevel, 
               mods = ~ dv_cat_freq_gc + dv_cat_heavy_gc + dv_cat_quantity_gc + dv_cat_peak_gc + dv_cat_BAC_gc + 
                 dv_cat_freq_gm + dv_cat_heavy_gm + dv_cat_quantity_gm + dv_cat_peak_gm + dv_cat_BAC_gm)
dv_A
Wald_test(dv_A, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE))
Wald_test(dv_A, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE, with_zero = TRUE), tidy = TRUE)

dv_B &amp;lt;- update(dv_multilevel, 
               mods = ~ dv_cat_freq_gc + dv_cat_heavy_gc + dv_cat_quantity_gc + dv_cat_peak_gc + dv_cat_BAC_gc)
dv_B
Wald_test(dv_B, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE))
Wald_test(dv_B, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE, with_zero = TRUE), tidy = TRUE)


dv_C &amp;lt;- update(dv_multilevel, 
               mods = ~ 0 + dv_cat + 
                 dv_cat_freq_gm + dv_cat_heavy_gm + dv_cat_quantity_gm + dv_cat_peak_gm + dv_cat_BAC_gm)

dv_C
Wald_test(dv_C, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_equal(1:6))
Wald_test(dv_C, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(1:6), tidy = TRUE)

dv_D &amp;lt;- rma.mv(yi = es,
               mods = ~ 0 + factor(studyid) + dv_cat,
               V = V_mat, 
               random = ~ 1 | esid,
               data = TSL15_cent, sparse = TRUE)
Wald_test(dv_D, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(&amp;quot;dv_cat&amp;quot;, reg_ex = TRUE))
Wald_test(dv_D, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(&amp;quot;dv_cat&amp;quot;, reg_ex = TRUE, with_zero = TRUE), tidy = TRUE)

coef(dv_A)[2:6]
coef(dv_B)[2:6]
coef(dv_C)[1:5] - coef(dv_C)[6]
coef(dv_D)[118:122]
coef(dv_C)[2:6] - coef(dv_C)[1]&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>lmeInfo</title>
      <link>/software/lmeinfo/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/software/lmeinfo/</guid>
      <description>&lt;p&gt;lmeInfo provides analytic derivatives and information matrices for fitted linear mixed effects models and generalized least squares models estimated using &lt;code&gt;nlme::lme()&lt;/code&gt; and &lt;code&gt;nlme::gls()&lt;/code&gt;, respectively. The package includes functions for estimating the sampling variance-covariance of variance component parameters using the inverse Fisher information. The variance components include the parameters of the random effects structure (for lme models), the variance structure, and the correlation structure. The expected and average forms of the Fisher information matrix are used in the calculations, and models estimated by full maximum likelihood or restricted maximum likelihood are supported. The package also includes a function for estimating standardized mean difference effect sizes (
&lt;a href=&#34;/publication/design-comparable-effect-sizes/&#34;&gt;Pustejovsky et al., 2014&lt;/a&gt;) based on fitted lme or gls models.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R package 
&lt;a href=&#34;https://cran.r-project.org/package=lmeInfo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/lmeInfo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R source code on Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Bug in nlme::lme with fixed sigma and REML estimation</title>
      <link>/bug-in-nlme-with-fixed-sigma/</link>
      <pubDate>Mon, 07 Nov 2016 00:00:00 +0000</pubDate>
      <guid>/bug-in-nlme-with-fixed-sigma/</guid>
      <description>


&lt;p&gt;About one year ago, the &lt;code&gt;nlme&lt;/code&gt; package introduced a feature that allowed the user to specify a fixed value for the residual variance in linear mixed effect models fitted with &lt;code&gt;lme()&lt;/code&gt;. This feature is interesting to me because, when used with the &lt;code&gt;varFixed()&lt;/code&gt; specification for the residual weights, it allows for estimation of a wide variety of meta-analysis models, including basic random effects models, bivariate models for estimating effects by trial arm, and other sorts of multivariate/multi-level random effects models. However, in kicking the tires on this feature, I noticed that the results that it produces are not quite consistent with the results produced by &lt;code&gt;metafor&lt;/code&gt;, which is the main package I use for fitting meta-analytic models.&lt;/p&gt;
&lt;p&gt;In this post, I document several examples of discrepant estimates between &lt;code&gt;lme()&lt;/code&gt; and &lt;code&gt;rma.mv()&lt;/code&gt;, using standard datasets included in the &lt;code&gt;metafor&lt;/code&gt; package. The main take-aways are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The discrepancies arise only with &lt;code&gt;REML&lt;/code&gt; estimation (not with &lt;code&gt;ML&lt;/code&gt; estimation).&lt;/li&gt;
&lt;li&gt;The discrepancies are present whether or not the &lt;code&gt;varFixed&lt;/code&gt; specification is used.&lt;/li&gt;
&lt;li&gt;The discrepancies are mostly small (with minimal impact on the standard errors of the fixed effect estimates), but are larger than I would expect from computational/convergence differences alone.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another example, based on a different dataset, is documented in &lt;a href=&#34;https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16975&#34;&gt;this bug report&lt;/a&gt;. Wolfgang Viechtbauer, author of the &lt;code&gt;metafor&lt;/code&gt; package, identified this problem with &lt;code&gt;lme&lt;/code&gt; a few months ago already (see his responses in &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q2/024862.html&#34;&gt;this thread&lt;/a&gt; on the R mixed models mailing list) and noted that the issue was localized to REML estimation. My thanks to Wolfgang for providing feedback on this post.&lt;/p&gt;
&lt;div id=&#34;basic-random-effects-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Basic random effects model&lt;/h3&gt;
&lt;p&gt;This example fits a basic random effects model to the BCG vaccine data, available within &lt;code&gt;metafor&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
library(nlme)

bcg_example &amp;lt;- function(method = &amp;quot;REML&amp;quot;, constant_var = FALSE) {
  
  data(dat.bcg)
  dat &amp;lt;- escalc(measure=&amp;quot;OR&amp;quot;, ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
  
  v_bar &amp;lt;- mean(dat$vi)
  if (constant_var) dat$vi &amp;lt;- v_bar
  
  # random-effects model using rma.uni()
  LOR_uni_fit &amp;lt;- rma(yi, vi, data=dat, method = method)
  LOR_uni &amp;lt;- with(LOR_uni_fit, 
                  data.frame(f = &amp;quot;rma.uni&amp;quot;, 
                             logLik = logLik(LOR_uni_fit),
                             est = as.numeric(b), 
                             se = se, 
                             tau = sqrt(tau2)))
  
  # random-effects model using rma.mv()
  LOR_mv_fit &amp;lt;- rma.mv(yi, vi, random = ~ 1 | trial, data=dat, method = method)
  LOR_mv &amp;lt;- with(LOR_mv_fit, 
                 data.frame(f = &amp;quot;rma.mv&amp;quot;, 
                            logLik = logLik(LOR_mv_fit),
                            est = as.numeric(b), 
                            se = se, 
                            tau = sqrt(sigma2)))
  
  # random-effects model using lme()
  if (constant_var) {
    LOR_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                       random = ~ 1 | trial,
                       control = lmeControl(sigma = sqrt(v_bar)))
    tau &amp;lt;- sqrt(as.numeric(coef(LOR_lme_fit$modelStruct$reStruct, unconstrained = FALSE)) * v_bar) 
  } else {
    LOR_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                       random = ~ 1 | trial,
                       weights = varFixed(~ vi),
                       control = lmeControl(sigma = 1))
    tau &amp;lt;- sqrt(as.numeric(coef(LOR_lme_fit$modelStruct$reStruct, unconstrained = FALSE)))
  }
  LOR_lme &amp;lt;- data.frame(f = &amp;quot;lme&amp;quot;, 
                        logLik = logLik(LOR_lme_fit),
                        est = as.numeric(fixef(LOR_lme_fit)), 
                        se = as.numeric(sqrt(vcov(LOR_lme_fit))), 
                        tau = tau)
  
  rbind(LOR_uni, LOR_mv, LOR_lme)
  
}

bcg_example(&amp;quot;REML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f    logLik        est        se       tau
## 1 rma.uni -12.57566 -0.7451778 0.1860279 0.5811816
## 2  rma.mv -12.57566 -0.7451778 0.1860280 0.5811818
## 3     lme -13.34043 -0.7471979 0.1916902 0.6030524&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_example(&amp;quot;REML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f    logLik        est        se       tau
## 1 rma.uni -12.96495 -0.7716272 0.1977007 0.5911451
## 2  rma.mv -12.96495 -0.7716272 0.1977007 0.5911452
## 3     lme -15.62846 -0.7716272 0.1899448 0.5571060&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_example(&amp;quot;ML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f    logLik        est        se       tau
## 1 rma.uni -13.07276 -0.7419668 0.1779534 0.5499605
## 2  rma.mv -13.07276 -0.7419669 0.1779534 0.5499608
## 3     lme -13.07276 -0.7419668 0.1779534 0.5499605&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_example(&amp;quot;ML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f     logLik        est        se       tau
## 1 rma.uni -13.525084 -0.7716272 0.1899447 0.5571059
## 2  rma.mv -13.525084 -0.7716272 0.1899447 0.5571059
## 3     lme  -2.479133 -0.7716272 0.1899447 0.5571060&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bi-variate-random-effects-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bi-variate random effects model&lt;/h3&gt;
&lt;p&gt;This example fits a bi-variate random effects model, also to the BCG vaccine data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate &amp;lt;- function(method = &amp;quot;REML&amp;quot;, constant_var = FALSE) {
  data(dat.bcg)
  dat_long &amp;lt;- to.long(measure=&amp;quot;OR&amp;quot;, ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
  levels(dat_long$group) &amp;lt;- c(&amp;quot;exp&amp;quot;, &amp;quot;con&amp;quot;)
  dat_long$group &amp;lt;- relevel(dat_long$group, ref=&amp;quot;con&amp;quot;)
  dat_long &amp;lt;- escalc(measure=&amp;quot;PLO&amp;quot;, xi=out1, mi=out2, data=dat_long)

  v_bar &amp;lt;- mean(dat_long$vi)
  
  if (constant_var) dat_long$vi &amp;lt;- v_bar
  
  # bivariate random-effects model using rma.mv()
  
  bv_rma_fit &amp;lt;- rma.mv(yi, vi, mods = ~ group, 
                       random = ~ group | study, 
                       struct = &amp;quot;UN&amp;quot;, method = method,
                       data=dat_long)
  bv_rma &amp;lt;- with(bv_rma_fit, data.frame(f = &amp;quot;rma.mv&amp;quot;,
                                        logLik = logLik(bv_rma_fit),
                                        tau1 = sqrt(tau2[1]),
                                        tau2 = sqrt(tau2[2])))
  
  # bivariate random-effects model using lme()
  if (constant_var) {
    bv_lme_fit &amp;lt;- lme(yi ~ group, data = dat_long, method = method, 
                      random = ~ group | study,
                      control = lmeControl(sigma = sqrt(v_bar)))
    tau_sq &amp;lt;- colSums(coef(bv_lme_fit$modelStruct$reStruct, unconstrained = FALSE) * matrix(c(1,0,0, 1,2,1), 3, 2)) * v_bar
    
  } else {
    bv_lme_fit &amp;lt;- lme(yi ~ group, data = dat_long, method = method, 
                      random = ~ group | study,
                      weights = varFixed(~ vi),
                      control = lmeControl(sigma = 1))
    
    tau_sq &amp;lt;- colSums(coef(bv_lme_fit$modelStruct$reStruct, unconstrained = FALSE) * matrix(c(1,0,0, 1,2,1), 3, 2))
    
  }
  
  bv_lme &amp;lt;- data.frame(f = &amp;quot;lme&amp;quot;,
                       logLik = logLik(bv_lme_fit),
                       tau1 = sqrt(tau_sq[1]),
                       tau2 = sqrt(tau_sq[2]))
  
  rbind(bv_rma, bv_lme)
  
}

bcg_bivariate(&amp;quot;REML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik     tau1     tau2
## 1 rma.mv -31.50167 1.617807 1.244429
## 2    lme -32.32612 1.631619 1.254437&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate(&amp;quot;REML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik     tau1     tau2
## 1 rma.mv -31.09623 1.644897 1.191679
## 2    lme -37.06035 1.578435 1.142260&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate(&amp;quot;ML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik     tau1     tau2
## 1 rma.mv -33.08793 1.551558 1.196399
## 2    lme -33.08793 1.551558 1.196399&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate(&amp;quot;ML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f     logLik     tau1    tau2
## 1 rma.mv -32.647023 1.578434 1.14226
## 2    lme  -2.237355 1.578434 1.14226&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;three-level-random-effects-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Three-level random-effects model&lt;/h3&gt;
&lt;p&gt;This example fits a three-level random-effects model to the data from Konstantopoulos (2011):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos &amp;lt;- function(method = &amp;quot;REML&amp;quot;, constant_var = FALSE) {
  
  dat &amp;lt;- get(data(dat.konstantopoulos2011))
  v_bar &amp;lt;- mean(dat$vi)
  if (constant_var) dat$vi &amp;lt;- v_bar
  
  # multilevel random-effects model using rma.mv()
  ml_rma_fit &amp;lt;- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat, method = method)
  
  ml_rma &amp;lt;- with(ml_rma_fit, 
                 data.frame(f = &amp;quot;rma.mv&amp;quot;, 
                            logLik = logLik(ml_rma_fit),
                            est = as.numeric(b), 
                            se = se, 
                            tau1 = sqrt(sigma2[1]), 
                            tau2 = sqrt(sigma2[2])))
  
  # multilevel random-effects model using lme()
  if (constant_var) {
    ml_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                      random = ~ 1 | district / school,
                      control = lmeControl(sigma = sqrt(v_bar)))
    tau &amp;lt;- sqrt(as.numeric(coef(ml_lme_fit$modelStruct$reStruct, unconstrained = FALSE)) * v_bar)
    
  } else {
    ml_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                      random = ~ 1 | district / school,
                      weights = varFixed(~ vi),
                      control = lmeControl(sigma = 1))
    tau &amp;lt;- sqrt(as.numeric(coef(ml_lme_fit$modelStruct$reStruct, unconstrained = FALSE)))
    
  }  
  ml_lme &amp;lt;- data.frame(f = &amp;quot;lme&amp;quot;,
                       logLik = logLik(ml_lme_fit),
                       est = as.numeric(fixef(ml_lme_fit)),
                       se = as.numeric(sqrt(diag(vcov(ml_lme_fit)))),
                       tau1 = tau[2],
                       tau2 = tau[1])
  
  rbind(ml_rma, ml_lme)
  
}

Konstantopoulos(&amp;quot;REML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f     logLik       est         se      tau1      tau2
## 1 rma.mv  -7.958724 0.1847132 0.08455592 0.2550724 0.1809324
## 2    lme -10.716781 0.1841827 0.08641374 0.2605790 0.1884588&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos(&amp;quot;REML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f     logLik       est         se      tau1      tau2
## 1 rma.mv  -9.724839 0.1724309 0.08052701 0.2401816 0.1878155
## 2    lme -16.119274 0.1724309 0.07980479 0.2380275 0.1848778&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos(&amp;quot;ML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik       est         se      tau1      tau2
## 1 rma.mv -8.394936 0.1844554 0.08048168 0.2402881 0.1812865
## 2    lme -8.394936 0.1844554 0.08048168 0.2402881 0.1812865&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos(&amp;quot;ML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik       est         se      tau1      tau2
## 1 rma.mv -10.11095 0.1712365 0.07645094 0.2250687 0.1881229
## 2    lme  90.21692 0.1712365 0.07645093 0.2250687 0.1881228&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bug in nlme::getVarCov</title>
      <link>/bug-in-nlme-getvarcov/</link>
      <pubDate>Wed, 10 Aug 2016 00:00:00 +0000</pubDate>
      <guid>/bug-in-nlme-getvarcov/</guid>
      <description>


&lt;p&gt;I have recently been working to ensure that &lt;a href=&#34;https://github.com/jepusto/clubSandwich&#34;&gt;my &lt;code&gt;clubSandwich&lt;/code&gt; package&lt;/a&gt; works correctly on fitted &lt;code&gt;lme&lt;/code&gt; and &lt;code&gt;gls&lt;/code&gt; models from the &lt;code&gt;nlme&lt;/code&gt; package, which is one of the main R packages for fitting hierarchical linear models. In the course of digging around in the guts of &lt;code&gt;nlme&lt;/code&gt;, I noticed a bug in the &lt;code&gt;getVarCov&lt;/code&gt; function. The purpose of the function is to extract the estimated variance-covariance matrix of the errors from a fitted &lt;code&gt;lme&lt;/code&gt; or &lt;code&gt;gls&lt;/code&gt; model.&lt;/p&gt;
&lt;p&gt;It seems that this function is sensitive to the order in which the input data are sorted. &lt;a href=&#34;https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16744&#34;&gt;This bug report&lt;/a&gt; noted the problem, but unfortunately their proposed fix doesn’t seem to solve the problem. In this post I’ll demonstrate the bug and a solution. (I’m posting this here because the R project’s bug reporting system is currently closed to people who were not registered as of early July, evidently due to some sort of spamming problem.)&lt;/p&gt;
&lt;div id=&#34;the-issue&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The issue&lt;/h1&gt;
&lt;p&gt;Here’s a simple demonstration of the problem. I’ll first fit a &lt;code&gt;gls&lt;/code&gt; model with a heteroskedastic variance function and an AR(1) auto-correlation structure (no need to worry about the substance of the specification—we’re just worried about computation here) and then extract the variances for each of the units.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Demonstrate the problem with gls model

library(nlme)
data(Ovary)

gls_raw &amp;lt;- gls(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), data = Ovary,
               correlation = corAR1(form = ~ 1 | Mare),
               weights = varPower())

Mares &amp;lt;- levels(gls_raw$groups)
V_raw &amp;lt;- lapply(Mares, function(g) getVarCov(gls_raw, individual = g))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’ll repeat the process using the same data, but sorted in a different order&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Ovary_sorted &amp;lt;- Ovary[with(Ovary, order(Mare, Time)),]
gls_sorted &amp;lt;- update(gls_raw, data = Ovary_sorted)

V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov(gls_sorted, individual = g))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variance component estimates are essentially equal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(gls_raw$modelStruct, gls_sorted$modelStruct)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the extracted variance-covariance matrices are not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Component 1: Mean relative difference: 0.03256&amp;quot;   
## [2] &amp;quot;Component 3: Mean relative difference: 0.05830791&amp;quot;
## [3] &amp;quot;Component 4: Mean relative difference: 0.1142209&amp;quot; 
## [4] &amp;quot;Component 5: Mean relative difference: 0.03619692&amp;quot;
## [5] &amp;quot;Component 6: Mean relative difference: 0.09260648&amp;quot;
## [6] &amp;quot;Component 8: Mean relative difference: 0.08650327&amp;quot;
## [7] &amp;quot;Component 9: Mean relative difference: 0.07627162&amp;quot;
## [8] &amp;quot;Component 10: Mean relative difference: 0.018103&amp;quot; 
## [9] &amp;quot;Component 11: Mean relative difference: 0.1020658&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the code of the relevant function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nlme:::getVarCov.gls&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## function (obj, individual = 1, ...) 
## {
##     S &amp;lt;- corMatrix(obj$modelStruct$corStruct)[[individual]]
##     if (!is.null(obj$modelStruct$varStruct)) {
##         ind &amp;lt;- obj$groups == individual
##         vw &amp;lt;- 1/varWeights(obj$modelStruct$varStruct)[ind]
##     }
##     else vw &amp;lt;- rep(1, nrow(S))
##     vars &amp;lt;- (obj$sigma * vw)^2
##     result &amp;lt;- t(S * sqrt(vars)) * sqrt(vars)
##     class(result) &amp;lt;- c(&amp;quot;marginal&amp;quot;, &amp;quot;VarCov&amp;quot;)
##     attr(result, &amp;quot;group.levels&amp;quot;) &amp;lt;- names(obj$groups)
##     result
## }
## &amp;lt;bytecode: 0x000000001bc39d00&amp;gt;
## &amp;lt;environment: namespace:nlme&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The issue is in the 4th line of the body. &lt;code&gt;getVarCov.gls&lt;/code&gt; assumes that &lt;code&gt;varWeights(obj$modelStruct$varStruct)&lt;/code&gt; is sorted in the same order as &lt;code&gt;obj$groups&lt;/code&gt;, which is not necessarily true. Instead, &lt;code&gt;varWeights&lt;/code&gt; seem to return the weights sorted according to the grouping variable. For this example, that means that the &lt;code&gt;varWeights&lt;/code&gt; will not depend on the order in which the groups are sorted.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;identical(gls_raw$groups, gls_sorted$groups)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;identical(varWeights(gls_raw$modelStruct$varStruct), 
          varWeights(gls_sorted$modelStruct$varStruct))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fix-for-nlmegetvarcov.gls&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fix for &lt;code&gt;nlme:::getVarCov.gls&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;I think this can be solved by either&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;putting the &lt;code&gt;varWeights&lt;/code&gt; back into the same order as the raw data or&lt;/li&gt;
&lt;li&gt;sorting &lt;code&gt;obj$groups&lt;/code&gt; before identifying the rows corresponding to the specified &lt;code&gt;individual&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s a revised function that takes the second approach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# proposed patch for getVarCov.gls

getVarCov_revised_gls &amp;lt;- function (obj, individual = 1, ...) {
    S &amp;lt;- corMatrix(obj$modelStruct$corStruct)[[individual]]
    if (!is.null(obj$modelStruct$varStruct)) {
        ind &amp;lt;- sort(obj$groups) == individual
        vw &amp;lt;- 1 / varWeights(obj$modelStruct$varStruct)[ind]
    }
    else vw &amp;lt;- rep(1, nrow(S))
    vars &amp;lt;- (obj$sigma * vw)^2
    result &amp;lt;- t(S * sqrt(vars)) * sqrt(vars)
    class(result) &amp;lt;- c(&amp;quot;marginal&amp;quot;, &amp;quot;VarCov&amp;quot;)
    attr(result, &amp;quot;group.levels&amp;quot;) &amp;lt;- names(obj$groups)
    result
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Testing that it works correctly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_raw &amp;lt;- lapply(Mares, function(g) getVarCov_revised_gls(gls_raw, individual = g))
V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov_revised_gls(gls_sorted, individual = g))
all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fix-for-nlmegetvarcov.lme&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fix for &lt;code&gt;nlme:::getVarCov.lme&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The same issue comes up in &lt;code&gt;getVarCov.lme&lt;/code&gt;. Here’s the fix and verification:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# proposed patch for getVarCov.lme

getVarCov_revised_lme &amp;lt;- function (obj, individuals, type = c(&amp;quot;random.effects&amp;quot;, &amp;quot;conditional&amp;quot;, &amp;quot;marginal&amp;quot;), ...) {
    type &amp;lt;- match.arg(type)
    if (any(&amp;quot;nlme&amp;quot; == class(obj))) 
        stop(&amp;quot;not implemented for \&amp;quot;nlme\&amp;quot; objects&amp;quot;)
    if (length(obj$group) &amp;gt; 1) 
        stop(&amp;quot;not implemented for multiple levels of nesting&amp;quot;)
    sigma &amp;lt;- obj$sigma
    D &amp;lt;- as.matrix(obj$modelStruct$reStruct[[1]]) * sigma^2
    if (type == &amp;quot;random.effects&amp;quot;) {
        result &amp;lt;- D
    }
    else {
        result &amp;lt;- list()
        groups &amp;lt;- sort(obj$groups[[1]])
        ugroups &amp;lt;- unique(groups)
        if (missing(individuals)) 
            individuals &amp;lt;- as.matrix(ugroups)[1, ]
        if (is.numeric(individuals)) 
            individuals &amp;lt;- ugroups[individuals]
        for (individ in individuals) {
            indx &amp;lt;- which(individ == ugroups)
            if (!length(indx)) 
                stop(gettextf(&amp;quot;individual %s was not used in the fit&amp;quot;, 
                  sQuote(individ)), domain = NA)
            if (is.na(indx)) 
                stop(gettextf(&amp;quot;individual %s was not used in the fit&amp;quot;, 
                  sQuote(individ)), domain = NA)
            ind &amp;lt;- groups == individ
            if (!is.null(obj$modelStruct$corStruct)) {
                V &amp;lt;- corMatrix(obj$modelStruct$corStruct)[[as.character(individ)]]
            }
            else V &amp;lt;- diag(sum(ind))
            if (!is.null(obj$modelStruct$varStruct)) 
                sds &amp;lt;- 1/varWeights(obj$modelStruct$varStruct)[ind]
            else sds &amp;lt;- rep(1, sum(ind))
            sds &amp;lt;- obj$sigma * sds
            cond.var &amp;lt;- t(V * sds) * sds
            dimnames(cond.var) &amp;lt;- list(1:nrow(cond.var), 1:ncol(cond.var))
            if (type == &amp;quot;conditional&amp;quot;) 
                result[[as.character(individ)]] &amp;lt;- cond.var
            else {
                Z &amp;lt;- model.matrix(obj$modelStruct$reStruc, getData(obj))[ind, 
                  , drop = FALSE]
                result[[as.character(individ)]] &amp;lt;- cond.var + 
                  Z %*% D %*% t(Z)
            }
        }
    }
    class(result) &amp;lt;- c(type, &amp;quot;VarCov&amp;quot;)
    attr(result, &amp;quot;group.levels&amp;quot;) &amp;lt;- names(obj$groups)
    result
}

lme_raw &amp;lt;- lme(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), 
               random = ~ 1 | Mare,
               correlation = corExp(form = ~ Time),
               weights = varPower(),
               data=Ovary)

lme_sorted &amp;lt;- update(lme_raw, data = Ovary_sorted)

all.equal(lme_raw$modelStruct, lme_sorted$modelStruct)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# current getVarCov
V_raw &amp;lt;- lapply(Mares, function(g) getVarCov(lme_raw, individual = g, type = &amp;quot;marginal&amp;quot;))
V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov(lme_sorted, individual = g, type = &amp;quot;marginal&amp;quot;))
all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Component 1: Component 1: Mean relative difference: 0.003989954&amp;quot; 
##  [2] &amp;quot;Component 3: Component 1: Mean relative difference: 0.003784181&amp;quot; 
##  [3] &amp;quot;Component 4: Component 1: Mean relative difference: 0.003028662&amp;quot; 
##  [4] &amp;quot;Component 5: Component 1: Mean relative difference: 0.0005997944&amp;quot;
##  [5] &amp;quot;Component 6: Component 1: Mean relative difference: 0.002350456&amp;quot; 
##  [6] &amp;quot;Component 7: Component 1: Mean relative difference: 0.007103733&amp;quot; 
##  [7] &amp;quot;Component 8: Component 1: Mean relative difference: 0.001887638&amp;quot; 
##  [8] &amp;quot;Component 9: Component 1: Mean relative difference: 0.0009601843&amp;quot;
##  [9] &amp;quot;Component 10: Component 1: Mean relative difference: 0.004748783&amp;quot;
## [10] &amp;quot;Component 11: Component 1: Mean relative difference: 0.001521097&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# revised getVarCov 
V_raw &amp;lt;- lapply(Mares, function(g) getVarCov_revised_lme(lme_raw, individual = g, type = &amp;quot;marginal&amp;quot;))
V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov_revised_lme(lme_sorted, individual = g, type = &amp;quot;marginal&amp;quot;))
all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Session info&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.3 (2020-02-29)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17763)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] nlme_3.1-144
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.4.6    bookdown_0.14   lattice_0.20-38 digest_0.6.25  
##  [5] grid_3.6.3      magrittr_1.5    evaluate_0.14   blogdown_0.18  
##  [9] rlang_0.4.5     stringi_1.4.3   rmarkdown_2.1   tools_3.6.3    
## [13] stringr_1.4.0   xfun_0.12       yaml_2.2.0      compiler_3.6.3 
## [17] htmltools_0.4.0 knitr_1.28&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>scdhlm</title>
      <link>/software/scdhlm/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/software/scdhlm/</guid>
      <description>&lt;p&gt;An R package implementing several methods of estimating a design-comparable standardized mean difference effect size based on data from a single-case design. Methods include those from Hedges, Pustejovsky, &amp;amp; Shadish (
&lt;a href=&#34;/publication/SMD-for-SCD&#34;&gt;2012&lt;/a&gt;, 
&lt;a href=&#34;/publication/SMD-for-MBD&#34;&gt;2013&lt;/a&gt;) and 
&lt;a href=&#34;/publication/design-comparable-effect-sizes/&#34;&gt;Pustejovsky, Hedges, &amp;amp; Shadish (2014)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://CRAN.R-project.org/package=scdhlm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;/getting-started-with-scdhlm&#34;&gt;Installation instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/scdhlm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Source code on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jepusto.shinyapps.io/scdhlm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scdhlm&lt;/a&gt;: An interactive web application for calculating design-comparable standardized mean difference effect sizes.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Design-comparable effect sizes in multiple baseline designs: A general modeling framework</title>
      <link>/publication/design-comparable-effect-sizes/</link>
      <pubDate>Wed, 01 Oct 2014 00:00:00 +0000</pubDate>
      <guid>/publication/design-comparable-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New article: Design-comparable effect sizes in multiple baseline designs: A general modeling framework</title>
      <link>/design-comparable-effect-sizes-in-multiple-baseline-designs/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 +0000</pubDate>
      <guid>/design-comparable-effect-sizes-in-multiple-baseline-designs/</guid>
      <description>


&lt;p&gt;My article with Larry Hedges and Will Shadish, titled “Design-comparable effect sizes in multiple baseline designs: A general modeling framework” has been accepted at Journal of Educational and Behavioral Statistics. The abstract is below. Here’s the article at &lt;a href=&#34;http://doi.org/10.3102/1076998614547577&#34;&gt;the journal website&lt;/a&gt;. &lt;a href=&#34;/files/Effect-sizes-in-multiple-baseline-designs-JEBS.pdf&#34;&gt;Postprint&lt;/a&gt; and &lt;a href=&#34;/files/Effect-sizes-in-multiple-baseline-designs-Simulation-results.pdf&#34;&gt;supporting materials&lt;/a&gt; are available. An R package that implements the proposed methods is &lt;a href=&#34;/getting-started-with-scdhlm/&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In single-case research, the multiple baseline design is a widely used approach for evaluating the effects of interventions on individuals. Multiple baseline designs involve repeated measurement of outcomes over time and the controlled introduction of a treatment at different times for different individuals. This article outlines a general approach for defining effect sizes in multiple baseline designs that are directly comparable to the standardized mean difference from a between-subjects randomized experiment. The target, design-comparable effect size parameter can be estimated using restricted maximum likelihood together with a small-sample correction analogous to Hedges’ g. The approach is demonstrated using hierarchical linear models that include baseline time trends and treatment-by-time interactions. A simulation compares the performance of the proposed estimator to that of an alternative, and an application illustrates the model-fitting process.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing single-case designs: d, G, hierarchical models, Bayesian estimators, generalized additive models, and the hopes and fears of researchers about analyses</title>
      <link>/publication/analyzing-scd-hopes-and-fears/</link>
      <pubDate>Fri, 18 Jul 2014 00:00:00 +0000</pubDate>
      <guid>/publication/analyzing-scd-hopes-and-fears/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Operationally comparable effect sizes for meta-analysis of single-case research</title>
      <link>/publication/operationally-comparable-effect-sizes/</link>
      <pubDate>Sat, 01 Jun 2013 00:00:00 +0000</pubDate>
      <guid>/publication/operationally-comparable-effect-sizes/</guid>
      <description>&lt;p&gt;This thesis studies quantitative methods for summarizing and synthesizing single-case studies, a class of research designs for evaluating the effects of interventions through repeated measurement of individuals. Despite long-standing interest in meta-analytic synthesis of single-case research, there remains a lack of consensus about appropriate methods, even about the most basic question of what effect size metrics are useful and appropriate. I argue that operational comparability, or invariance to heterogeneous operational procedures, is crucial property for an effect size metric. I then consider two problems with operational comparability that arise in single-case research. The first problem is to find effect sizes that can be applied across studies that use different research designs, such as single-case designs and two-group randomized experiments. The second problem is to find effect sizes that can be applied across studies that use varied operations for measuring the same construct. To address each of these problems, I propose structural models that capture essential features of multiple relevant operations (either design-related operations or measurement-related operations). I then use these structural models to precisely define target effect size parameters and to consider identification issues and estimation strategies.&lt;/p&gt;
&lt;p&gt;Chapter 1 defines operational comparability and situates the concept within the broad methodological concerns of meta-analysis, then reviews relevant features of single-case research and previously proposed effect sizes. Chapter 2 describes an abstract set of modeling criteria for constructing design-comparable effect sizes. Chapters 3 applies the general criteria to the case of standardized mean differences and proposes an effect size estimator based on restricted maximum likelihood. Chapter 4 presents several applications of the proposed models and methods. Chapter 5 proposes measurement-comparability model and defines effect size measures for use in studies of free-operant behavior, one of the most common classes of outcomes in single-case research. Chapter 6 extends the proposed effect size models to incorporate more complex features, including time trends and serial dependence, and studies a method of estimating those models through a combination of marginal quasi-likelihood and Gaussian pseudo-likelihood estimating equations. Chapter 7 collects various further extensions, areas for further research, and concluding thoughts.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
