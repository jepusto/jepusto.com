<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayes | James E. Pustejovsky</title>
    <link>https://www.jepusto.com/tags/bayes/</link>
      <atom:link href="https://www.jepusto.com/tags/bayes/index.xml" rel="self" type="application/rss+xml" />
    <description>Bayes</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2023</copyright><lastBuildDate>Wed, 06 Dec 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.jepusto.com/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Bayes</title>
      <link>https://www.jepusto.com/tags/bayes/</link>
    </image>
    
    <item>
      <title>Implementing Consul&#39;s generalized Poisson distribution in Stan</title>
      <link>https://www.jepusto.com/generalized-poisson-in-stan/</link>
      <pubDate>Wed, 06 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/generalized-poisson-in-stan/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a project I am working on, we are using &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; to fit generalized random effects location-scale models to a bunch of count data.
In &lt;a href=&#34;https://www.jepusto.com/double-poisson-in-Stan/&#34;&gt;a previous post&lt;/a&gt;, I walked through our implementation of &lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron’s (1986)&lt;/a&gt; double-Poisson distribution, which we are interested in using because it allows for both over- and under-dispersion relative to the Poisson distribution.
Another distribution with these properties is the generalized Poisson distribution described by &lt;a href=&#34;https://doi.org/10.1080/00401706.1973.10489112&#34;&gt;Consul and Jain (1973)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this post, I’ll walk through my implementation of the GPO in Stan.
The &lt;a href=&#34;https://cran.r-project.org/package=gamlss.dist&#34;&gt;&lt;code&gt;gamlss.dist&lt;/code&gt; package&lt;/a&gt; provides a full set of distributional functions for the generalized Poisson distribution, including a sampler, but the functions are configured to only allow for over-dispersion. Since I’m interested in allowing for under-dispersion as well, I’ll need to write my own functions. As in my previous post, I can validate my Stan functions against the functions from &lt;code&gt;gamlss.dist&lt;/code&gt; (although only for over-dispersion scenarios).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(patchwork)   # composing figures
library(gamlss.dist) # DPO distribution functions
library(rstan)       # Stan interface to R
library(brms)        # fitting generalized linear models
library(bayesplot)   # Examine fitted models
library(loo)         # Model fit measures&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-generalized-poisson&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The generalized Poisson&lt;/h2&gt;
&lt;p&gt;Consul and Jain’s generalized Poisson distribution is a discrete distribution for non-negative counts, with support &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{S}_X = \{0, 1, 2, 3, ...\}\)&lt;/span&gt;.
The mean-variance relationship of the generalized Poisson is constant; for &lt;span class=&#34;math inline&#34;&gt;\(X \sim GPO(\mu, \phi)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{E}(X) = \mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(X) = \mu / \phi\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(0 &amp;lt; \phi &amp;lt; 1\)&lt;/span&gt;; the expectation and variance are not exact but are close approximations when there is underdispersion, so &lt;span class=&#34;math inline&#34;&gt;\(\phi &amp;gt; 1\)&lt;/span&gt;. Thus, like the double-Poisson distribution, the generalized Poisson satisfies the assumptions of a quasi-Poisson generalized linear model (at least approximately).&lt;/p&gt;
&lt;p&gt;The density of the generalized Poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and inverse-disperson &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
f(x | \mu, \phi) = \mu \sqrt{\phi} \left( x + \sqrt{\phi}(\mu - x) \right)^{x-1} \frac{\exp \left[-\left( x + \sqrt{\phi}(\mu - x)\right)\right]}{x!}.
\]&lt;/span&gt;
We then have
&lt;span class=&#34;math display&#34;&gt;\[
\ln f(x | \mu, \phi) = \frac{1}{2} \ln \phi + \ln \mu + (x - 1) \ln \left( x + \sqrt{\phi}(\mu - x) \right) - \left( x + \sqrt{\phi}(\mu - x) \right) - \ln \left(x!\right).
\]&lt;/span&gt;
Using the GPO with under-dispersed data is a little bit more controversial (by statistical standards) than using the DPO.
This is because, for parameter values corresponding to under-dispersion, its probability mass function becomes negative for large counts. In particular, note that for values &lt;span class=&#34;math inline&#34;&gt;\(x &amp;gt; \frac{\mu\sqrt\phi}{\sqrt\phi - 1}\)&lt;/span&gt;, the quantity &lt;span class=&#34;math inline&#34;&gt;\(x + \sqrt{\phi}(\mu - x)\)&lt;/span&gt; becomes negative, and so &lt;span class=&#34;math inline&#34;&gt;\(f(x| \mu, \phi)\)&lt;/span&gt; is no longer a proper probability.
Consul suggested handling this situation by truncating the distribution at &lt;span class=&#34;math inline&#34;&gt;\(m = \left\lfloor \frac{\mu\sqrt\phi}{\sqrt\phi - 1}\right\rfloor\)&lt;/span&gt;. However, doing so makes the distribution only an approximation, such that &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is no longer exactly the mean and &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is no longer exactly the inverse dispersion.
For modest under-dispersion of no less than 60% of the mean, &lt;span class=&#34;math inline&#34;&gt;\(1 &amp;lt; \phi &amp;lt; 5 / 3\)&lt;/span&gt; and the truncation point is fairly extreme, with &lt;span class=&#34;math inline&#34;&gt;\(m \approx 4.4 \mu\)&lt;/span&gt;, so I’m not too worried about this issue.
We’ll see how it plays out in application, of course.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;log-of-the-probability-mass-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Log of the probability mass function&lt;/h1&gt;
&lt;p&gt;Here’s a Stan function implementing the lpmf, with the truncation bit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_lpmf &amp;lt;- &amp;quot;
real gpo_lpmf(int X, real mu, real phi) {
  real ans;
  real m = mu / (1 - inv(sqrt(phi)));
  real z = X + sqrt(phi) * (mu - X);
  if (phi &amp;gt; 1 &amp;amp;&amp;amp; X &amp;gt; m)
    ans = negative_infinity();
  else 
    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);
  return ans;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check that this is accurate, I’ll compare the Stan function to the corresponding function from &lt;code&gt;gamlss.dist&lt;/code&gt; for a couple of different parameter values and for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,100\)&lt;/span&gt;. If my function is accurate, my calculated log-probabilities should be equal to the results from &lt;code&gt;gamlss.dist::dGPO&lt;/code&gt;. Note that the &lt;code&gt;gamlss.dist&lt;/code&gt; function uses a different parameterization for the dispersion, with &lt;span class=&#34;math inline&#34;&gt;\(\sigma = \frac{\phi^{-1/2} - 1}{\mu}\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_lpmf, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;GPO-lpmf.stan&amp;quot;)
expose_stan_functions(&amp;quot;GPO-lpmf.stan&amp;quot;)

test_lpmf &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
    X = 0:100
  ) %&amp;gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    gamlss_lpmf = dGPO(x = X, mu = mu, sigma = sigma, log = TRUE),
    my_lpmf = pmap_dbl(.l = list(X = X, mu = mu, phi = phi), .f = gpo_lpmf),
    diff = my_lpmf - gamlss_lpmf
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_lpmf, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Checks out. Onward!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quantile-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quantile function&lt;/h1&gt;
&lt;p&gt;I’ll next implement the generalized Poisson quantile function, taking advantage of a simple recurrence relationship for sequential values. Note that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(0 | \mu, \phi) &amp;amp;= \exp \left(-\mu \sqrt{\phi}\right) \\
f(x | \mu, \phi) &amp;amp;= f(x - 1 | \mu, \phi) \times \frac{\left(x + \sqrt{\phi}(\mu - x)\right)^{x - 1}}{\left(x - 1 + \sqrt{\phi}(\mu - (x - 1))\right)^{x - 2}} \times \frac{\exp(\sqrt{\phi} - 1)}{x}
\end{aligned}
\]&lt;/span&gt;
where the second expression holds for &lt;span class=&#34;math inline&#34;&gt;\(x \geq 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The function below computes the quantile given a value &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; by computing the cumulative distribution function until &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is exceeded:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_quantile &amp;lt;- &amp;quot; 
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If my quantile function is accurate, it should match the value computed from &lt;code&gt;gamlss.dist::qDPO()&lt;/code&gt; exactly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_quantile, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;GPO-quantile.stan&amp;quot;)
expose_stan_functions(&amp;quot;GPO-quantile.stan&amp;quot;)

test_quantile &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
  ) %&amp;gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    p = map(1:n(), ~ runif(100)),
  ) %&amp;gt;%
  unnest(p) %&amp;gt;%
  mutate(
    my_q = pmap_dbl(list(p = p, mu = mu, phi = phi), .f = gpo_quantile),
    gamlss_q = qGPO(p, mu = mu, sigma = sigma),
    diff = my_q - gamlss_q
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_quantile, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/check-quantile-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I should enter this figure in the competition for the world’s most boring statistical graphic.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sampler&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sampler&lt;/h1&gt;
&lt;p&gt;The last thing I’ll need is a sampler, which I’ll implement by generating random points from a uniform distribution, then computing the generalized Poisson quantiles of these random points. My implementation just generates a single random variate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_qr &amp;lt;- &amp;quot;
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}

int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check this function, I’ll generate some large samples from the generalized Poisson with a few different parameter sets. If the sampler is working properly, the empirical cumulative distribution should line up closely with the cumulative distribution computed using &lt;code&gt;gamlss.dist::pGPO()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_qr, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;GPO-rng.stan&amp;quot;)
expose_stan_functions(&amp;quot;GPO-rng.stan&amp;quot;)

gpo_rng_sampler &amp;lt;- function(N, mu, phi) {
  replicate(N, gpo_rng(mu = mu, phi = phi))
}

test_rng &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
  ) %&amp;gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    x = pmap(.l = list(N = 10000, mu = mu, phi = phi), .f = gpo_rng_sampler),
    tb = map(x, ~ as.data.frame(table(.x)))
  ) %&amp;gt;%
  dplyr::select(-x) %&amp;gt;%
  group_by(mu, phi) %&amp;gt;%
  unnest(tb) %&amp;gt;%
  mutate(
    .x = as.integer(levels(.x))[.x],
    Freq_cum = cumsum(Freq) / 10000,
    gamlss_F = pGPO(q = .x, mu = mu, sigma = sigma)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_rng, aes(gamlss_F, Freq_cum, color = factor(phi))) + 
  geom_abline(slope = 1, color = &amp;quot;blue&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) + 
  geom_point() + geom_line() +  
  facet_grid(phi ~ mu, labeller = &amp;quot;label_both&amp;quot;) + 
  theme_minimal() + 
  labs(x = &amp;quot;Theoretical cdf (gamlss.dist)&amp;quot;, y = &amp;quot;Empirical cdf (my function)&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/check-rng-plot-1.png&#34; width=&#34;672&#34; /&gt;
Another approach to checking the sampler is to simulate a bunch of observations and check whether the empirical mean and variance match the theoretical moments. I’ll do this as well, using some values of &lt;span class=&#34;math inline&#34;&gt;\(\phi &amp;gt; 1\)&lt;/span&gt; to test whether the sampler still works when there’s under-dispersion.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test_moments &amp;lt;- 
  expand_grid(
    mu = c(5, 10, 20, 40, 60),
    phi = seq(1, 2, 0.1),
  ) %&amp;gt;%
  mutate(
    x = pmap(.l = list(N = 1e5, mu = mu, phi = phi), .f = gpo_rng_sampler),
    M = map_dbl(x, mean),
    S = map_dbl(x, sd),
    M_ratio = M / mu,
    S_ratio = S / sqrt(mu / phi)
  ) %&amp;gt;%
  dplyr::select(-x) %&amp;gt;%
  pivot_longer(ends_with(&amp;quot;_ratio&amp;quot;),names_to = &amp;quot;moment&amp;quot;,values_to = &amp;quot;ratio&amp;quot;) %&amp;gt;%
  mutate(
    moment = factor(moment, levels = c(&amp;quot;M_ratio&amp;quot;, &amp;quot;S_ratio&amp;quot;), labels = c(&amp;quot;Sample mean&amp;quot;, &amp;quot;Standard deviation&amp;quot;)),
    mu = factor(mu)
  )

ggplot(test_moments, aes(phi, ratio, color = mu)) + 
  geom_point() + geom_line() + 
  facet_wrap(~ moment) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/test-sample-moments-1.png&#34; width=&#34;768&#34; /&gt;
Looks like the sample moments closely match the parameter values, with deviations that look pretty much like random error. Nice!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-custom-distribution-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using the custom distribution functions&lt;/h1&gt;
&lt;p&gt;To finish out my tests of these functions, I’ll try out a small simulation. Following my &lt;a href=&#34;https://www.jepusto.com/Double-Poisson-in-Stan/&#34;&gt;previous post&lt;/a&gt;, I’ll generate data based on a generalized linear model with a single predictor &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, where the outcome &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; follows a generalized Poisson distribution conditional on &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The data-generating process is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
X &amp;amp;\sim N(0, 1) \\
Y|X &amp;amp;\sim GPO(\mu(X), \phi) \\
\log \mu(X) &amp;amp;= 2 + 0.3 \times X
\end{aligned}
\]&lt;/span&gt;
with the dispersion parameter set to &lt;span class=&#34;math inline&#34;&gt;\(\phi = 10 / 7\)&lt;/span&gt; so that the outcome is &lt;em&gt;under&lt;/em&gt;-dispersed.&lt;/p&gt;
&lt;p&gt;The following code generates a large sample from the data-generating process:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(20231204)
N &amp;lt;- 600
X &amp;lt;- rnorm(N)
mu &amp;lt;- exp(2 + 0.3 * X)
phi &amp;lt;- 10 / 7
Y &amp;lt;- map_dbl(mu, gpo_rng, phi = phi)
dat &amp;lt;- data.frame(X = X, Y = Y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what the sample looks like, along with a smoothed regression estimated using a basic cubic spline:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat, aes(X, Y)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = &amp;#39;gam&amp;#39;, formula = y ~ s(x, bs = &amp;quot;cs&amp;quot;)) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/glm-scatterplot-1.png&#34; width=&#34;576&#34; /&gt;
Here is a fit using quasi-likelihood estimation of a log-linear model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quasi_fit &amp;lt;- glm(Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
summary(quasi_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.8059  -0.5958  -0.0308   0.5275   2.8044  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  1.99558    0.01273  156.71   &amp;lt;2e-16 ***
## X            0.30081    0.01174   25.61   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 0.6689639)
## 
##     Null deviance: 852.98  on 599  degrees of freedom
## Residual deviance: 413.94  on 598  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This approach recovers the data-generating parameters quite well, with a dispersion estimate of 0.669 compared to the true dispersion parameter of 0.7.&lt;/p&gt;
&lt;div id=&#34;candidate-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Candidate models&lt;/h2&gt;
&lt;p&gt;Now let me fit the same generalized linear model but assuming that the outcome follow a couple of different distributions, including a true Poisson (with unit dispersion), a negative binomial, the double-Poisson distribution from the previous post, and the generalized Poisson distribution. Here goes!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Poisson_fit &amp;lt;- 
  brm(
    Y ~ X, family = poisson(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;negbin_fit &amp;lt;- 
  brm(
    Y ~ X, family = negbinomial(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_dpo &amp;lt;- &amp;quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
int dpo_quantile(real p, real mu, real phi, int maxval) {
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int q = 0;
  while (cdf_vec[q + 1] &amp;lt; p) {
      q += 1;
    }
  return q;
}
int dpo_rng(real mu, real phi, int maxval) {
  real p = uniform_rng(0,1);
  int x = dpo_quantile(p, mu, phi, maxval);
  return x;
}
&amp;quot;
double_Poisson &amp;lt;- custom_family(
  &amp;quot;dpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)

double_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_dpo, block = &amp;quot;functions&amp;quot;)

phi_prior &amp;lt;- prior(exponential(1), class = &amp;quot;phi&amp;quot;)

DPO_fit &amp;lt;- 
  brm(
    Y ~ X, family = double_Poisson,
    prior = phi_prior,
    stanvars = double_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )

expose_functions(DPO_fit, vectorize = TRUE)

log_lik_dpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  dpo_lpmf(y, mu, phi)
}

posterior_predict_dpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  if (is.null(maxval)) maxval &amp;lt;- 20 * mu / min(phi, 1)
  dpo_rng(mu, phi, maxval = maxval)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_gpo &amp;lt;- &amp;quot;
real gpo_lpmf(int X, real mu, real phi) {
  real ans;
  real m = mu / (1 - inv(sqrt(phi)));
  real z = X + sqrt(phi) * (mu - X);
  if (phi &amp;gt; 1 &amp;amp;&amp;amp; X &amp;gt; m)
    ans = negative_infinity();
  else 
    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);
  return ans;
}
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}
int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&amp;quot;
generalized_Poisson &amp;lt;- custom_family(
  &amp;quot;gpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)

generalized_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_gpo, block = &amp;quot;functions&amp;quot;)

phi_prior &amp;lt;- prior(exponential(1), class = &amp;quot;phi&amp;quot;)

GPO_fit &amp;lt;- 
  brm(
    Y ~ X, family = generalized_Poisson,
    prior = phi_prior,
    stanvars = generalized_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )

expose_functions(GPO_fit, vectorize = TRUE)

log_lik_gpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  gpo_lpmf(y, mu, phi)
}

posterior_predict_gpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  gpo_rng(mu, phi)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model comparison&lt;/h2&gt;
&lt;p&gt;Here is a comparison of LOOIC for all of the models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_comparison &amp;lt;- loo(Poisson_fit, negbin_fit, DPO_fit, GPO_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unsurprisingly, the model based on the true data-generating process clearly fits better than the models involving other outcome distributions.&lt;/p&gt;
&lt;p&gt;Here’s the posterior for the dispersion (i.e., &lt;span class=&#34;math inline&#34;&gt;\(1 / \phi\)&lt;/span&gt;) based on the GPO and DPO models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_scheme_set(&amp;quot;green&amp;quot;)
GPO_dispersion &amp;lt;- 
  mcmc_areas(GPO_fit, pars = &amp;quot;phi&amp;quot;, transformations = \(x) 1 / x) + 
  scale_x_continuous(limits = c(0.55, 0.95)) + 
  theme_minimal() + 
  ggtitle(&amp;quot;Generalized Poisson&amp;quot;)

color_scheme_set(&amp;quot;brightblue&amp;quot;)
DPO_dispersion &amp;lt;- 
  mcmc_areas(DPO_fit, pars = &amp;quot;phi&amp;quot;, transformations = \(x) 1 / x) + 
  scale_x_continuous(limits = c(0.55, 0.95)) + 
  theme_minimal() + 
  ggtitle(&amp;quot;Double Poisson&amp;quot;)

DPO_dispersion / GPO_dispersion&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/dispersion-comparison-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It looks like the estimated dispersion from the double Poisson model is biased upwards (towards one) a little bit). To get a better sense of this, I’ll run some posterior predictive checks, using the quasi-likelihood dispersion as a summary statistic:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yrep_Poisson &amp;lt;- posterior_predict(Poisson_fit, ndraws = 500) 
Yrep_negbin &amp;lt;- posterior_predict(negbin_fit, ndraws = 500)
Yrep_dpo &amp;lt;- posterior_predict(DPO_fit, ndraws = 500)
Yrep_gpo &amp;lt;- posterior_predict(GPO_fit, ndraws = 500)

dispersion_coef &amp;lt;- function(y) {
  quasi_fit &amp;lt;- glm(y ~ dat$X, family = quasipoisson(link = &amp;quot;log&amp;quot;))
  sum(residuals(quasi_fit, type = &amp;quot;pearson&amp;quot;)^2) / quasi_fit$df.residual
}

color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_disp &amp;lt;- ppc_stat(dat$Y, Yrep_Poisson, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
negbin_disp &amp;lt;- ppc_stat(dat$Y, Yrep_negbin, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;brightblue&amp;quot;)
dpo_disp &amp;lt;- ppc_stat(dat$Y, Yrep_dpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Double Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
gpo_disp &amp;lt;- ppc_stat(dat$Y, Yrep_gpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Generalized Poisson&amp;quot;)

Poisson_disp / negbin_disp / dpo_disp / gpo_disp &amp;amp;
  theme_minimal() &amp;amp; 
  xlim(c(0.45, 1.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/ppc-dispersion-1.png&#34; width=&#34;768&#34; /&gt;
Both the double Poisson and the generalized Poisson models generate data with levels of dispersion similar to the observed data. Squinting pretty hard, it looks like the double Poisson model could be a little bit biased.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;marginal-posterior-predictive-densities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Marginal posterior predictive densities&lt;/h2&gt;
&lt;p&gt;Here’s some rootograms for the posterior predictive density of the raw outcomes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_Poisson, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Poisson&amp;quot;)
color_scheme_set(&amp;quot;purple&amp;quot;)
negbin_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_negbin, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Negative-binomial&amp;quot;)
color_scheme_set(&amp;quot;brightblue&amp;quot;)
dpo_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_dpo, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Double Poisson&amp;quot;)
color_scheme_set(&amp;quot;green&amp;quot;)
gpo_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_gpo, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Generalized Poisson&amp;quot;)

Poisson_root / negbin_root / dpo_root / gpo_root &amp;amp;
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/ppd-1.png&#34; width=&#34;672&#34; /&gt;
You can see from these that the Poisson and negative-binomial models expect more low-frequency counts than are present in the observed data. However, the figure doesn’t really capture the degree of mis-fit that is apparent with the dispersion summary statistics. I think this is because the distribution of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; changes so much depending on the value of the predictor &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posterior-predictive-residual-densities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Posterior predictive residual densities&lt;/h2&gt;
&lt;p&gt;One way to focus in on the distributional assumption is to examine the distribution of residuals rather than raw outcomes. I’ll do that here by looking the deviance residuals from the quasi-Poisson GLM model, treating the calculation of the residuals as merely as transformation of the raw data. Here are some posterior predictive density plots of these deviance residuals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# quasi-Poisson deviance residuals
dat$resid &amp;lt;- residuals(quasi_fit)

# function to calculate quasi-Poisson deviance residuals
quasi_residuals &amp;lt;- function(y) as.numeric(residuals(glm(y ~ dat$X, family = quasipoisson(link = &amp;quot;log&amp;quot;))))

# transform posterior predictive data into residuals
R &amp;lt;- 50
resid_Poisson &amp;lt;- apply(Yrep_Poisson[1:R,], 1, quasi_residuals) |&amp;gt; t()
resid_negbin &amp;lt;- apply(Yrep_negbin[1:R,], 1, quasi_residuals) |&amp;gt; t()
resid_dpo &amp;lt;- apply(Yrep_dpo[1:R,], 1, quasi_residuals) |&amp;gt; t()
resid_gpo &amp;lt;- apply(Yrep_gpo[1:R,], 1, quasi_residuals) |&amp;gt; t()

# make density plots
color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_Poisson) + labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
negbin_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_negbin) + labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;brightblue&amp;quot;)
dpo_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_dpo) + labs(title = &amp;quot;Double Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
gpo_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_gpo) + labs(title = &amp;quot;Generalized Poisson&amp;quot;)

Poisson_resid_density / negbin_resid_density / dpo_resid_density / gpo_resid_density &amp;amp;
  theme_minimal() &amp;amp; 
  xlim(c(-3, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Generalized-Poisson-in-Stan_files/figure-html/ppd-residuals-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s quite a bit clearer from these plots that the DPO and GPO models are closer to replicating the distribution of the data than are the Poisson or negative binomial models.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;colophon&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Colophon&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 22621)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] loo_2.5.1           bayesplot_1.10.0    brms_2.18.0        
##  [4] Rcpp_1.0.10         rstan_2.26.23       StanHeaders_2.26.28
##  [7] gamlss.dist_6.0-5   MASS_7.3-58.1       patchwork_1.1.2    
## [10] forcats_0.5.2       stringr_1.5.0       dplyr_1.1.3        
## [13] purrr_1.0.2         readr_2.1.3         tidyr_1.3.0        
## [16] tibble_3.2.1        ggplot2_3.4.3       tidyverse_1.3.2    
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.4.1         backports_1.4.1      RcppEigen_0.3.3.9.2 
##   [4] plyr_1.8.7           igraph_1.3.5         splines_4.2.2       
##   [7] crosstalk_1.2.0      TH.data_1.1-2        rstantools_2.2.0    
##  [10] inline_0.3.19        digest_0.6.31        htmltools_0.5.4     
##  [13] fansi_1.0.4          BH_1.78.0-0          magrittr_2.0.3      
##  [16] checkmate_2.1.0      googlesheets4_1.0.1  tzdb_0.3.0          
##  [19] modelr_0.1.9         RcppParallel_5.1.5   matrixStats_0.63.0  
##  [22] xts_0.12.2           sandwich_3.0-2       timechange_0.2.0    
##  [25] prettyunits_1.1.1    colorspace_2.1-0     rvest_1.0.3         
##  [28] haven_2.5.1          xfun_0.40            callr_3.7.3         
##  [31] crayon_1.5.2         jsonlite_1.8.4       survival_3.4-0      
##  [34] zoo_1.8-12           glue_1.6.2           gtable_0.3.4        
##  [37] gargle_1.3.0         emmeans_1.8.2        distributional_0.3.1
##  [40] pkgbuild_1.4.0       abind_1.4-5          scales_1.2.1        
##  [43] mvtnorm_1.1-3        DBI_1.1.3            miniUI_0.1.1.1      
##  [46] xtable_1.8-4         stats4_4.2.2         DT_0.26             
##  [49] htmlwidgets_1.6.2    httr_1.4.5           threejs_0.3.3       
##  [52] posterior_1.3.1      ellipsis_0.3.2       pkgconfig_2.0.3     
##  [55] farver_2.1.1         sass_0.4.5           dbplyr_2.2.1        
##  [58] utf8_1.2.3           labeling_0.4.3       tidyselect_1.2.0    
##  [61] rlang_1.1.1          reshape2_1.4.4       later_1.3.0         
##  [64] munsell_0.5.0        cellranger_1.1.0     tools_4.2.2         
##  [67] cachem_1.0.6         cli_3.6.1            generics_0.1.3      
##  [70] ggridges_0.5.4       broom_1.0.1          evaluate_0.20       
##  [73] fastmap_1.1.0        yaml_2.3.7           processx_3.7.0      
##  [76] knitr_1.42           fs_1.6.1             nlme_3.1-160        
##  [79] mime_0.12            xml2_1.3.3           compiler_4.2.2      
##  [82] shinythemes_1.2.0    rstudioapi_0.14      reprex_2.0.2        
##  [85] bslib_0.4.2          stringi_1.7.12       highr_0.10          
##  [88] ps_1.7.1             blogdown_1.13        Brobdingnag_1.2-9   
##  [91] lattice_0.20-45      Matrix_1.6-3         markdown_1.8        
##  [94] shinyjs_2.1.0        tensorA_0.36.2       vctrs_0.6.3         
##  [97] pillar_1.9.0         lifecycle_1.0.3      jquerylib_0.1.4     
## [100] bridgesampling_1.1-2 estimability_1.4.1   httpuv_1.6.8        
## [103] QuickJSR_1.0.6       R6_2.5.1             bookdown_0.29       
## [106] promises_1.2.0.1     gridExtra_2.3        codetools_0.2-18    
## [109] colourpicker_1.2.0   gtools_3.9.4         assertthat_0.2.1    
## [112] withr_2.5.0          shinystan_2.6.0      multcomp_1.4-25     
## [115] mgcv_1.8-41          parallel_4.2.2       hms_1.1.2           
## [118] grid_4.2.2           coda_0.19-4          rmarkdown_2.20      
## [121] googledrive_2.0.0    shiny_1.7.2          lubridate_1.9.2     
## [124] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Implementing Efron&#39;s double Poisson distribution in Stan</title>
      <link>https://www.jepusto.com/double-poisson-in-stan/</link>
      <pubDate>Fri, 15 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/double-poisson-in-stan/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a project I am working on, we are using &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; to fit generalized random effects location-scale models to a bunch of count data. We’re interested in using the double-Poisson distribution, as described by &lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron (1986)&lt;/a&gt;.
This is an interesting distribution because it admits for both over- and under-dispersion relative to the Poisson distribution, whereas most of the conventional alternatives such as the negative binomial distribution or Poisson-normal mixture distribution allow only for over-dispersion.
The double-Poisson distribution is not implemented in Stan, so we’ve had to write our own distribution function. That’s fine and not particularly difficult. What’s a bit more of a challenge is writing Stan functions to generate random samples from the double-Poisson, so that we can generate posterior predictive checks.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; In this post, I’ll walk through the implementation of the custom distribution functions needed to use the double-Poisson in Stan.
The &lt;a href=&#34;https://cran.r-project.org/package=gamlss.dist&#34;&gt;&lt;code&gt;gamlss.dist&lt;/code&gt; package&lt;/a&gt; provides a full set of distributional functions for the double-Poisson distribution, including a sampler. Thus, I can validate my Stan functions against the functions from &lt;code&gt;gamlss.dist&lt;/code&gt;.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(patchwork)   # composing figures
library(gamlss.dist) # DPO distribution functions
library(rstan)       # Stan interface to R
library(brms)        # fitting generalized linear models
library(bayesplot)   # Examine fitted models
library(loo)         # Model fit measures&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-double-poisson&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The double-Poisson&lt;/h2&gt;
&lt;p&gt;The double-Poisson distribution is a discrete distribution for non-negative counts, with support &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{S}_X = \{0, 1, 2, 3, ...\}\)&lt;/span&gt;.
The mean-variance relationship of the double-Poisson is approximately constant; for &lt;span class=&#34;math inline&#34;&gt;\(X \sim DPO(\mu, \phi)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{E}(X) \approx \mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(X) \approx \mu / \phi\)&lt;/span&gt;, so that the double-Poisson distribution approximately satisfies the assumptions of a quasi-Poisson generalized linear model (although not quite exactly so).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron (1986)&lt;/a&gt; gives the following expression for the density of the double-Poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and inverse-disperson &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
f(x | \mu, \phi) = \frac{\phi^{1/2} e^{-\phi \mu}}{c(\mu,\phi)} \left(\frac{e^{-x} x^x}{x!}\right) \left(\frac{e \mu}{x}\right)^{\phi x},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(c(\mu,\phi)\)&lt;/span&gt; is a scaling constant to ensure that the density sums to one, which is closely approximated by
&lt;span class=&#34;math display&#34;&gt;\[
c(\mu, \phi) \approx 1 + \frac{1 - \phi}{12 \mu \phi}\left(1 + \frac{1}{\mu \phi}\right).
\]&lt;/span&gt;
We then have
&lt;span class=&#34;math display&#34;&gt;\[
\ln f(x | \mu, \phi) = \frac{1}{2} \ln \phi - \phi \mu - \ln c(\mu, \phi) + x (\phi + \phi \ln \mu - 1) + (1 - \phi) x \ln(x) - \ln \left(x!\right),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(0 \times \ln (0)\)&lt;/span&gt; is evaluated as 0.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;log-of-the-probability-mass-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Log of the probability mass function&lt;/h1&gt;
&lt;p&gt;For purposes of using this distribution in Stan, it’s sufficient to provide the log of the probability mass function up to a constant—there’s no need to normalize it to sum to one. Thus, we can ignore the &lt;span class=&#34;math inline&#34;&gt;\(c(\mu, \phi)\)&lt;/span&gt; term above. Here’s a Stan function implementing the lpmf:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_lpmf &amp;lt;- &amp;quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check that this is accurate, I’ll compare the Stan function to the corresponding function from &lt;code&gt;gamlss.dist&lt;/code&gt; for a couple of different parameter values and for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,100\)&lt;/span&gt;. If my function is accurate, the calculated log-probabilities should differ by a constant value for each set of parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_lpmf, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-lpmf.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-lpmf.stan&amp;quot;)

test_lpmf &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
    X = 0:100
  ) %&amp;gt;%
  mutate(
    gamlss_lpmf = dDPO(x = X, mu = mu, sigma = 1 / phi, log = TRUE),
    my_lpmf = pmap_dbl(.l = list(X = X, mu = mu, phi = phi), .f = dpo_lpmf),
    diff = my_lpmf - gamlss_lpmf
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_lpmf, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Checks out. Onward!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cumulative-distribution-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Cumulative distribution function&lt;/h1&gt;
&lt;p&gt;I’ll next implement a function to evaluate the cumulative distriution function over a range of values. This is an expensive calculation, but it can be improved a little bit by noting the relationship between sequential values of the probability mass function. Letting &lt;span class=&#34;math inline&#34;&gt;\(d = \exp \left(\phi + \phi \ln \mu - 1 \right)\)&lt;/span&gt;, observe that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(0 | \mu, \phi) &amp;amp;= \frac{\phi^{1/2} e^{-\phi \mu}}{c(\mu,\phi)} \\
f(1 | \mu, \phi) &amp;amp;= f(0 | \mu, \phi) \times d \\
f(x | \mu, \phi) &amp;amp;= f(x - 1 | \mu, \phi) \times d \times \frac{\exp\left[(1 - \phi)(x - 1)\left(\ln(x) - \ln(x - 1)\right) \right]}{x^\phi}
\end{aligned}
\]&lt;/span&gt;
where the last expression holds for &lt;span class=&#34;math inline&#34;&gt;\(x \geq 2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The function below computes the cumulative distribution function over the range &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,m\)&lt;/span&gt; as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compute &lt;span class=&#34;math inline&#34;&gt;\(f(x | \mu, \phi)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,1,2,...\)&lt;/span&gt;, without the scaling constant &lt;span class=&#34;math inline&#34;&gt;\(c(\mu, \phi)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Take &lt;span class=&#34;math inline&#34;&gt;\(F(0 | \mu, \phi) = f(0 | \mu, \phi)\)&lt;/span&gt; and accumulate &lt;span class=&#34;math inline&#34;&gt;\(F(x | \mu, \phi) = F(x - 1 | \mu, \phi) + f(x | \mu, \phi)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,m\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Check if &lt;span class=&#34;math inline&#34;&gt;\(f(x | \mu, \phi) / F(x | \mu, \phi)\)&lt;/span&gt; is small (less than &lt;span class=&#34;math inline&#34;&gt;\(10^{-8}\)&lt;/span&gt;), in which case accumulation stops at the value &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The normalized cumulative distribution function will then be &lt;span class=&#34;math inline&#34;&gt;\(F(x | \mu, \phi) / F(n | \mu, \phi)\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_cdf &amp;lt;- &amp;quot; 
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check that this is accurate, I’ll again compare the Stan function to the corresponding function from &lt;code&gt;gamlss.dist&lt;/code&gt;. If my function is accurate, the computed cdf values should be proportional to the cdf calculated from &lt;code&gt;gamlss.dist::pDPO()&lt;/code&gt; and the ratio should be very close to 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_cdf, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-cdf.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-cdf.stan&amp;quot;)

test_cdf &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
  ) %&amp;gt;%
  mutate(
    maxval = 20 * mu / pmin(1, phi),
    my_cdf = pmap(.l = list(mu = mu, phi = phi, maxval = maxval), .f = dpo_cdf)
  ) %&amp;gt;%
  unnest(my_cdf) %&amp;gt;%
  filter(!is.nan(my_cdf)) %&amp;gt;%
  group_by(mu, phi) %&amp;gt;%
  mutate(
    q = row_number() - 1L,
    gamlss_cdf = pDPO(q = q, mu = mu, sigma = 1 / phi),
    ratio = my_cdf / gamlss_cdf
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_cdf, aes(factor(phi), ratio, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  ylim(1 + c(-1e-6, 1e-6)) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Still on track here (although you might wonder—would I be sharing this post if I couldn’t get the function working?).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quantile-function-and-sampler&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quantile function and sampler&lt;/h1&gt;
&lt;p&gt;The main other thing we need is a function for generating random samples from the double-Poisson. The &lt;code&gt;gamlss.dist&lt;/code&gt; package has the function &lt;code&gt;rDPO()&lt;/code&gt; for this purpose. It’s implemented using the standard inversion method, by calculating quantiles of the double-Poisson corresponding to a random sample from a uniform distribution. Just for funzies, I’ll implement the same approach using Stan.&lt;/p&gt;
&lt;p&gt;The function below calculates quantiles by finding the minimum value of &lt;span class=&#34;math inline&#34;&gt;\(q \geq 0\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(F(q + 1 | \mu, \phi) \geq p\)&lt;/span&gt; for a specified probability &lt;span class=&#34;math inline&#34;&gt;\(p \in [0, 1]\)&lt;/span&gt;. It is vectorized over &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and solves for &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; by starting with the smallest &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and continuing through the largest value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_quantile &amp;lt;- &amp;quot; 
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
array[] int dpo_quantiles(vector p, real mu, real phi, int maxval) {
  int N = rows(p);
  array[N] int qs;
  array[N] int indices = sort_indices_asc(p);
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int j = 0;
  for (i in indices) {
    while (cdf_vec[j + 1] &amp;lt; p[i]) {
      j += 1;
    }
    qs[i] = j;
  }
  return qs;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If my quantile function is accurate, it should match the value computed from &lt;code&gt;gamlss.dist::qDPO()&lt;/code&gt; exactly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_quantile, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-quantile.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-quantile.stan&amp;quot;)

test_quantile &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
  ) %&amp;gt;%
  mutate(
    maxval = 20 * mu / pmin(1, phi),
    p = map(1:n(), ~ runif(100)),
    my_q = pmap(.l = list(p = p, mu = mu, phi = phi, maxval = maxval), .f = dpo_quantiles),
    gamlss_q = pmap(.l = list(p = p, mu = mu, sigma = 1 / phi), .f = qDPO)
  ) %&amp;gt;%
  unnest(c(p, my_q, gamlss_q)) %&amp;gt;%
  mutate(
    diff = my_q - gamlss_q
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_quantile, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Phew, still got it!&lt;/p&gt;
&lt;p&gt;The last piece of the puzzle is to write a sampler by generating random points from a uniform distribution, then computing the double-Poisson quantiles of these random points. I will implement this two ways: first with an argument for the number of random variates to generate and then, more simply, to generate a single random variate.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_qr &amp;lt;- &amp;quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
array[] int dpo_quantiles(vector p, real mu, real phi, int maxval) {
  int N = rows(p);
  array[N] int qs;
  array[N] int indices = sort_indices_asc(p);
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int j = 0;
  for (i in indices) {
    while (cdf_vec[j + 1] &amp;lt; p[i]) {
      j += 1;
    }
    qs[i] = j;
  }
  return qs;
}
array[] int dpo_sample_rng(int n, real mu, real phi, int maxval) {
  vector[n] p;
  for (i in 1:n) {
    p[i] = uniform_rng(0,1);
  }
  array[n] int x = dpo_quantiles(p, mu, phi, maxval);
  return x;
}
int dpo_quantile(real p, real mu, real phi, int maxval) {
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int q = 0;
  while (cdf_vec[q + 1] &amp;lt; p) {
      q += 1;
    }
  return q;
}
int dpo_rng(real mu, real phi, int maxval) {
  real p = uniform_rng(0,1);
  int x = dpo_quantile(p, mu, phi, maxval);
  return x;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check this function, I’ll generate some large samples from the double-Poisson with a few different parameter sets. If the sampler is working properly, the empirical cumulative distribution should line up closely with the cumulative distribution computed using &lt;code&gt;gamlss.dist::pDPO()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_qr, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-rng.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-rng.stan&amp;quot;)

test_rng &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
  ) %&amp;gt;%
  mutate(
    x = pmap(.l = list(n = 10000, mu = mu, phi = phi, maxval = 5000), .f = dpo_sample_rng),
    tb = map(x, ~ as.data.frame(table(.x)))
  ) %&amp;gt;%
  dplyr::select(-x) %&amp;gt;%
  group_by(mu, phi) %&amp;gt;%
  unnest(tb) %&amp;gt;%
  mutate(
    .x = as.integer(levels(.x))[.x],
    Freq_cum = cumsum(Freq) / 10000,
    gamlss_F = pDPO(q = .x, mu = mu, sigma = 1 / phi)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_rng, aes(gamlss_F, Freq_cum, color = factor(phi))) + 
  geom_abline(slope = 1, color = &amp;quot;blue&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) + 
  geom_point() + geom_line() +  
  facet_grid(phi ~ mu, labeller = &amp;quot;label_both&amp;quot;) + 
  theme_minimal() + 
  labs(x = &amp;quot;Theoretical cdf (gamlss.dist)&amp;quot;, y = &amp;quot;Empirical cdf (my function)&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks pretty good, no?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-custom-distribution-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using the custom distribution functions&lt;/h1&gt;
&lt;p&gt;To finish out my tests of these functions, let me demonstrate their use in an actual estimation problem. I’ll generate data based on a simple generalized linear model with a single predictor &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, where the outcome &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; follows a double-Poisson distribution conditional on &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The data-generating process is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
X &amp;amp;\sim N(0, 1) \\
Y|X &amp;amp;\sim DPO(\mu(X), \phi) \\
\log \mu(X) &amp;amp;= 2 + 0.3 \times X
\end{aligned}
\]&lt;/span&gt;
To make things interesting, I’ll set the dispersion parameter to &lt;span class=&#34;math inline&#34;&gt;\(1 / \phi = 0.6\)&lt;/span&gt; so that the outcome is &lt;em&gt;under&lt;/em&gt;-dispersed relative to the Poisson.&lt;/p&gt;
&lt;p&gt;The following code generates a large sample from the data-generating process. To keep things R-centric, I use &lt;code&gt;gamlss.dist::rDPO&lt;/code&gt; to generate the outcome.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(20230913)
N &amp;lt;- 600
X &amp;lt;- rnorm(N)
mu &amp;lt;- exp(2 + 0.3 * X)
phi_inv &amp;lt;- 0.6
Y &amp;lt;- rDPO(N, mu = mu, sigma = phi_inv)
dat &amp;lt;- data.frame(X = X, Y = Y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what the sample looks like, along with a smoothed regression estimated using a basic cubic spline:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat, aes(X, Y)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = &amp;#39;gam&amp;#39;, formula = y ~ s(x, bs = &amp;quot;cs&amp;quot;)) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;comparison-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparison models&lt;/h2&gt;
&lt;p&gt;Before using the custom distribution, I’ll fit a couple of out-of-the-box models that are useful points of comparison.
Surely the simplest, quickest, and dirtiest way to estimate such a regression is with a generalized linear model, using the “quasi-Poisson” family to allow for non-unit dispersion. In R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quasi_fit &amp;lt;- glm(Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
summary(quasi_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.77671  -0.58205  -0.03293   0.49158   2.52711  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  1.98784    0.01219  163.03   &amp;lt;2e-16 ***
## X            0.29276    0.01178   24.85   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 0.6324771)
## 
##     Null deviance: 777.74  on 599  degrees of freedom
## Residual deviance: 384.90  on 598  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This approach recovers the data-generating parameters quite well, with a dispersion estimate of 0.632 compared to the true dispersion parameter of 0.6.&lt;/p&gt;
&lt;p&gt;Now let me fit the same generalized linear model but assuming that the outcome follows a true Poisson distribution (with unit dispersion). I’ll fit the model in a Bayesian framework with the &lt;code&gt;brms&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Poisson_fit &amp;lt;- 
  brm(
    Y ~ X, family = poisson(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20230913
  )

summary(Poisson_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: poisson 
##   Links: mu = log 
## Formula: Y ~ X 
##    Data: dat (Number of observations: 600) 
##   Draws: 4 chains, each with iter = 1500; warmup = 500; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.99      0.02     1.96     2.02 1.00     2733     2582
## X             0.29      0.01     0.26     0.32 1.00     2705     2485
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This specification recovers the intercept and slope parameters well too, but doesn’t provide any estimate of dispersion.&lt;/p&gt;
&lt;p&gt;As an alternative, I’ll also fit the model using the negative binomial distribution, which is a generalization of the Poisson that allows for over-dispersion (but not under-dispersion):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;negbin_fit &amp;lt;- 
  brm(
    Y ~ X, family = negbinomial(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20230913
  )

summary(negbin_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: negbinomial 
##   Links: mu = log; shape = identity 
## Formula: Y ~ X 
##    Data: dat (Number of observations: 600) 
##   Draws: 4 chains, each with iter = 1500; warmup = 500; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.99      0.02     1.96     2.02 1.00     3571     3057
## X             0.29      0.01     0.26     0.32 1.00     3696     3141
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape   313.78    130.37   136.26   622.52 1.00     3132     3122
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;brms&lt;/code&gt; package implements the negative binomial using the rate parameterization, so the &lt;code&gt;shape&lt;/code&gt; parameter corresponds to the inverse dispersion. Thus, a large shape parameter (as in the above fit) implies dispersion that is very close to one (i.e., close to the Poisson).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;double-poisson-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Double-Poisson model&lt;/h2&gt;
&lt;p&gt;Now I’ll fit the same model as previously but using my custom-built double-Poisson distribution. Following &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_customfamilies.html&#34;&gt;Paul Buerkner’s vignette&lt;/a&gt; on using custom distributions in &lt;code&gt;brms&lt;/code&gt;, I’ll first specify the custom family object for the double-Poisson:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;double_Poisson &amp;lt;- custom_family(
  &amp;quot;dpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I set the defaults to use a log-link for the mean (just as with the Poisson and negative binomial families) and a log-link for the inverse-dispersion.
Next, I’ll create an object to add the custom stan code from above into the code created by &lt;code&gt;brm&lt;/code&gt; for fitting the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;double_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_qr, block = &amp;quot;functions&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll also need to specify a prior to use for the &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; parameter of the double-Poisson distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;phi_prior &amp;lt;- prior(exponential(1), class = &amp;quot;phi&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’m ready to fit the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DPO_fit &amp;lt;- 
  brm(
    Y ~ X, family = double_Poisson,
    prior = phi_prior,
    stanvars = double_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20230913
  )

summary(DPO_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: dpo 
##   Links: mu = log; phi = identity 
## Formula: Y ~ X 
##    Data: dat (Number of observations: 600) 
##   Draws: 4 chains, each with iter = 1500; warmup = 500; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.99      0.01     1.96     2.01 1.00     3468     3162
## X             0.29      0.01     0.27     0.32 1.00     3745     2786
## 
## Family Specific Parameters: 
##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## phi     1.55      0.09     1.38     1.73 1.00     3814     2780
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The regression coefficient estimates are basically identical to those from the Poisson and negative-binomial models, estimated with slightly better precision than with the Poisson or negative binomial families. However, we get a posterior for &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; that corresponds to &lt;em&gt;under&lt;/em&gt;-dispersion. Here’s the posterior for the dispersion (i.e., &lt;span class=&#34;math inline&#34;&gt;\(1 / \phi\)&lt;/span&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mcmc_areas(DPO_fit, pars = &amp;quot;phi&amp;quot;, transformations = \(x) 1 / x) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/DPO-dispersion-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model comparison&lt;/h2&gt;
&lt;p&gt;I’d like to get a sense of how much better the double-Poisson model does with capturing the real data-generating process compared to the simple Poisson model or the negative binomial model. There’s a wide range of diagnostics that can inform such comparisons. I’ll consider the leave-one-out information criteria (LOOIC) and also look at some posterior predictive checks.&lt;/p&gt;
&lt;p&gt;To calculate LOOIC for the double-Poisson model, I first need to provide a &lt;code&gt;log_lik&lt;/code&gt; function that &lt;code&gt;brms&lt;/code&gt; can use&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. Here’s code, using the Stan function from above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;expose_functions(DPO_fit, vectorize = TRUE)
log_lik_dpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  dpo_lpmf(y, mu, phi)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can then compute LOOIC for all three models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo(DPO_fit, Poisson_fit, negbin_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Output of model &amp;#39;DPO_fit&amp;#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1305.7 16.9
## p_loo         2.9  0.2
## looic      2611.5 33.8
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &amp;lt; 0.5).
## See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
## 
## Output of model &amp;#39;Poisson_fit&amp;#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1330.0 11.3
## p_loo         1.3  0.1
## looic      2660.1 22.6
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &amp;lt; 0.5).
## See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
## 
## Output of model &amp;#39;negbin_fit&amp;#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1333.2 11.1
## p_loo         1.3  0.1
## looic      2666.3 22.2
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &amp;lt; 0.5).
## See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
## 
## Model comparisons:
##             elpd_diff se_diff
## DPO_fit       0.0       0.0  
## Poisson_fit -24.3       6.1  
## negbin_fit  -27.4       6.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By these measures, the double-Poisson model has substantially better fit than either of the other models.&lt;/p&gt;
&lt;p&gt;To do posterior predictive checks, I need to provide a &lt;code&gt;posterior_predict&lt;/code&gt; function that &lt;code&gt;brms&lt;/code&gt; can use. I’ll again do an implementation that uses my custom &lt;code&gt;dpo_rng()&lt;/code&gt; from Stan.&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_predict_dpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  if (is.null(maxval)) maxval &amp;lt;- 20 * mu / min(phi, 1)
  dpo_rng(mu, phi, maxval = maxval)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Functions in hand, I can now compute posterior predictions for the double-Poisson model and make pretty pictures of them, along with corresponding plots for the Poisson and negative-binomial models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yrep_Poisson &amp;lt;- posterior_predict(Poisson_fit, draws = 400) 
color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_Poisson, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Poisson&amp;quot;)

Yrep_negbin &amp;lt;- posterior_predict(negbin_fit, draws = 400)
color_scheme_set(&amp;quot;green&amp;quot;)
negbin_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_negbin, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Negative-binomial&amp;quot;)

Yrep_dpo &amp;lt;- posterior_predict(DPO_fit, draws = 400)
color_scheme_set(&amp;quot;purple&amp;quot;)
dpo_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_dpo, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Double-Poisson&amp;quot;)

dpo_root / Poisson_root / negbin_root &amp;amp;
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/ppd-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The differences in predicted frequencies are not that obvious from these plots. The main notable difference is that the Poisson and negative-binomial distributions predict more small counts (in the range of 0 to 3) than are observed, whereas the double-Poisson does better at matching the observed frequency in this range.&lt;/p&gt;
&lt;p&gt;I think the lack of glaring differences in the above plots happens because I’m just looking at the marginal distribution of the outcome, and the (explained) variation due to the predictor dampens the degree of under-dispersion. To see this, I’ll create some plots that are grouped by quintiles of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat$g &amp;lt;- cut(dat$X, breaks = quantile(dat$X, seq(0,1,0.2)), include.lowest = TRUE)

color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_bars &amp;lt;- ppc_bars_grouped(
  dat$Y, Yrep_Poisson, dat$g, 
  prob = 0.5, 
  facet_args = list(ncol = 5)
) + 
  labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
negbin_bars &amp;lt;- ppc_bars_grouped(
  dat$Y, Yrep_negbin, dat$g, 
  prob = 0.5, 
  facet_args = list(ncol = 5)
) + 
  labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
dpo_bars &amp;lt;- ppc_bars_grouped(
  dat$Y, Yrep_dpo, dat$g, 
  prob = 0.5, 
  facet_args = list(ncol = 5)
) + 
  labs(title = &amp;quot;Double-Poisson&amp;quot;)

dpo_bars / Poisson_bars / negbin_bars &amp;amp;
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/ppd-grouped-1.png&#34; width=&#34;1152&#34; /&gt;
Still kind of subtle, I suppose, but you can see more clearly that the double-Poisson does a better job than the other distributions at matching the modes (peaks) of the empirical distribution in each of these subgroups.&lt;/p&gt;
&lt;p&gt;One last approach is to look directly at the degree of dispersion in the posterior predictive distributions relative to the actual data. I’ll calculate this dispersion by re-fitting the quick-and-dirty quasi-poisson model in each sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dispersion_coef &amp;lt;- function(y) {
  quasi_fit &amp;lt;- glm(y ~ dat$X, family = quasipoisson(link = &amp;quot;log&amp;quot;))
  sum(residuals(quasi_fit, type = &amp;quot;pearson&amp;quot;)^2) / quasi_fit$df.residual
}

color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_disp &amp;lt;- ppc_stat(dat$Y, Yrep_Poisson, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
negbin_disp &amp;lt;- ppc_stat(dat$Y, Yrep_negbin, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
dpo_disp &amp;lt;- ppc_stat(dat$Y, Yrep_dpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Double-Poisson&amp;quot;)

dpo_disp / Poisson_disp / negbin_disp &amp;amp;
  theme_minimal() &amp;amp; 
  xlim(c(0.45, 1.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Double-Poisson-in-Stan_files/figure-html/ppc-dispersion-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From this, we can clearly see that the Poisson and negative binomial model generate data with approximately unit dispersion, which doesn’t match at all with the degree of dispersion in the observed data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;kudos&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Kudos&lt;/h1&gt;
&lt;p&gt;So there you have it. It’s really quite feasible to build models with custom distributions. Efron (1986) also describes a double-binomial distribution (as an approximation to the “quasi-binomial” family of generalized linear models), which you could play with implementing for yourself, dear reader, if you are in the mood.
Major kudos to &lt;a href=&#34;https://paul-buerkner.github.io/&#34;&gt;Paul Buerkner&lt;/a&gt; for &lt;a href=&#34;https://paul-buerkner.github.io/brms/&#34;&gt;&lt;code&gt;brms&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://jgabry.github.io/&#34;&gt;Jonah Gabry&lt;/a&gt; and collaborators for &lt;a href=&#34;https://mc-stan.org/bayesplot/&#34;&gt;&lt;code&gt;bayesplot&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&#34;https://mc-stan.org/about/team/&#34;&gt;the incredible team of folks&lt;/a&gt; developing &lt;a href=&#34;https://mc-stan.org/&#34;&gt;&lt;code&gt;Stan&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;colophon&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Colophon&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19045)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] loo_2.5.1           bayesplot_1.9.0     brms_2.18.0        
##  [4] Rcpp_1.0.10         rstan_2.26.23       StanHeaders_2.26.27
##  [7] gamlss.dist_6.0-3   MASS_7.3-57         patchwork_1.1.1    
## [10] forcats_0.5.1       stringr_1.5.0       dplyr_1.1.2        
## [13] purrr_1.0.2         readr_2.1.2         tidyr_1.3.0        
## [16] tibble_3.2.1        ggplot2_3.4.0       tidyverse_1.3.1    
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.4.2         backports_1.4.1      RcppEigen_0.3.3.9.2 
##   [4] plyr_1.8.8           igraph_1.3.5         splines_4.2.2       
##   [7] crosstalk_1.2.0      TH.data_1.1-2        rstantools_2.2.0    
##  [10] inline_0.3.19        digest_0.6.30        htmltools_0.5.4     
##  [13] fansi_1.0.4          magrittr_2.0.3       BH_1.78.0-0         
##  [16] checkmate_2.1.0      tzdb_0.3.0           modelr_0.1.8        
##  [19] RcppParallel_5.1.5   matrixStats_0.62.0   xts_0.12.1          
##  [22] sandwich_3.0-1       timechange_0.2.0     prettyunits_1.1.1   
##  [25] colorspace_2.1-0     rvest_1.0.2          haven_2.5.0         
##  [28] xfun_0.34            callr_3.7.2          crayon_1.5.2        
##  [31] jsonlite_1.8.4       survival_3.4-0       zoo_1.8-10          
##  [34] glue_1.6.2           gtable_0.3.1         emmeans_1.7.3       
##  [37] distributional_0.3.1 pkgbuild_1.3.1       abind_1.4-5         
##  [40] scales_1.2.1         mvtnorm_1.1-3        DBI_1.1.2           
##  [43] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.2.2        
##  [46] DT_0.23              htmlwidgets_1.6.2    httr_1.4.3          
##  [49] threejs_0.3.3        posterior_1.3.1      ellipsis_0.3.2      
##  [52] pkgconfig_2.0.3      farver_2.1.1         sass_0.4.5          
##  [55] dbplyr_2.1.1         utf8_1.2.3           tidyselect_1.2.0    
##  [58] labeling_0.4.2       rlang_1.1.1          reshape2_1.4.4      
##  [61] later_1.3.0          munsell_0.5.0        cellranger_1.1.0    
##  [64] tools_4.2.2          cachem_1.0.6         cli_3.6.1           
##  [67] generics_0.1.3       broom_0.8.0          ggridges_0.5.3      
##  [70] evaluate_0.18        fastmap_1.1.0        yaml_2.3.5          
##  [73] processx_3.7.0       knitr_1.40           fs_1.6.1            
##  [76] nlme_3.1-157         mime_0.12            xml2_1.3.3          
##  [79] compiler_4.2.2       shinythemes_1.2.0    rstudioapi_0.13     
##  [82] reprex_2.0.1         bslib_0.4.2          stringi_1.7.12      
##  [85] highr_0.9            ps_1.6.0             blogdown_1.10       
##  [88] Brobdingnag_1.2-9    lattice_0.20-45      Matrix_1.5-1        
##  [91] markdown_1.7         shinyjs_2.1.0        tensorA_0.36.2      
##  [94] vctrs_0.6.3          pillar_1.9.0         lifecycle_1.0.3     
##  [97] jquerylib_0.1.4      bridgesampling_1.1-2 estimability_1.3    
## [100] httpuv_1.6.8         QuickJSR_1.0.5       R6_2.5.1            
## [103] bookdown_0.26        promises_1.2.0.1     gridExtra_2.3       
## [106] codetools_0.2-18     colourpicker_1.1.1   gtools_3.9.3        
## [109] assertthat_0.2.1     withr_2.5.0          shinystan_2.6.0     
## [112] multcomp_1.4-23      mgcv_1.8-41          parallel_4.2.2      
## [115] hms_1.1.3            grid_4.2.2           coda_0.19-4         
## [118] rmarkdown_2.18       shiny_1.7.4          lubridate_1.9.2     
## [121] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;To be clear up front, what I present is more complicated than really necessary because of these existing R functions to simulate values from the double-Poisson—we can just use the functions from &lt;code&gt;gamlss.dist&lt;/code&gt; for purposes of posterior predictive checks (about which more below).
I’m trying to work in Stan to the maximum extent possible solely as an excuse to learn more about the language, which I haven’t used much up until today.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I should also note that the &lt;a href=&#34;http://www.bamlss.org/index.html&#34;&gt;&lt;code&gt;bamlss&lt;/code&gt; package&lt;/a&gt; provides similar functionality and can be combined with &lt;code&gt;gamlss.dist&lt;/code&gt; to accomplish basically the same thing as I’m going to do here.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;The simpler version is what’s needed for generating posterior predictive checks, the fancy version is just to show off how clever I am.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Rather than exposing and calling the Stan function, one could just re-implement the log likelihood in R. (Probably the easier way in practice, but again I’m trying to learn me some Stan here…)&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Of course, I could have saved a bunch of trouble by just using &lt;code&gt;gamlss.dist::rDPO()&lt;/code&gt; instead.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
