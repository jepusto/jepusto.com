<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>meta-analysis | James E. Pustejovsky</title>
    <link>https://www.jepusto.com/tags/meta-analysis/</link>
      <atom:link href="https://www.jepusto.com/tags/meta-analysis/index.xml" rel="self" type="application/rss+xml" />
    <description>meta-analysis</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2023</copyright><lastBuildDate>Thu, 09 Nov 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.jepusto.com/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>meta-analysis</title>
      <link>https://www.jepusto.com/tags/meta-analysis/</link>
    </image>
    
    <item>
      <title>High replicability of newly-discovered social-behavioral findings is achievable.</title>
      <link>https://www.jepusto.com/publication/decline-effects/</link>
      <pubDate>Thu, 09 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/decline-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Equivalences between ad hoc strategies and meta-analytic models for dependent effect sizes</title>
      <link>https://www.jepusto.com/publication/equivalences-between-ad-hoc-strategies-and-models/</link>
      <pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/equivalences-between-ad-hoc-strategies-and-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The efficacy of combining cognitive training and non-invasive brain stimulation: A transdiagnostic systematic review and meta-analysis</title>
      <link>https://www.jepusto.com/publication/efficacy-of-combining-cognitive-training-and-nibs/</link>
      <pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/efficacy-of-combining-cognitive-training-and-nibs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cluster-Bootstrapping a meta-analytic selection model</title>
      <link>https://www.jepusto.com/cluster-bootstrap-selection-model/</link>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/cluster-bootstrap-selection-model/</guid>
      <description>
&lt;script src=&#34;https://www.jepusto.com/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.jepusto.com/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;style type=&#34;text/css&#34;&gt;
.greybox {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 60%;
  padding: 1em;
  background: lightgrey;
  border: 2px solid darkgrey;
  border-radius: 1px;
  font-size: 0.75em;
}
&lt;/style&gt;
&lt;div class=&#34;greybox&#34;&gt;
&lt;p&gt;The research reported here was supported, in whole or in part, by the Institute of Education Sciences, U.S. Department of Education, through grant R305D220026 to the American Institutes for Research. The opinions expressed are those of the authors and do not represent the views of the Institute or the U.S. Department of Education.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;
Selective reporting of study results is a big concern for meta-analysts. By selective reporting, we mean the phenomenon where affirmative findings—that is, statistically significant findings in the theoretically expected direction—are more likely to be reported and more likely to be available for a systematic review compared to non-affirmative findings. Selective reporting arises due to biases in the publication process, on the part of journals, editors, and reviewers, as well as strategic decisions on part of the authors &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-rothstein2006publication&#34; role=&#34;doc-biblioref&#34;&gt;Rothstein et al., 2006&lt;/a&gt;; &lt;a href=&#34;#ref-sutton2009publication&#34; role=&#34;doc-biblioref&#34;&gt;Sutton, 2009&lt;/a&gt;)&lt;/span&gt;. Research synthesists worry about selective reporting because it can distort the evidence base available for meta-analysis, almost like a fun-house mirror distorts your appearance, leading to inflation of average effect size estimates and biased estimates of heterogeneity.&lt;/p&gt;
&lt;p&gt;If you read the meta-analysis methods literature, you will find scores of tools available to investigate and adjust for the biases created by selective reporting. Well known and widely used methods include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;graphical representations like funnel plots and contour-enhanced funnel plots &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Sterne2011recommendations&#34; role=&#34;doc-biblioref&#34;&gt;Sterne et al., 2011&lt;/a&gt;; &lt;a href=&#34;#ref-sterne2001funnel&#34; role=&#34;doc-biblioref&#34;&gt;Sterne &amp;amp; Egger, 2001&lt;/a&gt;)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;tests for selective reporting (or at least funnel plot asymmetry) like Egger’s regression &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-egger1997bias&#34; role=&#34;doc-biblioref&#34;&gt;Egger et al., 1997&lt;/a&gt;)&lt;/span&gt; or Begg and Mazumdar’s rank correlation test &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-begg1994operating&#34; role=&#34;doc-biblioref&#34;&gt;Begg &amp;amp; Mazumdar, 1994&lt;/a&gt;)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;bias-adjustment methods like PET-PEESE &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-stanley2008metaregression&#34; role=&#34;doc-biblioref&#34;&gt;Stanley, 2008&lt;/a&gt;; &lt;a href=&#34;#ref-stanley2014metaregression&#34; role=&#34;doc-biblioref&#34;&gt;Stanley &amp;amp; Doucouliagos, 2014&lt;/a&gt;)&lt;/span&gt;, Trim-and-Fill &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-duval2000nonparametric&#34; role=&#34;doc-biblioref&#34;&gt;Duval &amp;amp; Tweedie, 2000&lt;/a&gt;)&lt;/span&gt;, and selection models &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hedges2005selection&#34; role=&#34;doc-biblioref&#34;&gt;Hedges &amp;amp; Vevea, 2005&lt;/a&gt;)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;p-value diagnostics like p-curve &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-simonsohn2014pcurve&#34; role=&#34;doc-biblioref&#34;&gt;Simonsohn et al., 2014&lt;/a&gt;)&lt;/span&gt;, p-uniform &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-vanaert2016conducting&#34; role=&#34;doc-biblioref&#34;&gt;Aert et al., 2016&lt;/a&gt;; &lt;a href=&#34;#ref-VanAssen2015meta&#34; role=&#34;doc-biblioref&#34;&gt;Assen et al., 2015&lt;/a&gt;)&lt;/span&gt;, and the test of excess significance &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-ioannidis2007exploratory&#34; role=&#34;doc-biblioref&#34;&gt;Ioannidis &amp;amp; Trikalinos, 2007&lt;/a&gt;)&lt;/span&gt;; and&lt;/li&gt;
&lt;li&gt;sensitivity analyses based on various forms of selection models &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Copas2001sensitivity&#34; role=&#34;doc-biblioref&#34;&gt;Copas &amp;amp; Shi, 2001&lt;/a&gt;; &lt;a href=&#34;#ref-mathur2020sensitivity&#34; role=&#34;doc-biblioref&#34;&gt;Mathur &amp;amp; VanderWeele, 2020&lt;/a&gt;; &lt;a href=&#34;#ref-vevea2005publication&#34; role=&#34;doc-biblioref&#34;&gt;Vevea &amp;amp; Woods, 2005&lt;/a&gt;)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, nearly all of the statistical methods here have the limitation that they are premised on observing independent effect sizes. That presents a problem for meta-analyses in education, psychology, and other social science fields, where it is very common to have meta-analyses involving &lt;em&gt;dependent&lt;/em&gt; effect sizes.&lt;/p&gt;
&lt;p&gt;Dependent effects occur in meta-analyses of group comparisons when primary studies report effects for multiple correlated measures of an outcome, at multiple points in time, or for multiple treatment groups compared to the same control group &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Becker2000multivariate&#34; role=&#34;doc-biblioref&#34;&gt;Becker, 2000&lt;/a&gt;)&lt;/span&gt;. Dependent effects are also common in meta-analyses of correlational effect sizes, where primary studies report more than one relevant correlation coefficient based on the same sample of participants. Methods such as multi-level meta-analysis &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-VandenNoortgate2013threelevel&#34; role=&#34;doc-biblioref&#34;&gt;Van den Noortgate et al., 2013&lt;/a&gt;)&lt;/span&gt; and robust variance estimation &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Hedges2010robust&#34; role=&#34;doc-biblioref&#34;&gt;Hedges et al., 2010&lt;/a&gt;)&lt;/span&gt; are available to accommodate dependent effects when summarizing findings across studies or investigating moderators of effect size using meta-regression, but these techniques have yet to be extended to methods for testing or correcting bias due to selective reporting. Consequently, it’s pretty common to see research synthesis papers that use very sophisticated models for part of the analysis, but then use kludgey, awkward, or hacky approaches when it comes time to investigating selective reporting &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-rodgers2020evaluating&#34; role=&#34;doc-biblioref&#34;&gt;Rodgers &amp;amp; Pustejovsky, 2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Along with &lt;a href=&#34;https://www.air.org/mosaic&#34;&gt;a group of our colleagues&lt;/a&gt; from the American Institutes for Research, we are currently working on a project to develop better methods for investigating selective reporting issues in meta-analyses of dependent effect sizes.
In this post, we will share an early peek under the hood at one little piece of what we’re studying, by sketching out what we think is a promising and pragmatic method for examining selective reporting while &lt;em&gt;also&lt;/em&gt; accounting for effect size dependency. The method is to use a cluster-level bootstrap, which involves re-sampling clusters of observations (i.e., the set of multiple effect size estimates reported within a given primary study) to approximate the sampling distribution of an estimator &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-boos2003introduction&#34; role=&#34;doc-biblioref&#34;&gt;Boos, 2003&lt;/a&gt;; &lt;a href=&#34;#ref-cameron2008bootstrap&#34; role=&#34;doc-biblioref&#34;&gt;Cameron et al., 2008&lt;/a&gt;)&lt;/span&gt;. To illustrate this technique, we will demonstrate how to bootstrap a Vevea-Hedges selection model.&lt;/p&gt;
&lt;p&gt;Selection models comprise a large class of models that have two parts: a model describing the evidence-generation process and a model describing the process by which evidence is reported &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hedges2005selection&#34; role=&#34;doc-biblioref&#34;&gt;Hedges &amp;amp; Vevea, 2005&lt;/a&gt;)&lt;/span&gt;. Vevea-Hedges selection models &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hedges1992modeling&#34; role=&#34;doc-biblioref&#34;&gt;Hedges, 1992&lt;/a&gt;; &lt;a href=&#34;#ref-Hedges1996estimating&#34; role=&#34;doc-biblioref&#34;&gt;Hedges &amp;amp; Vevea, 1996&lt;/a&gt;; &lt;a href=&#34;#ref-vevea1995general&#34; role=&#34;doc-biblioref&#34;&gt;Vevea &amp;amp; Hedges, 1995&lt;/a&gt;)&lt;/span&gt; involve a random effects meta-regression model for the evidence-generation process and a step function for the reporting process. With a step function, we assume that the probability that an effect size estimate is observed depends on the range in which its p-value falls. For instance, effects with &lt;span class=&#34;math inline&#34;&gt;\(.01 &amp;lt; p \leq .05\)&lt;/span&gt; might have some probability &lt;span class=&#34;math inline&#34;&gt;\(\lambda_1\)&lt;/span&gt; of being reported, effects with &lt;span class=&#34;math inline&#34;&gt;\(.05 &amp;lt; p \leq .10\)&lt;/span&gt; might have some other probability &lt;span class=&#34;math inline&#34;&gt;\(\lambda_2\)&lt;/span&gt;, and effects with &lt;span class=&#34;math inline&#34;&gt;\(.10 &amp;lt; p\)&lt;/span&gt; might have some other probability &lt;span class=&#34;math inline&#34;&gt;\(\lambda_3\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Because the Vevea-Hedges model and other selection models separate the data-generation process into these two distinct stages, their parameters have clear interpretations and they can be used to generate bias-adjusted estimates of the distribution of effect sizes and to test for selective reporting issues. The only problem is that available implementations of selection models do not account for effect size dependency—but that’s where cluster bootstrapping could potentially help.&lt;/p&gt;
&lt;div id=&#34;disclaimer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;To be clear, this post is based on work in progress. The cluster-bootstrap selection model that we’re going to demonstrate is an &lt;em&gt;experimental&lt;/em&gt; and &lt;em&gt;exploratory&lt;/em&gt; technique. We’re currently studying its properties and performance using Monte Carlo simulations, but we don’t have formal results to share yet. In the spirit of open and collaborative science, we wrote this post to demonstrate our approach to coding the method, in case others would like to experiment with the technique. Given that there are so few methods available for investigating selective reporting in meta-analyses with dependent effect sizes, we think this method is worth playing with and investigating further, and we would be happy to have others try it out as well. But, if you do so, please treat the results as tentative until we learn more about when the methods work well enough to trust the results.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An Example&lt;/h2&gt;
&lt;p&gt;For demonstrating this method, we will use data from a recent meta-analysis by Lehmann and colleagues &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-lehmann2018metaanalysis&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; that examined the effects of the color red on attractiveness judgments. The data is available via the &lt;a href=&#34;https://wviechtb.github.io/metadat/reference/dat.lehmann2018.html&#34;&gt;&lt;code&gt;metadat&lt;/code&gt;&lt;/a&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-metadat&#34; role=&#34;doc-biblioref&#34;&gt;White et al., 2022&lt;/a&gt;)&lt;/span&gt;. The dataset includes 81 effect sizes from 41 unique studies. You can browse the data for yourself here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metadat)   # for the example dataset
library(tidyverse) # for tidying
library(janitor)   # for tidying variable names
library(metafor)   # for meta-analysis
library(boot)      # for bootstrapping
library(tictoc)    # for keeping time

lehmann_dat &amp;lt;- 
  dat.lehmann2018 %&amp;gt;%
  clean_names() %&amp;gt;%
  mutate(study = str_split_fixed(short_title, pattern = &amp;quot;-&amp;quot;, n = 2)[, 1]) %&amp;gt;%
  arrange(study) %&amp;gt;%
  select(study, presentation = stimuli_presentation, yi, vi, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped table-hover&#34; style=&#34;font-size: 10px; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
study
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
presentation
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
yi
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
vi
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
short_title
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
full_citation
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
pr_publication
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
source_type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
preregistered
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
moderator_group
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
context
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
gender
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_contrast
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_form
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
photo_type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
photo_similarity
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_type
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_items
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_scale
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_scale_bottom
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_scale_top
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
location
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
continent
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
participants
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
participant_notes
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
design
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_majority
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_majority_detail
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_stim
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_match
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_age
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_age
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_red
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_control
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_original
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_match
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
presentation_control
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_m
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_sd
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_m
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_sd
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
sd_diff
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
rm_r
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_attractiveness
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
notes
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
total_sample_size
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
pooled
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Banas, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Banas, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Banas, K. (2014, July 7). Replication of Elliot et al. (2010) for CREP at the University of Edinburgh. Retrieved from osf.io/cvdpw
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scotland
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berthold, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berthold, 2013 - Exp 1 - In Group
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berthold, A. (2013). Unpublished data
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow, M.G., Taylor, G. &amp;amp; Underwood, M. (2013). Context-moderated effect of color on physiological and self-report measures of emotional response. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(37.43/59.24/47.63)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(36.68/34.86/87.99)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow, M.G., Taylor, G. &amp;amp; Underwood, M. (2013). Context-moderated effect of color on physiological and self-report measures of emotional response. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(37.43/59.24/47.63)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(36.68/34.86/87.99)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, C. (2014, August 4). Replication of Elliot et al. (2010). Red, rank, and romance in women viewing men. Retrieved from osf.io/tx2u5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, German translation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not part of CREP because Used white as control condition, dropped yellow as not an original control color, age not included because separated into categories (&amp;lt;25, 26-40, &amp;gt;=41)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
149
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2015 - Class Exp
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, C. (2015). Unpublished data from a class experiment
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adults
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31.40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Boelk &amp;amp; Madden, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Boelk &amp;amp; Madden, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Boelk, K., &amp;amp; Madden, W. (2014, August 5). Fork of Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Retrieved from osf.io/zf7c9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Buechner et al., 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Buechner et al., 2015 - Exp 1 - Prideful Pose
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Buechner, V. L., Maier, M. A., Lichtenfeld, S., &amp;amp; Elliot, A. J. (2015). Emotion Expression and Color: Their Joint Influence on Perceived Attractiveness and Social Position. Current Psychology, 34(2), 422-433. &lt;a href=&#34;http://doi.org/10.1007/s12144-014-9266-x&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1007/s12144-014-9266-x&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Dot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
High School
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16.88
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.9, 59.7, 25.7)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(49.2, 60.2, 278.2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello J., Groeneboom L. &amp;amp; Pollet T. (2017). Romantic red: Do red products enhance the attractiveness of the consumer? Unpublished masters degree manuscript, University of Leiden
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Item
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
129
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello J., Groeneboom L. &amp;amp; Pollet T. (2017). Romantic red: Do red products enhance the attractiveness of the consumer? Unpublished masters degree manuscript, University of Leiden
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Item
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
140
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same filters applied as in Exp 1 (excluded homosexual and preferred not to answer). Control combines blue and green
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
207
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Maier, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Maier, 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Maier, M. a. (2013). The red-attractiveness effect, applying the Ioannidis and Trikalinos (2007b) test, and the broader scientific context: a reply to Francis (2013). Journal of Experimental Psychology. General, 142(1), 297-300. &lt;a href=&#34;http://doi.org/10.1037/a0029592&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0029592&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(42.6, 45.2, 15.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(43.0, -, 296.7)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
144
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.97
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(46.1, 51.2, 29.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(46.1, 51.0, 147.6)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 58.7, 30.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 52.6)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.77
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(45.9, 54.8, 32.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(46.0, 54.9, 283.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.75
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(55.5, 78.0, 28.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.3, 58.8, 29.9)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
df doesn’t match sample size
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mehrabian &amp;amp; Blum’s Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinese
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinese
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinese
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.60
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.3, 51.7, 30.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.5, 51.6, 136.6)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(49.6, 58.8, 30.4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
df doesn’t match sample size
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maner et al perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(54.8, 43.2, 30.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(55.1, 43.7, 283.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.46
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(49.6, 58.8, 30.4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sample size taken from Francis, t(df) seems to be using ANOVA df for post-hoc, age data for both male and female participants (separate was not provided)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Tracy, J. L., Pazda, A. D., &amp;amp; Beall, A. T. (2013). Red enhances women’s attractiveness to men: First evidence suggesting universality. Journal of Experimental Social Psychology, 49(1), 165-168. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2012.07.017&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2012.07.017&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burkina Faso
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Africa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adults
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Black
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Black
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Black
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.80
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(42.7, 51.5, 20.4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(43.4, 51.5, 269.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Frazier, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Frazier, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Frazier, A. (2014, November 13). Fork of Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Retrieved from osf.io/u0mig
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.90
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gilston &amp;amp; Privitera, 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gilston &amp;amp; Privitera, 2016 - Exp 1 - Healthy
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gilston, A., &amp;amp; Privitera, G. J. (2015). A ‘Healthy’ Color: Information About Healthy Eating Attenuates the ‘Red Effect.’ Global Journal of Health Science, 8(1), 56-61. &lt;a href=&#34;https://doi.org/10.5539/gjhs.v8n1p56&#34; class=&#34;uri&#34;&gt;https://doi.org/10.5539/gjhs.v8n1p56&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gueguen, 2012
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gueguen, 2012 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gueguen, N. (2012). Color and Women Attractiveness: When Red Clothed Women Are Perceived to Have More Intense Sexual Intent. The Journal of Social Psychology, 152(3), 261-265. &lt;a href=&#34;http://doi.org/10.1080/00224545.2011.605398&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1080/00224545.2011.605398&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2012.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
France
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control is average of blue, white, and green
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
120
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger, V. M., Goldbach, L., Carbon, C.-C., Allgemeine, A., Psychologie, E., &amp;amp; Note, A. (2015). Men in red: A reexamination of the red-attractiveness effect. Psychonomic Bulletin &amp;amp; Review, 55(4), 1-6. &lt;a href=&#34;http://doi.org/10.3758/s13423-015-0866-8&#34; class=&#34;uri&#34;&gt;http://doi.org/10.3758/s13423-015-0866-8&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, German translation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CIE-Lab(50, 51, 30)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.98
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger, V. M., Goldbach, L., Carbon, C.-C., Allgemeine, A., Psychologie, E., &amp;amp; Note, A. (2015). Men in red: A reexamination of the red-attractiveness effect. Psychonomic Bulletin &amp;amp; Review, 55(4), 1-6. &lt;a href=&#34;http://doi.org/10.3758/s13423-015-0866-8&#34; class=&#34;uri&#34;&gt;http://doi.org/10.3758/s13423-015-0866-8&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, German translation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.60
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CIE-Lab(50, 51, 30)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Johnson et al., 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Johnson et al., 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Johnson, K., Meltzer, A., &amp;amp; Grahe, J. E. (2015, October 12). Fork of Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Retrieved from osf.io/ictud
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.94
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.92
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.99
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yellow group also run, but not included
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Khislavsky, 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Khislavsky, 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Khislavsky, A. (2016, March 14). Replication of Elliot et al. (2010). Red, rank, and romance in women viewing men. Retrieved from osf.io/f2udj
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not reviewed by CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
187
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015 - Exp 1 - Heterosexual
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, F. (2015). Wahrgenommene Attraktivitaet und sexuelle Orientierung: Die Wirkung von Rot und Farbpraeferenzen (Perceived attractiveness and sexual orientation: The effects of red and color preferences). Wiesbaden: Springer. doi: 10.1007/978-3-658-08405-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.83
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Cross-gender rating (females rating males). Age includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
161
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015 - Exp 1 - Heterosexual
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, F. (2015). Wahrgenommene Attraktivitaet und sexuelle Orientierung: Die Wirkung von Rot und Farbpraeferenzen (Perceived attractiveness and sexual orientation: The effects of red and color preferences). Wiesbaden: Springer. doi: 10.1007/978-3-658-08405-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Monograph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Cross-gender rating (males rating females). Age includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
105
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, F. (2015). Wahrgenommene Attraktivitaet und sexuelle Orientierung: Die Wirkung von Rot und Farbpraeferenzen (Perceived attractiveness and sexual orientation: The effects of red and color preferences). Wiesbaden: Springer. doi: 10.1007/978-3-658-08405-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Monograph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Means are only for cross-gender rating (males rating females)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Legate et al., 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Legate et al., 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Legate, N., Baciu, C., Horne, L. M., Fiol, S., Paniagua, D., Muqeet, M., &amp;amp; Zachocki, E. (2015, June 27). Replication of Elliot et al. (2010) at IIT. Retrieved from osf.io/zih7c
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (21 white, 16 asian)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2015 - Class Exp
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White/Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.3, 58.2, 29.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.49
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
116
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White/Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38.32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
114
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
130
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
244
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2015 - Class Exp
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33.88
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
102
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35.85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
104
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
106
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
210
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.3, 58.2, 29.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lin, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lin, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lin, H. (2014). Red-colored products enhance the attractiveness of women. Displays, 35(4), 202-205. &lt;a href=&#34;http://doi.org/10.1016/j.displa.2014.05.009&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.displa.2014.05.009&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Item
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Taiwan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.39
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control condition is blue; silver condition is dropped as it is not an original control color
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maves &amp;amp; Nadler, 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maves &amp;amp; Nadler, 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maves, M., &amp;amp; Nadler, J. T. (2016, June 2). Data and Analysis. Retrieved from osf.io/9bm8v
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.86
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.48
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
130
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015 - Exp 1 - Masculine Face
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., &amp;amp; Trujillo, A. (2015), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015 - Exp 2 - Masculine Face
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., &amp;amp; Trujillo, A. (2015), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28.23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 2 - Long Shirt
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 2 - Tank Top
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 1 - Long Shirt
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 1 - Tank Top
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 3 - Tank Top
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.83
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
106
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 3 - Long Shirt
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.77
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
120
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2012
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2012 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A. D., Elliot, A. J., &amp;amp; Greitemeyer, T. (2012). Sexy red: Perceived sexual receptivity mediates the red-attraction relation in men viewing woman. Journal of Experimental Social Psychology, 48(3), 787-790. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2011.12.009&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2011.12.009&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2012.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Austria
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(40.6, 40.4, 20.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(40.3, 41.2, 146.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A. D., Elliot, A. J., &amp;amp; Greitemeyer, T. (2014). Perceived sexual receptivity and fashionableness: Separate paths linking red and black to perceived attractiveness. Color Research &amp;amp; Application, 39(2), 208-212. &lt;a href=&#34;http://doi.org/10.1002/col.21804&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1002/col.21804&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not specified
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unknown
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (170 white, 142 Asian)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
109
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
125
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
234
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A., Thorstenson &amp;amp; Elliot, A. (2017). Unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single Item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab study
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
red LCh(42.00, 57.92, 348.89), green LCh(41.50, 56.71, 92.17)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
115
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
115
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
115
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.31
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A., Thorstenson &amp;amp; Elliot, A. (2017). Unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single Item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
red LCh(42.00, 57.92, 348.89), green LCh(41.50, 56.71, 92.17)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
228
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
228
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.87
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
228
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016 - Exp 1 - Short Term
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn, L. S., Roberts, S. C., &amp;amp; Pollet, T. V. (2016). Revisiting the Red Effect on Attractiveness and Sexual Receptivity: No Effect of the Color Red on Human Mate Preferences. Evolutionary Psychology, 14(4). &lt;a href=&#34;http://doi.org/10.1177/1474704916673841&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/1474704916673841&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016 - Exp 2 - Short Term
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn, L. S., Roberts, S. C., &amp;amp; Pollet, T. V. (2016). Revisiting the Red Effect on Attractiveness and Sexual Receptivity: No Effect of the Color Red on Human Mate Preferences. Evolutionary Psychology, 14(4). &lt;a href=&#34;http://doi.org/10.1177/1474704916673841&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/1474704916673841&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pollet, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pollet, 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pollet T. (2013). Unpublished data
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Primarily dutch nationality
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28.40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Only blue control color used as other control colors were not in original
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009 - Exp 1 - High Arousal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, M. A. (2009). The influence of the amygdala and color on judgments of attractiveness. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2009.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(185, 26, 23)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(216,216,216)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009 - Exp 1 - Low Arousal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, M. A. (2009). The influence of the amygdala and color on judgments of attractiveness. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2009.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(185, 26, 23)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(216,216,216)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.47
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.21
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.82
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.88
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.75
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.74
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013 - Exp 1 - Adults Rate Young
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz, S., &amp;amp; Singer, M. (2013). Romantic red revisited: Red enhances men’s attraction to young, but not menopausal women. Journal of Experimental Social Psychology, 49(1), 161-164. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2012.08.004&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2012.08.004&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adults
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lum: 35.2, Chroma: 39.3, Hue no specified
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013 - Exp 1 - UGrads Rate Young
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz, S., &amp;amp; Singer, M. (2013). Romantic red revisited: Red enhances men’s attraction to young, but not menopausal women. Journal of Experimental Social Psychology, 49(1), 161-164. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2012.08.004&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2012.08.004&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lum: 35.2, Chroma: 39.3, Hue no specified
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, T., &amp;amp; Klement, V. (2015). The Impact of the Colour Red on Attractiveness Perception. In 4th Advanced Research in Scientific Areas (pp. 20-24). &lt;a href=&#34;http://doi.org/10.18638/arsa.2015.4.1.799&#34; class=&#34;uri&#34;&gt;http://doi.org/10.18638/arsa.2015.4.1.799&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived Attractiveness, subscale of Haselton und Gangestad (2006)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(255.0.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(0.139.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, T., &amp;amp; Klement, V. (2015). The Impact of the Colour Red on Attractiveness Perception. In 4th Advanced Research in Scientific Areas (pp. 20-24). &lt;a href=&#34;http://doi.org/10.18638/arsa.2015.4.1.799&#34; class=&#34;uri&#34;&gt;http://doi.org/10.18638/arsa.2015.4.1.799&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived Attractiveness, subscale of Haselton und Gangestad (2006)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(255.0.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(0.139.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, T. (2015). Romantic Red Effect in the Attractiveness Perception. In Hassacc (pp. 31-34). &lt;a href=&#34;http://doi.org/10.18638/hassacc.2015.3.1.186&#34; class=&#34;uri&#34;&gt;http://doi.org/10.18638/hassacc.2015.3.1.186&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived Attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Stefan &amp;amp; Gueguen, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Stefan &amp;amp; Gueguen, 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Stefan J. &amp;amp; Gueguen, N. (2013). Unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
France
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Data provided by Elliot
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Two-year class project posted on OSF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
102
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age recorded as dichotomy (younger then 20, older than 20) so not included
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.75
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age recorded as dichotomy (younger then 20, older than 20) so not included
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wartenberg et al., 2011
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wartenberg et al., 2011 - Exp 1 - In Group
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wartenberg, W., Hoepfner, T., Potthast, P., &amp;amp; Mirau, A. (2011). If you wear red on a date, you will please your mate. Proceedings of Empiriepraktikumskongress, 6th, Aug. 7, pp 26-27. University of Jena, Germany.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2011.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.86
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Translation of summary provided by Elliot; within subjects info still needed
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014 - Exp 1 - Feminine Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen, F., Zuo, B., Wu, Y., Sun, S., &amp;amp; Liu, K. (2014). Red is Romantic, but Only for Feminine Females: Sexual Dimorphism Moderates Red Effect on Sexual Attraction. Evolutionary Psychology, 12(4), 719-735. &lt;a href=&#34;http://doi.org/10.1177/147470491401200404&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491401200404&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, extracted factor
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.1, 57.7, 27.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.6, 57.6, 278.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control is average of blue and white conditions; only normalized scores provided. Age range includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014 - Exp 1 - Masculine Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen, F., Zuo, B., Wu, Y., Sun, S., &amp;amp; Liu, K. (2014). Red is Romantic, but Only for Feminine Females: Sexual Dimorphism Moderates Red Effect on Sexual Attraction. Evolutionary Psychology, 12(4), 719-735. &lt;a href=&#34;http://doi.org/10.1177/147470491401200404&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491401200404&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, extracted factor
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.1, 57.7, 27.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.6, 57.6, 278.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control is average of blue and white conditions; only normalized scores provided. Age range includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013 - Exp 1 - All
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams, C. L. &amp;amp; Neelon, M. (2013). Conditional beauty: The impact of emotionally linked images on the red effect in sexual attraction. Psi Chi Journal of Psychological Research, 18(1), 10-19.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (noted by authors)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(183,70,60)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(76,105,200)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Data provided by Elliot
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013 - Exp 2 - Positive and Neutral
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams, C. L. &amp;amp; Neelon, M. (2013). Conditional beauty: The impact of emotionally linked images on the red effect in sexual attraction. Psi Chi Journal of Psychological Research, 18(1), 10-19.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (noted by authors)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(183,70,60)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(76,105,200)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Data provided by Elliot
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015 - Exp 1 - More Attractive
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, S. G. (2015). The effect of red on male perceptions of female attractiveness: Moderation by baseline attractiveness of female faces. European Journal of Social Psychology, 45(2), 146-151. &lt;a href=&#34;http://doi.org/10.1002/ejsp.2098&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1002/ejsp.2098&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.90
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.7, 84.6, 34.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.6, -, 265.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.86
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.84
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015 - Exp 2 - More Attractive
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, S. G. (2015). The effect of red on male perceptions of female attractiveness: Moderation by baseline attractiveness of female faces. European Journal of Social Psychology, 45(2), 146-151. &lt;a href=&#34;http://doi.org/10.1002/ejsp.2098&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1002/ejsp.2098&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.7, 84.6, 34.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.7, 84.6, 34.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.98
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue and Gray ratings averaged, then compared to red; original data provided
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;preliminary-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Preliminary Analysis&lt;/h3&gt;
&lt;p&gt;As a little warm-up exercise, here is a basic random effects meta-analysis of these data, fit via the &lt;a href=&#34;https://wviechtb.github.io/metafor/&#34;&gt;metafor&lt;/a&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Viechtbauer2010conducting&#34; role=&#34;doc-biblioref&#34;&gt;Viechtbauer, 2010&lt;/a&gt;)&lt;/span&gt;. We use cluster-robust standard errors to account for effect size dependency.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Estimate random effects model
RE_mod &amp;lt;- rma.uni(yi, vi = vi, data = lehmann_dat, method = &amp;quot;ML&amp;quot;)

# Calculate cluster-robust standard errors
RE_robust &amp;lt;- robust(RE_mod, cluster = study, clubSandwich = TRUE)
RE_robust&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 81; tau^2 estimator: ML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.1009 (SE = 0.0245)
## tau (square root of estimated tau^2 value):      0.3176
## I^2 (total heterogeneity / total variability):   81.54%
## H^2 (total variability / sampling variability):  5.42
## 
## Test for Heterogeneity:
## Q(df = 80) = 246.9683, p-val &amp;lt; .0001
## 
## Number of estimates:   81
## Number of clusters:    41
## Estimates per cluster: 1-6 (mean: 1.98, median: 1)
## 
## Model Results:
## 
## estimate      se¹    tval¹     df¹    pval¹   ci.lb¹   ci.ub¹     
##   0.2069  0.0569   3.6331   23.41   0.0014   0.0892   0.3245   ** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## 1) results based on cluster-robust inference (var-cov estimator: CR2,
##    approx t-test and confidence interval, df: Satterthwaite approx)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The random effects model indicates an average effect size of about 0.21 standard deviations and substantial heterogeneity, with &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.32\)&lt;/span&gt;. The cluster-robust standard error is about 27% bigger than the model-based standard error (not shown) because the latter does not account for dependent effect sizes.&lt;/p&gt;
&lt;p&gt;Here is a contour-enhanced funnel plot of the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funnel(RE_mod, refline = 0, level=c(90, 95, 99), shade=c(&amp;quot;white&amp;quot;, &amp;quot;gray55&amp;quot;, &amp;quot;gray75&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/cluster-bootstrap-selection-model_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The funnel plot shows some asymmetry, suggesting that there is reason to be concerned about selective reporting bias in these data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-selection-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A Selection Model&lt;/h3&gt;
&lt;p&gt;For starters, we will fit a very simple selection model, with a single step in the probability of reporting at &lt;span class=&#34;math inline&#34;&gt;\(\alpha = .025\)&lt;/span&gt;. This is what’s come to be called the &lt;em&gt;three-parameter selection model&lt;/em&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcshane2016adjusting&#34; role=&#34;doc-biblioref&#34;&gt;McShane et al., 2016&lt;/a&gt;)&lt;/span&gt;. The step is defined in terms of a one-sided p-value, so &lt;span class=&#34;math inline&#34;&gt;\(\alpha = .025\)&lt;/span&gt; corresponds to the point where an effect size estimate in the theoretically expected direction would have a regular, two-sided p-value of .05, right at the mystical threshold of statistical significance. We fit the model using &lt;code&gt;metafor&lt;/code&gt;’s &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/selmodel.html&#34;&gt;&lt;code&gt;selmodel()&lt;/code&gt;&lt;/a&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RE_sel &amp;lt;- selmodel(RE_mod, type = &amp;quot;stepfun&amp;quot;, steps = .025)
RE_sel&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 81; tau^2 estimator: ML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.0811 (SE = 0.0261)
## tau (square root of estimated tau^2 value):      0.2848
## 
## Test for Heterogeneity:
## LRT(df = 1) = 37.3674, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub    
##   0.1328  0.0655  2.0267  0.0427  0.0044  0.2612  * 
## 
## Test for Selection Model Parameters:
## LRT(df = 1) = 1.7646, p-val = 0.1840
## 
## Selection Model Results:
## 
##                      k  estimate      se     zval    pval   ci.lb   ci.ub    
## 0     &amp;lt; p &amp;lt;= 0.025  25    1.0000     ---      ---     ---     ---     ---    
## 0.025 &amp;lt; p &amp;lt;= 1      56    0.5485  0.2495  -1.8097  0.0703  0.0594  1.0375  . 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The selection parameter represents the probability that an effect size estimate that is not in the theoretically expected direction or not statistically significant at the conventional level would be included in the synthesis, relative to the probability that an affirmative, statistically significant effect size estimate would be included. In this example, the probability of selection is estimated as 0.55, meaning only about 55% of the non-significant results that we would expect were generated are actually reported. Adjusting for this selection bias, the model estimates an overall average effect size of 0.13 SD—smaller than the unadjusted random effects estimate—with heterogeneity of &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.28\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The problem with this analysis is that the selection model is set up under the assumption that the effect size estimates are all independent. As a result, the reported standard errors are probably smaller than they should be and the confidence intervals are narrower than they should be. We’ll use cluster bootstrapping to get standard errors and confidence intervals that should better account for effect size dependency.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;cluster-bootstrapping-a-selection-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cluster Bootstrapping a Selection Model&lt;/h2&gt;
&lt;p&gt;In R, the &lt;a href=&#34;https://cran.r-project.org/web/packages/boot/boot.pdf&#34;&gt;&lt;code&gt;boot&lt;/code&gt;&lt;/a&gt; package provides tools for running a variety of different bootstrap techniques and obtaining confidence intervals based on bootstrap distributions &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-boot&#34; role=&#34;doc-biblioref&#34;&gt;Canty &amp;amp; Ripley, 2021&lt;/a&gt;)&lt;/span&gt;. It’s been around for ages and has some very nice features, but it requires a bit of trickery to use it for cluster bootstrapping. The main challenge is that the package functionality is set up under the assumption that every row of the dataset should be treated as an independent observation. To make it work for cluster bootstrapping, we will need a function to fit the selection model, which takes in a dataset with one row per cluster and returns a vector of parameter estimates. The function also has to have an index argument which is a vector of row indexes used to create the bootstrap sample. Here is a skeleton for such a function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(
    dat,   # dataset with one row per cluster
    index, # vector of indexes used to create the bootstrap sample
    ...    # any further arguments
) { 
  
  # take subset of data
  boot_dat &amp;lt;- dat[index,]
  
  # fit selection model
  
  # compile parameter estimates into a vector
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;clustering-and-unclustering&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Clustering and unclustering&lt;/h3&gt;
&lt;p&gt;The Lehmann dataset has one row per effect size, sometimes with multiple rows per study, so we need to modify the data to have one row per study. There are at least two ways to accomplish this. One option is to create a dataset consisting only of study-level IDs, then merge it back on to the full data to get the effect-size level data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make a dataset of study IDs
cluster_IDs &amp;lt;- data.frame(study = unique(lehmann_dat$study))

glimpse(cluster_IDs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 41
## Columns: 1
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Ble…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Merge with full data
full_dat &amp;lt;- merge(cluster_IDs, lehmann_dat, by = &amp;quot;study&amp;quot;)

full_dat %&amp;gt;% select(study, yi, vi) %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 81
## Columns: 3
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Big…
## $ yi    &amp;lt;dbl&amp;gt; 0.05716727, 0.55411916, 0.31467980, -0.73259462, 0.07921700, -0.…
## $ vi    &amp;lt;dbl&amp;gt; 0.10267348, 0.06030579, 0.29520322, 0.53354343, 0.02692608, 0.05…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another option is to use the &lt;a href=&#34;https://dplyr.tidyverse.org/reference/nest_by.html&#34;&gt;&lt;code&gt;dplyr::nest_by()&lt;/code&gt;&lt;/a&gt; function to nest the data by cluster &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. Then, we can use &lt;a href=&#34;https://tidyr.tidyverse.org/reference/unnest.html&#34;&gt;&lt;code&gt;tidyr::unnest()&lt;/code&gt;&lt;/a&gt; to recover the effect size level data &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. Like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Nest the data for each study
lehmann_nested &amp;lt;- nest_by(lehmann_dat, study, .key = &amp;quot;data&amp;quot;)

glimpse(lehmann_nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 41
## Columns: 2
## Rowwise: study
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Ble…
## $ data  &amp;lt;list&amp;lt;tibble[,49]&amp;gt;&amp;gt; [&amp;lt;tbl_df[1 x 49]&amp;gt;], [&amp;lt;tbl_df[1 x 49]&amp;gt;], [&amp;lt;tbl_df[2…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Recover the full dataset
full_dat &amp;lt;-
  lehmann_nested %&amp;gt;%
  unnest(data)

full_dat %&amp;gt;% select(study, yi, vi) %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 81
## Columns: 3
## Groups: study [41]
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Big…
## $ yi    &amp;lt;dbl&amp;gt; 0.05716727, 0.55411916, 0.31467980, -0.73259462, 0.07921700, -0.…
## $ vi    &amp;lt;dbl&amp;gt; 0.10267348, 0.06030579, 0.29520322, 0.53354343, 0.02692608, 0.05…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will follow the latter strategy for the remainder of our example.&lt;/p&gt;
&lt;p&gt;With this nest-and-unnest approach, we can fill in a little bit more of our function skeleton:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(
    dat,   # dataset with one row per cluster
    index, # vector of indexes used to create the bootstrap sample
    ...    # any further arguments
) { 
  
  # take subset of data
  boot_dat_cluster &amp;lt;- dat[index, ]
  
  # expand to one row per effect size
  boot_dat &amp;lt;- tidyr::unnest(boot_dat_cluster, data)
  
  # fit selection model
  
  # compile parameter estimates into a vector
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;selection-model-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Selection model function&lt;/h3&gt;
&lt;p&gt;Next, we need to complete the function by writing code to fit the selection model. This is a little bit involved because of the way the &lt;code&gt;metafor&lt;/code&gt; package implements the Vevea-Hedges selection model. We first need to fit a regular random effects model using &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/rma.uni.html&#34;&gt;&lt;code&gt;metafor::rma.uni()&lt;/code&gt;&lt;/a&gt;, then pass the result to the &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/selmodel.html&#34;&gt;&lt;code&gt;metafor::selmodel()&lt;/code&gt;&lt;/a&gt; function to fit a selection model, and then pull out the parameter estimates as a vector. To make the code clearer, we will move this step out into its own function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_sel_model &amp;lt;- function(dat, steps = .025) {
  
  # initial random effects model
  RE_mod &amp;lt;- metafor::rma.uni(
      yi = yi, vi = vi, data = dat, method = &amp;quot;ML&amp;quot;
  )
  
  # fit selection model
  res &amp;lt;- metafor::selmodel(
    RE_mod, type = &amp;quot;stepfun&amp;quot;, steps = steps,
    skiphes = TRUE, # turn off SE calculation
    skiphet = TRUE # turn off heterogeneity test
  )
  
  # compile parameter estimates into a vector
  c(beta = res$beta[,1], tau = sqrt(res$tau2), delta = res$delta[-1])
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the use of &lt;code&gt;skiphes&lt;/code&gt; and &lt;code&gt;skiphet&lt;/code&gt; arguments in the &lt;code&gt;selmodel()&lt;/code&gt; call, which skip the calculation of standard errors and skip the calculation of the test for heterogeneity. We don’t need the standard errors here because we’re going to use bootstrapping instead, and we’re not interested in the heterogeneity test. Turning off these calculations saves computational time.&lt;/p&gt;
&lt;p&gt;A further complication with fitting a selection model is that the parameter estimates are obtained by maximum likelihood, using an iterative optimization algorithm that sometimes fails to converge. To handle non-convergence, we will pass our function through &lt;a href=&#34;https://purrr.tidyverse.org/reference/possibly.html&#34;&gt;&lt;code&gt;purrr::possibly()&lt;/code&gt;&lt;/a&gt; so that errors are suppressed, rather than causing everything to grind to a halt &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. We set the &lt;code&gt;otherwise&lt;/code&gt; argument so that non-convergent results are returned as &lt;code&gt;NA&lt;/code&gt; values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_sel_model &amp;lt;- purrr::possibly(run_sel_model, otherwise = rep(NA_real_, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-first-bootstrap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A first bootstrap&lt;/h3&gt;
&lt;p&gt;Here is the completed fitting function called &lt;code&gt;fit_selmodel()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(dat, 
                         index = 1:nrow(dat), 
                         steps = 0.025) {
  
  # take subset of data
  boot_dat_cluster &amp;lt;- dat[index, ]
  
  # expand to one row per effect size
  boot_dat &amp;lt;- tidyr::unnest(boot_dat_cluster, data)
  
  # fit selection model, return vector
  run_sel_model(boot_dat, steps = steps)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we take a subset of the data based on the index argument. This generates a bootstrap sample from the original data based on re-sampled clusters. We then use &lt;a href=&#34;https://tidyr.tidyverse.org/reference/unnest.html&#34;&gt;&lt;code&gt;tidyr::unnest()&lt;/code&gt;&lt;/a&gt; to get the effect size level data for those re-sampled clusters. We then re-fit the model using our &lt;code&gt;run_sel_model()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Now let’s apply our function to the Lehmann dataset. We will first need to create a nested version of the dataset, with one row per study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lehmann_nested &amp;lt;- nest_by(lehmann_dat, study, .key = &amp;quot;data&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can fit the selection model using &lt;code&gt;fit_sel_model()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel(lehmann_nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## beta.intrcpt          tau        delta 
##    0.1327996    0.2848302    0.5484540&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results reproduce what we saw earlier when we estimated the three parameter selection model.&lt;/p&gt;
&lt;p&gt;Now we can bootstrap using the &lt;a href=&#34;https://cran.r-project.org/web/packages/boot/boot.pdf&#34;&gt;&lt;code&gt;boot::boot()&lt;/code&gt;&lt;/a&gt; function. The inputs to &lt;code&gt;boot()&lt;/code&gt; are the nested dataset, the function to fit the selection model, and then any additional arguments passed to &lt;code&gt;fit_selmodel()&lt;/code&gt;—here we include an argument for &lt;code&gt;steps&lt;/code&gt;—and finally, the number of bootstrap replications:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate bootstrap
set.seed(20230321)

tic()

boots &amp;lt;- boot(
  data = lehmann_nested,            # nested dataset
  statistic = fit_selmodel,         # function for fitting selection model
  steps = .025,                     # further arguments to the fitting function
  R = 1999                          # number of bootstraps
)

time_seq &amp;lt;- toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 265.2 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code takes a while to run, but we can speed it up with parallel processing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parallel-processing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Parallel processing&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;boot&lt;/code&gt; package has some handy parallel processing features, but they can be a bit finicky to use here because of how R manages environments across multiple processes. With the above code, we can’t simply turn on parallel processing because the worker processes won’t know where to find the &lt;code&gt;run_sel_model()&lt;/code&gt; function that gets called inside &lt;code&gt;fit_selmodel()&lt;/code&gt;. To fix this, we include the &lt;code&gt;run_sel_model()&lt;/code&gt; function &lt;em&gt;inside&lt;/em&gt; our fitting function, as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(dat, 
                         index = 1:nrow(dat), 
                         steps = 0.025) {
  
  # take subset of data
  boot_dat_cluster &amp;lt;- dat[index, ]
  
  # expand to one row per effect size
  boot_dat &amp;lt;- tidyr::unnest(boot_dat_cluster, data)
  
  # build run_selmodel
  run_sel_model &amp;lt;- function(dat, steps = .025) {
  
    # initial random effects model
    RE_mod &amp;lt;- metafor::rma.uni(
      yi = yi, vi = vi, data = dat, method = &amp;quot;ML&amp;quot;
    )
    
    # fit selection model
    res &amp;lt;- metafor::selmodel(
      RE_mod, type = &amp;quot;stepfun&amp;quot;, steps = steps,
      skiphes = TRUE, # turn off SE calculation
      skiphet = TRUE # turn off heterogeneity test
    )
    
    # compile parameter estimates into a vector
    c(beta = res$beta[,1], tau = sqrt(res$tau2), delta = res$delta[-1])
    
  }
  
  p &amp;lt;- 2L + length(steps)  # calculate total number of model parameters
  
  # error handling for run_sel_model
  run_sel_model &amp;lt;- purrr::possibly(run_sel_model, otherwise = rep(NA_real_, p))
  
  # fit selection model, return vector of parameter estimates
  run_sel_model(boot_dat, steps = steps)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can call &lt;code&gt;boot()&lt;/code&gt; with options for parallel processing. The machine we used to compile this post has 12 cores. We will use half of the available cores for parallel processing. The configuration of parallel processing will depend on your operating system (different options are available for Mac), so you may need to adapt this code a bit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ncpus &amp;lt;- parallel::detectCores() / 2

# Generate bootstrap
set.seed(20230321)

tic()

boots &amp;lt;- boot(
  data = lehmann_nested,
  statistic = fit_selmodel, steps = .025,
  R = 1999,
  parallel = &amp;quot;snow&amp;quot;, ncpus = ncpus # parallel processing options
)

time_par &amp;lt;- toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 63.08 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Parallel processing is really helpful here. We get 2000 bootstraps in 63 seconds, 4.2 times faster than sequential processing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-errors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Standard Errors&lt;/h3&gt;
&lt;p&gt;The standard deviations of the bootstrapped parameter estimates can be interpreted as standard errors for the parameter estimates that take into account the dependence structure of the effect size estimates. Here is a table comparing the cluster-bootstrapped standard errors to the model-based standard errors generated by &lt;code&gt;selmodel()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est &amp;lt;- boots$t0 # original parameter estimates

# calculate bootstrap SEs
boot_SE &amp;lt;- apply(boots$t, 2, sd, na.rm = TRUE)  

# calculate model-based SEs
model_SE &amp;lt;- with(RE_sel, c(se, se.tau2 / (2 * sqrt(tau2)), se.delta[-1]))

# make a table
res &amp;lt;- tibble(
  Parameter = names(est),
  Est = est,
  `SE(bootstrap)` = boot_SE,
  `SE(model)` = model_SE,
  `SE(bootstrap) / SE(model)` = boot_SE / model_SE
)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-condensed&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Parameter
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Est
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SE(bootstrap)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SE(model)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SE(bootstrap) / SE(model)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
beta.intrcpt
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.133
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.113
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.066
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.732
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tau
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.285
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.148
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.046
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.233
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
delta
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.548
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.780
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.127
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The standard errors based on cluster bootstrapping are all substantially larger than the model-based standard errors, which don’t account for dependence.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;confidence-intervals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Confidence Intervals&lt;/h3&gt;
&lt;p&gt;For reporting results from this sort of analysis, it is useful to provide confidence intervals along with the model parameter estimates and standard errors. These can be calculated using the &lt;a href=&#34;https://cran.r-project.org/web/packages/boot/boot.pdf&#34;&gt;&lt;code&gt;boot::boot_ci()&lt;/code&gt;&lt;/a&gt; function. This function provides several different types of confidence intervals; for illustration, we will stick with simple percentile confidence intervals, which are calculated by taking percentiles of the bootstrap distribution of each parameter estimate. To use the function, we’ll specify the type of confidence interval and the index of the parameter we want. An index of 1 is for the overall average effect size:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot.ci(boots, type = &amp;quot;perc&amp;quot;, index = 1) # For overall average ES&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1995 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boots, type = &amp;quot;perc&amp;quot;, index = 1)
## 
## Intervals : 
## Level     Percentile     
## 95%   (-0.0038,  0.4171 )  
## Calculations and Intervals on Original Scale&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the confidence interval for between-study heterogeneity:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot.ci(boots, type = &amp;quot;perc&amp;quot;, index = 2) # For heterogeneity&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1995 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boots, type = &amp;quot;perc&amp;quot;, index = 2)
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.001,  0.489 )  
## Calculations and Intervals on Original Scale&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And for the selection weight:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot.ci(boots, type = &amp;quot;perc&amp;quot;, index = 3) # For selection weight&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1995 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boots, type = &amp;quot;perc&amp;quot;, index = 3)
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.0574,  2.7536 )  
## Calculations and Intervals on Original Scale&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Percentile confidence intervals can be asymmetric, and here the confidence interval for the selection weight parameter is notably asymmetric. The end-points of the confidence interval range from 0.057 (which represents very strong selective reporting, with only 6% of non-significant results reported) to 2.754 (which represents very strong selection &lt;em&gt;against&lt;/em&gt; affirmative results).&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; So, overall we can’t really draw any strong conclusions about the strength of selective reporting.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this post, we’ve demonstrated how to code a cluster-level bootstrap for a three parameter version of the Vevea-Hedges selection model. We think this cluster-bootstrapping technique is interesting and promising because it can be applied with a very broad swath of models and methods to investigate selective reporting. For instance, the code we’ve demonstrated could be modified by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using a meta-regression model instead of just a summary meta-analysis;&lt;/li&gt;
&lt;li&gt;using a different form of selection function such as the beta-weight model proposed by Citkowicz and Vevea &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Citkowicz2017parsimonious&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; or a more elaborate step function with multiple steps; or&lt;/li&gt;
&lt;li&gt;using a step function model applied across subsets of effect sizes, as in &lt;span class=&#34;citation&#34;&gt;Coburn &amp;amp; Vevea (&lt;a href=&#34;#ref-Coburn2015publication&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;a href=&#34;https://wviechtb.github.io/metafor/&#34;&gt;metafor&lt;/a&gt; package implements an expansive set of selection models with the &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/selmodel.html&#34;&gt;&lt;code&gt;selmodel&lt;/code&gt;&lt;/a&gt; function, so one could really just swap specifications in and out. In principle, the cluster-level bootstrap could also be used in combination with other forms of selective reporting analysis such as PET-PEESE &lt;span class=&#34;citation&#34;&gt;(although with such regression adjustments, cluster-robust variance estimation is also an option, see &lt;a href=&#34;#ref-rodgers2020evaluating&#34; role=&#34;doc-biblioref&#34;&gt;Rodgers &amp;amp; Pustejovsky, 2020&lt;/a&gt;)&lt;/span&gt; or Copas-style sensitivity analyses &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Copas2001sensitivity&#34; role=&#34;doc-biblioref&#34;&gt;Copas &amp;amp; Shi, 2001&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We are currently studying the performance of bootstrapping a three parameter selection model in some big Monte Carlo simulations. Based on some very preliminary results, it looks like the cluster bootstrapped selection model provides confidence intervals with reasonable coverage levels. We have more to do before we share these results, so again we want to emphasize that what we have demonstrated in this post is &lt;em&gt;experimental&lt;/em&gt; and &lt;em&gt;exploratory&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Further questions we need to investigate are how things work if we include covariates in the selection model, whether there are better variations of the bootstrap than what we have demonstrated here &lt;span class=&#34;citation&#34;&gt;(e.g., the fractionally weighted bootstrapping, &lt;a href=&#34;#ref-xu2020applications&#34; role=&#34;doc-biblioref&#34;&gt;Xu et al., 2020&lt;/a&gt;)&lt;/span&gt;, and the limits of this method in terms of the number of studies needed for adequate performance. If things pan out, we also plan to turn the workflow we’ve demonstrated here into some more user-friendly functions, perhaps as part of the &lt;a href=&#34;https://meghapsimatrix.github.io/wildmeta/index.html&#34;&gt;wildmeta&lt;/a&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-vanaert2016conducting&#34; class=&#34;csl-entry&#34;&gt;
Aert, R. C. M. van, Wicherts, J. M., &amp;amp; Assen, M. A. L. M. van. (2016). Conducting meta-analyses based on &lt;em&gt;p&lt;/em&gt; values: Reservations and recommendations for applying &lt;em&gt;p&lt;/em&gt; -uniform and &lt;em&gt;p&lt;/em&gt; -curve. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(5), 713–729. &lt;a href=&#34;https://doi.org/10.1177/1745691616650874&#34;&gt;https://doi.org/10.1177/1745691616650874&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-VanAssen2015meta&#34; class=&#34;csl-entry&#34;&gt;
Assen, M. A. L. M. van, Van Aert, R. C. M., &amp;amp; Wicherts, J. M. (2015). &lt;span class=&#34;nocase&#34;&gt;Meta-analysis using effect size distributions of only statistically significant studies&lt;/span&gt;. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;20&lt;/em&gt;(3), 293–309. https://doi.org/&lt;a href=&#34;http://dx.doi.org/10.1037/met0000025&#34;&gt;http://dx.doi.org/10.1037/met0000025&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Becker2000multivariate&#34; class=&#34;csl-entry&#34;&gt;
Becker, B. J. (2000). &lt;span class=&#34;nocase&#34;&gt;Multivariate Meta-analysis&lt;/span&gt;. In S. D. Brown &amp;amp; H. E. A. Tinsley (Eds.), &lt;em&gt;Handbook of applied multivariate statistics and mathematical modeling&lt;/em&gt; (pp. 499–525). Academic Press. &lt;a href=&#34;https://doi.org/10.1016/B978-012691360-6/50018-5&#34;&gt;https://doi.org/10.1016/B978-012691360-6/50018-5&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-begg1994operating&#34; class=&#34;csl-entry&#34;&gt;
Begg, C. B., &amp;amp; Mazumdar, M. (1994). Operating characteristics of a rank correlation test for publication bias. &lt;em&gt;Biometrics&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(4), 1088. &lt;a href=&#34;https://doi.org/10.2307/2533446&#34;&gt;https://doi.org/10.2307/2533446&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-boos2003introduction&#34; class=&#34;csl-entry&#34;&gt;
Boos, D. D. (2003). Introduction to the bootstrap world. &lt;em&gt;Statistical Science&lt;/em&gt;, &lt;em&gt;18&lt;/em&gt;(2), 168–174.
&lt;/div&gt;
&lt;div id=&#34;ref-cameron2008bootstrap&#34; class=&#34;csl-entry&#34;&gt;
Cameron, A. C., Gelbach, J. B., &amp;amp; Miller, D. L. (2008). Bootstrap-based improvements for inference with clustered errors. &lt;em&gt;The Review of Economics and Statistics&lt;/em&gt;, &lt;em&gt;90&lt;/em&gt;(3), 414–427.
&lt;/div&gt;
&lt;div id=&#34;ref-boot&#34; class=&#34;csl-entry&#34;&gt;
Canty, A., &amp;amp; Ripley, B. D. (2021). &lt;em&gt;Boot: Bootstrap r (s-plus) functions&lt;/em&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-Citkowicz2017parsimonious&#34; class=&#34;csl-entry&#34;&gt;
Citkowicz, M., &amp;amp; Vevea, J. L. (2017). &lt;span class=&#34;nocase&#34;&gt;A parsimonious weight function for modeling publication bias&lt;/span&gt;. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;22&lt;/em&gt;(1), 28–41. &lt;a href=&#34;https://doi.org/10.1037/met0000119&#34;&gt;https://doi.org/10.1037/met0000119&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Coburn2015publication&#34; class=&#34;csl-entry&#34;&gt;
Coburn, K. M., &amp;amp; Vevea, J. L. (2015). &lt;span class=&#34;nocase&#34;&gt;Publication bias as a function of study characteristics&lt;/span&gt;. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;20&lt;/em&gt;(3), 310–330. &lt;a href=&#34;https://doi.org/10.1037/met0000046&#34;&gt;https://doi.org/10.1037/met0000046&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Copas2001sensitivity&#34; class=&#34;csl-entry&#34;&gt;
Copas, J., &amp;amp; Shi, J. Q. (2001). &lt;span class=&#34;nocase&#34;&gt;A sensitivity analysis for publication bias in systematic reviews.&lt;/span&gt; &lt;em&gt;Statistical Methods in Medical Research&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;, 251–265.
&lt;/div&gt;
&lt;div id=&#34;ref-duval2000nonparametric&#34; class=&#34;csl-entry&#34;&gt;
Duval, S., &amp;amp; Tweedie, R. (2000). A nonparametric &#34;trim and fill&#34; method of accounting for publication bias in meta-analysis. &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt;, &lt;em&gt;95&lt;/em&gt;(449), 89–98. &lt;a href=&#34;https://doi.org/10.2307/2669529&#34;&gt;https://doi.org/10.2307/2669529&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-egger1997bias&#34; class=&#34;csl-entry&#34;&gt;
Egger, M., Smith, G. D., Schneider, M., &amp;amp; Minder, C. (1997). Bias in meta-analysis detected by a simple, graphical test. &lt;em&gt;BMJ&lt;/em&gt;, &lt;em&gt;315&lt;/em&gt;(7109), 629–634.
&lt;/div&gt;
&lt;div id=&#34;ref-hedges1992modeling&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V. (1992). Modeling publication selection effects in meta-analysis. &lt;em&gt;Statistical Science&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;(2), 246–255.
&lt;/div&gt;
&lt;div id=&#34;ref-Hedges2010robust&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V., Tipton, E., &amp;amp; Johnson, M. C. (2010). &lt;span class=&#34;nocase&#34;&gt;Robust variance estimation in meta-regression with dependent effect size estimates&lt;/span&gt;. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(1), 39–65. &lt;a href=&#34;https://doi.org/10.1002/jrsm.5&#34;&gt;https://doi.org/10.1002/jrsm.5&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Hedges1996estimating&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V., &amp;amp; Vevea, J. L. (1996). &lt;span class=&#34;nocase&#34;&gt;Estimating effect size under publication bias: Small sample properties and robustness of a random effects selection model&lt;/span&gt;. &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt;, &lt;em&gt;21&lt;/em&gt;(4), 299. &lt;a href=&#34;https://doi.org/10.2307/1165338&#34;&gt;https://doi.org/10.2307/1165338&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hedges2005selection&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V., &amp;amp; Vevea, J. L. (2005). Selection method approaches. In &lt;em&gt;Publication bias in meta-analysis: Prevention, assessment, and adjustments&lt;/em&gt; (pp. 145–174). John Wiley &amp;amp; Sons.
&lt;/div&gt;
&lt;div id=&#34;ref-ioannidis2007exploratory&#34; class=&#34;csl-entry&#34;&gt;
Ioannidis, J. P. A., &amp;amp; Trikalinos, T. A. (2007). An exploratory test for an excess of significant findings. &lt;em&gt;Clinical Trials&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(3), 245–253. &lt;a href=&#34;https://doi.org/10.1177/1740774507079441&#34;&gt;https://doi.org/10.1177/1740774507079441&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-lehmann2018metaanalysis&#34; class=&#34;csl-entry&#34;&gt;
Lehmann, G. K., Elliot, A. J., &amp;amp; Calin-Jageman, R. J. (2018). Meta-analysis of the effect of red on perceived attractiveness. &lt;em&gt;Evolutionary Psychology&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(4), 147470491880241. &lt;a href=&#34;https://doi.org/10.1177/1474704918802412&#34;&gt;https://doi.org/10.1177/1474704918802412&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mathur2020sensitivity&#34; class=&#34;csl-entry&#34;&gt;
Mathur, M. B., &amp;amp; VanderWeele, T. J. (2020). Sensitivity analysis for publication bias in meta‐analyses. &lt;em&gt;Journal of the Royal Statistical Society: Series C (Applied Statistics)&lt;/em&gt;, &lt;em&gt;69&lt;/em&gt;(5), 1091–1119. &lt;a href=&#34;https://doi.org/10.1111/rssc.12440&#34;&gt;https://doi.org/10.1111/rssc.12440&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcshane2016adjusting&#34; class=&#34;csl-entry&#34;&gt;
McShane, B. B., Böckenholt, U., &amp;amp; Hansen, K. T. (2016). Adjusting for publication bias in meta-analysis an evaluation of selection methods and some cautionary notes. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(5), 730–749. &lt;a href=&#34;http://pps.sagepub.com/content/11/5/730.short&#34;&gt;http://pps.sagepub.com/content/11/5/730.short&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rodgers2020evaluating&#34; class=&#34;csl-entry&#34;&gt;
Rodgers, M. A., &amp;amp; Pustejovsky, J. E. (2020). Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes. &lt;em&gt;Psychological Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1037/met0000300&#34;&gt;https://doi.org/10.1037/met0000300&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rothstein2006publication&#34; class=&#34;csl-entry&#34;&gt;
Rothstein, H. R., Sutton, A. J., &amp;amp; Borenstein, M. (2006). &lt;em&gt;Publication bias in meta-analysis: Prevention, assessment and adjustments&lt;/em&gt;. John Wiley &amp;amp; Sons.
&lt;/div&gt;
&lt;div id=&#34;ref-simonsohn2014pcurve&#34; class=&#34;csl-entry&#34;&gt;
Simonsohn, U., Nelson, L. D., &amp;amp; Simmons, J. P. (2014). P-curve and effect size: Correcting for publication bias using only significant results. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(6), 666–681. &lt;a href=&#34;https://doi.org/10.1177/1745691614553988&#34;&gt;https://doi.org/10.1177/1745691614553988&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stanley2008metaregression&#34; class=&#34;csl-entry&#34;&gt;
Stanley, T. D. (2008). Meta-regression methods for detecting and estimating empirical effects in the presence of publication selection*. &lt;em&gt;Oxford Bulletin of Economics and Statistics&lt;/em&gt;, &lt;em&gt;70&lt;/em&gt;(1), 103–127. &lt;a href=&#34;https://doi.org/10.1111/j.1468-0084.2007.00487.x&#34;&gt;https://doi.org/10.1111/j.1468-0084.2007.00487.x&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stanley2014metaregression&#34; class=&#34;csl-entry&#34;&gt;
Stanley, T. D., &amp;amp; Doucouliagos, H. (2014). Meta-regression approximations to reduce publication selection bias. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;5&lt;/em&gt;(1), 60–78.
&lt;/div&gt;
&lt;div id=&#34;ref-sterne2001funnel&#34; class=&#34;csl-entry&#34;&gt;
Sterne, J. A. C., &amp;amp; Egger, M. (2001). Funnel plots for detecting bias in meta-analysis: Guidelines on choice of axis. &lt;em&gt;Journal of Clinical Epidemiology&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(10), 1046–1055.
&lt;/div&gt;
&lt;div id=&#34;ref-Sterne2011recommendations&#34; class=&#34;csl-entry&#34;&gt;
Sterne, J. A. C., Sutton, A. J., Ioannidis, J. P. A., Terrin, N., Jones, D. R., Lau, J., Carpenter, J., Rücker, G., Harbord, R. M., Schmid, C. H., Tetzlaff, J., Deeks, J. J., Peters, J. L., Macaskill, P., Schwarzer, G., Duval, S., Altman, D. G., Moher, D., &amp;amp; Higgins, J. P. T. (2011). &lt;span class=&#34;nocase&#34;&gt;Recommendations for examining and interpreting funnel plot asymmetry in meta-analyses of randomised controlled trials.&lt;/span&gt; &lt;em&gt;BMJ&lt;/em&gt;, &lt;em&gt;343&lt;/em&gt;, d4002. &lt;a href=&#34;https://doi.org/10.1136/bmj.d4002&#34;&gt;https://doi.org/10.1136/bmj.d4002&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-sutton2009publication&#34; class=&#34;csl-entry&#34;&gt;
Sutton, A. (2009). Publication bias. In &lt;em&gt;The handbook of research synthesis and meta-analysis&lt;/em&gt; (pp. 435–445). Russell Sage Foundation.
&lt;/div&gt;
&lt;div id=&#34;ref-VandenNoortgate2013threelevel&#34; class=&#34;csl-entry&#34;&gt;
Van den Noortgate, W., López-López, J. A., Marín-Martínez, F., &amp;amp; Sánchez-Meca, J. (2013). &lt;span class=&#34;nocase&#34;&gt;Three-level meta-analysis of dependent effect sizes&lt;/span&gt;. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;45&lt;/em&gt;(2), 576–594. &lt;a href=&#34;https://doi.org/10.3758/s13428-012-0261-6&#34;&gt;https://doi.org/10.3758/s13428-012-0261-6&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vevea1995general&#34; class=&#34;csl-entry&#34;&gt;
Vevea, J. L., &amp;amp; Hedges, L. V. (1995). A general linear model for estimating effect size in the presence of publication bias. &lt;em&gt;Psychometrika&lt;/em&gt;, &lt;em&gt;60&lt;/em&gt;(3), 419–435. &lt;a href=&#34;https://doi.org/10.1007/BF02294384&#34;&gt;https://doi.org/10.1007/BF02294384&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vevea2005publication&#34; class=&#34;csl-entry&#34;&gt;
Vevea, J. L., &amp;amp; Woods, C. M. (2005). Publication bias in research synthesis: Sensitivity analysis using a priori weight functions. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(4), 428–443. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.10.4.428&#34;&gt;https://doi.org/10.1037/1082-989X.10.4.428&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Viechtbauer2010conducting&#34; class=&#34;csl-entry&#34;&gt;
Viechtbauer, W. (2010). &lt;span class=&#34;nocase&#34;&gt;Conducting meta-analyses in R with the metafor package&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(3), 1–48.
&lt;/div&gt;
&lt;div id=&#34;ref-metadat&#34; class=&#34;csl-entry&#34;&gt;
White, T., Noble, D., Senior, A., Hamilton, W. K., &amp;amp; Viechtbauer, W. (2022). &lt;em&gt;Metadat: Meta-analysis datasets&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=metadat&#34;&gt;https://CRAN.R-project.org/package=metadat&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the &lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-xu2020applications&#34; class=&#34;csl-entry&#34;&gt;
Xu, L., Gotwalt, C., Hong, Y., King, C. B., &amp;amp; Meeker, W. Q. (2020). Applications of the fractional-random-weight bootstrap. &lt;em&gt;The American Statistician&lt;/em&gt;, &lt;em&gt;74&lt;/em&gt;(4), 345–358. &lt;a href=&#34;https://doi.org/10.1080/00031305.2020.1731599&#34;&gt;https://doi.org/10.1080/00031305.2020.1731599&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Technically, these parameters &lt;span class=&#34;math inline&#34;&gt;\(\lambda_1,\lambda_2,\lambda_3\)&lt;/span&gt; are not absolute probabilities but instead &lt;em&gt;relative&lt;/em&gt; risks of being reported, compared to a reference range of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values. In the above example, they would be defined relative to the probability of being reported for an effect size estimate with &lt;span class=&#34;math inline&#34;&gt;\(p \leq .01\)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Compare this to the model-based confidence interval of &lt;span class=&#34;math inline&#34;&gt;\([0.059, 1.037]\)&lt;/span&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>POMADE</title>
      <link>https://www.jepusto.com/software/pomade/</link>
      <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/software/pomade/</guid>
      <description>&lt;p&gt;An R package for computing power levels, minimum detectable effect sizes, and minimum required sample sizes for the test of the overall average effect size in meta-analysis of dependent effect sizes. The package also includes functions for creating plots of power analysis results.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Single case design research in Special Education: Next generation standards and considerations</title>
      <link>https://www.jepusto.com/publication/single-case-next-generation-standards/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/single-case-next-generation-standards/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Power approximations for overall average effects in meta-analysis of dependent effect sizes</title>
      <link>https://www.jepusto.com/publication/power-approximations-for-dependent-effects/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/power-approximations-for-dependent-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating narrative performance in children with developmental language disorder: A systematic review and meta-analysis</title>
      <link>https://www.jepusto.com/publication/investigating-narrative-performance/</link>
      <pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/investigating-narrative-performance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-level meta-analysis of single-case experimental designs using robust variance estimation</title>
      <link>https://www.jepusto.com/publication/sced-mlma-rve/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/sced-mlma-rve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meta-Analysis with robust variance estimation: Expanding the range of working models</title>
      <link>https://www.jepusto.com/publication/rve-meta-analysis-expanding-the-range/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/rve-meta-analysis-expanding-the-range/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cluster wild bootstrapping to handle dependent effect sizes in meta-analysis with a small number of studies</title>
      <link>https://www.jepusto.com/publication/cluster-wild-bootstrap-for-meta-analysis/</link>
      <pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/cluster-wild-bootstrap-for-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Examining the effects of social stories on challenging behavior and prosocial skills in young children: A systematic review and meta-analysis</title>
      <link>https://www.jepusto.com/publication/effects-of-social-stories-on-challenging-behavior-and-prosocial-skills/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/effects-of-social-stories-on-challenging-behavior-and-prosocial-skills/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Variance component estimates in meta-analysis with mis-specified sampling correlation</title>
      <link>https://www.jepusto.com/variance-components-with-misspecified-correlation/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/variance-components-with-misspecified-correlation/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In a recent paper with Beth Tipton, we proposed &lt;a href=&#34;https://www.jepusto.com/publication/rve-meta-analysis-expanding-the-range/&#34;&gt;new working models&lt;/a&gt; for meta-analyses involving dependent effect sizes. The central idea of our approach is to use a working model that captures the main features of the effect size data, such as by allowing for both between- and within-study heterogeneity in the true effect sizes (rather than only between-study heterogeneity). Doing so will lead to more precise estimates of overall average effects or, in models that include predictor variables, more precise estimates of meta-regression coefficients. Further, one can combine this working model with robust variance estimation methods to provide protection against the possibility that some of the model’s assumptions could be mis-specified.&lt;/p&gt;
&lt;p&gt;In order to estimate these new working models, the analyst must first make some assumption about the degree of correlation between effect size estimates that come from the same sample. In typical applications, it can be difficult to obtain good empirical information about the correlation between effect size estimates, and so it is common to impose some simplifying assumptions and use rough guesses about the degree of correlation. There’s a sense that this might not matter much—particularly because robust variance estimation should protect the inferences if the assumptions about the correlation are wrong. However, I’m still curious about the extent to which these assumptions about the correlation structure matter for anything.&lt;/p&gt;
&lt;p&gt;There’s a few reasons to wonder about how much the correlation matters. One is that the analyst might actually care about the variance component estimates from the working model, if they’re substantively interested in the extent of heterogeneity or if they’re trying to make predictions about the distribution of effect sizes that could be expected in a new study. Compared to earlier working models, the variance component estimates of the models that we proposed in the paper seem to be relatively more sensitive to the assumed correlation. Second, one alternative analytic strategy that’s been proposed (and applied) for meta-analysis of dependent effect sizes is to use a multi-level meta-analysis (MLMA) model. The MLMA is a special case of the correlated-and-hierarchical effects model that we described in the paper, the main difference being that MLMA &lt;em&gt;ignores&lt;/em&gt; any correlations between effect size estimates (at the level of the sampling errors), or equivalently, assumes that the correlations are all zero. Thus, MLMA is one specific way that this correlation assumption might be mis-specified. There’s some simulation evidence that inferences based on MLMA may be robust (even without using robust variance estimation), but it’s not clear how general this robustness property might be.&lt;/p&gt;
&lt;p&gt;In this post, I’m going to look at the implications of using a mis-specified assumption about the sampling correlation for the variance components in the correlated-and-hierarchical effects working model. As in &lt;a href=&#34;https://www.jepusto.com/weighting-in-multivariate-meta-analysis/&#34;&gt;my previous post on weights in multivariate meta-analysis&lt;/a&gt;, I’m going to mostly limit consideration to the simple (but important!) case of an intercept-only model, without any further predictors of effect size, to see what can be learned about how the variance components can go wrong.&lt;/p&gt;
&lt;div id=&#34;the-correlated-and-hierarchical-effects-che-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The correlated-and-hierarchical effects (CHE) model&lt;/h1&gt;
&lt;p&gt;Consider a meta-analytic dataset with effect size estimates &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,k_j\)&lt;/span&gt; indexes effect size estimates within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes studies, for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;. Say that effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; has sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{ij}\)&lt;/span&gt;, and there is some sampling correlation between effect sizes &lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, denoted &lt;span class=&#34;math inline&#34;&gt;\(\phi_{hij}\)&lt;/span&gt;.
The correlated-and-hierarchical effects (or CHE) model describes the distribution of effect sizes using random effects to capture between-study heterogeneity (as in the basic random effects model) and within-study heterogeneity in true effect sizes. In hierarchical notation, the model is
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
T_{ij} &amp;amp;= \theta_j + \nu_{ij} + e_{ij} \\
\theta_j &amp;amp;= \mu + \eta_j
\end{align}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\Var(e_{ij}) = \sigma^2_{ij}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\Var(\nu_{ij}) = \omega^2\)&lt;/span&gt; is the within-study variance, and &lt;span class=&#34;math inline&#34;&gt;\(\Var(\eta_j) = \tau^2\)&lt;/span&gt; is the between-study variance.
To simplify things, let us also assume that the effect size estimates from a given study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; all have equal sampling variance, so &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{1j} = \sigma^2_{2j} = \cdots = \sigma^2_{k_jj} = \sigma^2_j\)&lt;/span&gt;, and that there is a common correlation between any pair of effect size estimates from the same study, so &lt;span class=&#34;math inline&#34;&gt;\(\Cov(e_{hj}, e_{ij}) = \phi \sigma^2_j\)&lt;/span&gt; for some correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Typically, the analyst would estimate this working model using restricted maximum likelihood (REML) estimation to obtain estimates of the variance components &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;, after specifying a value of &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. With an adequately large sample of studies, the REML estimators should be close-to-unbiased and accurate. But what if the assumed correlation is wrong? Let’s suppose that the analyst estimates (via REML) the CHE working model but uses the assumption that there is a common correlation between effect size estimates of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, which is not necessarily equal to the true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. What are the consequences for estimating &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mis-specified-reml&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mis-specified REML&lt;/h1&gt;
&lt;p&gt;To figure out what’s going on here, we need to know something about how REML estimators behave under mis-specified models. For starters, I’ll work with a more general case than the CHE model described above. Suppose that we have a vector of multi-variate normal outcomes &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, explained by a set of covariates &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt;, and with true variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi_j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_j \ \sim \ N\left( \mathbf{X}_j \beta, \boldsymbol\Phi_j \right)
\]&lt;/span&gt;
However, suppose that we posit a variance structure &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega_j(\boldsymbol\theta)\)&lt;/span&gt;, which is a function of a &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;-dimensional variance component parameter &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt;, and where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi_j\)&lt;/span&gt; is not necessarily conformable to &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega_j(\boldsymbol\theta)\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; denote the full vector of outcomes and the full (stacked) predictor matrix for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega\)&lt;/span&gt; denote the corresponding block-diagonal variance-covariance matrices.&lt;/p&gt;
&lt;p&gt;We estimate &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt; by REML, which maximizes the log likelihood
&lt;span class=&#34;math display&#34;&gt;\[
2 l_R(\boldsymbol\theta) = c -\log \left|\boldsymbol\Omega_j(\boldsymbol\theta)\right| - \log \left|\mathbf{X}&amp;#39; \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X}\right| - \mathbf{T}&amp;#39;\mathbf{Q}(\boldsymbol\theta)\mathbf{T},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Q}(\boldsymbol\theta) = \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) - \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X} \left(\mathbf{X}&amp;#39; \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X}\right)^{-1} \mathbf{X}&amp;#39;\boldsymbol\Omega^{-1}_j(\boldsymbol\theta)\)&lt;/span&gt;. Equivalently, the REML estimators solve the score equations
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial l_R(\boldsymbol\theta)}{\partial \theta_q} = 0, \qquad \text{for} \qquad q = 1,...,v.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Under mis-specification, the REML estimators converge (as &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; increases) to the values that minimize the Kullback-Liebler divergence between the posited model and the true data-generating process. For the restricted likelihood, the Kullback-Liebler divergence is given by
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathcal{KL}(\theta, \theta_0) &amp;amp;= \E\left[l_R(\boldsymbol\Phi) - l_R(\boldsymbol\theta)\right] \\
&amp;amp;= c + \log \left| \boldsymbol\Omega(\boldsymbol\theta) \right| + \log \left| \mathbf{X}&amp;#39;\boldsymbol\Omega^{-1}(\boldsymbol\theta) \mathbf{X} \right| + \text{tr}\left(\mathbf{Q}(\boldsymbol\theta) \boldsymbol\Phi\right),
\end{aligned}
\]&lt;/span&gt;
where the expectation in the first line is taken with respect to the true data-generating process and where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; (in the second line) is a constant that does not depend on &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;back-to-che&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Back to CHE&lt;/h1&gt;
&lt;p&gt;Let me now jump back to the special case of the CHE model for a meta-analysis with no predictors. Let &lt;span class=&#34;math inline&#34;&gt;\(\tau_*^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega_*^2\)&lt;/span&gt; denote the variance components in the true data-generating process. Let &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; denote the asymptotic limits of the REML estimators under the mis-specified model. In this model, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j = \mathbf{1}_j\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\boldsymbol\Phi_j &amp;amp;= \left(\tau_*^2 + \phi \sigma_j^2\right) \mathbf{1}_j \mathbf{1}_j&amp;#39; + \left(\omega_*^2 + (1 - \phi) \sigma_j^2\right) \mathbf{I}_j \\
\boldsymbol\Omega_j &amp;amp;= \left(\tilde\tau^2 + \rho \sigma_j^2\right) \mathbf{1}_j \mathbf{1}_j&amp;#39; + \left(\tilde\omega^2 + (1 - \rho) \sigma_j^2\right) \mathbf{I}_j \\
\boldsymbol\Omega_j^{-1} &amp;amp;= \frac{1}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\left[\mathbf{I}_j - \frac{\tilde\tau^2 + \rho \sigma_j^2}{k_j \tilde\tau^2 + k_j \rho \sigma_j^2 + \tilde\omega^2 + (1 - \rho)\sigma_j^2} \mathbf{1}_j \mathbf{1}_j&amp;#39; \right].
\end{aligned}
\]&lt;/span&gt;
Let &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{\tilde{w}_j = \frac{k_j}{k_j \tilde\tau^2 + k_j \rho \sigma_j^2 + \tilde\omega^2 + (1 - \rho)\sigma_j^2}}\)&lt;/span&gt; denote the weight assigned to study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under the mis-specified model, with the total weight denoted as &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{\tilde{W} = \sum_{j=1}^J \tilde{w}_j}\)&lt;/span&gt;. Similarly, let &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{w^*_j = \frac{k_j}{k_j \tau_*^2 + k_j \phi \sigma_j^2 + \omega_*^2 + (1 - \phi)\sigma_j^2}}\)&lt;/span&gt; denote the weight that &lt;em&gt;should&lt;/em&gt; be assigned to study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under the true model. Then we have that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{tr}\left(\mathbf{Q} \boldsymbol\Phi\right) &amp;amp;= \text{tr}\left(\boldsymbol\Omega^{-1} \boldsymbol\Phi\right) - \text{tr}\left[\left(\mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \mathbf{1}\right)^{-1} \mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \boldsymbol\Phi \boldsymbol\Omega^{-1} \mathbf{1}\right] \\
&amp;amp;= \sum_{j=1}^J \text{tr}\left(\boldsymbol\Omega^{-1}_j \boldsymbol\Phi_j\right) - \frac{1}{\tilde{W}}\sum_{j=1}^J \mathbf{1}_j&amp;#39;\boldsymbol\Omega^{-1}_j \boldsymbol\Phi_j \boldsymbol\Omega_j^{-1} \mathbf{1}_j \\
&amp;amp;= \sum_{j=1}^J \frac{k_j}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\left[\tau_*^2 + \omega_*^2 + \sigma_j^2 - \left(\tilde\tau^2 + \rho \sigma_j^2\right) \frac{\tilde{w}_j}{w^*_j}\right] - \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j} \\
&amp;amp;= \sum_{j=1}^J (k_j - 1) \left(\frac{\omega_*^2 + (1 - \phi)\sigma_j^2}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\right) + \sum_{j=1}^J \frac{\tilde{w}_j}{w_j^*} - \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j},
\end{aligned}
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\log \left| \boldsymbol\Omega \right| = \sum_{j=1}^J\log \left| \boldsymbol\Omega_j \right| = \sum_{j=1}^J\left[ \left(k_j - 1\right) \log\left(\tilde\omega^2 + (1 - \rho)\sigma_j^2\right) - \log \left(\frac{\tilde{w}_j}{k_j}\right)\right]
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\log \left|\mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \mathbf{1}\right| = \log \left(\tilde{W}\right),
\]&lt;/span&gt;
It follows that the REML estimators converge to the values &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; that minimize
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathcal{KL}\left(\tilde\tau^2, \tilde\omega^2, \rho, \tau_*^2, \omega_*^2, \phi\right) &amp;amp;= \sum_{j=1}^J (k_j - 1) \left(\frac{\omega_*^2 + (1 - \phi)\sigma_j^2}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\right) + \sum_{j=1}^J \frac{\tilde{w}_j}{w_j^*} - \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j} \\
&amp;amp; \qquad \qquad + \sum_{j=1}^J\left(k_j - 1\right) \log\left(\tilde\omega^2 + (1 - \rho)\sigma_j^2\right) - \sum_{j=1}^J \log \left(\frac{\tilde{w}_j}{k_j}\right) + \log(\tilde{W})
\end{aligned}
\]&lt;/span&gt;
This is a complicated non-linear objective function, but it can be minimized numerically using standard techniques.&lt;/p&gt;
&lt;p&gt;Here are some heatmaps of the function for &lt;span class=&#34;math inline&#34;&gt;\(\tau = 0.2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\omega = 0.1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi = 0.4\)&lt;/span&gt;, and some simulated values for &lt;span class=&#34;math inline&#34;&gt;\(k_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j^2\)&lt;/span&gt;, for three different assumed correlations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
set.seed(20211124)

CHE_KL &amp;lt;- function(to, tau, omega, phi, rho, k_j, sigmasq_j) {
  
  trs_j &amp;lt;- to[1]^2 + rho * sigmasq_j
  ors_j &amp;lt;- to[2]^2 + (1 - rho) * sigmasq_j
  w_j &amp;lt;- k_j / (k_j * trs_j + ors_j)
  W &amp;lt;- sum(w_j)
  
  tausq_ps_j &amp;lt;- tau^2 + phi * sigmasq_j
  omegasq_ps_j &amp;lt;- omega^2 + (1 - phi) * sigmasq_j
  wj_star &amp;lt;- k_j / (k_j * tausq_ps_j + omegasq_ps_j)
  
  A1 &amp;lt;- sum((k_j - 1) * omegasq_ps_j / ors_j)
  A2 &amp;lt;- sum(w_j / wj_star)
  A3 &amp;lt;- sum(w_j^2 / wj_star) / W
  B &amp;lt;- sum((k_j - 1) * log(ors_j) - log(w_j / k_j))
  C &amp;lt;- log(W)
  
  A1 + A2 - A3 + B + C
  
}

tau &amp;lt;- 0.2
omega &amp;lt;- 0.1
phi &amp;lt;- 0.4
J &amp;lt;- 20
k_j &amp;lt;- 1 + rpois(J, 5)
sigmasq_j &amp;lt;- 4 / pmax(rgamma(J, 3, scale = 30), 20)


KL_dat &amp;lt;- 
  cross_df(list(t = seq(0,0.4,0.01),
                o = seq(0,0.2,0.005),
                rho = c(0, 0.4, 0.8))) %&amp;gt;%
  mutate(
    to = map2(.x = t, .y = o, ~ c(.x, .y)),
    KL = map2_dbl(.x = to, .y = rho, .f = CHE_KL, 
                  tau = tau, omega = omega,
                  phi = phi, k_j = k_j, sigmasq_j = sigmasq_j),
    rho = paste(&amp;quot;rho ==&amp;quot;, rho)
  ) %&amp;gt;%
  group_by(rho)

KL_min &amp;lt;- 
  KL_dat %&amp;gt;%
  filter(KL == min(KL))

KL_dat %&amp;gt;%
  mutate(KL = -pmin(0.25, (KL - min(KL)) / (max(KL) - min(KL)))) %&amp;gt;%
ggplot() + 
  facet_wrap(~ rho, scales = &amp;quot;free&amp;quot;, labeller = &amp;quot;label_parsed&amp;quot;) + 
  geom_contour_filled(aes(x = t, y = o, z = KL), bins = 30) + 
  geom_point(x = tau, y = omega, color = &amp;quot;white&amp;quot;, size = 2) + 
  geom_point(data = KL_min, aes(x = t, y = o), color = &amp;quot;red&amp;quot;, size = 2) + 
  theme_minimal() + 
  labs(x = expression(tau), y = expression(omega)) + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Variance-component-estimation-in-misspecified-CHE_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The white points correspond to the true parameter values, while the red points correspond with the values that minimized the K-L divergence. In the middle plot, where &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.4\)&lt;/span&gt; corresponds to the true sampling correlation, the function is minimized at the true values of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;. In the left-hand plot, assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.0\)&lt;/span&gt; leads to an upwardly biased value of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and a downwardly biased value of &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;. In the right-hand plot, assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.8\)&lt;/span&gt; leads to a smaller value of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and a larger value of &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;completely-balanced-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Completely balanced designs&lt;/h2&gt;
&lt;p&gt;Things simplify considerably in the special case that the sample of studies is completely balanced, such that &lt;span class=&#34;math inline&#34;&gt;\(k_1 = k_2 = \cdots = k_J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2 = \sigma_2^2 = \cdots = \sigma_J^2\)&lt;/span&gt;. In such a design, the log-likelihood depends on &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; only through the quantities &lt;span class=&#34;math inline&#34;&gt;\(a = \tau^2 + \rho \sigma^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b = \omega^2 + (1 - \rho) \sigma^2\)&lt;/span&gt;. It follows that
&lt;span class=&#34;math display&#34;&gt;\[
l_R\left(\tau^2, \omega^2, \phi\right) = l_R\left(\tilde\tau^2, \tilde\omega^2, \rho\right)
\]&lt;/span&gt;
so long as
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tau^2 + \phi \sigma^2 &amp;amp;= \tilde\tau^2 + \rho \sigma^2 \\
\omega^2 + (1 - \phi)\sigma^2 &amp;amp;= \tilde\omega^2 + (1 - \rho) \sigma^2.
\end{aligned}
\]&lt;/span&gt;
If we assume that &lt;span class=&#34;math inline&#34;&gt;\((\rho - \phi)\sigma^2 &amp;lt; \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\((\phi - \rho)\sigma^2 &amp;lt; \omega^2\)&lt;/span&gt;, then we can set
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tilde\tau^2 &amp;amp;= \tau^2 - \left(\rho - \phi\right) \sigma^2 \\
\tilde\omega^2 &amp;amp;= \omega^2 + \left(\rho - \phi\right) \sigma^2
\end{aligned}
\]&lt;/span&gt;
and achieve the exact same likelihood.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Because the Kullback-Liebler divergence is minimized at the log likelihood of the true parameter values, setting &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; equal to the above quantities will also minimize the K-L divergence.&lt;/p&gt;
&lt;p&gt;The relationships here are fairly intuitive, I think. When &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is an over-estimate of the true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, then the between-study variance will be under-estimated and the within-study variance will be over-estimated, each to an extent that depends on a) the difference between &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; and b) the size of the (average) sampling variance. When &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is an under-estimate of the true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, then the between-study variance will be over-estimated and the within-study variance will be under-estimated, each to an extent that depends on the same components. It’s also rather intriguing to see that the total variance (the sum of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;) is totally invariant to &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; and will be preserved no matter what assumption we make regarding the sample correlation.&lt;/p&gt;
&lt;p&gt;In practice, of course, it’s pretty unlikely to have a meta-analytic dataset that is completely balanced. Still, the formulas for this completely balanced case might nonetheless be useful as heuristics for the direction of the biases in the parameter estimates—perhaps even as rough guides for the magnitude of bias that could be expected.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finding-tildetau2-and-tildeomega2-in-imbalanced-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Finding &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; in imbalanced designs&lt;/h2&gt;
&lt;p&gt;In imbalanced designs, we can find &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; by direct minimization of &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{KL}\)&lt;/span&gt;, given design information &lt;span class=&#34;math inline&#34;&gt;\(k_1,...,k_J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2,...,\sigma_J^2\)&lt;/span&gt;; true parameter values &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;; and assumed correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. The plot below depicts how &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega\)&lt;/span&gt;, and the total SD &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{\tilde\tau^2 + \tilde\omega^2}\)&lt;/span&gt; change as a function of the assumed correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, for various levels of true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, when the design is imbalanced. As previously, I use &lt;span class=&#34;math inline&#34;&gt;\(\tau = 0.2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega = 0.1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_tau_omega &amp;lt;- function(tau, omega, phi, rho, k_j, sigmasq_j) {

  res &amp;lt;- optim(par = c(tau + 0.001, omega + 0.001), fn = CHE_KL, 
                tau = tau, omega = omega, phi = phi, rho = rho,
                k_j = k_j, sigmasq_j = sigmasq_j,
                lower = c(0,0), method = &amp;quot;L-BFGS-B&amp;quot;)

  data.frame(tau_tilde = res$par[1], omega_tilde = res$par[2])
}

sigmasq_bar &amp;lt;- mean(sigmasq_j)

opt_params &amp;lt;- 
  cross_df(list(tau = tau,
                omega = omega,
                phi = seq(0.2,0.8,0.2),
                rho = seq(0,0.95,0.05))) %&amp;gt;%
  mutate(
    res = pmap(., .f = find_tau_omega, k_j = k_j, sigmasq_j = sigmasq_j),
  ) %&amp;gt;%
  unnest(res) %&amp;gt;%
  mutate(
    total_tilde = sqrt(tau_tilde^2 + omega_tilde^2),
    tau_pred = sqrt(pmax(0,tau^2 + (phi - rho) * sigmasq_bar)),
    omega_pred = sqrt(pmax(0, omega^2 - (phi - rho) * sigmasq_bar)),
    total_pred = sqrt(tau_pred^2+ omega_pred^2),
    phi_lab = paste(&amp;quot;phi ==&amp;quot;, phi)
  )

opt_params %&amp;gt;% 
  pivot_longer(c(ends_with(&amp;quot;_tilde&amp;quot;), ends_with(&amp;quot;_pred&amp;quot;)),
               names_to = &amp;quot;q&amp;quot;, values_to = &amp;quot;p&amp;quot;) %&amp;gt;%
  separate(q, into = c(&amp;quot;param&amp;quot;,&amp;quot;type&amp;quot;)) %&amp;gt;%
  mutate(
    type = recode(type, tilde = &amp;quot;exact&amp;quot;, pred = &amp;quot;balanced&amp;quot;),
    type = factor(type, levels = c(&amp;quot;exact&amp;quot;,&amp;quot;balanced&amp;quot;)),
    param = factor(param, levels = c(&amp;quot;tau&amp;quot;,&amp;quot;omega&amp;quot;,&amp;quot;total&amp;quot;),
                   labels = c(&amp;quot;tau&amp;quot;,&amp;quot;omega&amp;quot;,&amp;quot;sqrt(tau^2 + omega^2)&amp;quot;))
  ) %&amp;gt;%
  ggplot(aes(rho, p, color = type, linetype = type)) + 
  geom_hline(yintercept = 0) + 
  geom_line() + 
  scale_color_brewer(type = &amp;quot;qual&amp;quot;, palette = 2) + 
  facet_grid(param ~ phi_lab, labeller = &amp;quot;label_parsed&amp;quot;) + 
  theme_minimal() + 
  labs(x = expression(rho), y = &amp;quot;Parameter&amp;quot;, color = &amp;quot;&amp;quot;, linetype = &amp;quot;&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Variance-component-estimation-in-misspecified-CHE_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The top row of the figure shows &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau\)&lt;/span&gt;, the middle row shows &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega\)&lt;/span&gt;, and the bottom row shows the total SD, for varying levels of assumed correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. The solid green lines represent the values that actually minimize the KL divergence. The dashed orange lines correspond to the minimizing values assuming complete balance (and using the average value of the &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j^2\)&lt;/span&gt;’s to evaluate the bias). The “balanced” approximations are fairly close—close enough to use as heuristics, at least—although they’re not perfect. In particular, the balanced approximation becomes discrepant from the real minimizing values when &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega\)&lt;/span&gt; gets closer to zero. It’s also notable that the total variance is nearly constant (except when one or the other variance component is zero) and the balanced approximation is quite close to the real minimizing values.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;implications&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Implications&lt;/h1&gt;
&lt;p&gt;This post was mostly just to satisfy my own curiosity about how variance components behave in the MLMA and, more broadly, under mis-specified correlated-and-hierarchical effects meta-analysis models. I don’t think the bias formulas have much practical utility because, if you’re concerned about bias due to mis-specified sampling correlations, the first thing to do is try and develop better assumptions about the sampling correlation structure. Still, I think this analysis might be helpful for purposes of gauging how far off from the true your variance component estimates might be. In further work along these lines, it might be useful to examine the consequences of the biased variance component estimates for the efficiency of overall average effect size estimates based on mis-specified CHE models and the accuracy of model-based standard errors and confidence intervals under mis-specification. It would also be important to verify that these approximations provide accurate predictions for the bias of variance component estimates in realistic meta-analytic data (especially with a small or moderate number of studies).&lt;/p&gt;
&lt;p&gt;Another implication of this investigation is that &lt;em&gt;imbalance&lt;/em&gt; in the data structure seems to matter. When all studies have an equal number of effect sizes and are equally precise, then everything is simpler and more robust to mistaken assumptions about sampling correlation. Variance component estimation matters more for meta-analytic data in which some studies are more precise or contribute more effect size estimates than others. Therefore, further investigations—including simulation studies—of methods for handling dependent effect sizes really need to examine conditions with imbalanced data in order to draw defensible, generalizable conclusions about the robustness or utility of particular methods.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Consequently, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is not identifiable (in the statistical sense) in the completely balanced design.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Implications of mean-variance relationships for standardized mean differences</title>
      <link>https://www.jepusto.com/mean-variance-relationships-and-smds/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/mean-variance-relationships-and-smds/</guid>
      <description>


&lt;p&gt;I spend more time than I probably should discussing meta-analysis problems on the &lt;a href=&#34;https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis&#34;&gt;R-SIG-meta-analysis listserv&lt;/a&gt;. The questions that folks pose there are often quite interesting—especially when they’re motivated by issues that they’re wrestling with while trying to complete meta-analysis projects in their diverse fields. For those interested in meta-analytic methodology, I think perusing the mailing list is a good way to get a bit of ground sense about problems that come up in practice and places where there is a need for new methodological work, or at least further methodological guidance.&lt;/p&gt;
&lt;p&gt;Recently, a &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003318.html&#34;&gt;question came up&lt;/a&gt; on the listserv about whether it was reasonable to use the standardized mean difference metric for synthesizing studies where the outcomes are measured as proportions. Luke Martinez wrote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I’m doing a meta-analysis where the papers report only “mean” and “sd” of some form of proportion and/or “mean” and “sd” of corresponding raw frequencies. (For context, the papers ask students to read, find, and correct the wrong words in a text.) … My question is given that all these studies only report “mean” and “sd”, can I simply use a SMD effect size?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think this is an interesting question because, while the &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003320.html&#34;&gt;SMD could work perfectly fine&lt;/a&gt; as an effect size metric for proportions, there are also other alternatives that could be considered, such as odds ratios or response ratios or raw differences in proportions. Further, there are some situations where the SMD has disadvantages for synthesizing contrasts between proportions. Thus, it’s a situation where one has to make a choice about the effect size metric, and where the most common metric (the SMD) might not be the right answer. As &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003331.html&#34;&gt;I wrote in reply&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I would suggest that you could also consider other effect measures besides the SMD. For example, the response ratio is also a scale-free metric that could work with the proportion outcomes that you’ve described, and would also be appropriate for raw frequency counts as long as the total number possible is the same for the groups being compared within a given study.&lt;/p&gt;
&lt;p&gt;Whether the response ratio would be more appropriate than the SMD is hard to gauge. One would need to know more about how the proportions were assessed and how the assessment procedures varied from study to study. For instance, did some studies use passages with many possible errors to be corrected while other studies used passages with just a few errors? Did the difficulty of the passages differ from study to study? Were there very low or very high mean proportions in any studies? Does there seem to be a relationship between the means and the variances of the proportions of a given group?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In a &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003361.html&#34;&gt;follow-up&lt;/a&gt;, I elaborated on some potential problems with using the SMD:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Variation in the number of possible errors (and perhaps also in the length of the time provided for the test?) suggests that the measures from different studies may have varying degrees of reliability. Varying reliability introduces heterogeneity in the SMD (because the denominator is inflated or shrunk by the degree of reliability).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A relationship between the M and SD of the proportions for a given group suggests that the distribution of the individual-level outcomes might also exhibit mean-variance relationships. (I say “suggests” rather than implies because there’s an ecological inference here, i.e., assuming something about individual-level variation on the basis of group-level variation.) If this supposition is reasonable, then that introduces a further potential source of heterogeneity in the SMDs (study-to-study variation in the M for the reference group influences the SD of the reference group, thereby inflating or shrinking the SMDs).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;And I suggested a possible work-flow for examining the choice of effect size metric:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here’s how I might proceed if I were conducting
this analysis:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Calculate &lt;em&gt;both&lt;/em&gt; SMDs and log-transformed response ratios for the full set of studies.&lt;/li&gt;
&lt;li&gt;Examine the distribution of effect size estimates for each metric (using histograms or funnel plots). If one of the distributions is skewed or has extreme outliers, take that as an indication that the metric might not be appropriate.&lt;/li&gt;
&lt;li&gt;Fit meta-analytic models to summarize the distribution of effect sizes in each metric, using a model that appropriately describes the dependence structure of the estimates. Calculate I-squared statistics, give preference to the metric with lower I-squared.&lt;/li&gt;
&lt;li&gt;If (2) and (3) don’t lead to a clearly preferable metric, then choose between SMD and RR based on whichever will make the synthesis results easier to explain to people.&lt;/li&gt;
&lt;li&gt;(Optional/extra credit) Whichever metric you choose, repeat your main analyses using the other metric and stuff all those results in supplementary materials, to satisfy any inveterate statistical curmudgeons who might review/read your synthesis.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;(When I referred to “inveterate statistical curmudgeons”, I mostly had myself in mind.)&lt;/p&gt;
&lt;p&gt;In this post, I want to provide a bit more detail regarding why I think mean-variance relationships in raw data can signal that the standardized mean differences might be less useful as an effect size metric compared to alternatives. The concern is actually broader than meta-analyses of outcomes measured as proportions, so I’ll start with a different case and then return to a situation similar to the one described in the original question.&lt;/p&gt;
&lt;div id=&#34;mean-variance-relationships-can-induce-heterogeneity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mean-variance relationships can induce heterogeneity&lt;/h2&gt;
&lt;p&gt;The standardized mean difference parameter for a given study can be defined as:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sigma_{Ai}},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt; are the (population) mean outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; of study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{Ai}\)&lt;/span&gt; is the (population) standard deviation in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; of study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;
The ideal case for using the SMD metric is when the outcomes in different studies are linearly equatable, so that the outcome scale in one study can be directly translated into the outcome scale of another study. However, if outcomes exhibit mean-variance relationships, linearly equatability seems rather implausible, and we might expect that SMDs will display heterogeneity across studies as a result.&lt;/p&gt;
&lt;p&gt;Let me lay out an example of a situation where the outcomes exhibit mean-variance relationships and where, as a consequence, the SMD metric becomes heterogeneous. Suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, each involving a two-group comparison, with groups of equal size. In study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; follow a poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;, so that the variance of the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is also &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,k\)&lt;/span&gt;. The outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; follow a poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt;, so the variance is also &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt;. Now, suppose that there is a fixed, proportional relationship between &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;,
so that &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi} = \lambda \mu_{Ai}\)&lt;/span&gt; for some &lt;span class=&#34;math inline&#34;&gt;\(\lambda &amp;gt; 0\)&lt;/span&gt;. In other words, the treatment contrast is &lt;em&gt;constant&lt;/em&gt; on the scale of the response ratio.
However, the means in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; vary from study to study. To make things concrete, let’s assume that the means in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; follow a gamma distribution with shape parameter &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and rate parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\mu_{Ai} \sim \Gamma(\alpha, \beta).
\]&lt;/span&gt;
What does this model imply about the distribution of standardized mean differences across this set of studies?&lt;/p&gt;
&lt;p&gt;Under this model, the SMD parameter for study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sqrt{\mu_{Ai}}} = (\lambda - 1) \times \sqrt{\mu_{Ai}}.
\]&lt;/span&gt;
The first term in the above expression is a constant that only
depend on the size of the response ratio, but the second term is random because we have assumed that the group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means vary from study to study. It will therefore create heterogeneity in the SMD parameters—the greater the variance of the &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;’s, the greater the heterogeneity in &lt;span class=&#34;math inline&#34;&gt;\(\delta_i\)&lt;/span&gt;. Specifically, under the above assumptions, the effect size parameters follow a &lt;a href=&#34;https://en.wikipedia.org/wiki/Nakagami_distribution&#34;&gt;Nakagami distribution&lt;/a&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i \sim \text{Nakagami}\left(m = \alpha, \Omega = \frac{(\lambda - 1)^2 \alpha}{\beta}\right)
\]&lt;/span&gt;
Thus, even though we have a model where there is an underlying fixed relationship between &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt;, using the SMD metric for synthesis will lead to a situation with heterogeneous effects (even if all of the studies had large sample sizes and so effect sizes in individual studies are precisely estimated).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-with-proportions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An example with proportions&lt;/h2&gt;
&lt;p&gt;This sort of behavior is not restricted to the poisson-gamma model I sketched above. The key features of that example are a) the assumption that the outcomes have a strong mean-variance relationship and b) the assumption that the &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;’s are heterogeneous across studies. If both of these hold, then the resulting SMDs will also be heterogeneous. I’ll now describe a similar model, but where the outcomes within each study are proportions.&lt;/p&gt;
&lt;p&gt;As before, suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, each involving a two-group comparison, with groups of equal size. In study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; follow a binomial distribution with mean proportion &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; trials, so that the variance of the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\left(1 - \pi_{Ai}\right) T_i\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,k\)&lt;/span&gt;. The outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; also follow a binomial distribution, this one with mean proportion &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Bi}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; trials, so the variance is &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Bi}\left(1 - \pi_{Bi}\right) T_i\)&lt;/span&gt;. Next, to induce variation in the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means, let’s assume that the mean proportions follow a beta distribution:
&lt;span class=&#34;math display&#34;&gt;\[
\pi_{Ai} \sim \text{Beta}(\alpha, \beta).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Finally, suppose that &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Bi} = \lambda_i \pi_{Ai}\)&lt;/span&gt; for some &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i &amp;gt; 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Under these assumptions, the SMD parameter for study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i = \frac{\pi_{Bi}T_i - \pi_{Ai} T_i}{\sqrt{\pi_{Ai} (1 - \pi_{Ai}) T_i}} = (\lambda_i - 1) \times \sqrt{T_i} \times \sqrt{\frac{\pi_{Ai}}{1 - \pi_{Ai}}}.
\]&lt;/span&gt;
From the above expression, it can be seen that there are three potential sources of variation in &lt;span class=&#34;math inline&#34;&gt;\(\delta_i\)&lt;/span&gt;: variation in the study-specific response ratio &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt;, variation in the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; proportions &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt;, and variation in the number of trials &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;. The total heterogeneity in &lt;span class=&#34;math inline&#34;&gt;\(\delta_i\)&lt;/span&gt; will depend on all three, as well as on the co-variation between &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To make this concrete, let me simulate some meta-analytic data that follows the above model. To do so, I’ll need to make some additional distributional assumptions&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;that &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt; is log-normally distributed such that &lt;span class=&#34;math inline&#34;&gt;\(\ln \lambda_i \sim N(\ln \Lambda, \tau^2)\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;that the number of trials is uniformly distributed on the integers between &lt;span class=&#34;math inline&#34;&gt;\(t_{min}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t_{max}\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;that &lt;span class=&#34;math inline&#34;&gt;\(N_i\)&lt;/span&gt;, the number of observations per group in study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, is uniformly distributed on the integers between &lt;span class=&#34;math inline&#34;&gt;\(n_{min}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_{max}\)&lt;/span&gt;; and&lt;/li&gt;
&lt;li&gt;that &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(N_i\)&lt;/span&gt; are mutually independent.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here’s a function that generates study-specific parameter values and sample proportions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_binom_summary &amp;lt;- function(pi_i, T_i, n_i) {
  y &amp;lt;- rbinom(n_i, size = T_i, prob = pi_i) / T_i
  data.frame(M = mean(y), SD = sd(y))
}

sim_props &amp;lt;- function(
  k, # number of studies
  alpha, beta, # parameters of pi_Ai distribution,
  Lambda, tau, # parameters of lambda_i distribution
  t_min, t_max, # parameters of T_i distribution
  n_min, n_max # parameters of the sample size distribution
) {
  
  # simulate parameters
  pi_Ai &amp;lt;- rbeta(k, shape1 = alpha, shape2 = beta)
  lambda_i &amp;lt;- exp(rnorm(k, mean = log(Lambda), sd = tau))
  pi_Bi &amp;lt;- lambda_i * pi_Ai
  T_i &amp;lt;- sample(t_min:t_max, size = k, replace = TRUE)
  delta_i &amp;lt;- (pi_Bi - pi_Ai) * T_i / sqrt(pi_Ai * (1 - pi_Ai) * T_i)
  n_i &amp;lt;- sample(n_min:n_max, size = k, replace = TRUE)
  
  # simulate data
  stats_A &amp;lt;- purrr::pmap_dfr(list(pi_i = pi_Ai, T_i = T_i, n_i = n_i),
                             sim_binom_summary) 
                             
  stats_B &amp;lt;- purrr::pmap_dfr(list(pi_i = pi_Bi, T_i = T_i, n_i = n_i),
                             sim_binom_summary)
  
  # compile
  res &amp;lt;- data.frame(
    pi_Ai = pi_Ai, pi_Bi = pi_Bi, 
    lambda_i = lambda_i, T_i = T_i, 
    delta_i = delta_i, n_i = n_i,
    mA = stats_A$M, sdA = stats_A$SD,
    mB = stats_B$M, sdB = stats_B$SD
  )

  # effect size calculations
  res &amp;lt;- metafor::escalc(
    data = res, measure = &amp;quot;ROM&amp;quot;, var.names = c(&amp;quot;lRR&amp;quot;, &amp;quot;V_lRR&amp;quot;),
    m1i = mB, m2i = mA, 
    sd1i = sdB, sd2i = sdA,
    n1i = n_i, n2i = n_i
  )
  res &amp;lt;- metafor::escalc(
    data = res, measure = &amp;quot;SMD&amp;quot;, var.names = c(&amp;quot;d&amp;quot;, &amp;quot;V_d&amp;quot;),
    m1i = mB, m2i = mA, 
    sd1i = sdB, sd2i = sdA,
    n1i = n_i, n2i = n_i
  )
  
  res
}

set.seed(20211024)
dat &amp;lt;- sim_props(k = 60, alpha = 12, beta = 4, 
                 Lambda = 0.7, tau = .05,
                 t_min = 5, t_max = 18,
                 n_min = 10, n_max = 40)

head(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##       pi_Ai     pi_Bi  lambda_i T_i    delta_i n_i        mA       sdA 
## 1 0.7584480 0.5836965 0.7695933  11 -1.3540950  24 0.7500000 0.1080650 
## 2 0.7359047 0.4950740 0.6727420  16 -2.1851474  24 0.7786458 0.1222235 
## 3 0.7132014 0.4773027 0.6692398  12 -1.8068471  10 0.7333333 0.1097134 
## 4 0.6223653 0.4627406 0.7435193   9 -0.9877857  30 0.6666667 0.1399386 
## 5 0.5916619 0.4205407 0.7107787   6 -0.8527716  28 0.5833333 0.2103299 
## 6 0.7266748 0.5014601 0.6900751   9 -1.5160305  35 0.7619048 0.1209466 
##          mB       sdB     lRR  V_lRR       d    V_d 
## 1 0.6174242 0.1285066 -0.1945 0.0027 -1.0983 0.0959 
## 2 0.5260417 0.1275776 -0.3922 0.0035 -1.9888 0.1245 
## 3 0.3583333 0.1622089 -0.7161 0.0227 -2.5934 0.3681 
## 4 0.4555556 0.1943213 -0.3808 0.0075 -1.2306 0.0793 
## 5 0.4583333 0.2060055 -0.2412 0.0119 -0.5921 0.0746 
## 6 0.4920635 0.1793349 -0.4372 0.0045 -1.7447 0.0789&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the specified parameter values, there is only a small amount of true heterogeneity in the log of the response ratios (the blue density). Of course, there is further heterogeneity in the log response ratio estimates (the green density) due to sampling error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
ggplot(dat) + 
  geom_density(aes(log(lambda_i), ..scaled..), fill = &amp;quot;blue&amp;quot;, alpha = 0.5) + 
  geom_density(aes(lRR, ..scaled..), fill = &amp;quot;green&amp;quot;, alpha = 0.2) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;576&#34; /&gt;
A random effects meta-analysis confirms that there is only a modest degree of true heterogeneity in the log response ratios:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
rma(yi = lRR, vi = V_lRR, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.0028 (SE = 0.0013)
## tau (square root of estimated tau^2 value):      0.0529
## I^2 (total heterogeneity / total variability):   42.01%
## H^2 (total variability / sampling variability):  1.72
## 
## Test for Heterogeneity:
## Q(df = 59) = 100.6304, p-val = 0.0006
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub      
##  -0.3498  0.0111  -31.5751  &amp;lt;.0001  -0.3715  -0.3281  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Contrast this with what we get from using the standardized mean difference metric. The distributions of true effect sizes (blue) and of effect size estimates (light purple) have large spread as well as strong left skew:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
ggplot(dat) + 
  geom_density(aes(delta_i, ..scaled..), fill = &amp;quot;blue&amp;quot;, alpha = 0.2) + 
  geom_density(aes(d, ..scaled..), fill = &amp;quot;purple&amp;quot;, alpha = 0.5) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;
A random effects meta-analysis of the standardized mean differences shows a greater degree of true heterogeneity, both in terms of the estimated &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and in &lt;span class=&#34;math inline&#34;&gt;\(I^2\)&lt;/span&gt;, or the proportion of total variance in the effect size estimates that is attributable to true heterogeneity:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma(yi = d, vi = V_d, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.2838 (SE = 0.0743)
## tau (square root of estimated tau^2 value):      0.5327
## I^2 (total heterogeneity / total variability):   72.61%
## H^2 (total variability / sampling variability):  3.65
## 
## Test for Heterogeneity:
## Q(df = 59) = 203.0513, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub      
##  -1.5967  0.0824  -19.3771  &amp;lt;.0001  -1.7582  -1.4352  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;diagnostics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Diagnostics&lt;/h2&gt;
&lt;p&gt;The code above more-or-less implements the workflow I suggested for deciding between the standardized mean difference or response ratio metric (for proportions, we could also add further comparisons with log odds ratios and with raw differences in proportions). But is there further diagnostic information in the data that could provide a better sense of what is going on? I think there are a few things that might be helpful to consider.&lt;/p&gt;
&lt;p&gt;First, the issues I’m concerned with here will arise when there are mean-variance relationships in the outcomes. To get at that, we can simply plot the means and SDs of each group. In the code below, I re-structure the data so that there is one row per group per study. I then plot the SD versus the mean of each group:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(tidyr)

long_summary_stats &amp;lt;- 
  dat %&amp;gt;%
  select(n_i, T_i, mA, sdA, mB, sdB) %&amp;gt;%
  pivot_longer(cols = c(mA, sdA, mB, sdB), 
               names_to = c(&amp;quot;.value&amp;quot;,&amp;quot;group&amp;quot;),
               names_pattern = &amp;quot;(m|sd)(A|B)&amp;quot;)

ggplot(long_summary_stats,
       aes(m, sd, color = group)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  expand_limits(y = 0) + 
  theme_minimal() + 
  theme(legend.position = c(0.1, 0.9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;
The plot above does suggest a mean-variance relationship, though it’s a bit messy. We can do better by using the scaled SD, after adjusting for the degree of spread that we would expect given &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;long_summary_stats %&amp;gt;%
  mutate(
    sd_scaled = sd * sqrt(T_i)
  ) %&amp;gt;%
  ggplot(aes(m, sd_scaled, color = group)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  geom_function(fun = function(x) sqrt(x * (1 - x)),
                color = &amp;quot;black&amp;quot;) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  expand_limits(y = 0) + 
  theme_minimal() + 
  theme(legend.position = c(0.1, 0.9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;
From the above, it does appear that there could be a relationship between the scaled SD and the mean. The black curve indicates the theoretical mean-variance relationship that would be expected under the binomial distribution, and indeed the empirical relationship appears to be quite similar. This suggests that mean-variance relationships might be at play (a correct supposition, since of course we know the true data-generating process here).&lt;/p&gt;
&lt;p&gt;Second, since the outcomes in each group are all proportions, we can simply plot the mean in group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; versus the mean in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat, aes(mA, mB)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;, formula = y ~ x) + 
  coord_cartesian(xlim = c(0,1), ylim = c(0,1), expand = FALSE) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;
This plot shows that there is a strong linear relationship between the two means, with a best-fit line that might go through the origin. This suggests that the response ratio might be an appropriate metric (although the difference in proportions might also be appropriate here, since a line with unit slope would probably fit quite well).&lt;/p&gt;
&lt;p&gt;Third (and most speculatively/hand-wavily), I think exploratory moderator analysis can be useful here, but interpreted in a non-typical way. Under the model I’ve sketched, we would expect that the standardized mean difference estimates should be systematically associated with the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means, as well as with the number of trials used to assess outcomes. The scatter-plots below show that this is indeed the case (the right-hand plot shows &lt;span class=&#34;math inline&#34;&gt;\(d_i\)&lt;/span&gt; versus &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{T_i}\)&lt;/span&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(patchwork)
mA_d_plot &amp;lt;- 
  ggplot(dat, aes(mA, d)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  theme_minimal()

Ti_d_plot &amp;lt;- 
  ggplot(dat, aes(sqrt(T_i), d)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  theme_minimal()

mA_d_plot + Ti_d_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This impression is also born out by a meta-regression that includes the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means and &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{T_i}\)&lt;/span&gt; as moderators:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma(d ~ mA + sqrt(T_i), vi = V_d, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0238 (SE = 0.0238)
## tau (square root of estimated tau^2 value):             0.1544
## I^2 (residual heterogeneity / unaccounted variability): 18.12%
## H^2 (unaccounted variability / sampling variability):   1.22
## R^2 (amount of heterogeneity accounted for):            91.60%
## 
## Test for Residual Heterogeneity:
## QE(df = 57) = 68.9706, p-val = 0.1330
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 110.9125, p-val &amp;lt; .0001
## 
## Model Results:
## 
##            estimate      se     zval    pval    ci.lb    ci.ub      
## intrcpt      2.5225  0.3964   6.3632  &amp;lt;.0001   1.7455   3.2995  *** 
## mA          -2.8326  0.4336  -6.5321  &amp;lt;.0001  -3.6825  -1.9827  *** 
## sqrt(T_i)   -0.6109  0.0756  -8.0855  &amp;lt;.0001  -0.7590  -0.4628  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the same plots as above, but using the log of the response ratio as the effect size metric:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mA_lRR_plot &amp;lt;- 
  ggplot(dat, aes(mA, lRR)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  theme_minimal()

Ti_lRR_plot &amp;lt;- 
  ggplot(dat, aes(sqrt(T_i), lRR)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  theme_minimal()

mA_lRR_plot + Ti_lRR_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the left-hand plot, there does not appear to be any relationship between the effect size estimates and the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means. In the right-hand plot, there does seem to be a mild relationship between the effect size estimates and &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{T_i}\)&lt;/span&gt;, which is a bit surprising, although the strength of the relationship is much weaker than what we saw with the standardized mean differences. Meta-regression analysis supports these interpretations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma(lRR ~  mA + sqrt(T_i), vi = V_lRR, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0019 (SE = 0.0011)
## tau (square root of estimated tau^2 value):             0.0439
## I^2 (residual heterogeneity / unaccounted variability): 32.87%
## H^2 (unaccounted variability / sampling variability):   1.49
## R^2 (amount of heterogeneity accounted for):            31.30%
## 
## Test for Residual Heterogeneity:
## QE(df = 57) = 84.4977, p-val = 0.0105
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 10.6344, p-val = 0.0049
## 
## Model Results:
## 
##            estimate      se     zval    pval    ci.lb    ci.ub     
## intrcpt     -0.2362  0.0950  -2.4864  0.0129  -0.4224  -0.0500   * 
## mA           0.1061  0.0948   1.1196  0.2629  -0.0796   0.2918     
## sqrt(T_i)   -0.0553  0.0179  -3.0852  0.0020  -0.0904  -0.0202  ** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, you might think that a meta-analyst should get excited about the standardized mean difference results, since they’ve uncovered two systematic predictors of effect size magnitude. However, both of these factors are purely operational, arbitrary features of the (simulated) study designs, rather than theoretically or substantively interesting features of the studies. Considered in this light, the finding that they each moderate the magnitude of the standardized mean differences is, more than anything else, &lt;em&gt;annoying&lt;/em&gt;. If we wanted to examine other more theoretically interesting moderators, we’d have to do so in a way that accounts for these methodological predictors. At minimum, that would mean including them all in a meta-regression (leading to a model with 3+ predictors). Further, we would have to worry about whether the functional form of the regression is reasonable. Simply adding the theoretical moderator to the model amounts to assuming that it predicts effect size magnitude in a linear, additive fashion, but what if that’s not the right model? Since we know the true data-generating process here, we can see that the linear, additive model &lt;em&gt;would not&lt;/em&gt; be correct. But in practice, when we don’t know the true process, this would be much murkier.&lt;/p&gt;
&lt;p&gt;The general principle that I’m suggesting here is that effect sizes should ideally be on a metric that is &lt;em&gt;independent&lt;/em&gt; of arbitrary methodological factors because this should &lt;em&gt;reduce&lt;/em&gt; overall heterogeneity and &lt;em&gt;simplify&lt;/em&gt; the model, making it easier to detect real relations of interest. If one has a choice between several different effect size metrics, then a metric that shows clear associations with methodological factors should be discounted in favor of metrics that do not show such associations or show them only weakly. How to fully operationalize this sort of decision (as one would need to when writing a protocol for a meta-analysis, for example), I’m not yet sure about. It seems like a useful avenue for further methodological work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Yes, there are other ways to define the SMD. Yes, usually we use the standard deviation pooled across both groups. I’m going to use the standard deviation in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; alone because it simplifies some of the mathy bits. Please feel free to work through the case with a pooled SD for yourself.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;One of the vexing things about simulations is that you often end up needing to specify a bunch of assumptions about auxiliary quantities, beyond those of the model you’re actually interested in investigating.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A systematic review and meta‐analysis of effects of psychosocial interventions on spiritual well‐being in adults with cancer</title>
      <link>https://www.jepusto.com/publication/psychosocial-interventions-for-spiritual-well-being/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/psychosocial-interventions-for-spiritual-well-being/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Systematic review and meta-analysis of stay-play-talk interventions for improving social behaviors of young children</title>
      <link>https://www.jepusto.com/publication/stay-play-talk-meta-analysis/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/stay-play-talk-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An ANCOVA puzzler</title>
      <link>https://www.jepusto.com/ancova-puzzler/</link>
      <pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/ancova-puzzler/</guid>
      <description>


&lt;p&gt;Doing effect size calculations for meta-analysis is a good way to lose your faith in humanity—or at least your faith in researchers’ abilities to do anything like sensible statistical inference. Try it, and you’re surely encounter head-scratchingly weird ways that authors have reported even simple analyses, like basic group comparisons. When you encounter this sort of thing, you have two paths: you can despair, curse, and/or throw things, or you can view the studies as curious little puzzles—brain-teasers, if you will—to keep you awake and prevent you from losing track of those notes you took during your stats courses, back when. Here’s one of those curious little puzzles, which I recently encountered in helping a colleague with a meta-analysis project.&lt;/p&gt;
&lt;p&gt;A researcher conducts a randomized experiment, assigning participants to each of &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; groups. Each participant is assessed on a variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at pre-test and at post-test (we can assume there’s no attrition). In their study write-up, the researcher reports sample sizes for each group, means and standard deviations for each group at pre-test and at post-test, and &lt;em&gt;adjusted&lt;/em&gt; means at post-test, where the adjustment is done using a basic analysis of covariance, controlling for pre-test scores only. The data layout looks like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Group&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Adjusted post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Group A&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(n_A\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_{A}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{A0}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{A}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{A1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}_A\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Group B&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(n_B\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_{B}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{B0}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{B}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{B1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}_B\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note that the write-up does &lt;em&gt;not&lt;/em&gt; provide an estimate of the correlation between the pre-test and the post-test, nor does it report a standard deviation or standard error for the mean change-score between pre-test and post-test within each group. All we have are the summary statistics, plus the adjusted post-test scores. We can assume that the adjustment was done according to the basic ANCOVA model, assuming a common slope across groups as well as homoskedasticity and so on. The model is then
&lt;span class=&#34;math display&#34;&gt;\[
y_{ig} = \alpha_g + \beta x_{ig} + e_{ig},
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(g = 1,...,G\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(e_{ig}\)&lt;/span&gt; is an independent error term that is assumed to have constant variance across groups.&lt;/p&gt;
&lt;div id=&#34;for-realz&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;For realz?&lt;/h3&gt;
&lt;p&gt;Here’s an example with real data, drawn from Table 2 of &lt;a href=&#34;https://doi.org/10.1080/10573560500455703&#34;&gt;Murawski (2006)&lt;/a&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Group&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Adjusted post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Group A&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;37.48&lt;/td&gt;
&lt;td&gt;4.64&lt;/td&gt;
&lt;td&gt;37.96&lt;/td&gt;
&lt;td&gt;4.35&lt;/td&gt;
&lt;td&gt;37.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Group B&lt;/td&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;36.85&lt;/td&gt;
&lt;td&gt;5.18&lt;/td&gt;
&lt;td&gt;36.46&lt;/td&gt;
&lt;td&gt;3.86&lt;/td&gt;
&lt;td&gt;36.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Group C&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;37.88&lt;/td&gt;
&lt;td&gt;3.88&lt;/td&gt;
&lt;td&gt;37.38&lt;/td&gt;
&lt;td&gt;4.76&lt;/td&gt;
&lt;td&gt;36.98&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;That study reported this information for each of several outcomes, with separate analyses for each of two sub-groups (LD and NLD). The text also reports that they used a two-level hierarchical linear model for the ANCOVA adjustment. For simplicity, let’s just ignore the hierarchical linear model aspect and assume that it’s a straight, one-level ANCOVA.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-puzzler&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The puzzler&lt;/h3&gt;
&lt;p&gt;Calculate an estimate of the standardized mean difference between group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; and group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;, along with the sampling variance of the SMD estimate, that adjusts for pre-test differences between groups. Candidates for numerator of the SMD include the adjusted mean difference, &lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}_B - \tilde{y}_A\)&lt;/span&gt; or the difference-in-differences, &lt;span class=&#34;math inline&#34;&gt;\(\left(\bar{y}_B - \bar{x}_B\right) - \left(\bar{y}_A - \bar{x}_A\right)\)&lt;/span&gt;. In either case, the tricky bit is finding the sampling variance of this quantity, which involves the pre-post correlation. For the denominator of the SMD, you use the post-test SD, either pooled across just groups &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; or pooled across all &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; groups, assuming a common population variance.&lt;/p&gt;
&lt;p&gt;Have an idea for how to solve this? Post it in the comments or email it to me. Need the solution because you have a study like this in your meta-analysis? Contact me and I’ll share it with you directly. I’m being coy because I’m teaching meta-analysis next semester, and I feel like this would make a good extra credit problem…&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes</title>
      <link>https://www.jepusto.com/publication/selective-reporting-with-dependent-effects/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/selective-reporting-with-dependent-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What do meta-analysts mean by &#39;multivariate&#39; meta-analysis?</title>
      <link>https://www.jepusto.com/what-does-multivariate-mean/</link>
      <pubDate>Sat, 27 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/what-does-multivariate-mean/</guid>
      <description>


&lt;p&gt;If you’ve ever had class with me or attended one of my presentations, you’ve probably heard me grouse about how statisticians are mostly awful about naming things.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; A lot of the terminology in our field is pretty bad and ineloquent. As a leading example, look no further than Rubin and Little’s classification of missing data mechanisms as missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR). Clear as mud, and the last one sounds like something you’d see on a handmade sign with a picture of someone’s pet puppy who wandered off last week.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://petkey.blob.core.windows.net/resource/images/940000/949000/949340_500W.jpg&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;As another example, consider that introductory statistics students always struggle to distinguish between no less than &lt;strong&gt;&lt;em&gt;three&lt;/em&gt;&lt;/strong&gt; different concepts that are all called “variance”: population variance, sample variance, and sampling variance.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Unless the instructor also took diction training from the Royal Shakespeare Company, it’s no wonder that a fair number of students are left confused.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/img/Hamlet-z-transform.jpg&#34; /&gt;
In this post, I will try to clarify (at least a little bit) another mess of terminology that crops up a lot in my work on meta-analysis: what do we mean when we say a model or method is “multivariate”? In the context of meta-analysis methods, I think there are at least three distinct senses in which this term is used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As an umbrella term for models/methods where there is more than one effect size estimate per study,&lt;/li&gt;
&lt;li&gt;As a description for a class of methods within that broad umbrella, where certain aspects of the model are treated as known, or&lt;/li&gt;
&lt;li&gt;As a description for a class of models for multivariate effect size estimates, where each effect size estimate from a study falls into one of a set of distinct categories.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let me explain what I mean by each of these.&lt;/p&gt;
&lt;div id=&#34;multivariate-handwaving&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multivariate handwaving&lt;/h2&gt;
&lt;p&gt;In the context of meta-analysis, the broadest meaning of “multivariate” is any method used for modeling data that includes more than one effect size estimate in some or all of the included studies. Formally, the term would apply to any model appropriate for a set of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; includes &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; effect size estimates, and where the effect size estimates would be denoted &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;As it is used here, “multivariate” is really an umbrella term that could encompass a wide variety of methods and models, including multi-level meta-analysis or meta-regression models, multivariate methods in the narrower senses I will describe subsequently, and even robust variance estimation methods. It would also encompass techniques for handling this sort of data structure that aren’t strictly models, such as aggregating effect size estimates to the level of the study or using Harris Cooper’s “shifting unit-of-analysis” method &lt;span class=&#34;citation&#34;&gt;(Cooper, &lt;a href=&#34;#ref-Cooper1998synthesizing&#34; role=&#34;doc-biblioref&#34;&gt;1998&lt;/a&gt;)&lt;/span&gt;.
This usage of “multivariate” involves a bit too much hand-waving for my taste (although I’ve been guilty of using the term this way in the past). I think a better, clearer term for this broad class of methods would be to call them methods for &lt;strong&gt;&lt;em&gt;meta-analysis of dependent effect sizes&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multivariate-sampling-errors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multivariate sampling errors&lt;/h2&gt;
&lt;p&gt;Another sense in which “multivariate” is used pertains to a certain class of models for dependent effect sizes. In particular, “multivariate meta-analysis” sometimes means a model where the sampling variances and covariances of the effect size estimates are treated as fully known. Say that each effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; has a corresponding true effect size parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta_{ij}\)&lt;/span&gt;, so that the sampling error is &lt;span class=&#34;math inline&#34;&gt;\(e_{ij} = T_{ij} - \theta_{ij}\)&lt;/span&gt;, or
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \theta_{ij} + e_{ij}.
\]&lt;/span&gt;
Typically, meta-analysis techniques treat the sampling errors as having known variances, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(e_{ij}) = \sigma_{ij}^2\)&lt;/span&gt; for known &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{ij}^2\)&lt;/span&gt;.
Here, a multivariate meta-analysis would go a step further and make assumptions that &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{hj}, e_{ij}) = \rho_{hij}\sigma_{hj} \sigma_{ij}\)&lt;/span&gt; for &lt;em&gt;known&lt;/em&gt; correlations &lt;span class=&#34;math inline&#34;&gt;\(\rho_{hij}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h,i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j=1,...,k\)&lt;/span&gt;.
Typically, the sampling variances and covariances would play into how the model is estimated and how one conducts inference and gets standard errors on things, etc.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Becker (&lt;a href=&#34;#ref-Becker2000multivariate&#34; role=&#34;doc-biblioref&#34;&gt;2000&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Gleser &amp;amp; Olkin (&lt;a href=&#34;#ref-Gleser2009stochastically&#34; role=&#34;doc-biblioref&#34;&gt;2009&lt;/a&gt;)&lt;/span&gt; describe a whole slew of different situations where meta-analysts will encounter multiple effect size estimates within a given study, and both provide formulas for the covariances between those effect sizes.
In some situations, these covariances can be calculated just based on primary study sample sizes or other information readily available from study reports.
In other situations (such as when one calculates &lt;a href=&#34;https://www.jepusto.com/correlations-between-smds/&#34;&gt;standardized mean differences for each of several outcomes on a common set of participants&lt;/a&gt;), the information needed to calculate covariances might not be available, which is where methods like robust variance estimation come in.
With this meaning of the term, multivariate meta-analysis methods are those that both directly model the dependent effects structure and that treat the sampling covariances as known. They are therefore distinct from methods, such as robust variance estimation, that do not rely on knowing the exact variance-covariance structure of the sampling errors.
In my own work, I find it helpful to be able to draw this distinction, so I rather like this usage of “multivariate.” This will surely irritate some statisticians, though, who prefer the third, stricter meaning of the term.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;strictly-multivariate-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Strictly multivariate models&lt;/h2&gt;
&lt;p&gt;A third meaning of multivariate is to denote a class of models for multivariate data, meaning data where each unit is measured on several dimensions or characteristics. In the meta-analysis context, multivariate effect sizes are ones where, for each included study or sample, we have effect sizes describing outcomes (e.g., treatment effects) on one or more dimensions.
For example, say that we have a bunch of studies examining some sort of educational intervention, and each study reports effect sizes describing the intervention’s impact on a) reading performance, b) social studies achievement, and/or c) language arts achievement. What differentiates this sort of multivariate data from the first, “umbrella” sense of the term is that with strictly multivariate data, no study has more than one effect size within a given dimension. In contrast, meta-analysis of dependent effect sizes deal with data structures that are not necessarily so tidy and organized, such that we might not be able to classify each effect size into one of a finite and exhaustive set of categories.&lt;/p&gt;
&lt;p&gt;When working with strictly multivariate data like this, a multivariate meta-analysis (or meta-regression) model would entail estimating average effects (or regression coefficients) &lt;em&gt;for each dimension&lt;/em&gt; rather than aggregating across dimensions. This class of models was discussed extensively in an excellent article by &lt;span class=&#34;citation&#34;&gt;Jackson et al. (&lt;a href=&#34;#ref-Jackson2011multivariate&#34; role=&#34;doc-biblioref&#34;&gt;2011&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; With my example of educational intervention studies, we would estimate average impacts on reading performance, social studies achievement, and language arts achievement. Estimating an overall aggregate effect on academic achievement would make little sense here, because we’d be mixing apples, oranges, and kiwis.&lt;/p&gt;
&lt;p&gt;Formally, this sort of data structure and model can be described as follows. As previously, say that we have a set of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; has &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; effect sizes, &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, and correspoding sampling variances &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{ij}^2\)&lt;/span&gt;, both for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...k\)&lt;/span&gt;. Effect size &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; can be classified into one of &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; dimensions. Let &lt;span class=&#34;math inline&#34;&gt;\(d^c_{ij}\)&lt;/span&gt; be an indicator for whether effect &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; falls into dimension &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(c = 1,...,C\)&lt;/span&gt;. With a strictly multivariate structure, there is never more than one effect per category, so &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^{n_j} d^c_{ij} \leq 1\)&lt;/span&gt; for each &lt;span class=&#34;math inline&#34;&gt;\(c = 1,...,C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;. A typical multivariate random effects model would then be
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \sum_{c=1}^C \left(\mu_c + v_{cj}\right) d^c_{ij} + e_{ij},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mu_c\)&lt;/span&gt; is the average effect size for category &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(v_{cj}\)&lt;/span&gt; is a random effect for category &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(e_{ij}\)&lt;/span&gt; is the sampling error term. The classic assumption about the random effects is that they are dependent within study, so
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(v_{cj}) = \tau^2_c \qquad \text{and} \qquad \text{Cov}(v_{bj}, v_{cj}) = \tau_{bc}
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(b,c = 1,...,C\)&lt;/span&gt;. Typically, these sorts of models would also rely on assumptions about the correlations between the sampling errors, just as with the second meaning of multivariate. Thus, to complete the model, we would have &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{hj}, e_{ij}) = \rho_{hij}\sigma_{hj}\sigma_{ij}\)&lt;/span&gt; for known &lt;span class=&#34;math inline&#34;&gt;\(\rho_{hij}\)&lt;/span&gt;. In practice, we might want to impose some common structure to the correlations across studies, such as using &lt;span class=&#34;math inline&#34;&gt;\(\rho_{hij}\)&lt;/span&gt;’s that depend on the dimensions being correlated but are common across studies. Formally, we would have
&lt;span class=&#34;math display&#34;&gt;\[
\rho_{hij} = \sum_{b=1}^C \sum_{c=1}^C d^b_{ij} \ d^c_{ij} \ \rho_{bc}.
\]&lt;/span&gt;
Of course, even getting this level of detail about correlations between effect sizes might often be pretty challenging.&lt;/p&gt;
&lt;p&gt;In a strictly multivariate meta-regression model, we would also allow the coefficients for each predictor to be specific to each category, so that
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \sum_{c=1}^C \left(\mathbf{x}_{ij}\boldsymbol\beta_c + v_{cj}\right) d^c_{ij} + e_{ij},
\]&lt;/span&gt;
In my example of educational intervention impact studies, say that are interested in whether the effects differ between quasi-experimental studies and true randomized control trials, and whether the effects differ based on the proportion of the sample that was economically disadvantaged. The strictly multivariate model would always involve interacting these predictors with the outcome category. In R’s equation notation, the meta-regression specification would be&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ES ~ 0 + Cat + Cat:RCT + Cat:disadvantaged_pct&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In contrast, in a generic meta-regression for dependent effect sizes, we might not include all of the interactions, and instead assume that the associations of the predictors were constant across outcome dimensions, as in&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ES ~ 0 + outcome_cat + RCT + college_pct&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the strict sense of the term, the model without interactions is no longer really a multivariate meta-regression.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;remarks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Remarks&lt;/h2&gt;
&lt;p&gt;An interesting property of strict multivariate meta-analysis models is that they involve partial pooling—or “borrowing of strength”—across dimensions &lt;span class=&#34;citation&#34;&gt;(Riley et al., &lt;a href=&#34;#ref-riley_evaluation_2007&#34; role=&#34;doc-biblioref&#34;&gt;2007&lt;/a&gt;, &lt;a href=&#34;#ref-riley_multivariate_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;. Even though the model has separate coefficients for each dimension, the estimates for a given dimension are influenced by the available effect sizes for &lt;em&gt;all&lt;/em&gt; dimensions. For instance, in the meta-analysis of educational intervention studies, the average impact on reading performance outcomes is based in part on the effect size estimates for the social studies and language arts performance. This happens because the model treats all of the dimensions as &lt;em&gt;correlated&lt;/em&gt;—through the correlated sampling errors and, potentially, through the correlated random effects structure. &lt;span class=&#34;citation&#34;&gt;Copas et al. (&lt;a href=&#34;#ref-copas_role_2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; examine how this works and propose a diagnostic plot to understand how it happens in application. &lt;span class=&#34;citation&#34;&gt;Kirkham et al. (&lt;a href=&#34;#ref-kirkham_multivariate_2012&#34; role=&#34;doc-biblioref&#34;&gt;2012&lt;/a&gt;)&lt;/span&gt; also show that the borrowing of strength phenomenon can partially mitigate bias from selective outcome reporting. These concepts could be quite relevant even beyond the “strict” multivariate meta-analysis context in which they have been explored. It strikes me that it would be useful to investigate them in the more general context of meta-analysis with dependent effect sizes—that is, multivariate meta-analysis in the first, broadest sense.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Becker2000multivariate&#34;&gt;
&lt;p&gt;Becker, B. J. (2000). Multivariate meta-analysis. In S. D. Brown &amp;amp; H. E. A. Tinsley (Eds.), &lt;em&gt;Handbook of applied multivariate statistics and mathematical modeling&lt;/em&gt; (pp. 499–525). Academic Press. &lt;a href=&#34;https://doi.org/10.1016/B978-012691360-6/50018-5&#34;&gt;https://doi.org/10.1016/B978-012691360-6/50018-5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Cooper1998synthesizing&#34;&gt;
&lt;p&gt;Cooper, H. M. (1998). &lt;em&gt;Synthesizing Research: A Guide for Literature Reviews&lt;/em&gt; (3rd ed.). Sage Publications, Inc.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-copas_role_2018&#34;&gt;
&lt;p&gt;Copas, J. B., Jackson, D., White, I. R., &amp;amp; Riley, R. D. (2018). The role of secondary outcomes in multivariate meta-analysis. &lt;em&gt;Journal of the Royal Statistical Society: Series C (Applied Statistics)&lt;/em&gt;, &lt;em&gt;67&lt;/em&gt;(5), 1177–1205. &lt;a href=&#34;https://doi.org/10.1111/rssc.12274&#34;&gt;https://doi.org/10.1111/rssc.12274&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Gleser2009stochastically&#34;&gt;
&lt;p&gt;Gleser, L. J., &amp;amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp;amp; J. C. Valentine (Eds.), &lt;em&gt;The handbook of research synthesis and meta-analysis&lt;/em&gt; (2nd ed., pp. 357–376). Russell Sage Foundation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Jackson2011multivariate&#34;&gt;
&lt;p&gt;Jackson, D., Riley, R. D., &amp;amp; White, I. R. (2011). Multivariate meta-analysis: Potential and promise. &lt;em&gt;Statistics in Medicine&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1002/sim.4172&#34;&gt;https://doi.org/10.1002/sim.4172&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kirkham_multivariate_2012&#34;&gt;
&lt;p&gt;Kirkham, J. J., Riley, R. D., &amp;amp; Williamson, P. R. (2012). A multivariate meta-analysis approach for reducing the impact of outcome reporting bias in systematic reviews. &lt;em&gt;Statistics in Medicine&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(20), 2179–2195. &lt;a href=&#34;https://doi.org/10.1002/sim.5356&#34;&gt;https://doi.org/10.1002/sim.5356&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-riley_evaluation_2007&#34;&gt;
&lt;p&gt;Riley, R. D., Abrams, K. R., Lambert, P. C., Sutton, A. J., &amp;amp; Thompson, J. R. (2007). An evaluation of bivariate random-effects meta-analysis for the joint synthesis of two correlated outcomes. &lt;em&gt;Statistics in Medicine&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(1), 78–97. &lt;a href=&#34;https://doi.org/10.1002/sim.2524&#34;&gt;https://doi.org/10.1002/sim.2524&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-riley_multivariate_2017&#34;&gt;
&lt;p&gt;Riley, R. D., Jackson, D., Salanti, G., Burke, D. L., Price, M., Kirkham, J., &amp;amp; White, I. R. (2017). Multivariate and network meta-analysis of multiple outcomes and multiple treatments: Rationale, concepts, and examples. &lt;em&gt;BMJ&lt;/em&gt;, j3932. &lt;a href=&#34;https://doi.org/10.1136/bmj.j3932&#34;&gt;https://doi.org/10.1136/bmj.j3932&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;“Mostly” rather than “uniformly” due to exceptions like Brad Efron (a.k.a. Mr. Bootstrap) and Rob Tibshirani (a.k.a. Mr. Lasso).&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;And then consider the square roots of these quantities, respectively: population standard deviation, sample standard deviation, and &lt;strong&gt;&lt;em&gt;standard error&lt;/em&gt;&lt;/strong&gt;. WTF?&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Read this article! It’s essential. And it comes with pages and pages of commentary by other statisticans.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Weighting in multivariate meta-analysis</title>
      <link>https://www.jepusto.com/weighting-in-multivariate-meta-analysis/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/weighting-in-multivariate-meta-analysis/</guid>
      <description>


&lt;p&gt;One common question about multivariate/multi-level meta-analysis is how such models assign weight to individual effect size estimates. When a version of the question came up recently on the &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2020-June/002149.html&#34;&gt;R-sig-meta-analysis listserv&lt;/a&gt;, Dr. Wolfgang Viechtbauer offered a &lt;a href=&#34;http://www.metafor-project.org/doku.php/tips:weights_in_rma.mv_models&#34;&gt;whole blog post&lt;/a&gt; in reply, demonstrating how weights work in simpler fixed effect and random effects meta-analysis and then how things get more complicated in multivariate models. I started thumb-typing my own reply as well, but then decided it would be better to write up a post so that I could use a bit of math notation (and to give my thumbs a break). So, in this post I’ll try to add some further intuition on how weights work in certain multivariate meta-analysis models. Most of the discussion will apply to models that include multiple level of random effects, but no predictors. I’ll also comment briefly on meta-regression models with only study-level predictor variables, and finally give some pointers to work on more complicated models.&lt;/p&gt;
&lt;div id=&#34;a-little-background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A little background&lt;/h2&gt;
&lt;p&gt;It’s helpful to start by looking briefly at the basic fixed effect and random effects models, assuming that we’ve got a set of studies that each contribute a single effect size estimate so everything’s independent. Letting &lt;span class=&#34;math inline&#34;&gt;\(T_j\)&lt;/span&gt; be the effect size from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, with sampling variance &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;, both for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;, the basic random effects model is:
&lt;span class=&#34;math display&#34;&gt;\[
T_j = \mu + \eta_j + e_j
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall average effect size, &lt;span class=&#34;math inline&#34;&gt;\(v_j\)&lt;/span&gt; is a random effect with variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e_j\)&lt;/span&gt; is a sampling error with known variance &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;. The first step in estimating this model is to estimate &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;. There’s lots of methods for doing so, but let’s not worry about those details—just pick one and call the estimate &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt;. Then, to estimate &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, we take a weighted average of the effect size estimates:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\mu = \frac{1}{W} \sum_{j=1}^k w_j T_j, \qquad \text{where} \quad W = \sum_{j=1}^k w_j.
\]&lt;/span&gt;
The weights used in the weighted average are chosen to make the overall estimate as precise as possible (i.e., having the smallest possible sampling variance or standard error). Mathematically, the best possible weights are &lt;strong&gt;&lt;em&gt;inverse variance&lt;/em&gt;&lt;/strong&gt; weights, that is, setting the weight for each effect size estimate proportional to the inverse of how much variance there is in each estimate. With inverse variance weights, larger studies with more precise effect size estimates will tend to get more weight and smaller, noisier studies will tend to get less weight.&lt;/p&gt;
&lt;p&gt;In the basic random effects model, the weights for each study are proportional to
&lt;span class=&#34;math display&#34;&gt;\[
w_j = \frac{1}{\hat\tau^2 + V_j},
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;. The denominator term here includes both the (estimated) between-study heterogeneity and the sampling variance because both terms contribute to how noisy the effect size estimate is. In the fixed effect model, we ignore between-study heterogeneity so the weights are inversely proportional to the sampling variances, with &lt;span class=&#34;math inline&#34;&gt;\(w_j = 1 / V_j\)&lt;/span&gt;. In the random effects model, larger between-study heterogeneity will make the weights closer to equal, while smaller between-study heterogeneity will lead to weights that tend to emphasize larger studies with more precise estimates. In the remainder, I’ll show that there are some similar dynamics at work in a more complicated, multivariate meta-analysis model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-multivariate-meta-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A multivariate meta-analysis&lt;/h2&gt;
&lt;p&gt;Now let’s consider the case where some or all studies in our synthesis contribute more than one effect size estimate. Say that we have effect sizes &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; indexes effect size estimates within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes studies, for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;. Say that effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; has sampling variance &lt;span class=&#34;math inline&#34;&gt;\(V_{ij}\)&lt;/span&gt;, and there is some sampling correlation between effect sizes &lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, denoted &lt;span class=&#34;math inline&#34;&gt;\(r_{hij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There are many models that a meta-analyst might consider for this data structure. A fairly common one would be a model that includes random effects not only for between-study heterogeneity (as in the basic random effects model) but also random effects capturing within-study heterogeneity in true effect sizes. Let me write this model heirarchically, as
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
T_{ij} &amp;amp;= \theta_j + \nu_{ij} + e_{ij} \\
\theta_j &amp;amp;= \mu + \eta_j
\end{align}
\]&lt;/span&gt;
In the first line of the model, &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; denotes the average effect size parameter for study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\nu_{ij}\)&lt;/span&gt; captures within-study heterogeneity in the true effect size parameters and &lt;span class=&#34;math inline&#34;&gt;\(e_{ij}\)&lt;/span&gt; is a sampling error. Above, I’ve assumed that we know the structure of the sampling errors, so &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(e_{ij}) = V_{ij}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{hj}, e_{ij}) = r_{hij} \sqrt{V_{hj} V_{ij}}\)&lt;/span&gt;. Let’s also denote the within-study variance as &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;, so &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\nu_{ij}) = \omega^2\)&lt;/span&gt;.
In the second line of the model, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is still the overall average effect size across all studies and effect sizes within studies and &lt;span class=&#34;math inline&#34;&gt;\(\eta_j\)&lt;/span&gt; is a between-study error, with &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt;, capturing the degree of heterogeneity in the &lt;em&gt;average&lt;/em&gt; effect sizes (the &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;’s) across studies.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One thing to note about this model is that it treats all of the effect sizes as coming from a population with a common mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. Some statisticians might object to calling it a multivariate model because we’re not distinguishing averages for different dimensions (or variates) of the effect sizes. To this I say: whatev’s, donkey! I’m calling it multivariate because you have to use the &lt;code&gt;rma.mv()&lt;/code&gt; function from the &lt;code&gt;metafor&lt;/code&gt; package to estimate it. I will acknowledge, though, that there will often be reason to use more complicated models, for example by replacing the overall average &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; with some meta-regression &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_{ij} \boldsymbol\beta\)&lt;/span&gt;. That’s a discussion for another day. For now, we’re only going to consider the model with an overall average effect size parameter &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. The question is, &lt;strong&gt;&lt;em&gt;how do the individual effect size estimates &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; contribute to the estimate of this overall average effect?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;equally-precise-effect-size-estimates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Equally precise effect size estimates&lt;/h2&gt;
&lt;p&gt;To make some headway, it is helpful to first consider an even more specific model where, within a given study, all effect size estimates are equally precise and equally correlated. In particular, let’s assume that for each study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, the sampling variances are all equal, with &lt;span class=&#34;math inline&#34;&gt;\(V_{ij} = V_j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt;, and the correlations between the sampling errors are also all equal, with &lt;span class=&#34;math inline&#34;&gt;\(r_{hij} = r_j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(h,i = 1,...,n_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;These assumptions might not be all that far-fetched. Within a given study, if the effect size estimates are for different measures of a common construct, it’s not unlikely that they would all be based on similar sample sizes (+/- a bit of item non-response). It might be a bit less likely if the effect size estimates are for treatment effects from different follow-up times (since drop-out/non-response tends to increase over time) or different treatment groups compared to a common control group—but still perhaps not entirely unreasonable. Further, it’s rather &lt;em&gt;uncommon&lt;/em&gt; to have good information about the correlations between effect size estimates from a given study (because primary studies don’t often report all of the information needed to calculate these correlations). In practice, meta-analysts might need to simply &lt;a href=&#34;https://www.jepusto.com/imputing-covariance-matrices-for-multi-variate-meta-analysis/&#34;&gt;make a rough guess about the correlations&lt;/a&gt; and then use robust variance estimation and/or sensitivity analysis to check themselves. And if we’re just ball-parking, then we’ll probably assume a single correlation for all of the studies.&lt;/p&gt;
&lt;p&gt;The handy thing about this particular scenario is that, because all of the effect size estimates within a study are equally precise and equally correlated, the most efficient way to estimate an average effect for a given study is to &lt;strong&gt;&lt;em&gt;just take the simple average&lt;/em&gt;&lt;/strong&gt; (and, intuitively, this seems like the only sensible thing to do). To be precise, consider how we would estimate &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; for a given study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;. The most precise possible estimate is simply
&lt;span class=&#34;math display&#34;&gt;\[
\hat\theta_j = \frac{1}{n_j} \sum_{i=1}^{n_j} T_{ij}.
\]&lt;/span&gt;
And we could do the same for each of the other studies, &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;.
It turns out that the estimate of the overall average effect size is a weighted average of these study-specific average effect sizes:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\mu = \frac{1}{W} \sum_{j=1}^k w_j \hat\theta_j,
\]&lt;/span&gt;
for some weights &lt;span class=&#34;math inline&#34;&gt;\(w_1,...,w_k\)&lt;/span&gt;. But what are these weights? Just like in the basic random effects model, they are inverse-variance weights. It’s just that the variance is a little bit more complicated.&lt;/p&gt;
&lt;p&gt;Consider how precise each of the study-specific estimates are, relative to the true effects in their respective studies. Conditional on the true effect &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\hat\theta_j | \theta_j) = \frac{1}{n_j}\left(\omega^2 + (n_j - 1) r_j V_j + V_j\right).
\]&lt;/span&gt;
Without conditioning on &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;, the variance of the &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta_j\)&lt;/span&gt; estimates also includes a term for variation in the true study-specific average effect sizes, becoming
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\hat\theta_j) = \tau^2 + \frac{1}{n_j}\left(\omega^2 + (n_j - 1) r_j V_j + V_j\right).
\]&lt;/span&gt;
The weights used in estimating &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; are the inverse of this quantity:
&lt;span class=&#34;math display&#34;&gt;\[
w_j = \frac{1}{\tau^2 + \frac{1}{n_j}\left(\omega^2 + (n_j - 1) r_j V_j + V_j\right)}.
\]&lt;/span&gt;
Within a study, each individual effect size gets an &lt;span class=&#34;math inline&#34;&gt;\(n_j^{th}\)&lt;/span&gt; of this study-level weight. We can therefore write the overall average as
&lt;span class=&#34;math display&#34;&gt;\[
\hat\mu = \frac{1}{W} \sum_{j=1}^k \sum_{i=1}^{n_j} w_{ij} T_{ij},
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
w_{ij} = \frac{1}{n_j \tau^2 + \omega^2 + (n_j - 1) r_j V_j + V_j}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;There are several things worth noting about this expression for the weights. First, suppose that there is little between-study or within-study heterogeneity, so &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; are both close to zero. Then the weights are driven by the number of effect sizes within the study (&lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt;), the sampling variance of those effect sizes (&lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;) and their correlation &lt;span class=&#34;math inline&#34;&gt;\(r_j\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(r_j\)&lt;/span&gt; is near one, then averaging together a bunch of highly correlated estimates doesn’t improve precision much, relative to just using one of the effect sizes. The study-specific average effect estimate will therefore have variance close to &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt; (i.e., the variance of a single effect size estimate). If &lt;span class=&#34;math inline&#34;&gt;\(r_j\)&lt;/span&gt; is below one, then averaging yields a more precise estimate than any of the individual effect sizes, and averaging together more effect sizes will yield a more precise estimate at the study level. If the assumed correlations are reasonably accurate, the weights used in the multi-variate meta-analysis will appropriately take into account the number of effect sizes within each study and the precision of those effect sizes.&lt;/p&gt;
&lt;p&gt;Second, now suppose that there is no between-study heterogeneity (&lt;span class=&#34;math inline&#34;&gt;\(\tau^2 = 0\)&lt;/span&gt;) but there is positive within-study heterogeneity. Larger degrees of within-study heterogeneity will tend to equalize the weights &lt;em&gt;at the effect size level&lt;/em&gt;, regardless of how effect size estimates are nested within studies. When there is within-study heterogeneity, averaging together a bunch of estimates will yield a more precise estimate of study-specific average effects. Therefore, when &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; is larger, studies with more effect sizes will tend to get a relatively larger share of the weight.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Third and finally, between-study heterogeneity will tend to equalize the weights at the study level, so that the overall average is pulled closer to a simple average of the study-specific average effects. This works very much like in basic random effects meta-analysis, where increased heterogeneity will lead to weights that are closer to equal and an average effect size estimate that is closer to a simple average.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-computational-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A computational example&lt;/h2&gt;
&lt;p&gt;I think it’s useful to verify algebraic results like the ones I’ve given above by checking that you can reproduce them with real data. I’ll use the &lt;code&gt;corrdat&lt;/code&gt; dataset from the &lt;code&gt;robumeta&lt;/code&gt; package for illustration. The dataset has one duplicated row in it (I have no idea why!), which I’ll remove before analyzing further.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

data(corrdat, package = &amp;quot;robumeta&amp;quot;)

corrdat &amp;lt;- 
  corrdat %&amp;gt;%
  distinct(studyid, esid, .keep_all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This dataset included a total of 171 effect size estimates from 39 unique studies. For each study, between 1 and 18 eligible effect size estimates were reported. Here is a histogram depicting the number of studies by the number of reported effect size estimates:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is the plot of the variances of each effect size versus the study IDs:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For most of the studies, the effect sizes have very similar sampling variances. One exception is study 9, where two of the effect sizes have variances of under 0.20 and the other two effect sizes have variances in excess of 0.35. Another exception is study 30, which has one effect size with much larger variance than the others.&lt;/p&gt;
&lt;p&gt;Just for sake of illustration, I’m going to &lt;em&gt;enforce&lt;/em&gt; my assumption that effect sizes have equal variances within each study by recomputing the sampling variances as the &lt;em&gt;average&lt;/em&gt; sampling variance within each study. I will then impute a sampling variance-covariance matrix for the effect sizes, assuming a correlation of 0.7 for effects from the same study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)

corrdat &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(V_bar = mean(var)) %&amp;gt;%
  ungroup()

V_mat &amp;lt;- impute_covariance_matrix(vi = corrdat$V_bar, 
                                  cluster = corrdat$studyid,
                                  r = 0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this variance-covariance matrix, I can then estimate the multivariate meta-analysis model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)

MVMA_fit &amp;lt;- rma.mv(yi = effectsize, V = V_mat, 
                   random = ~ 1 | studyid / esid,
                   data = corrdat)

summary(MVMA_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 171; method: REML)
## 
##   logLik  Deviance       AIC       BIC      AICc   
## -94.7852  189.5703  195.5703  204.9777  195.7149   
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed        factor 
## sigma^2.1  0.0466  0.2159     39     no       studyid 
## sigma^2.2  0.1098  0.3314    171     no  studyid/esid 
## 
## Test for Heterogeneity:
## Q(df = 170) = 1141.4235, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub      
##   0.2263  0.0589  3.8413  0.0001  0.1108  0.3417  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this model, between-study heterogeneity is estimated as &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.216\)&lt;/span&gt; and within-study heterogeneity is estimated as &lt;span class=&#34;math inline&#34;&gt;\(\hat\omega = 0.331\)&lt;/span&gt;, both of which are quite high. The overall average effect size estimate is 0.226, with a standard error of 0.059.&lt;/p&gt;
&lt;p&gt;I’ll first get the weights used in &lt;code&gt;rma.mv&lt;/code&gt; to compute the overall average. The weights are represented as an &lt;span class=&#34;math inline&#34;&gt;\(N \times N\)&lt;/span&gt; matrix. Taking the row or column sums, then rescaling by the total, gives the weight assigned to each effect size estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;W_mat &amp;lt;- weights(MVMA_fit, type = &amp;quot;matrix&amp;quot;)
corrdat$w_ij_metafor &amp;lt;- colSums(W_mat) / sum(W_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To verify that the formulas above are correct, I’ll use them to directly compute weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r &amp;lt;- 0.7
tau_sq &amp;lt;- MVMA_fit$sigma2[1]
omega_sq &amp;lt;- MVMA_fit$sigma2[2]

corrdat_weights &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(
    n_j = n(),
    w_ij = 1 / (n_j * tau_sq + omega_sq + (n_j - 1) * r * V_bar + V_bar)
  ) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(
    w_ij = w_ij / sum(w_ij)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The weights I computed are perfectly correlated with the weights used &lt;code&gt;rma.mv&lt;/code&gt;, as can be seen in the plot below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(corrdat_weights, aes(w_ij, w_ij_metafor)) + 
  geom_point() + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we remove the within-study random effect term from the model, the weights will be equivalent to setting &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; to zero, but with a different estimate of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVMA_no_omega &amp;lt;- rma.mv(yi = effectsize, V = V_mat, 
                        random = ~ 1 | studyid,
                        data = corrdat)
MVMA_no_omega&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 171; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2    0.0951  0.3084     39     no  studyid 
## 
## Test for Heterogeneity:
## Q(df = 170) = 1141.4235, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub      
##   0.2235  0.0619  3.6122  0.0003  0.1022  0.3448  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Re-fitting the model with &lt;code&gt;rma.mv()&lt;/code&gt; gives an between-study heterogeneity estimate of &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.308\)&lt;/span&gt; and an overall average effect size estimate of &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu = 0\)&lt;/span&gt;. Using this estimate, I’ll compute the weights based on the formula and then use those weights to determine the overall average effect size estimate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tau_sq &amp;lt;- MVMA_no_omega$sigma2

corrdat_weights &amp;lt;- 
  corrdat_weights %&amp;gt;%
  mutate(
    w_ij_no_omega = 1 / (n_j * tau_sq + (n_j - 1) * r * V_bar + V_bar),
    w_ij_no_omega = w_ij_no_omega / sum(w_ij_no_omega)
  )

with(corrdat_weights, weighted.mean(effectsize, w = w_ij_no_omega))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2235231&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This matches the output of &lt;code&gt;rma.mv()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is a plot showing the weights of individual effect sizes for each study. In blue are the weights under the assumption that &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 = 0\)&lt;/span&gt;. In green are the weights allowing for &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 &amp;gt; 0\)&lt;/span&gt;. It’s notable here that introducing the within-study heterogeneity term leads to pretty big changes in the weights for some studies. In particular, studies that have only a single effect size estimate (e.g., studys 7, 8, 22, 25, 28) lose &lt;em&gt;a lot&lt;/em&gt; of weight when &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 &amp;gt; 0\)&lt;/span&gt;. That’s partially because &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; tends to pull weight towards studies with more effect sizes, and partially because of the change in the estimate of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, which tends to equalize the weight assigned to each study.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Below is a plot illustrating the changes in study-level weights (i.e., aggregating the weight assigned to each study). The bar color corresponds to the number of effect size estimates in each study; light grey studies have just one effect size, while studies with more effect sizes are more intensly purple. The notable drops in weight for studies with a single effect size estimate (light grey) are visible here too. Studies with more effect sizes (e.g., studies 2, 15, 30, with dark purple bars) gain weight when we allow &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; to be greater than zero.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in
## ggplot2 3.3.4.
## ℹ Please use &amp;quot;none&amp;quot; instead.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-without-compound-symmetry&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Now without compound symmetry&lt;/h2&gt;
&lt;p&gt;If we remove the restrictions that effect sizes from the same study have the same sampling variance and are equi-correlated, then the weights get a little bit more complicated. However, the general intuitions carry through. Let’s now consider the model with arbitrary sampling variance &lt;span class=&#34;math inline&#34;&gt;\(V_{ij}\)&lt;/span&gt; and sampling correlations within studies &lt;span class=&#34;math inline&#34;&gt;\(r_{hij}\)&lt;/span&gt;. The most efficient estimate of the study-specific average effect is now a &lt;em&gt;weighted&lt;/em&gt; average, with weights that depend on both the variances and covariances of the effect size estimates within each study. Let
&lt;span class=&#34;math display&#34;&gt;\[
\boldsymbol{\hat\Sigma}_j = \hat\omega^2 \mathbf{I}_j + \mathbf{V}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{I}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times n_j\)&lt;/span&gt; identity matrix and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt; is the sampling variance-covariance matrix of the effect size estimates, with entry &lt;span class=&#34;math inline&#34;&gt;\((h,i)\)&lt;/span&gt; equal to &lt;span class=&#34;math inline&#34;&gt;\(\left[\mathbf{V}_j\right]_{h,i} = r_{hij} \sqrt{V_{hj} V_{ij}}\)&lt;/span&gt;. The estimate of the study-specific average effect size for study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is still a weighted average:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\theta_j = \frac{\sum_{i=1}^{n_j} s_{ij} T_{ij}}{\sum_{i=1}^{n_j} s_{ij}},
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
s_{ij} = \displaystyle{\sum_{h=1}^{n_j} \left[\boldsymbol{\hat\Sigma}^{-1}\right]_{hi}},
\]&lt;/span&gt;
and &lt;span class=&#34;math inline&#34;&gt;\(\left[\boldsymbol{\hat\Sigma}^{-1}\right]_{hi}\)&lt;/span&gt; denotes entry &lt;span class=&#34;math inline&#34;&gt;\((h,i)\)&lt;/span&gt; in the inverse of the matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\hat\Sigma}\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(V^C_j\)&lt;/span&gt; denote the variance of the study-specific average effect size estimate, conditional on the true &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
V^C_j = \text{Var}(\hat\theta_j | \theta_j) = \left(\sum_{i=1}^{n_j} s_{ij} \right)^{-1}
\]&lt;/span&gt;
The unconditional variance of &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta_j\)&lt;/span&gt; is then
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\hat\theta_j) = \tau^2 + V^C_j.
\]&lt;/span&gt;
Because the overall average effect size estimate is (still) the inverse-variance weighted average, the weight assigned at the study level is equal to
&lt;span class=&#34;math display&#34;&gt;\[
w_j = \frac{1}{\hat\tau^2 + V^C_j}
\]&lt;/span&gt;
and the weight assigned to individual effect sizes is
&lt;span class=&#34;math display&#34;&gt;\[
w_{ij} = \frac{s_{ij} V^C_j}{\hat\tau^2 + V^C_j}.
\]&lt;/span&gt;
How do &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; affect these more general weights? The intuitions that I described earlier still mostly hold. Increasing &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; will tend to equalize the weights at the effect size level (i.e., equalize the &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt; across &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;), pulling weight towards studies with more effect size estimates. Increasing &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; will tend to equalize the weights at the study-level.&lt;/p&gt;
&lt;p&gt;One wrinkle with the more general form of the weights is that the effect-size level weights can sometimes be &lt;em&gt;negative&lt;/em&gt; (i.e., negative &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt;). This will tend to happen when the sampling variances within a study are discrepant, such as when one &lt;span class=&#34;math inline&#34;&gt;\(V_{ij}\)&lt;/span&gt; is much smaller than the others in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, when the (assumed or estimated) sampling correlation is high, and when &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; is zero or small. This is something that warrants further investigation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-meta-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What about meta-regression?&lt;/h2&gt;
&lt;p&gt;Some of the foregoing analysis also applies to models that include predictors. In particular, the formulas I’ve given for the weights will still hold for meta-regression models &lt;strong&gt;&lt;em&gt;that include only study-level predictors&lt;/em&gt;&lt;/strong&gt;. In other words, they work for models of the following form:
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \mathbf{x}_j \boldsymbol\beta + \eta_j + \nu_{ij} + e_{ij},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_j\)&lt;/span&gt; is a row-vector of one or more predictors for study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (including a constant intercept). Introducing these predictors will alter the variance component estimates &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat\omega^2\)&lt;/span&gt;, but the form of the weights will remain the same as above, and the intuitions still hold. This is because, for purposes of estimating &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt;, the model is essentially the same as a meta-regression at the study level, using the study-specific average effect size estimates as input:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\theta_j = \mathbf{x}_j \boldsymbol\beta + \eta_j + \tilde{e}_j
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\tilde{e}_j) = \text{Var}(\hat\theta_j | \theta_j)\)&lt;/span&gt;.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here is an illustration with the &lt;code&gt;corrdat&lt;/code&gt; meta-analysis. In these data, the variable &lt;code&gt;college&lt;/code&gt; indicates whether the effect size comes from a college-age sample; it varies only at the study level. The variable &lt;code&gt;males&lt;/code&gt;, &lt;code&gt;binge&lt;/code&gt;, and &lt;code&gt;followup&lt;/code&gt; have some within-study variation, which I’ll by taking the average of each of these predictors at the study level:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrdat &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(
    males_M = mean(males),
    binge_M = mean(binge),
    followup_M = mean(followup)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s fit a meta-regression model using all of the study-level predictors:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVMR_fit &amp;lt;- rma.mv(yi = effectsize, V = V_mat,
                   mods = ~ college + males_M + binge_M + followup_M,  
                   random = ~ 1 | studyid / esid,
                   data = corrdat)

summary(MVMR_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 171; method: REML)
## 
##   logLik  Deviance       AIC       BIC      AICc   
## -86.6244  173.2488  187.2488  209.0327  187.9577   
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed        factor 
## sigma^2.1  0.0297  0.1723     39     no       studyid 
## sigma^2.2  0.1068  0.3268    171     no  studyid/esid 
## 
## Test for Residual Heterogeneity:
## QE(df = 166) = 1083.6655, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:5):
## QM(df = 4) = 13.0787, p-val = 0.0109
## 
## Model Results:
## 
##             estimate      se     zval    pval    ci.lb    ci.ub    
## intrcpt      -0.0361  0.3678  -0.0982  0.9218  -0.7571   0.6849    
## college       0.2660  0.1384   1.9215  0.0547  -0.0053   0.5373  . 
## males_M       0.0023  0.0048   0.4753  0.6346  -0.0072   0.0118    
## binge_M       0.3441  0.1570   2.1927  0.0283   0.0365   0.6518  * 
## followup_M   -0.0023  0.0011  -2.0379  0.0416  -0.0044  -0.0001  * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you might expect, between-study heterogeneity is reduced a bit by the inclusion of these predictors.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We can check my claim of computational equivalence by fitting the meta-regression model at the study level. Here I’ll aggregate everything up to the study level and compute the study-level weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tau_sq_reg &amp;lt;- MVMR_fit$sigma2[1]
omega_sq_reg &amp;lt;- MVMR_fit$sigma2[2]

corrdat_studylevel &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(n_j = n()) %&amp;gt;%
  summarize_at(vars(effectsize, n_j, V_bar, college, binge_M, followup_M, males_M), mean
  ) %&amp;gt;%
  mutate(
    V_cond = (omega_sq_reg + (n_j - 1) * r * V_bar + V_bar) / n_j,
    w_j = 1 / (tau_sq_reg + V_cond)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can fit a study-level meta-regression model. I use the &lt;code&gt;weights&lt;/code&gt; argument to ensure that the meta-regression is estimated using the &lt;span class=&#34;math inline&#34;&gt;\(w_j\)&lt;/span&gt; weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MR_study_fit &amp;lt;- rma(yi = effectsize, vi = V_cond, 
                    mods = ~ college + males_M + binge_M + followup_M, 
                    weights = w_j, data = corrdat_studylevel)
summary(MR_study_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 39; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc   
## -13.0651   26.1303   38.1303   47.2884   41.2414   
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0297 (SE = 0.0264)
## tau (square root of estimated tau^2 value):             0.1723
## I^2 (residual heterogeneity / unaccounted variability): 26.89%
## H^2 (unaccounted variability / sampling variability):   1.37
## R^2 (amount of heterogeneity accounted for):            37.90%
## 
## Test for Residual Heterogeneity:
## QE(df = 34) = 46.5050, p-val = 0.0748
## 
## Test of Moderators (coefficients 2:5):
## QM(df = 4) = 13.0787, p-val = 0.0109
## 
## Model Results:
## 
##             estimate      se     zval    pval    ci.lb    ci.ub    
## intrcpt      -0.0361  0.3678  -0.0982  0.9218  -0.7571   0.6849    
## college       0.2660  0.1384   1.9215  0.0547  -0.0053   0.5373  . 
## males_M       0.0023  0.0048   0.4753  0.6346  -0.0072   0.0118    
## binge_M       0.3441  0.1570   2.1927  0.0283   0.0365   0.6518  * 
## followup_M   -0.0023  0.0011  -2.0379  0.0416  -0.0044  -0.0001  * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The meta-regression coefficient estimates are essentially identical to those from the multi-variate meta-regression, although the between-study heterogeneity estimate differs slightly because it is based on maximizing the single-level model, conditional on an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;and-beyond&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;And beyond!&lt;/h1&gt;
&lt;p&gt;In true multi-variate models, the meta-regression specification would typically include indicators for each dimension of the model. More generally, we might have a model that includes predictors varying within study, encoding characteristics of the outcome measures, sub-groups, or treatment conditions corresponding to each effect size estimate. The weights in these model get substantially more complicated, not in the least because the weights &lt;em&gt;are specific to the predictors&lt;/em&gt;. For instance, in a model with four within-study predictors, a different set of weights is used in estimating the coefficients corresponding to each predictor. As Dr. &lt;a href=&#34;https://twitter.com/Richard_D_Riley&#34;&gt;Richard Riley&lt;/a&gt; noted on Twitter, relevant work on more complicated models includes &lt;a href=&#34;https://doi.org/10.1177/0962280215611702&#34;&gt;this great paper by Dan Jackson and colleagues&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.1177/0962280216688033&#34;&gt;this paper by Riley and colleagues&lt;/a&gt;. The latter paper demonstrates how multivariate models entail partial “borrowing of strength” across dimensions of the effect sizes, which is very helpful for building intuition about how these models work. I would encourage you to check out both papers if you are grappling with understanding how weights work in complex meta-regression models.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Note that this model also encompasses the multi-level meta-analysis described by &lt;a href=&#34;https://doi.org/10.1002/jrsm.35&#34;&gt;Konstantopoulos (2011)&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.3758/s13428-012-0261-6&#34;&gt;Van den Noortgate, et al. (2013)&lt;/a&gt; as a special case, with &lt;span class=&#34;math inline&#34;&gt;\(r_{hij} = 0\)&lt;/span&gt; for all &lt;span class=&#34;math inline&#34;&gt;\(h,i=1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Perhaps that makes sense, if you’ve carefully selected the set of effect sizes for inclusion in your meta-analysis. However, it seems to me that it could sometimes lead to perverse results. Say that all studies but one include just a single effect size estimate, each using the absolute gold standard approach to assessing the outcome, but that one study took a “kitchen sink” approach and assessed the outcome a bunch of different ways, including the gold standard plus a bunch of junky scales. Inclusion of the junky scales will lead to within-study heterogeneity, which in turn will &lt;em&gt;pull the overall average effect size towards this study—the one with all the junk!&lt;/em&gt; That seems less than ideal, and the sort of situation where it would be better to select from the study with multiple outcomes the single effect size estimate based on the outcome assessment that most closely aligns with the other studies.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Things get even simpler if the model does not include within-study random effects, as I discussed in &lt;a href=&#34;https://www.jepusto.com/sometimes-aggregating-effect-sizes-is-fine/&#34;&gt;a previous post&lt;/a&gt;.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;However, this need not be the case—it’s possible that introducing between-study predictors could &lt;em&gt;increase&lt;/em&gt; the estimate of between-study heterogeneity. Yes, that’s totally counter-intuitive. Multi-level models can be weird.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Psychosocial interventions for cancer survivors: A meta-analysis of effects on positive affect</title>
      <link>https://www.jepusto.com/publication/psychosocial-interventions-for-positive-affect/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/psychosocial-interventions-for-positive-affect/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulating correlated standardized mean differences for meta-analysis</title>
      <link>https://www.jepusto.com/simulating-correlated-smds/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/simulating-correlated-smds/</guid>
      <description>


&lt;p&gt;As I’ve discussed in &lt;a href=&#34;https://www.jepusto.com/Sometimes-aggregating-effect-sizes-is-fine&#34;&gt;previous posts&lt;/a&gt;, meta-analyses in psychology, education, and other areas often include studies that contribute multiple, statistically dependent effect size estimates.
I’m interested in methods for meta-analyzing and meta-regressing effect sizes from data structures like this, and studying this sort of thing often entails conducting Monte Carlo simulations.
Monte Carlo simulations involve generating artificial data—in this case, a set of studies, each of which has one or more dependent effect size estimates—that follows a certain distributional model, applying different analytic methods to the artificial data, and then repeating the process a bunch of times.
Because we know the true parameters that govern the data-generating process, we can evaluate the performance of the analytic methods in terms of bias, accuracy, hypothesis test calibration and power, confidence interval coverage, and the like.&lt;/p&gt;
&lt;p&gt;In this post, I’ll discuss two alternative methods to simulate meta-analytic datasets that include studies with multiple, dependent effect size estimates: simulating individual participant-level data or simulating summary statistics. I’ll focus on the case of the standardized mean difference (SMD) because it is so common in meta-analyses of intervention studies. For simplicity, I’ll assume that the effect sizes all come from simple, two-group comparisons (without any covariate adjustment or anything like that) and that the individual observations are multi-variate normally distributed within each group. Our goal will be to simulate a set of &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is based on measuring &lt;span class=&#34;math inline&#34;&gt;\(J_k\)&lt;/span&gt; outcomes on a sample of &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt; participants, all for &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;.
Let &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\delta_k = (\delta_{1k} \cdots \delta_{J_k k})&amp;#39;\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of true standardized mean differences for study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
I’ll assume that we know these true effect size parameters for all &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, so that I can avoid committing to any particular form of random effects model.&lt;/p&gt;
&lt;div id=&#34;simulating-individual-participant-level-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulating individual participant-level data&lt;/h1&gt;
&lt;p&gt;The most direct way to simulate this sort of effect size data is to generate outcome data for every artificial participant in every artificial study. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_{ik}^T\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of outcomes for treatment group participant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_{ik}^C\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector outcomes for control group participant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i=1,...,N_k / 2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;. Assuming multi-variate normality of the outcomes, we can generate these outcome vectors as
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{Y}_{ik}^T \sim N\left(\boldsymbol\delta_k, \boldsymbol\Psi_k\right) \qquad \text{and}\qquad \mathbf{Y}_{ik}^C \sim N\left(\mathbf{0}, \boldsymbol\Psi_k\right),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Psi_k\)&lt;/span&gt; is the population correlation matrix of the outcomes in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
Note that I am setting the mean outcomes of the control group participants to zero and also specifying that the outcomes all have unit variance within each group.
After simulating data based on these distributions, the effect size estimates for each outcome can be calculated directly, following standard formulas.&lt;/p&gt;
&lt;p&gt;Here’s what this approach looks like in code.
It is helpful to simplify things by focusing on simulating just a single study with multiple, correlated effect sizes.
Focusing first on just the input parameters, a function might look like the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_SMDs_raw &amp;lt;- function(delta, J, N, Psi) {
  # stuff
  return(ES_data)  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above function skeleton, &lt;code&gt;delta&lt;/code&gt; would be the true effect size parameter &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\delta_k\)&lt;/span&gt;, &lt;code&gt;J&lt;/code&gt; would be the number of effect sizes to generate &lt;span class=&#34;math inline&#34;&gt;\((J_k)\)&lt;/span&gt;, &lt;code&gt;N&lt;/code&gt; is the total number of participants &lt;span class=&#34;math inline&#34;&gt;\((N_k)\)&lt;/span&gt;, and &lt;code&gt;Psi&lt;/code&gt; is a matrix of correlations between the outcomes &lt;span class=&#34;math inline&#34;&gt;\((\Psi_k)\)&lt;/span&gt;.
From these parameters, we’ll generate raw data, calculate effect size estimates and standard errors, and return the results in a little dataset.&lt;/p&gt;
&lt;p&gt;To make the function a little bit easier to use, I’m going overload the &lt;code&gt;Psi&lt;/code&gt; argument so that it can be a single number, indicating a common correlation between the outcomes. Thus, instead of having to feed in a &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; matrix, you can specify a single correlation &lt;span class=&#34;math inline&#34;&gt;\(r_k\)&lt;/span&gt;, and the function will assume that all of the outcomes are equicorrelated. In code, the logic is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!is.matrix(Psi)) Psi &amp;lt;- Psi + diag(1 - Psi, nrow = J)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the function with the innards:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_SMDs_raw &amp;lt;- function(delta, J, N, Psi) {

  require(mvtnorm) # for simulating multi-variate normal data
  
  # create Psi matrix assuming equicorrelation
  if (!is.matrix(Psi)) Psi &amp;lt;- Psi + diag(1 - Psi, nrow = J)
  
  # generate control group summary statistics
  Y_C &amp;lt;- rmvnorm(n = N / 2, mean = rep(0, J), sigma = Psi)
  ybar_C &amp;lt;- colMeans(Y_C)
  sd_C &amp;lt;- apply(Y_C, 2, sd)
  
  # generate treatment group summary statistics
  delta &amp;lt;- rep(delta, length.out = J)
  Y_T &amp;lt;- rmvnorm(n = N / 2, mean = delta, sigma = Psi)
  ybar_T &amp;lt;- colMeans(Y_T)
  sd_T &amp;lt;- apply(Y_T, 2, sd)

  # calculate Cohen&amp;#39;s d
  sd_pool &amp;lt;- sqrt((sd_C^2 + sd_T^2) / 2)
  ES &amp;lt;- (ybar_T - ybar_C) / sd_pool
  
  # calculate SE of d
  SE &amp;lt;- sqrt(4 / N + ES^2 / (2 * (N - 2)))

  data.frame(ES = ES, SE = SE, N = N)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In action:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;delta &amp;lt;- rnorm(4, mean = 0.2, sd = 0.1)
r_SMDs_raw(delta = delta, J = 4, N = 40, Psi = 0.6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: mvtnorm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            ES        SE  N
## 1 -0.19106514 0.3169863 40
## 2  0.18427227 0.3169334 40
## 3  0.25646209 0.3175932 40
## 4  0.00210429 0.3162279 40&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or if you’d rather specify the full &lt;span class=&#34;math inline&#34;&gt;\(\Psi_k\)&lt;/span&gt; matrix yourself:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Psi_k &amp;lt;- 0.6 + diag(0.4, nrow = 4)
Psi_k&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4]
## [1,]  1.0  0.6  0.6  0.6
## [2,]  0.6  1.0  0.6  0.6
## [3,]  0.6  0.6  1.0  0.6
## [4,]  0.6  0.6  0.6  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_SMDs_raw(delta = delta, J = 4, N = 40, Psi = Psi_k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           ES        SE  N
## 1 -0.1597097 0.3167580 40
## 2 -0.1717717 0.3168410 40
## 3 -0.4369032 0.3201744 40
## 4  0.0657410 0.3163177 40&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercises&lt;/h2&gt;
&lt;p&gt;The function above is serviceable but quite basic. I can think of several additional features that one might like to have for use in research simulations, but I’m feeling both cheeky and lazy at the moment, so I’ll leave them for you, dear reader. Here are some suggested exercises:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Add an argument to the function, &lt;code&gt;Hedges_g = TRUE&lt;/code&gt;, which controls where the simulated effect size is Hedges’ &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; or Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. If it is Hedges’ g, make sure that the standard error is corrected too.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add an argument to the function, &lt;code&gt;p_val = TRUE&lt;/code&gt;, which allows the user to control whether or not to return &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values from the test of mean differences for each outcome. Note that the p-values should be for a test of the &lt;em&gt;raw&lt;/em&gt; mean differences between groups, rather than a test of the effect size &lt;span class=&#34;math inline&#34;&gt;\(\delta_{jk} = 0\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add an argument to the function, &lt;code&gt;corr_mat = FALSE&lt;/code&gt;, which controls whether the function returns just the simulated effect sizes and SEs or both the simulated effect sizes and the full sampling variance-covariance matrix of the effect sizes. See &lt;a href=&#34;https://www.jepusto.com/correlations-between-SMDs&#34;&gt;here&lt;/a&gt; for the relevant formulas.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simulating-summary-statistics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulating summary statistics&lt;/h1&gt;
&lt;p&gt;Another approach to simulating SMDs is to sample from the distribution of the &lt;em&gt;summary statistics&lt;/em&gt; used in calculating the effect size. This approach should simplify the code, at the cost of having to use a bit of distribution theory. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\bar{y}}_{Tk}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\bar{y}}_{Ck}\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vectors of sample means for the treatment and control groups, respectively. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_k\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; sample covariance matrix of the outcomes, pooled across the treatment and control groups. Again assuming multi-variate normality, and following the same notation as above:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{\bar{y}}_{Ck} \sim N\left(\mathbf{0}, \frac{2}{N_k} \boldsymbol\Psi_k\right), \qquad \mathbf{\bar{y}}_{Tk} \sim N\left(\boldsymbol\delta_k, \frac{2}{N_k} \boldsymbol\Psi_k\right),
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\left(\mathbf{\bar{y}}_{Tk} - \mathbf{\bar{y}}_{Ck}\right) \sim N\left(\boldsymbol\delta_k, \frac{4}{N_k} \boldsymbol\Psi_k\right).
\]&lt;/span&gt;
This shows how we could directly simulate the numerator of the standardized mean difference.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;https://www.jepusto.com/distribution-of-sample-variances&#34;&gt;further bit of distribution theory&lt;/a&gt; says that the pooled sample covariance matrix follows a multiple of a &lt;a href=&#34;https://en.wikipedia.org/wiki/Wishart_distribution&#34;&gt;Wishart distribution&lt;/a&gt; with &lt;span class=&#34;math inline&#34;&gt;\(N_k - 2\)&lt;/span&gt; degrees of freedom and scale matrix &lt;span class=&#34;math inline&#34;&gt;\(\Psi_k\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
(N_k - 2) \mathbf{S}_k \sim Wishart\left(N_k - 2, \Psi_k \right).
\]&lt;/span&gt;
Thus, to simulate the denominators of the SMD estimates, we can simulate a single Wishart matrix, pull out the diagonal entries, divide by &lt;span class=&#34;math inline&#34;&gt;\(N_k - 2\)&lt;/span&gt;, and take the square root. In all, we draw a single &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; observation from a multi-variate normal distribution and a single &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; observation from a Wishart distribution. In contrast, the raw data approach requires simulating &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt; observations from a multi-variate normal distribution, then calculating &lt;span class=&#34;math inline&#34;&gt;\(4 J_k\)&lt;/span&gt; summary statistics (M and SD for each group on each outcome).&lt;/p&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercises&lt;/h2&gt;
&lt;p&gt;Once again, I’ll leave it to you, dear reader, to do the fun programming bits:&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create a modified version of the function &lt;code&gt;r_SMDs_raw&lt;/code&gt; that simulates summary statistics instead of raw data (Call it &lt;code&gt;r_SMDs_stats&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;microbenchmark&lt;/code&gt; package (or your preferred benchmarking tool) to compare the computational efficiency of both versions of the function.&lt;/li&gt;
&lt;li&gt;Check your work! Verify that both versions of the function generate the same distributions if the same parameters are used as input.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;which-approach-is-better&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Which approach is better?&lt;/h1&gt;
&lt;p&gt;Like many things in research, there’s no clearly superior method here. The advantage of the summary statistics approach is computational efficiency. It should generally be faster than the raw data approach, and if you need to generate 10,000 meta-analysis each with 80 studies in them, the computational savings might add up. On the other hand, computational efficiency isn’t everything.&lt;/p&gt;
&lt;p&gt;I see two potential advantages of the raw data approach. First is interpretability: simulating raw data is likely easier to understand. It feels tangible and familiar, harkening back to those bygone days we spent learning ANOVA, whereas the summary statistics approach requires a bit of distribution theory to follow (bookmark this blog post!). Second is extensibility: it is relatively straightforward to extend the approach to use other distributional models for the raw dat (perhaps you want to look at outcomes that follow a &lt;a href=&#34;https://en.wikipedia.org/wiki/Multivariate_t-distribution&#34;&gt;multi-variate &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; distribution&lt;/a&gt;?) or more complicated estimators of the SMD (difference-in-differences? covariate-adjusted? cluster-randomized trial?). To use the summary statistics approach in more complicated scenarios, you’d have to work out the sampling distributions for yourself, or locate the right reference.&lt;/p&gt;
&lt;p&gt;Of course, there’s also no need to choose between these two approaches. As I’m trying to hint at in Exercise 6, it’s actually useful to write both. Then, you can use the (potentially slower) raw data version to verify that the summary statistics version is correct.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulating-full-meta-analyses&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulating full meta-analyses&lt;/h1&gt;
&lt;p&gt;So far we’ve got a data-generating function that simulates a single study’s worth of effect size estimates. To study meta-analytic methods, we’ll need to build out the function to simulate multiple studies. To do so, I think it’s useful to use the technique of &lt;a href=&#34;https://r4ds.had.co.nz/iteration.html&#34;&gt;mapping&lt;/a&gt;, as implemented in the &lt;code&gt;purrr&lt;/code&gt; package’s &lt;code&gt;map_*&lt;/code&gt; functions. The idea here is to first generate a “menu” of study-specific parameters for each of &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, then apply the &lt;code&gt;r_SMDs&lt;/code&gt; function to each parameter set.&lt;/p&gt;
&lt;p&gt;Let’s consider how to do this for a simple random effects model, where the true effect size parameter is constant within each study (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\delta_k = (\delta_k \cdots \delta_k)&amp;#39;\)&lt;/span&gt;), and in a model without covariates. We’ll need to generate a true effect for each study, along with a sample size, an outcome dimension, and a correlation between outcomes. For the true effects, I’ll assume that
&lt;span class=&#34;math display&#34;&gt;\[
\delta_k \sim N(\mu, \tau^2),
\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
J_k \sim 2 + Poisson(3),
\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
N_k \sim 20 + 2 \times Poisson(10),
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
r_k \sim Beta\left(\rho \nu, (1 - \rho)\nu\right),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\rho = \text{E}(r_k)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\nu &amp;gt; 0\)&lt;/span&gt; controls the variability of &lt;span class=&#34;math inline&#34;&gt;\(r_k\)&lt;/span&gt; across studies, with smaller &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; corresponding to more variable correlations.
Specifically, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(r_k) = \rho (1 - \rho) / (1 + \nu)\)&lt;/span&gt;.
These distributions are just made up, without any particular justification.&lt;/p&gt;
&lt;p&gt;Here’s what these distributional models look like in R code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;K &amp;lt;- 6
mu &amp;lt;- 0.2
tau &amp;lt;- 0.05
J_mean &amp;lt;- 5
N_mean &amp;lt;- 45
rho &amp;lt;- 0.6
nu &amp;lt;- 39

study_data &amp;lt;- 
  data.frame(
    delta = rnorm(K, mean = mu, sd = tau),
    J = 2 + rpois(K, J_mean - 2),
    N = 20 + 2 * rpois(K, (N_mean - 20) / 2),
    Psi = rbeta(K, rho * nu, (1 - rho) * nu)
  )

study_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       delta J  N       Psi
## 1 0.1749657 6 56 0.6670410
## 2 0.1371771 4 52 0.7952095
## 3 0.1430044 2 46 0.5551301
## 4 0.1953675 6 46 0.5339670
## 5 0.1653242 4 42 0.5623903
## 6 0.1419457 7 40 0.6615825&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have the “menu” of study-level characteristics, it’s just a matter of mapping the parameters to the data-generating function. One way to do this is with &lt;code&gt;pmap_df&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
meta_data &amp;lt;- pmap_df(study_data, r_SMDs_raw, .id = &amp;quot;study&amp;quot;)
meta_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    study           ES        SE  N
## 1      1  0.427048814 0.2704019 56
## 2      1  0.206502285 0.2679989 56
## 3      1  0.270244756 0.2685234 56
## 4      1  0.423149362 0.2703451 56
## 5      1  0.525878094 0.2720096 56
## 6      1  0.746186579 0.2767383 56
## 7      2 -0.005809721 0.2773507 52
## 8      2 -0.082222645 0.2774719 52
## 9      2  0.114670949 0.2775871 52
## 10     2 -0.001432641 0.2773501 52
## 11     3 -0.031231291 0.2949027 46
## 12     3  0.302264458 0.2966391 46
## 13     4  0.085338908 0.2950242 46
## 14     4 -0.062511255 0.2949592 46
## 15     4 -0.040178730 0.2949150 46
## 16     4 -0.082519741 0.2950151 46
## 17     4  0.207953122 0.2957160 46
## 18     4 -0.005713721 0.2948845 46
## 19     5  0.293666394 0.3103483 42
## 20     5  0.258312309 0.3099551 42
## 21     5  0.362126706 0.3112512 42
## 22     5  0.177656049 0.3092452 42
## 23     6 -0.115158991 0.3165035 40
## 24     6  0.094349350 0.3164129 40
## 25     6 -0.052996601 0.3162862 40
## 26     6 -0.042766762 0.3162658 40
## 27     6 -0.314584445 0.3182800 40
## 28     6  0.078519103 0.3163560 40
## 29     6 -0.103034241 0.3164486 40&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(meta_data$study)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 1 2 3 4 5 6 
## 6 4 2 6 4 7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Putting it all together into a function, we have&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_meta &amp;lt;- function(K, mu, tau, J_mean, N_mean, rho, nu) {
  require(purrr)
  
  study_data &amp;lt;- 
    data.frame(
      delta = rnorm(K, mean = mu, sd = tau),
      J = 2 + rpois(K, J_mean - 2),
      N = 20 + 2 * rpois(K, (N_mean - 20) / 2),
      Psi = rbeta(K, rho * nu, (1 - rho) * nu)
    )
  
  pmap_df(study_data, r_SMDs_raw, .id = &amp;quot;study&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercises&lt;/h2&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Modify &lt;code&gt;r_meta&lt;/code&gt; so that it uses &lt;code&gt;r_SMDs_stats&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add options to &lt;code&gt;r_meta&lt;/code&gt; for &lt;code&gt;Hedges_g&lt;/code&gt;, &lt;code&gt;p_val = TRUE&lt;/code&gt;, and &lt;code&gt;corr_mat = FALSE&lt;/code&gt; and ensure that these get passed along to the &lt;code&gt;r_SMDs&lt;/code&gt; function.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One way to check that the &lt;code&gt;r_meta&lt;/code&gt; function is working properly is to generate a very large meta-analytic dataset, then to verify that the generated distributions align with expectations. Here’s a very large meta-analytic dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_data &amp;lt;- 
  r_meta(100000, mu = 0.2, tau = 0.05, 
         J_mean = 5, N_mean = 40, 
         rho = 0.6, nu = 39)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare the distribution of the simulated dataset against what you would expect to get based on the input parameters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modify the &lt;code&gt;r_meta&lt;/code&gt; function so that &lt;span class=&#34;math inline&#34;&gt;\(J_k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt; are correlated, according to
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
J_k &amp;amp;\sim 2 + Poisson(\mu_J - 2) \\
N_k &amp;amp;\sim 20 + 2 \times Poisson\left(\frac{1}{2}(\mu_N - 20) + \alpha (J_k - \mu_J) \right)
\end{align}
\]&lt;/span&gt;
for user-specified values of &lt;span class=&#34;math inline&#34;&gt;\(\mu_J\)&lt;/span&gt; (the average number of outcomes per study), &lt;span class=&#34;math inline&#34;&gt;\(\mu_N\)&lt;/span&gt; (the average total sample size per study), and &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, which controls the degree of dependence between &lt;span class=&#34;math inline&#34;&gt;\(J_k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;a-challenge&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A challenge&lt;/h2&gt;
&lt;p&gt;The meta-analytic model that we’re using here is quite simple—simplistic, even—and for some simulation studies, something more complex might be needed. For example, we might need to generate data from a model that includes within-study random effects, as in:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_{jk} = \mu + u_k + v_{jk}, \quad \text{where}\quad u_k \sim N(0, \tau^2), \quad v_{jk} \sim N(0, \omega^2).
\]&lt;/span&gt;
Even more complex would be to simulate from a multi-level meta-regression model
&lt;span class=&#34;math display&#34;&gt;\[
\delta_{jk} = \mathbf{x}_{jk} \boldsymbol\beta + u_k + v_{jk}, \quad \text{where}\quad u_k \sim N(0, \tau^2), \quad v_{jk} \sim N(0, \omega^2),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_{jk}\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(1 \times p\)&lt;/span&gt; row-vector of covariates describing outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(p \times 1\)&lt;/span&gt; vector of meta-regression coefficients. In past work, I’ve done this by writing a data-generating function that takes a fixed design matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X} = \left(\mathbf{x}_{11}&amp;#39; \cdots \mathbf{x}_{J_K K}&amp;#39;\right)&amp;#39;\)&lt;/span&gt; as an input argument, along with &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt;. The design matrix would also include an identifier for each unique study. There are surely better (simpler, easier to follow) ways to implement the multi-level meta-regression model. I’ll once again leave it to you to work out an approach.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Sometimes, aggregating effect sizes is fine</title>
      <link>https://www.jepusto.com/sometimes-aggregating-effect-sizes-is-fine/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/sometimes-aggregating-effect-sizes-is-fine/</guid>
      <description>


&lt;p&gt;In meta-analyses of psychology, education, and other social science research, it is very common that some of the included studies report more than one relevant effect size.
For example, in a meta-analysis of intervention effects on reading outcomes, some studies may have used multiple measures of reading outcomes (each of which meets inclusion criteria), or may have measured outcomes at multiple follow-up times; some studies might have also investigated more than one version of an intervention, and it might be of interest to include effect sizes comparing each version to the no-intervention control condition;
and it’s even possible that some studies may have &lt;em&gt;all&lt;/em&gt; of these features, potentially contributing &lt;em&gt;lots&lt;/em&gt; of effect size estimates.&lt;/p&gt;
&lt;p&gt;These situations create a technical challenge for conducting a meta-analysis.
Because effect size estimates from the same study are correlated, it’s not usually reasonable to use methods that are premised on each effect size estimate being independent (i.e., univariate methods).
Instead, the analyst needs to apply methods that take into account the dependencies among estimates coming from the same study.
It used to be common to use ad hoc approaches for handling dependence, such as averaging the estimates together or selecting one estimate per study and then using univariate methods &lt;span class=&#34;citation&#34;&gt;(cf. Becker, &lt;a href=&#34;#ref-Becker2000multivariate&#34; role=&#34;doc-biblioref&#34;&gt;2000&lt;/a&gt;)&lt;/span&gt;.
More sophisticated, multivariate meta-analysis (MVMA) models that directly account for correlations among the effect size estimates had been developed &lt;span class=&#34;citation&#34;&gt;(Kalaian &amp;amp; Raudenbush, &lt;a href=&#34;#ref-Kalaian1996multivariate&#34; role=&#34;doc-biblioref&#34;&gt;1996&lt;/a&gt;)&lt;/span&gt; but were challenging to implement and so rarely used (at least, that’s my impression).
More recently, techniques such as multi-level meta-analysis &lt;span class=&#34;citation&#34;&gt;(MLMA; Van den Noortgate et al., &lt;a href=&#34;#ref-VandenNoortgate2013threelevel&#34; role=&#34;doc-biblioref&#34;&gt;2013&lt;/a&gt;, &lt;a href=&#34;#ref-VandenNoortgate2015metaanalysis&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; and robust variance estimation &lt;span class=&#34;citation&#34;&gt;(RVE; Hedges et al., &lt;a href=&#34;#ref-Hedges2010robust&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;)&lt;/span&gt; have emerged, which account for dependencies while using all available effect size estimates and still being feasible to implement.
These new techniques of MLMA and RVE are starting to be more widely adopted in practice, and it is not implausible that they will become the standard approach in psychological and educational meta-analysis within a few years.&lt;/p&gt;
&lt;p&gt;Given the extent of interest in MLMA and RVE, one might wonder: are the older ad hoc approaches &lt;em&gt;ever&lt;/em&gt; reasonable or appropriate?
I think that some are, under certain circumstances.
In this post I’ll highlight one such circumstance, where aggregating effect size estimates is not only reasonable but leads to &lt;em&gt;exactly the same results&lt;/em&gt; as a multivariate model. This occurs when two conditions are met:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We are not interested in within-study heterogeneity of effects and&lt;/li&gt;
&lt;li&gt;Any predictors included in the model vary between studies but not within a given study (i.e., effect sizes from the same study all have the same values of the predictors).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In short, if all we care about is understanding between-study variation in effect sizes, then it is fine to aggregate them up to the study level.&lt;/p&gt;
&lt;div id=&#34;a-model-thats-okay-to-average&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A model that’s okay to average&lt;/h1&gt;
&lt;p&gt;To make this argument precise, let me lay out a model where it applies.
For full generality, I’ll consider a meta-regression model for a collection of &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; contributes &lt;span class=&#34;math inline&#34;&gt;\(J_k \geq 1\)&lt;/span&gt; effect size estimates.
Let &lt;span class=&#34;math inline&#34;&gt;\(T_{jk}\)&lt;/span&gt; denote effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, with sampling variance &lt;span class=&#34;math inline&#34;&gt;\(S_{jk}^2\)&lt;/span&gt;.
Effect size estimates from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; maybe be correlated at the sampling level, with correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho_{ijk}\)&lt;/span&gt; between effect size estimates &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
I will assume that the correlations are known, although in practice one might need to just take a guess about the degree of correlation, such as by assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho_{ijk} = 0.7\)&lt;/span&gt; for all pairs of estimates from each included study.
Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_k\)&lt;/span&gt; be a row vector of predictor variables for study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
Note that the predictors do not have a subscript &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; because I’m assuming here that they are constant within a study.&lt;/p&gt;
&lt;p&gt;A multivariate meta-regression model for these data might be:
&lt;span class=&#34;math display&#34;&gt;\[
T_{jk} = \mathbf{x}_k \boldsymbol\beta + u_k + e_{jk},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(u_k\)&lt;/span&gt; is a between-study random effect with variance &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e_{jk}\)&lt;/span&gt; is the sampling error for effect size &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, assumed to have known variance &lt;span class=&#34;math inline&#34;&gt;\(S_{jk}^2\)&lt;/span&gt;.
Errors from the same study are correlated, so &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{ik}, e_{jk}) = \rho_{ijk} S_{ik} S_{jk}\)&lt;/span&gt;.
This is a commonly considered model for dependent effect size estimates.
In the paper that introduced RVE, &lt;span class=&#34;citation&#34;&gt;Hedges et al. (&lt;a href=&#34;#ref-Hedges2010robust&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;)&lt;/span&gt; termed it the “correlated effects” model (implemented in &lt;code&gt;robumeta&lt;/code&gt; as &lt;code&gt;model = &#34;CORR&#34;&lt;/code&gt;, which is the default).
Note that it also satisfies the conditions I outlined above: no within-study random effects, predictors that vary only between study.
We can fit it using the &lt;code&gt;rma.mv()&lt;/code&gt; function in the &lt;code&gt;metafor&lt;/code&gt; package, as I will demonstrate below.&lt;/p&gt;
&lt;p&gt;An alternative to this multivariate model would be to first average the effects within each study, then fit a univariate random effects model.
Just how we do the averaging will matter: we’ll need to use inverse-variance weighting.
Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of effect size estimates from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_k\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; sampling covariance matrix for &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{1}_k\)&lt;/span&gt; be a &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of 1s. The inverse-variance weighted average of the effects from study k can then be written as
&lt;span class=&#34;math display&#34;&gt;\[
\bar{T}_k = V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{T}_k, 
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(V_k = 1 / (\mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{1}_k)\)&lt;/span&gt;. The quantity &lt;span class=&#34;math inline&#34;&gt;\(V_k\)&lt;/span&gt; is also the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(\bar{T}_k\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A conventional, univariate random effects model for the averaged effect sizes is
&lt;span class=&#34;math display&#34;&gt;\[
\bar{T}_k = \mathbf{x}_k \boldsymbol\beta + u_k + \bar{e}_k, 
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(u_k) = \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\bar{e}_k) = V_k\)&lt;/span&gt;.
This model can be fit using &lt;code&gt;rma.uni&lt;/code&gt; from &lt;code&gt;metafor&lt;/code&gt;.
In fact, doing so will yield the same estimates of model parameters as fitting the multivariate model—for all intents and purposes, they are equivalent models.
There are at several different ways to see that this equivalence holds.
I’ll offer three, from most practical to most theoretical.
(If you’d rather just take my word that this claim is true, feel free to skip down to the &lt;a href=&#34;#so-what&#34;&gt;last section&lt;/a&gt;, where I comment on implications.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;computational-equivalence&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Computational equivalence&lt;/h1&gt;
&lt;p&gt;One good way to check the equivalence of the univariate and multivariate models is to apply both to a dataset. I’ll use the data from a stylized example described in &lt;span class=&#34;citation&#34;&gt;Tanner-Smith &amp;amp; Tipton (&lt;a href=&#34;#ref-TannerSmith2013robust&#34; role=&#34;doc-biblioref&#34;&gt;2013&lt;/a&gt;)&lt;/span&gt;, looking at the effects of alcohol abuse interventions on alcohol consumption among adolescents and young adults. (The data are simulated for teaching purposes, so don’t infer anything about real life from the results below!) The data are included in the &lt;code&gt;robumeta&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

data(corrdat, package = &amp;quot;robumeta&amp;quot;)

# sort by study
corrdat &amp;lt;- arrange(corrdat, studyid, esid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data consist of 172 effect sizes from 39 studies. Some studies report effects at multiple follow-up times and/or for multiple programs compared to a common control condition, leading to dependent effect size estimates.The data also include variables encoding a variety of sample and study characteristics, such as whether the study was conducted with a college student sample and the gender composition of the sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(corrdat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   esid studyid effectsize        var binge followup males college
## 1 4006       1  0.2086383 0.03246468     1 51.42857    67       0
## 2 4016       1  0.2244635 0.03244931     1 51.42857    67       0
## 3 4026       1  0.3151743 0.03278697     1 51.42857    67       0
## 4 3513       2  0.2220929 0.01972874     0 17.14286    81       1
## 5 3514       2 -0.1922628 0.02031393     0 17.14286    86       1
## 6 3556       2  0.3273109 0.01987042     0 17.14286    81       1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose that we are interested in estimating the differences in average effects by type of sample (college versus adolescent), controlling for the proportion of males in the study. For some reason, there is within-study variation in the percentage of males, so I’ll take the study-level average for this covariate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrdat &amp;lt;-
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(males = mean(males))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then fit this model using a multi-variate meta-regression in metafor.&lt;/p&gt;
&lt;p&gt;In order to estimate the model, we’ll first need to create a variance-covariance matrix for the effect size estimates in each study, which can be accomplished using &lt;code&gt;impute_covariance_matrix&lt;/code&gt; from &lt;code&gt;clubSandwich&lt;/code&gt; (&lt;a href=&#34;https://www.jepusto.com/imputing-covariance-matrices-for-multi-variate-meta-analysis/&#34;&gt;further details here&lt;/a&gt;). I’ll assume a correlation of 0.6 between pairs of effect sizes within a given study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)
library(metafor)

V_list &amp;lt;- impute_covariance_matrix(vi = corrdat$var, cluster = corrdat$studyid, r = 0.6)

MV_fit &amp;lt;- rma.mv(effectsize ~ college + males, V = V_list, 
                 random = ~ 1 | studyid,
                 data = corrdat, method = &amp;quot;REML&amp;quot;)
MV_fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 172; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2    0.0590  0.2429     39     no  studyid 
## 
## Test for Residual Heterogeneity:
## QE(df = 169) = 815.2448, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 9.9016, p-val = 0.0071
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb    ci.ub 
## intrcpt    0.6466  0.2693   2.4007  0.0164   0.1187   1.1744   * 
## college    0.3703  0.1317   2.8123  0.0049   0.1122   0.6283  ** 
## males     -0.0076  0.0038  -1.9832  0.0473  -0.0152  -0.0001   * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternately, we could aggregate the effects up to the study level and then fit a univariate meta-regression using the same moderators. Here is a function to calculate the aggregated effect size estimates and variances:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;agg_effects &amp;lt;- function(yi, vi, r = 0.6) {
  corr_mat &amp;lt;- r + diag(1 - r, nrow = length(vi))
  sd_mat &amp;lt;- tcrossprod(sqrt(vi))
  V_inv_mat &amp;lt;- chol2inv(chol(sd_mat * corr_mat))
  V &amp;lt;- 1 / sum(V_inv_mat)
  data.frame(es = V * sum(yi * V_inv_mat), var = V)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the data-munging:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrdat_agg &amp;lt;-
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  summarise(
    es = list(agg_effects(yi = effectsize, vi = var, r = 0.6)),
    males = mean(males),
    college = mean(college)
  ) %&amp;gt;%
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `cols` is now required.
## Please use `cols = c(es)`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(corrdat_agg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   studyid      es    var males college
##     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1       1  0.249  0.0239  67         0
## 2       2 -0.0210 0.0129  81         1
## 3       3  0.726  0.0819  76.2       0
## 4       4  0.370  0.0431  80         1
## 5       5 -0.0911 0.0281  79         0
## 6       6 -0.416  0.0111  74         0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here’s the meta-regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uni_fit &amp;lt;- rma.uni(es ~ college + males, vi = var, 
                   data = corrdat_agg, method = &amp;quot;REML&amp;quot;)
uni_fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 39; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0590 (SE = 0.0242)
## tau (square root of estimated tau^2 value):             0.2429
## I^2 (residual heterogeneity / unaccounted variability): 61.42%
## H^2 (unaccounted variability / sampling variability):   2.59
## R^2 (amount of heterogeneity accounted for):            19.12%
## 
## Test for Residual Heterogeneity:
## QE(df = 36) = 96.7794, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 9.9016, p-val = 0.0071
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb    ci.ub 
## intrcpt    0.6466  0.2693   2.4007  0.0164   0.1187   1.1744   * 
## college    0.3703  0.1317   2.8123  0.0049   0.1122   0.6283  ** 
## males     -0.0076  0.0038  -1.9832  0.0473  -0.0152  -0.0001   * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The heterogeneity estimates are nearly equal (the difference is due to using numerical optimization):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MV_fit$sigma2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0589972&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uni_fit$tau2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.05899673&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the meta-regression coefficient estimates are identical to six decimal places:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(MV_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      intrcpt      college        males 
##  0.646561371  0.370274721 -0.007633517&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(uni_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      intrcpt      college        males 
##  0.646561352  0.370274307 -0.007633519&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(coef(MV_fit), coef(uni_fit))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Mean relative difference: 4.243578e-07&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this example we arrive at the same results using either multivariate meta-analysis or univariate meta-analysis of aggregated effect size estimates.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; The main limitation of this illustration is generality—how can we be sure that these results aren’t just a quirk of this particular dataset? Would we get the same results for &lt;em&gt;any&lt;/em&gt; dataset?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;from-multivariate-to-univariate-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;From multivariate to univariate model&lt;/h1&gt;
&lt;p&gt;Here’s another, somewhat more general perspective on the relationship between the models: the univariate model can be &lt;em&gt;derived&lt;/em&gt; directly from the multivariate one. Start with the multivariate model in matrix form:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_k = \mathbf{x}_k \boldsymbol\beta \mathbf{1}_k + u_k \mathbf{1}_k + \mathbf{e}_k,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{e}_k\)&lt;/span&gt; is the vector of sampling errors for study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{e}_k) = \mathbf{S}_k\)&lt;/span&gt;. Pre-multiply both sides by &lt;span class=&#34;math inline&#34;&gt;\(V_k \mathbf{1}_k’ \mathbf{S}_k^{-1}\)&lt;/span&gt; to get
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{T}_k &amp;amp;= V_k \left(\mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{1}_k\right) \mathbf{x}_k \boldsymbol\beta + u_k V_k \left(\mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{1}_k\right) + V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{e}_k \\
\bar{T}_k &amp;amp;= \mathbf{x}_k \boldsymbol\beta + u_k + \bar{e}_k,
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\bar{e}_k) = V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{S}_k \mathbf{S}_k^{-1} \mathbf{1}_k V_k = V_k\)&lt;/span&gt;, just as in the univariate model.&lt;/p&gt;
&lt;p&gt;This demonstrates that the parameters of the two models are the same quantities—that is, both models are estimating the same thing. But that would also hold if we used &lt;em&gt;any&lt;/em&gt; weighted average of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt;—it needn’t be inverse-variance. The only thing that would be different is &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\bar{e}_k)\)&lt;/span&gt;. To fully establish the equivalence of the two models, I’ll examine the likelihoods of each model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;equivalence-of-likelihoods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Equivalence of likelihoods&lt;/h1&gt;
&lt;p&gt;Multivariate meta-analysis models are typically estimated by full maximum likelihood (FML) or restricted maximum likelihood methods. FML and RML are also commonly used for univariate meta-analysis. With these methods, estimates are obtained as the parameter values that maximize the log likelihood of the model, given the data (or the restricted likelihood for RML). Therefore, we can establish the exact equivalence of parameter estimates by showing that the log likelihood of the univariate and multivariate models differ by a constant value (so that the location of the maxima are identical).&lt;/p&gt;
&lt;div id=&#34;full-likelihood&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full likelihood&lt;/h2&gt;
&lt;p&gt;For the univariate model, the log-likelihood contribution of study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
l^{U}_k\left(\boldsymbol\beta, \tau^2\right) = -\frac{1}{2} \log\left(\tau^2 + V_k\right) - \frac{1}{2} \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k}.
\]&lt;/span&gt;
For the multivariate model, the log-likelihood contribution of study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
l^{MV}_k\left(\boldsymbol\beta, \tau^2\right) = -\frac{1}{2} A -\frac{1}{2} B
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
A = \log\left|\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right| 
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
B = \left(\mathbf{T}_k - \mathbf{x}_k \boldsymbol\beta \mathbf{1}_k\right)&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \left(\mathbf{T}_k - \mathbf{x}_k \boldsymbol\beta \mathbf{1}_k\right).
\]&lt;/span&gt;
The term &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; can be rearranged as
&lt;span class=&#34;math display&#34;&gt;\[
A = \log\left|\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1} + \mathbf{I}_k\right) \mathbf{S}_k\right|
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{I}_k\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; identity matrix. One of the properties of determinants is that the determinant of a product of two matrices is equal to the product of the determinants. Another is that, for two vectors &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{v}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\left|\mathbf{I} + \mathbf{u}\mathbf{v}&amp;#39;\right| = 1 + \mathbf{v}&amp;#39;\mathbf{u}\)&lt;/span&gt;. Applying both of these properties, it follows that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
A &amp;amp;= \log\left|\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1} + \mathbf{I}_k\right) \mathbf{S}_k\right| \\
&amp;amp;= \log \left( \left|\mathbf{I}_k + \tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\right| \left|\mathbf{S}_k\right|\right) \\
&amp;amp;= \log \left(1 + \frac{\tau^2}{V_k}\right) + \log \left|\mathbf{S}_k\right| \\
&amp;amp;= \log(\tau^2 + V_k) - \log(V_k) + \log \left|\mathbf{S}_k\right|.
\end{aligned}
\]&lt;/span&gt;
The &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; term takes a little more work.
From &lt;a href=&#34;https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula&#34;&gt;the Sherman-Morrison identity&lt;/a&gt;, we have that:
&lt;span class=&#34;math display&#34; id=&#34;eq:Sherman&#34;&gt;\[
\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} = \mathbf{S}_k^{-1} - \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1},
\tag{1}
\]&lt;/span&gt;
by which it follows that
&lt;span class=&#34;math display&#34; id=&#34;eq:inversevariance&#34;&gt;\[
\mathbf{1}_k&amp;#39;\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1}\mathbf{1}_k = \frac{1}{\tau^2 + V_k}.
\tag{2}
\]&lt;/span&gt;
Now, rearrange the &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; term to get
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B &amp;amp;= \left[\mathbf{T}_k - \bar{T}_k \mathbf{1}_k + \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \mathbf{1}_k\right]&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \left[\mathbf{T}_k - \bar{T}_k \mathbf{1}_k + \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \mathbf{1}_k\right] \\
&amp;amp;= B_1 + 2 B_2 + B_3
\end{aligned}
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B_1 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) \\
B_2 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \\
B_3 &amp;amp;= \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \mathbf{1}_k&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)
\end{aligned}
\]&lt;/span&gt;
Applying &lt;a href=&#34;#eq:Sherman&#34;&gt;(1)&lt;/a&gt; to &lt;span class=&#34;math inline&#34;&gt;\(B_1\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B_1 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left[\mathbf{S}_k^{-1} - \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\right] \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) \\ 
&amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) - \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) \\
&amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right).
\end{aligned}
\]&lt;/span&gt;
The second term drops out because &lt;span class=&#34;math inline&#34;&gt;\(\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1} \mathbf{1}_k = \bar{T}_k / V_k - \bar{T}_k / V_k = 0\)&lt;/span&gt;. Along similar lines,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B_2 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left[\mathbf{S}_k^{-1} - \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\right] \mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \\ 
&amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) - \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \\
&amp;amp;= 0.
\end{aligned}
\]&lt;/span&gt;
Finally, the third term simplifies using &lt;a href=&#34;#eq:inversevariance&#34;&gt;(2)&lt;/a&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
B_3 = \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k}.
\]&lt;/span&gt;
Thus, the full &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; term reduces to
&lt;span class=&#34;math display&#34;&gt;\[
B = \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) + \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k}
\]&lt;/span&gt;
and the multivariate log likelihood contribution is
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
l^{MV}_k\left(\boldsymbol\beta, \tau^2\right) &amp;amp;= -\frac{1}{2} \log(\tau^2 + V_k) + \frac{1}{2} \log(V_k) - \frac{1}{2}\log \left|\mathbf{S}_k\right| - \frac{1}{2} \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) -\frac{1}{2} \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k} \\
&amp;amp;= l^U_k\left(\boldsymbol\beta, \tau^2\right) + \frac{1}{2} \log(V_k) - \frac{1}{2}\log \left|\mathbf{S}_k\right| - \frac{1}{2} \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right).
\end{aligned}
\]&lt;/span&gt;
The last three terms depend on the data (&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_k\)&lt;/span&gt;) but not on the parameters &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;. Therefore, the univariate and multivariate likelihoods will be maximized at the same parameter values, i.e., the FML estimators are identical.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;restricted-likelihood&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Restricted likelihood&lt;/h2&gt;
&lt;p&gt;In practice, it is more common to use RML estimation rather than FML.
The RML estimators maximize a different objective function that includes the full likelihood, plus an additional term. The RML objective function for the univariate model is
&lt;span class=&#34;math display&#34;&gt;\[
\sum_{k=1}^K l^U_k(\boldsymbol\beta, \tau^2) - \frac{1}{2} R^U(\tau^2)
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
R^U(\tau^2) = \log \left|\sum_{k=1}^k\frac{\mathbf{x}_k&amp;#39; \mathbf{x}_k}{\tau^2 + V_k} \right|.
\]&lt;/span&gt;
For the multivariate model, the RML objective is
&lt;span class=&#34;math display&#34;&gt;\[
\sum_{k=1}^K l^{MV}_k(\boldsymbol\beta, \tau^2) - \frac{1}{2} R^{MV}(\tau^2).
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
R^{MV}(\tau^2) &amp;amp;= \log \left|\sum_{k=1}^k \mathbf{x}_k&amp;#39;\mathbf{1}_k&amp;#39;\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1}\mathbf{1}_k \mathbf{x}_k \right|\\
&amp;amp;= \log \left|\sum_{k=1}^k\frac{\mathbf{x}_k&amp;#39; \mathbf{x}_k}{\tau^2 + V_k} \right| \\
&amp;amp;= R^U(\tau^2)
\end{aligned}
\]&lt;/span&gt;
because of &lt;a href=&#34;#eq:inversevariance&#34;&gt;(2)&lt;/a&gt;. Thus, the univariate and multivariate models also have the same RML estimators.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;so-what&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;So what?&lt;/h1&gt;
&lt;p&gt;Beyond being a good excuse to write a bunch of matrix algebra, why does any of this matter? I think there are two main implications. First, it is useful to recognize the equivalence of these models in order to understand when the multivariate model is &lt;em&gt;necessary&lt;/em&gt;. If both of the conditions that I’ve described hold, then it is entirely acceptable to use aggregation rather than the more complicated multivariate model.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; Using the simpler univariate model might be desirable in practice because it makes the analysis easier to follow, because it makes it easier to run diagnostics or create illustrations of the results, or because of software limitations. Conversely, if either of the conditions does not hold, then there may be differences between the two approaches and the analyst will need to think carefully about which method better addresses their research questions.&lt;/p&gt;
&lt;p&gt;A second implication is computational: because it gives the same results, the univariate model could be used as a short-cut for fitting the multivariate model. Compare the differences in computational time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(microbenchmark)
microbenchmark(
  uni = rma.uni(es ~ college + males, vi = var, 
                data = corrdat_agg, method = &amp;quot;REML&amp;quot;),
  multi = rma.mv(effectsize ~ college + males, V = V_list, 
                 random = ~ 1 | studyid,
                 data = corrdat, method = &amp;quot;REML&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##   expr     min      lq     mean   median       uq      max neval
##    uni  8.5638  8.7961 11.13178  8.96360  9.20370 110.2299   100
##  multi 78.7393 82.2588 85.56066 83.22175 84.71775 182.2056   100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the aggregation is done in advance, it is &lt;em&gt;way&lt;/em&gt; quicker to fit the univariate model. The short-cut would be useful if we needed to estimate &lt;em&gt;lots&lt;/em&gt; of multi-variate meta-regressions (as long as the equivalence conditions hold). For example, if we needed to bootstrap the multivariate model, we could pre-compute the aggregated effects and then just bootstrap the much simpler, much quicker univariate model.&lt;/p&gt;
&lt;p&gt;I suspect that the results I’ve presented here can be further generalized, but this will need a bit of further investigation. For one, there are also equivalences between variance estimators: using the CR2 cluster-robust variance estimator for the multivariate model is equivalent to using the HC2 heteroskedasticity-robust variance estimator for the univariate model with aggregated effects.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;
For another, the same sort of equivalence relationships hold even if there are additional random effects in the model, so long as the random effects are at the study level or higher levels of aggregation (e.g., lab effects, where labs are nested within studies).
I’ll leave these generalizations as exercises for a future rainy day.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Becker2000multivariate&#34;&gt;
&lt;p&gt;Becker, B. J. (2000). Multivariate meta-analysis. In S. D. Brown &amp;amp; H. E. A. Tinsley (Eds.), &lt;em&gt;Handbook of applied multivariate statistics and mathematical modeling&lt;/em&gt; (pp. 499–525). Academic Press. &lt;a href=&#34;https://doi.org/10.1016/B978-012691360-6/50018-5&#34;&gt;https://doi.org/10.1016/B978-012691360-6/50018-5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-borenstein2009introduction&#34;&gt;
&lt;p&gt;Borenstein, M., Hedges, L. V., Higgins, J. P. T., &amp;amp; Rothstein, H. R. (2009). &lt;em&gt;Introduction to Meta-Analysis&lt;/em&gt;. John Wiley &amp;amp; Sons, Ltd. &lt;a href=&#34;https://doi.org/10.1002/9780470743386&#34;&gt;https://doi.org/10.1002/9780470743386&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Hedges2010robust&#34;&gt;
&lt;p&gt;Hedges, L. V., Tipton, E., &amp;amp; Johnson, M. C. (2010). Robust variance estimation in meta-regression with dependent effect size estimates. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(1), 39–65. &lt;a href=&#34;https://doi.org/10.1002/jrsm.5&#34;&gt;https://doi.org/10.1002/jrsm.5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Kalaian1996multivariate&#34;&gt;
&lt;p&gt;Kalaian, H. a., &amp;amp; Raudenbush, S. W. (1996). A multivariate mixed linear model for meta-analysis. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(3), 227–235. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.1.3.227&#34;&gt;https://doi.org/10.1037/1082-989X.1.3.227&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-TannerSmith2013robust&#34;&gt;
&lt;p&gt;Tanner-Smith, E. E., &amp;amp; Tipton, E. (2013). Robust variance estimation with dependent effect sizes: Practical considerations including a software tutorial in Stata and SPSS. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;5&lt;/em&gt;(1), 1–34. &lt;a href=&#34;https://doi.org/10.1002/jrsm.1091&#34;&gt;https://doi.org/10.1002/jrsm.1091&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-VandenNoortgate2013threelevel&#34;&gt;
&lt;p&gt;Van den Noortgate, W., López-López, J. A., Marín-Martínez, F., &amp;amp; Sánchez-Meca, J. (2013). Three-level meta-analysis of dependent effect sizes. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;45&lt;/em&gt;(2), 576–594. &lt;a href=&#34;https://doi.org/10.3758/s13428-012-0261-6&#34;&gt;https://doi.org/10.3758/s13428-012-0261-6&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-VandenNoortgate2015metaanalysis&#34;&gt;
&lt;p&gt;Van den Noortgate, W., López-López, J. A., Marín-Martínez, F., &amp;amp; Sánchez-Meca, J. (2015). Meta-analysis of multiple outcomes: A multilevel approach. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(4), 1274–1294. &lt;a href=&#34;https://doi.org/10.3758/s13428-014-0527-2&#34;&gt;https://doi.org/10.3758/s13428-014-0527-2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;A common special case is that the sampling variances for effect sizes within a given study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; are &lt;em&gt;all equal&lt;/em&gt;, so that &lt;span class=&#34;math inline&#34;&gt;\(S_{ik} = s_{jk} = S_k\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i,j = 1,...,J_ik\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;. We might further posit that there is a constant sampling correlation between every pair of effect sizes within a given study, so that &lt;span class=&#34;math inline&#34;&gt;\(\rho_{ijk} = \rho_k\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i,j = 1,...,J_ik\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;. If both of these conditions hold, then the inverse-variance weighted average effect size simplifies to the arithmetic average
&lt;span class=&#34;math display&#34;&gt;\[
\bar{T}_k = \frac{1}{J_k} \sum_{j=1}^{J_k} T_{jk}
\]&lt;/span&gt;
with sampling variance
&lt;span class=&#34;math display&#34;&gt;\[
V_k = \frac{(J_k - 1)\rho_k + 1}{J} \times S_k^2
\]&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;(cf. Borenstein et al., &lt;a href=&#34;#ref-borenstein2009introduction&#34; role=&#34;doc-biblioref&#34;&gt;2009&lt;/a&gt;, Eq. (24.6), p. 230)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;The same thing holds if we use FML rather than RML estimation—try it for yourself and see!&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;As RVE and MLMA become more wide-spread, I could imagine it happening that a meta-analyst who uses aggregation and a univariate model might get push-back from a reviewer, who uncritically recommends using a “more advanced” method to handle dependence. The results in this post provide a way for the meta-analyst to establish that doing so would be unnecessary.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Here’s verification with the computational example from above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# multivariate CR2
coef_test(MV_fit, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Coef. Estimate      SE t-stat d.f. p-val (Satt) Sig.
## 1 intrcpt  0.64656 0.17647   3.66 11.5      0.00345   **
## 2 college  0.37027 0.18648   1.99 11.9      0.07053    .
## 3   males -0.00763 0.00287  -2.66 14.5      0.01826    *&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# univariate HC2
coef_test(uni_fit, vcov = &amp;quot;CR2&amp;quot;, cluster = corrdat_agg$studyid)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Coef. Estimate      SE t-stat d.f. p-val (Satt) Sig.
## 1 intrcpt  0.64656 0.17622   3.67 11.5      0.00342   **
## 2 college  0.37027 0.18597   1.99 11.9      0.06985    .
## 3   males -0.00763 0.00287  -2.66 14.5      0.01808    *&lt;/code&gt;&lt;/pre&gt;
&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Interventions to enhance self-efficacy in cancer patients and survivors: A meta-analysis of randomized controlled trials</title>
      <link>https://www.jepusto.com/publication/interventions-to-enhance-self-efficacy-in-cancer-patients/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/interventions-to-enhance-self-efficacy-in-cancer-patients/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effects of psychosocial interventions on meaning and purpose in adults with cancer: A systematic review and meta-analysis</title>
      <link>https://www.jepusto.com/publication/psychosocial-interventions-meaning-and-purpose/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/psychosocial-interventions-meaning-and-purpose/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CRAN downloads of my packages</title>
      <link>https://www.jepusto.com/package-downloads/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/package-downloads/</guid>
      <description>
&lt;script src=&#34;https://www.jepusto.com/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.jepusto.com/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;p&gt;At AERA this past weekend, one of the recurring themes was how software availability (and its usability and default features) influences how people conduct meta-analyses. That got me thinking about the R packages that I’ve developed, how to understand the extent to which people are using them, how they’re being used, and so on. I’ve had badges on my github repos for a while now:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clubSandwich: &lt;a href=&#34;https://CRAN.R-project.org/package=clubSandwich&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/clubSandwich&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ARPobservation: &lt;a href=&#34;https://CRAN.R-project.org/package=ARPobservation&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/ARPobservation&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;scdhlm: &lt;a href=&#34;https://CRAN.R-project.org/package=scdhlm&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/scdhlm&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SingleCaseES: &lt;a href=&#34;https://CRAN.R-project.org/package=SingleCaseES&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/SingleCaseES&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These statistics come from the &lt;a href=&#34;https://www.r-pkg.org/&#34;&gt;METACRAN&lt;/a&gt; site, which makes available data on daily downloads of all packages on CRAN (one of the main repositories for sharing R packages). The downloads are from the RStudio mirror of CRAN, which is only one of many mirrors around the world. Although the data do not represent complete tallies of all package downloads, they are nonetheless the best available source that I’m aware of.&lt;/p&gt;
&lt;p&gt;The thing is, the download numbers are rather hard to interpret. Beyond knowing that somebody out there is at least &lt;em&gt;trying&lt;/em&gt; to use the tools I’ve made, it’s pretty hard to gauge whether 300 or 3000 or 3 million downloads a month is a good usage level. In this post, I’ll attempt to put just a little bit of context around these numbers. Emphasis on &lt;em&gt;little bit&lt;/em&gt;, as I’m not all that satisfied with what I’ll show below, but at least it’s something beyond four numbers floating in the air.&lt;/p&gt;
&lt;div id=&#34;getting-package-download-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting package download data&lt;/h3&gt;
&lt;p&gt;I used the &lt;code&gt;cranlogs&lt;/code&gt; package to get daily download counts of all currently available CRAN packages over the period 2018-04-05 18:00:00 through 2019-04-06. I then limited the sample to packages that had been downloaded at least once between 2018-04-05 18:00:00 and 2018-10-05. This had the effect of excluding about 1000 packages that were either only recently added to CRAN or that had been discontinued but were still sitting on CRAN.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(cranlogs)

to_date &amp;lt;- &amp;quot;2019-04-06&amp;quot;
from_date &amp;lt;- as.character(as_date(to_date) - duration(1, &amp;quot;year&amp;quot;))
file_name &amp;lt;- paste0(&amp;quot;CRAN package downloads &amp;quot;, to_date, &amp;quot;.rds&amp;quot;)

pkg_downloads &amp;lt;-
  available.packages() %&amp;gt;%
  as_tibble() %&amp;gt;%
  select(Package, Version) %&amp;gt;%
  mutate(grp = 1 + trunc((row_number() - 1) / 100)) %&amp;gt;%
  nest(Package, Version) %&amp;gt;%
  mutate(downloads = map(.$data, ~ cran_downloads(packages = .$Package, 
                                                  from = from_date, 
                                                  to = to_date))) %&amp;gt;%
  select(-data) %&amp;gt;%
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;downloaded_last_yr &amp;lt;- 
  pkg_downloads %&amp;gt;%
  filter(date &amp;lt;= as_date(as_date(to_date) - duration(6, &amp;quot;months&amp;quot;))) %&amp;gt;%
  group_by(package) %&amp;gt;%
  summarise(
    count = sum(count),
    .groups = &amp;quot;drop&amp;quot;
  ) %&amp;gt;%
  filter(count &amp;gt; 0) %&amp;gt;%
  select(package)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This yielded 12925 packages. For each of these packages, I then calculated the average monthly download rate over the most recent six months, along with where that rate falls as a percentile of all packages in the sample.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;downloads_past_six &amp;lt;-
  pkg_downloads %&amp;gt;%
  filter(date &amp;gt; as_date(as_date(to_date) - duration(6, &amp;quot;months&amp;quot;))) %&amp;gt;%
  semi_join(downloaded_last_yr, by = &amp;quot;package&amp;quot;) %&amp;gt;%
  group_by(package) %&amp;gt;%
  summarise(
    count = sum(count) / 6,
    .groups = &amp;quot;drop&amp;quot;
  ) %&amp;gt;%
  mutate(
    package = fct_reorder(factor(package), count),
    pct_less = cume_dist(count)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pustos-packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Pusto’s packages&lt;/h3&gt;
&lt;p&gt;I have developed four packages that are currently available on CRAN:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;clubSandwich&lt;/code&gt; package provides cluster-robust variance estimators for a variety of different linear models (including meta-regression, hierarchical linear models, panel data models, etc.), as well as (more recently) some instrumental variables models. The package has received some attention in connection with estimating meta-analysis and meta-regression models, and it’s also relevant to applied micro-economics, field experiments, and other fields.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;scdhlm&lt;/code&gt; and &lt;code&gt;SingleCaseES&lt;/code&gt; packages provide functions and interactive web apps for calculating various effect sizes for single-case experimental designs. The &lt;code&gt;SingleCaseES&lt;/code&gt; package is fairly new and I haven’t yet written any articles that feature it. Both it and &lt;code&gt;scdhlm&lt;/code&gt; are relevant in fairly specialized fields where single-case experimental designs are commonly used—and where there is a need to meta-analyze results from such designs—and so I would not expect them to be widely downloaded.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;ARPobservation&lt;/code&gt; package provides tools for simulating behavioral observation data based on an alternating renewal process model. I developed this package for my own dissertation work, and my students and I have used it in some subsequent work. I think of it mostly as a tool for my group’s work on statistical methods for single-case experimental designs, and so would not expect to be widely downloaded or used outside of this area.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As points of comparison to my contributions, it is perhaps useful to look at two popular packages for conducting meta-analysis, the &lt;code&gt;metafor&lt;/code&gt; package and the &lt;code&gt;robumeta&lt;/code&gt; package:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;metafor&lt;/code&gt; package, developed by Wolfgang Viechtbauer, has been around for 10 years and includes all sorts of incredible tools for calculating effect sizes, estimating meta-analysis and meta-regression models, investigating fitted models, and representing the results graphically. In contrast, the &lt;code&gt;clubSandwich&lt;/code&gt; package is narrower in scope—it just calculates robust standard errors, confidence intervals, etc.—so &lt;code&gt;metafor&lt;/code&gt; is not a perfect point of comparison.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;robumeta&lt;/code&gt; package, by Zachary Fisher and Elizabeth Tipton, is a closer match in terms of scope. It is used for estimating meta-regression models with robust variance estimation, using specific methods proposed by Hedges, Tipton, and Johnson (2010).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am having a harder time thinking of good comparables for the &lt;code&gt;scdhlm&lt;/code&gt;, &lt;code&gt;SingleCaseES&lt;/code&gt;, and &lt;code&gt;ARPobservation&lt;/code&gt; packages due to their specialized focus. (Ideas? Suggestions? I’m all ears!)&lt;/p&gt;
&lt;p&gt;With that background, here are the average monthly download rates (over the past six months) for each of my four packages, along with &lt;code&gt;metafor&lt;/code&gt; and &lt;code&gt;robumeta&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(knitr)
library(kableExtra)

Pusto_pkgs &amp;lt;- c(&amp;quot;ARPobservation&amp;quot;,&amp;quot;scdhlm&amp;quot;,&amp;quot;SingleCaseES&amp;quot;,&amp;quot;clubSandwich&amp;quot;)
meta_pkgs &amp;lt;- c(&amp;quot;metafor&amp;quot;,&amp;quot;robumeta&amp;quot;)

focal_downloads &amp;lt;- 
  downloads_past_six %&amp;gt;%
  filter(package %in% c(Pusto_pkgs, meta_pkgs)) %&amp;gt;%
  mutate(
    count = round(count),
    pct_less = round(100 * pct_less, 1)
  ) %&amp;gt;%
  arrange(desc(count))

focal_downloads %&amp;gt;%
  rename(`Average monthly downloads` = count, 
         `Percentile of CRAN packages` = pct_less) %&amp;gt;%
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;), full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-hover table-condensed&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
package
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Average monthly downloads
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Percentile of CRAN packages
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
metafor
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7348
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
94.0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
clubSandwich
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2992
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90.3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
robumeta
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2025
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
87.9
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ARPobservation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
387
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
SingleCaseES
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
306
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
scdhlm
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
229
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Thus, &lt;code&gt;clubSandwich&lt;/code&gt; sits in between &lt;code&gt;metafor&lt;/code&gt; and &lt;code&gt;robumeta&lt;/code&gt;, at the 90th percentile among all active packages on CRAN. The other packages are much less widely downloaded, averaging between 200 and 400 downloads per month. The distribution of monthly download rates is &lt;em&gt;highly&lt;/em&gt; skewed, as can be seen in the figure below. About 68% of packages are downloaded 500 times or fewer per month, while only 7% of packages get more than 5000 downloads per month.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(colorspace)
library(ggrepel)

downloads_sample &amp;lt;- 
  downloads_past_six %&amp;gt;%
  arrange(count) %&amp;gt;%
  mutate(
    focal = package %in% c(Pusto_pkgs,meta_pkgs),
    tenth = (row_number(count) %% 10) == 1
  ) %&amp;gt;%
  filter(focal | tenth)

focal_pkg_dat &amp;lt;- 
  downloads_sample %&amp;gt;%
  filter(focal) %&amp;gt;%
  mutate(Pusto = if_else(package %in% Pusto_pkgs, &amp;quot;Pusto&amp;quot;,&amp;quot;comparison&amp;quot;))

title_str &amp;lt;- paste(&amp;quot;Average monthly downloads of R packages from&amp;quot;, as_date(as_date(to_date) - duration(6, &amp;quot;months&amp;quot;)),&amp;quot;through&amp;quot;,to_date)

qualitative_hcl(n = 2, h = c(140, -30), c = 90, l = 40, register = &amp;quot;custom-qual&amp;quot;)

ggplot(downloads_sample, aes(x = package, y = count)) +
  geom_col() + 
  geom_col(data = focal_pkg_dat, aes(color = Pusto, fill = Pusto), size = 1.5) + 
  geom_label_repel(
    data = focal_pkg_dat, aes(color = Pusto, label = package),
    segment.size = 0.4,
    segment.color = &amp;quot;grey50&amp;quot;,
    nudge_y = 0.5,
    point.padding = 0.3
  ) + 
  scale_y_log10(breaks = c(20, 50, 200, 500, 2000, 5000, 20000, 50000, 200000), labels = scales::comma) + 
  scale_fill_discrete_qualitative(palette = &amp;quot;custom-qual&amp;quot;) + 
  scale_color_discrete_qualitative(palette = &amp;quot;custom-qual&amp;quot;) + 
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;Downloads (per month)&amp;quot;, title = title_str) + 
  theme(legend.position = &amp;quot;none&amp;quot;, axis.line.x = element_blank(), axis.ticks.x = element_blank(), axis.text.x = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/CRAN-package-downloads_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;downloads-over-time&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Downloads over time&lt;/h3&gt;
&lt;p&gt;Here are the weekly download rates for each of my packages over the past two years. (Note that the vertical scales of the graphs differ.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weekly_downloads &amp;lt;- 
  pkg_downloads %&amp;gt;%
  mutate(
    yr = year(date),
    wk = week(date)
  ) %&amp;gt;%
  group_by(package, yr, wk) %&amp;gt;%
  mutate(
    date = max(date)
  ) %&amp;gt;%
  group_by(package, date) %&amp;gt;%
  summarise(
    count = sum(count),
    days = n(),
    .groups = &amp;quot;drop&amp;quot;
  )

weekly_downloads %&amp;gt;%
  filter(
    days == 7,
    package %in% Pusto_pkgs
  ) %&amp;gt;%
  ggplot(aes(date, count, color = package)) + 
  geom_line() + 
  expand_limits(y = 0) + 
  facet_wrap(~ package, scales = &amp;quot;free&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;Downloads (per month)&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/CRAN-package-downloads_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are a couple of curious features in these plots. For one, there are big spikes in downloads of &lt;code&gt;ARPobservation&lt;/code&gt; and &lt;code&gt;SingleCaseES&lt;/code&gt;. The &lt;code&gt;ARPobservation&lt;/code&gt; spike was in mid-June of 2018, when I was at the IES Single-Case Design training institute and demonstrated some of the package’s tools. The &lt;code&gt;SingleCaseES&lt;/code&gt; spike was in early January, 2019. Perhaps someone was teaching a class in single-case research and demonstrated the package? Or something at the IES PI meeting (January 9-10, 2019)?&lt;/p&gt;
&lt;p&gt;Another interesting pattern is in the download rate of &lt;code&gt;scdhlm&lt;/code&gt;, which looks like it increased systematically starting in September, 2018. I wonder if this was the result of someone demonstrating or incorporating use of the package into a course. Lacking details about where the downloads are coming from, it’s hard to do anything but speculate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;caveats-and-musings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Caveats and musings&lt;/h3&gt;
&lt;p&gt;Clearly, download counts are only a very rough proxy for package usage. In marketing-speak, they might be more like leads than conversion, in that people might be downloading a package only to discover that it’s not good for anything and then never use it to accomplish anything. Downloads are also not one-time events. If they use it in their work, a single person will likely download a package many times, over a span of time as new versions are released, onto multiple machines that they might use, by accident in the process of trying to install some other package, and so on. Downloads of inter-related packages are likely to be highly correlated too, as they will be with release of new major versions of R, which probably makes it a bit tricky to do event studies.&lt;/p&gt;
&lt;p&gt;Ultimately, I don’t know that knowing where my packages stand in terms of download rankings is all that useful. The packages that I’ve developed are all aimed at fairly academic audiences, which means that citations would probably be a better measure of contribution. The problem is, many people don’t know that they should be citing software, or how to do it. As usual, there’s an R function for that. Here’s how to get the citation for &lt;code&gt;clubSandwich&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;citation(package=&amp;quot;clubSandwich&amp;quot;) %&amp;gt;%
  print(style = &amp;quot;textVersion&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which returns the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;James Pustejovsky (2020). clubSandwich: Cluster-Robust (Sandwich) Variance Estimators with Small-Sample
Corrections. R package version 0.5.0. &lt;a href=&#34;https://CRAN.R-project.org/package=clubSandwich&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/package=clubSandwich&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Systematic Reviews and Meta-analysis SIG at AERA 2019</title>
      <link>https://www.jepusto.com/aera-2019-srma-sig/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/aera-2019-srma-sig/</guid>
      <description>


&lt;p&gt;This year, &lt;a href=&#34;https://pure.qub.ac.uk/portal/en/persons/laura-dunne(7bf21af1-3fa0-4c1b-aab9-7b5f526cb1c9).html&#34;&gt;Dr. Laura Dunne&lt;/a&gt; and I are serving as program co-chairs for the AERA special interest group on &lt;a href=&#34;http://www.aera.net/SIG176/Systematic-Reviews-and-Meta-Analysis-SIG176&#34;&gt;Systematic Reviews and Meta-Analysis&lt;/a&gt;, which is a great group of scholars interested in the methodology and application of research synthesis to questions in education and the broader social sciences. We had a strong batch of submissions to the SIG and (since we’re new and still a fairly small group) only a few sessions to fill with them. In assembling this year’s program, Laura and I noted a few common themes that stood out to us. In this post, I’ll highlight a few of them and hopefully whet your appetite to hear more during our sessions at this year’s convention. And if you want to skip the details for now, just take a look at our handy pdf with &lt;a href=&#34;https://www.jepusto.com/files/2019_SRMA_Schedule.pdf&#34;&gt;the full SIG program&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;sig-highlights&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;SIG highlights&lt;/h2&gt;
&lt;p&gt;First, two of this year’s presentations deal with &lt;strong&gt;&lt;em&gt;network meta-analysis&lt;/em&gt;&lt;/strong&gt;, an approach that goes beyond a single intervention-control comparison, to instead synthesize evidence on the comparative effects of multiple alternative interventions (not just red pill vs blue pill, but also red versus green, green versus blue, etc.). Network meta-analysis is increasingly important in clinical medicine (for example, &lt;a href=&#34;https://ora.ox.ac.uk/objects/uuid:95a796fa-e842-4e11-bee6-b0b2237a2541&#34;&gt;here’s a recent synthesis&lt;/a&gt; examining the relative efficacy of 21 different anti-depressant drugs) but it is still relatively rare in education and other social science meta-analyses. Not in this year’s SIG program though! Both our &lt;a href=&#34;http://tinyurl.com/ybfxaqq9&#34;&gt;Sunday morning paper session&lt;/a&gt; and &lt;a href=&#34;http://tinyurl.com/y773wb5x&#34;&gt;Monday round table&lt;/a&gt; feature applications of network meta-analysis: one on &lt;a href=&#34;http://tinyurl.com/y7ehtuhf&#34;&gt;distance and face-to-face learning&lt;/a&gt;, and one on &lt;a href=&#34;http://tinyurl.com/y8x5dh7f&#34;&gt;interventions for treatment of post-traumatic stress disorder&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Second, &lt;strong&gt;&lt;em&gt;publication bias&lt;/em&gt;&lt;/strong&gt; and other forms of &lt;strong&gt;&lt;em&gt;outcome reporting bias&lt;/em&gt;&lt;/strong&gt; remain one of the most vexing challenges for meta-analysis. Our &lt;a href=&#34;http://tinyurl.com/ybfxaqq9&#34;&gt;Sunday morning paper session&lt;/a&gt; includes an innovative methodological study on &lt;a href=&#34;http://tinyurl.com/yaze63jr&#34;&gt;how to detect selective outcome reporting in multi-level meta-analyses&lt;/a&gt;—an important setting where publication bias techniques have yet to be explored. Even with very sophisticated statistical tools, though, the best way to address publication bias is probably to try and prevent it in the first place. To that end, our &lt;a href=&#34;http://tinyurl.com/y773wb5x&#34;&gt;Monday round table session&lt;/a&gt; includes a presentation on &lt;a href=&#34;http://tinyurl.com/y6vslf6m&#34;&gt;locating unreported outcome data for use in meta-analysis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Third, the Systematic Reviews and Meta-Analysis SIG has always included &lt;strong&gt;&lt;em&gt;a mix of theory and practice&lt;/em&gt;&lt;/strong&gt;. In this year’s program, we’ve tried to preserve that mix within each of our sessions, so that our Sunday paper session and Monday round table each include both methodological research and substantive applications of meta-analysis. We hope that this will promote interesting and valuable dialogues within our community.&lt;/p&gt;
&lt;p&gt;Finally, I am very excited that &lt;a href=&#34;http://tinyurl.com/y45wbgfe&#34;&gt;our business meeting&lt;/a&gt; will feature an address by &lt;strong&gt;&lt;em&gt;&lt;a href=&#34;https://scholar.gse.upenn.edu/maynard&#34;&gt;Dr. Rebecca Maynard&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;, who is the University Trustee Chair Professor of Education and Social Policy at the University of Pennsylvania Graduate School of Education, and an influential voice in the use of research synthesis methods to inform education and social policy. She’ll be speaking on &lt;strong&gt;&lt;em&gt;Expanded Roles for Meta-Analysis in Supporting Evidence-Based Policy and Practice&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Be sure to check out &lt;a href=&#34;https://www.jepusto.com/files/2019_SRMA_Schedule.pdf&#34;&gt;the SIG program&lt;/a&gt; for more details and other sessions of interest. I look forward to seeing everyone in Toronto!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Testing for funnel plot asymmetry of standardized mean differences</title>
      <link>https://www.jepusto.com/publication/testing-for-funnel-plot-asymmetry-of-smds/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/testing-for-funnel-plot-asymmetry-of-smds/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Current practices in meta-regression in psychology, education, and medicine</title>
      <link>https://www.jepusto.com/publication/current-practices-in-meta-regression/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/current-practices-in-meta-regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A history of meta-regression: Technical, conceptual, and practical developments between 1974 and 2018</title>
      <link>https://www.jepusto.com/publication/history-of-meta-regression/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/history-of-meta-regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sampling variance of Pearson r in a two-level design</title>
      <link>https://www.jepusto.com/variance-of-r-in-two-level-design/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/variance-of-r-in-two-level-design/</guid>
      <description>


&lt;p&gt;Consider Pearson’s correlation coefficient, &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;, calculated from two variables &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; with population correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. If one calculates &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; from a simple random sample of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; observations, then its sampling variance will be approximately&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(r) \approx \frac{1}{N}\left(1 - \rho^2\right)^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;But what if the observations are drawn from a multi-stage sample? If one uses the raw correlation between the observations (ignoring the multi-level structure), then the &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; will actually be a weighted average of within-cluster and between-cluster correlations (see Snijders &amp;amp; Bosker, 2012). Intuitively, I would expect that the sampling variance of the between-cluster correlation will be a function of the number of clusters (regardless of the number of observations per cluster), so the variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; from a multi-stage sample would not necessarily be the same as that from a simple random sample. What is the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; in this design?&lt;/p&gt;
&lt;p&gt;Let me be more precise here by formalizing the sampling process. Suppose that we have a sample with &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; clusters, &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; observations in cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and total sample size &lt;span class=&#34;math inline&#34;&gt;\(N = \sum_{j=1}^m n_j\)&lt;/span&gt;. Assume that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
X_{ij} &amp;amp;= \mu_x + v^x_j + e^x_{ij} \\
Y_{ij} &amp;amp;= \mu_y + v^y_j + e^y_{ij},
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(i=1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j=1,...,m\)&lt;/span&gt;, where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\left[\begin{array}{c} v^x_j \\ v^y_j \end{array}\right] &amp;amp;\sim N\left(\left[\begin{array}{c}0 \\ 0 \end{array}\right], \left[\begin{array}{cc}\omega_x^2 &amp;amp; \phi \omega_x \omega_y \\ \phi \omega_x \omega_y &amp;amp; \omega_y^2\end{array}\right]\right) \\ 
\left[\begin{array}{c} e^x_{ij} \\ e^y_{ij} \end{array}\right] &amp;amp;\sim N\left(\left[\begin{array}{c}0 \\ 0 \end{array}\right], \left[\begin{array}{cc}\sigma_x^2 &amp;amp; \rho \sigma_x \sigma_y \\ \rho \sigma_x \sigma_y &amp;amp; \sigma_y^2\end{array}\right]\right)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the error terms are mutually independent unless otherwise noted. The raw Pearson’s &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is calculated using the total sums of squares and cross-products:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
r = \frac{SS_{xy}}{\sqrt{SS_{xx} SS_{yy}}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
SS_{xx} &amp;amp;= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(X_{ij} - \bar{\bar{x}}\right)^2, \qquad \bar{\bar{x}} = \frac{1}{N} \sum_{j=1}^m \sum_{i=1}^{n_j} X_{ij} \\
SS_{xy} &amp;amp;= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(Y_{ij} - \bar{\bar{y}}\right)^2, \qquad \bar{\bar{y}} = \frac{1}{N} \sum_{j=1}^m \sum_{i=1}^{n_j} Y_{ij} \\
SS_{xy} &amp;amp;= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(X_{ij} - \bar{\bar{x}}\right) \left(Y_{ij} - \bar{\bar{y}}\right).
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;common-correlation-and-icc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Common correlation and ICC&lt;/h3&gt;
&lt;p&gt;The distribution of the total correlation seems to be pretty complicated. So far, I’ve been able to obtain the variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; for a special case that makes some further, fairly restrictive assumptions. Specifically, assume that the correlation is constant across the two levels, so that &lt;span class=&#34;math inline&#34;&gt;\(\phi = \rho\)&lt;/span&gt;, and that the intra-class correlation of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is the same as that of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(k = \omega_x^2 / \sigma_x^2 = \omega_y^2 / \sigma_y^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\psi = k / (k + 1) = \omega_x^2 / (\omega_x^2 + \sigma_x^2)\)&lt;/span&gt;. Then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(r) \approx \frac{(1 - \rho^2)^2}{\tilde{N}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{N} = \frac{N[g_1 k + 1]^2}{g_2 k^2 + 2 g_1 k + 1} \approx \frac{N}{1 + (g_2 - g_1^2)\psi^2},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{g_1 = 1 - \frac{1}{N^2}\sum_{j=1}^m n_j^2}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{g_2 = \frac{1}{N}\sum_{j=1}^m n_j^2 - \frac{2}{N^2}\sum_{j=1}^m n_j^3 + \frac{1}{N^3} \left(\sum_{j=1}^m n_j^2 \right)^2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;If the clusters are all of equal size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{N} = \frac{nm[k(m - 1) / m + 1]^2}{k^2 n (m - 1)/m + 2 k (m - 1) / m + 1} \approx \frac{N}{1 + (n - 1) \psi^2},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The right-hand expression is a further approximation that will be very close to right so long as &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; is not too too small.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;z-transformation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Z-transformation&lt;/h3&gt;
&lt;p&gt;Under the (restrictive) assumptions of common correlation and equal ICCs, Fisher’s z transformation is variance-stabilizing (as it is under simple random sampling), so it seems reasonable to use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(z(r)\right) \approx \frac{1}{\tilde{N} - 3}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;design-effect&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Design effect&lt;/h3&gt;
&lt;p&gt;The design effect (&lt;span class=&#34;math inline&#34;&gt;\(DEF\)&lt;/span&gt;) is the ratio of the actual sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; to the sampling variance in a simple random sample of the same size. For the special case that I’ve described,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
DEF = \frac{N}{\tilde{N}} = 1 + (g_2 - g_1^2) \psi^2,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or with equal cluster-sizes, &lt;span class=&#34;math inline&#34;&gt;\(DEF = 1 + (n - 1)\psi^2\)&lt;/span&gt;. These expressions make it clear that the design effect for the correlation is &lt;em&gt;not&lt;/em&gt; equivalent to the well-known design effect for means or mean differences in cluster-randomized designs, which is &lt;span class=&#34;math inline&#34;&gt;\(1 + (n - 1)\psi\)&lt;/span&gt;. We need to take the &lt;em&gt;square&lt;/em&gt; of the ICC here, which will make the design effect for &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; &lt;em&gt;smaller&lt;/em&gt; than the design effect for a mean (or difference in means) based on the same sample.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-special-cases&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other special cases&lt;/h3&gt;
&lt;p&gt;There are some further special cases that are not to hard to work out and could be useful as rough approximations at least. One is if the within-cluster correlation is zero &lt;span class=&#34;math inline&#34;&gt;\((\rho = 0)\)&lt;/span&gt; and we’re interested in the between-cluster correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. Then the total correlation can be corrected for what is essentially measurement error using formulas from &lt;a href=&#34;https://www.amazon.com/Methods-Meta-Analysis-Correcting-Research-Findings/dp/141290479X&#34;&gt;Hunter and Schmidt (2004)&lt;/a&gt;. A further specialization is if &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is a cluster-level measure, so that &lt;span class=&#34;math inline&#34;&gt;\(\sigma_x^2 = 0\)&lt;/span&gt;. I’ll consider these in a later post, perhaps.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New paper: Using response ratios for meta-analyzing SCDs with behavioral outcomes</title>
      <link>https://www.jepusto.com/using-response-ratios-paper/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/using-response-ratios-paper/</guid>
      <description>


&lt;p&gt;I’m pleased to announce that my article “Using response ratios for meta-analyzing SCDs with behavioral outcomes” has been accepted at &lt;em&gt;Journal of School Psychology&lt;/em&gt;. There’s a multitude of ways that you can access this work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the next 6 weeks or so, the published version of the article will be &lt;a href=&#34;https://authors.elsevier.com/a/1Wj5D56ZN7p98&#34;&gt;available at the journal website&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The pre-print will always remain &lt;a href=&#34;https://psyarxiv.com/nj28d/&#34;&gt;available at PsyArXiv&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Some supporting materials and replication code are &lt;a href=&#34;https://osf.io/c3fe9/&#34;&gt;available on the Open Science Framework&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s the abstract of the paper:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Methods for meta-analyzing single-case designs (SCDs) are needed to inform evidence-based practice in clinical and school settingsand to draw broader and more defensible generalizations in areas where SCDs comprise a large part of the research base. The most widely used outcomesin single-case research are measures of behavior collected using systematic direct observation, which typically take the form of rates or proportions. For studies that use such measures, one simple and intuitive way to quantify effect sizes is in terms of proportionate change from baseline, using an effect size known as the log response ratio. This paper describes methods for estimating log response ratios and combining the estimates using meta-analysis. The methods are based on a simple model for comparing two phases, where the level of the outcome is stable within each phase and the repeated outcome measurements are independent. Although auto-correlation will lead to biased estimates of the sampling variance of the effect size, meta-analysis of response ratios can be conducted with robust variance estimation procedures that remain valid even when sampling variance estimates are biased. The methods are demonstrated using data from a recent meta-analysis on group contingency interventions for student problem behavior.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Using response ratios for meta-analyzing single-case designs with behavioral outcomes</title>
      <link>https://www.jepusto.com/publication/using-response-ratios/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/using-response-ratios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Introduction to the special issue on single-case systematic reviews and meta-analysis</title>
      <link>https://www.jepusto.com/publication/rase-special-issue-introduction/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/rase-special-issue-introduction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Imputing covariance matrices for meta-analysis of correlated effects</title>
      <link>https://www.jepusto.com/imputing-covariance-matrices-for-multi-variate-meta-analysis/</link>
      <pubDate>Thu, 10 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/imputing-covariance-matrices-for-multi-variate-meta-analysis/</guid>
      <description>


&lt;p&gt;In many systematic reviews, it is common for eligible studies to contribute effect size estimates from not just one, but &lt;em&gt;multiple&lt;/em&gt; relevant outcome measures, for a common sample of participants. If those outcomes are correlated, then &lt;a href=&#34;https://www.jepusto.com/Correlations-between-SMDs&#34;&gt;so too will be the effect size estimates&lt;/a&gt;. To estimate the degree of correlation, you would need the sample correlation among the outcomes—information that is woefully uncommon for primary studies to report (and best of luck to you if you try to follow up with author queries). Thus, the meta-analyst is often left in a situation where the sampling &lt;em&gt;variances&lt;/em&gt; of the effect size estimates can be reasonably well approximated, but the sampling &lt;em&gt;covariances&lt;/em&gt; are unknown for some or all studies.&lt;/p&gt;
&lt;p&gt;Several solutions to this conundrum have been proposed in the meta-analysis methodology literature. One possible strategy is to just impute a correlation based on subject-matter knowledge (or at least feigned expertise), and assume that this correlation is constant across studies. This analysis could be supplemented with sensitivity analyses to examine the extent to which the parameter estimates and inferences are sensitive to alternative assumptions about the inter-correlation of effects within studies. A related strategy, described by &lt;a href=&#34;https://dx.doi.org/10.1002/sim.5679&#34;&gt;Wei and Higgins (2013)&lt;/a&gt;, is to meta-analyze any available correlation estimates and then use the results to impute correlations for any studies with missing correlations.&lt;/p&gt;
&lt;p&gt;Both of these approaches require the meta-analyst to calculate block-diagonal sampling covariance matrices for the effect size estimates, which can be a bit unwieldy. I often use the impute-the-correlation strategy in my meta-analysis work and have written a helper function to compute covariance matrices, given known sampling variances and imputed correlations for each study. In the interest of not repeating myself, I’ve added the function to the latest version of my clubSandwich package. In this post, I’ll explain the function and demonstrate how to use it for conducting meta-analysis of correlated effect size estimates.&lt;/p&gt;
&lt;div id=&#34;an-r-function-for-block-diagonal-covariance-matrices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An R function for block-diagonal covariance matrices&lt;/h2&gt;
&lt;p&gt;Here is the function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;impute_covariance_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## function (vi, cluster, r, return_list = identical(as.factor(cluster), 
##     sort(as.factor(cluster)))) 
## {
##     cluster &amp;lt;- droplevels(as.factor(cluster))
##     vi_list &amp;lt;- split(vi, cluster)
##     r_list &amp;lt;- rep_len(r, length(vi_list))
##     vcov_list &amp;lt;- Map(function(V, rho) (rho + diag(1 - rho, nrow = length(V))) * 
##         tcrossprod(sqrt(V)), V = vi_list, rho = r_list)
##     if (return_list) {
##         return(vcov_list)
##     }
##     else {
##         vcov_mat &amp;lt;- metafor::bldiag(vcov_list)
##         cluster_index &amp;lt;- order(order(cluster))
##         return(vcov_mat[cluster_index, cluster_index])
##     }
## }
## &amp;lt;bytecode: 0x0000000018309e80&amp;gt;
## &amp;lt;environment: namespace:clubSandwich&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function takes three required arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;vi&lt;/code&gt; is a vector of sampling variances.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cluster&lt;/code&gt; is a vector identifying the study from which effect size estimates are drawn. Effects with the same value of &lt;code&gt;cluster&lt;/code&gt; will be treated as correlated.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;r&lt;/code&gt; is the assumed value(s) of the correlation between effect size estimates from each study. Note that &lt;code&gt;r&lt;/code&gt; can also be a vector with separate values for each study.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a simple example to demonstrate how the function works. Say that there are just three studies, contributing 2, 3, and 4 effects, respectively. I’ll just make up some values for the effect sizes and variances:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- data.frame(study = rep(LETTERS[1:3], 2:4), 
                  yi = rnorm(9), 
                  vi = 4:12)
dat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   study          yi vi
## 1     A -1.33148823  4
## 2     A -0.02725897  5
## 3     B -0.70125406  6
## 4     B -1.71119746  7
## 5     B -0.70957554  8
## 6     C -0.40639264  9
## 7     C -0.13290344 10
## 8     C -1.10272160 11
## 9     C -0.38033372 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll assume that effect size estimates from a given study are correlated at 0.7:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_list &amp;lt;- impute_covariance_matrix(vi = dat$vi, cluster = dat$study, r = 0.7)
V_list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $A
##          [,1]     [,2]
## [1,] 4.000000 3.130495
## [2,] 3.130495 5.000000
## 
## $B
##          [,1]     [,2]     [,3]
## [1,] 6.000000 4.536518 4.849742
## [2,] 4.536518 7.000000 5.238320
## [3,] 4.849742 5.238320 8.000000
## 
## $C
##          [,1]      [,2]      [,3]      [,4]
## [1,] 9.000000  6.640783  6.964912  7.274613
## [2,] 6.640783 10.000000  7.341662  7.668116
## [3,] 6.964912  7.341662 11.000000  8.042388
## [4,] 7.274613  7.668116  8.042388 12.000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a list of matrices, where each entry corresponds to the variance-covariance matrix of effects from a given study. To see that the results are correct, let’s examine the correlation matrix implied by these correlation matrices:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov2cor(V_list$A)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]  1.0  0.7
## [2,]  0.7  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov2cor(V_list$B)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3]
## [1,]  1.0  0.7  0.7
## [2,]  0.7  1.0  0.7
## [3,]  0.7  0.7  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov2cor(V_list$C)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4]
## [1,]  1.0  0.7  0.7  0.7
## [2,]  0.7  1.0  0.7  0.7
## [3,]  0.7  0.7  1.0  0.7
## [4,]  0.7  0.7  0.7  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As requested, effects are assumed to be equi-correlated with r = 0.7.&lt;/p&gt;
&lt;p&gt;If the data are sorted in order of the cluster IDs, then the list of matrices returned by &lt;code&gt;impute_covariance_matrix()&lt;/code&gt; can be fed directly into the &lt;code&gt;rma.mv&lt;/code&gt; function in metafor (as I demonstrate below). However, if the data are not sorted by &lt;code&gt;cluster&lt;/code&gt;, then feeding in the list of matrices will not work correctly. Instead, the full &lt;span class=&#34;math inline&#34;&gt;\(N \times N\)&lt;/span&gt; variance-covariance matrix (where &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; is the total number of effect size estimates) will need to be calculated so that the rows and columns appear in the correct order. To address this possibility, the function includes an optional argument, &lt;code&gt;return_list&lt;/code&gt;, which determines whether to output a list of matrices (one matrix per study/cluster) or a single matrix corresponding to the full variance-covariance matrix across all studies. By default, &lt;code&gt;return_list&lt;/code&gt; tests for whether the &lt;code&gt;cluster&lt;/code&gt; argument is sorted and returns the appropriate form. The argument can also be set directly by the user.&lt;/p&gt;
&lt;p&gt;Here’s what happens if we feed in the data in a different order:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_scramble &amp;lt;- dat[sample(nrow(dat)),]
dat_scramble&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   study          yi vi
## 9     C -0.38033372 12
## 3     B -0.70125406  6
## 8     C -1.10272160 11
## 5     B -0.70957554  8
## 6     C -0.40639264  9
## 2     A -0.02725897  5
## 1     A -1.33148823  4
## 4     B -1.71119746  7
## 7     C -0.13290344 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_mat &amp;lt;- round(impute_covariance_matrix(vi = dat_scramble$vi, cluster = dat_scramble$study, r = 0.7), 3)
V_mat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         [,1]  [,2]   [,3]  [,4]  [,5] [,6] [,7]  [,8]   [,9]
##  [1,] 12.000 0.000  8.042 0.000 7.275 0.00 0.00 0.000  7.668
##  [2,]  0.000 6.000  0.000 4.850 0.000 0.00 0.00 4.537  0.000
##  [3,]  8.042 0.000 11.000 0.000 6.965 0.00 0.00 0.000  7.342
##  [4,]  0.000 4.850  0.000 8.000 0.000 0.00 0.00 5.238  0.000
##  [5,]  7.275 0.000  6.965 0.000 9.000 0.00 0.00 0.000  6.641
##  [6,]  0.000 0.000  0.000 0.000 0.000 5.00 3.13 0.000  0.000
##  [7,]  0.000 0.000  0.000 0.000 0.000 3.13 4.00 0.000  0.000
##  [8,]  0.000 4.537  0.000 5.238 0.000 0.00 0.00 7.000  0.000
##  [9,]  7.668 0.000  7.342 0.000 6.641 0.00 0.00 0.000 10.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see that this is correct, check that the diagonal entries of &lt;code&gt;V_mat&lt;/code&gt; are the same as &lt;code&gt;vi&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(dat_scramble$vi, diag(V_mat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-with-real-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An example with real data&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://dx.doi.org/10.1037/1082-989X.1.3.227&#34;&gt;Kalaian and Raudenbush (1996)&lt;/a&gt; introduced a multi-variate random effects model, which can be used to perform a joint meta-analysis of studies that contribute effect sizes on distinct, related outcome constructs. They demonstrate the model using data from a synthesis on the effects of SAT coaching, where many studies reported effects on both the math and verbal portions of the SAT. The data are available in the &lt;code&gt;clubSandwich&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr, warn.conflicts=FALSE)
data(SATcoaching)

# calculate the mean of log of coaching hours
mean_hrs_ln &amp;lt;- 
  SATcoaching %&amp;gt;% 
  group_by(study) %&amp;gt;%
  summarise(hrs_ln = mean(log(hrs))) %&amp;gt;%
  summarise(hrs_ln = mean(hrs_ln, na.rm = TRUE))

# clean variables, sort by study ID
SATcoaching &amp;lt;- 
  SATcoaching %&amp;gt;%
  mutate(
    study = as.factor(study),
    hrs_ln = log(hrs) - mean_hrs_ln$hrs_ln
  ) %&amp;gt;%
  arrange(study, test)

SATcoaching %&amp;gt;%
  select(study, year, test, d, V, hrs_ln) %&amp;gt;%
  head(n = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    study year   test     d      V      hrs_ln
## 1  Alderman &amp;amp; Powers (A) 1980 Verbal  0.22 0.0817 -0.54918009
## 2  Alderman &amp;amp; Powers (B) 1980 Verbal  0.09 0.0507 -0.19250515
## 3  Alderman &amp;amp; Powers (C) 1980 Verbal  0.14 0.1045 -0.14371499
## 4  Alderman &amp;amp; Powers (D) 1980 Verbal  0.14 0.0442 -0.19250515
## 5  Alderman &amp;amp; Powers (E) 1980 Verbal -0.01 0.0535 -0.70333077
## 6  Alderman &amp;amp; Powers (F) 1980 Verbal  0.14 0.0557 -0.88565233
## 7  Alderman &amp;amp; Powers (G) 1980 Verbal  0.18 0.0561 -0.09719497
## 8  Alderman &amp;amp; Powers (H) 1980 Verbal  0.01 0.1151  1.31157225
## 9              Burke (A) 1986 Verbal  0.50 0.0825  1.41693276
## 10             Burke (B) 1986 Verbal  0.74 0.0855  1.41693276
## 11                Coffin 1987   Math  0.33 0.2534  0.39528152
## 12                Coffin 1987 Verbal -0.23 0.2517  0.39528152
## 13            Curran (A) 1988   Math -0.08 0.1065 -0.70333077
## 14            Curran (A) 1988 Verbal -0.10 0.1066 -0.70333077
## 15            Curran (B) 1988   Math -0.29 0.1015 -0.70333077
## 16            Curran (B) 1988 Verbal -0.14 0.1007 -0.70333077
## 17            Curran (C) 1988   Math -0.34 0.1104 -0.70333077
## 18            Curran (C) 1988 Verbal -0.16 0.1092 -0.70333077
## 19            Curran (D) 1988   Math -0.06 0.1089 -0.70333077
## 20            Curran (D) 1988 Verbal -0.07 0.1089 -0.70333077&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The correlation betwen math and verbal test scores are not available, but it seems reasonable to use a correlation of r = 0.66, as reported in the SAT technical information. To synthesize these effects, I’ll first compute the required variance-covariances:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_list &amp;lt;- impute_covariance_matrix(vi = SATcoaching$V, 
                                   cluster = SATcoaching$study, 
                                   r = 0.66)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This can then be fed into &lt;code&gt;metafor&lt;/code&gt; to estimate a fixed effect or random effects meta-analysis or meta-regression models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor, quietly = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading &amp;#39;metafor&amp;#39; package (version 2.1-0). For an overview 
## and introduction to the package please type: help(metafor).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate fixed effect meta-analysis
MVFE_null &amp;lt;- rma.mv(d ~ 0 + test, V = V_list, data = SATcoaching)
MVFE_null&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 67; method: REML)
## 
## Variance Components: none
## 
## Test for Residual Heterogeneity:
## QE(df = 65) = 72.1630, p-val = 0.2532
## 
## Test of Moderators (coefficients 1:2):
## QM(df = 2) = 19.8687, p-val &amp;lt; .0001
## 
## Model Results:
## 
##             estimate      se    zval    pval   ci.lb   ci.ub 
## testMath      0.1316  0.0331  3.9783  &amp;lt;.0001  0.0668  0.1965  *** 
## testVerbal    0.1215  0.0313  3.8783  0.0001  0.0601  0.1829  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate fixed effect meta-regression
MVFE_hrs &amp;lt;- rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, 
                   data = SATcoaching)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, data = SATcoaching):
## Rows with NAs omitted from model fitting.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVFE_hrs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 65; method: REML)
## 
## Variance Components: none
## 
## Test for Residual Heterogeneity:
## QE(df = 61) = 67.9575, p-val = 0.2523
## 
## Test of Moderators (coefficients 1:4):
## QM(df = 4) = 23.7181, p-val &amp;lt; .0001
## 
## Model Results:
## 
##                    estimate      se    zval    pval    ci.lb   ci.ub 
## testMath             0.0946  0.0402  2.3547  0.0185   0.0159  0.1734   * 
## testVerbal           0.1119  0.0341  3.2762  0.0011   0.0449  0.1788  ** 
## testMath:hrs_ln      0.1034  0.0546  1.8946  0.0581  -0.0036  0.2103   . 
## testVerbal:hrs_ln    0.0601  0.0442  1.3592  0.1741  -0.0266  0.1467     
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate random effects meta-analysis
MVRE_null &amp;lt;- rma.mv(d ~ 0 + test, V = V_list, data = SATcoaching, 
                 random = ~ test | study, struct = &amp;quot;UN&amp;quot;)
MVRE_null&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 67; method: REML)
## 
## Variance Components:
## 
## outer factor: study (nlvls = 47)
## inner factor: test  (nlvls = 2)
## 
##             estim    sqrt  k.lvl  fixed   level 
## tau^2.1    0.0122  0.1102     29     no    Math 
## tau^2.2    0.0026  0.0507     38     no  Verbal 
## 
##         rho.Math  rho.Vrbl    Math  Vrbl 
## Math           1   -1.0000       -    no 
## Verbal   -1.0000         1      20     - 
## 
## Test for Residual Heterogeneity:
## QE(df = 65) = 72.1630, p-val = 0.2532
## 
## Test of Moderators (coefficients 1:2):
## QM(df = 2) = 18.1285, p-val = 0.0001
## 
## Model Results:
## 
##             estimate      se    zval    pval   ci.lb   ci.ub 
## testMath      0.1379  0.0434  3.1783  0.0015  0.0528  0.2229   ** 
## testVerbal    0.1168  0.0337  3.4603  0.0005  0.0506  0.1829  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate random effects meta-regression
MVRE_hrs &amp;lt;- rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, 
                   data = SATcoaching,
                   random = ~ test | study, struct = &amp;quot;UN&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, data = SATcoaching, :
## Rows with NAs omitted from model fitting.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVRE_hrs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 65; method: REML)
## 
## Variance Components:
## 
## outer factor: study (nlvls = 46)
## inner factor: test  (nlvls = 2)
## 
##             estim    sqrt  k.lvl  fixed   level 
## tau^2.1    0.0152  0.1234     28     no    Math 
## tau^2.2    0.0014  0.0373     37     no  Verbal 
## 
##         rho.Math  rho.Vrbl    Math  Vrbl 
## Math           1   -1.0000       -    no 
## Verbal   -1.0000         1      19     - 
## 
## Test for Residual Heterogeneity:
## QE(df = 61) = 67.9575, p-val = 0.2523
## 
## Test of Moderators (coefficients 1:4):
## QM(df = 4) = 23.6459, p-val &amp;lt; .0001
## 
## Model Results:
## 
##                    estimate      se    zval    pval    ci.lb   ci.ub 
## testMath             0.0893  0.0507  1.7631  0.0779  -0.0100  0.1887   . 
## testVerbal           0.1062  0.0357  2.9738  0.0029   0.0362  0.1762  ** 
## testMath:hrs_ln      0.1694  0.0725  2.3354  0.0195   0.0272  0.3116   * 
## testVerbal:hrs_ln    0.0490  0.0459  1.0681  0.2855  -0.0409  0.1389     
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results of fitting this model using restricted maximum likelihood with metafor are actually a bit different from the estimates reported in the original paper, potentially because Kalaian and Raudenbush use a Cholesky decomposition of the sampling covariances, which alters the interpretation of the random effects variance components. The metafor fit is also a bit goofy because the correlation between the random effects for math and verbal scores is very close to -1, although evidently it is not uncommon to obtain such degenerate estimates of the random effects structure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;robust-variance-estimation.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Robust variance estimation.&lt;/h2&gt;
&lt;p&gt;Experienced meta-analysts will no doubt point out that a further, alternative analytic strategy to the one described above would be to use robust variance estimation methods (RVE; &lt;a href=&#34;https://dx.doi.org/10.1002/jrsm.5&#34;&gt;Hedges, Tipton, &amp;amp; Johnson&lt;/a&gt;). However, RVE is not so much an alternative strategy as it is a complementary technique, which can be used in combination with any of the models estimated above. Robust standard errors and hypothesis tests can readily be obtained with the &lt;a href=&#34;https://cran.r-project.org/package=clubSandwich&#34;&gt;clubSandwich package&lt;/a&gt;. Here’s how to do it for the random effects meta-regression model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)
coef_test(MVRE_hrs, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               Coef. Estimate     SE t-stat  d.f. p-val (Satt) Sig.
## 1          testMath   0.0893 0.0360   2.48 20.75       0.0218    *
## 2        testVerbal   0.1062 0.0215   4.94 16.45       &amp;lt;0.001  ***
## 3   testMath:hrs_ln   0.1694 0.1010   1.68  7.90       0.1325     
## 4 testVerbal:hrs_ln   0.0490 0.0414   1.18  7.57       0.2725&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RVE is also available in the &lt;a href=&#34;https://CRAN.R-project.org/package=robumeta&#34;&gt;robumeta R package&lt;/a&gt;, but there are several differences between the implementation there and the method I’ve demonstrated here. From the user’s perspective, an advantage of robumeta is that it does all of the covariance imputation calculations “under the hood,” whereas with metafor the calculations need to be done prior to fitting the model. Beyond this, differences include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;robumeta uses a specific random effects structure that can’t be controlled by the user, whereas metafor can be used to estimate a variety of different random effects structures;&lt;/li&gt;
&lt;li&gt;robumeta uses a moment estimator for the between-study variance, whereas metafor provides FML or REML estimation;&lt;/li&gt;
&lt;li&gt;robumeta uses semi-efficient, diagonal weights when fitting the meta-regression, whereas metafor uses weights that are fully efficient (exactly inverse-variance) under the working model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The advantages and disadvantages of these two approaches involve some subtleties that I’ll get into in a future post.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A meta-analysis of school-based group contingency interventions for students with challenging behavior: An update</title>
      <link>https://www.jepusto.com/publication/school-based-group-contingencies-meta-analysis/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/school-based-group-contingencies-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A meta-analysis of technology-aided instruction and intervention for students with ASD</title>
      <link>https://www.jepusto.com/publication/taii-meta-analysis/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/taii-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>You wanna PEESE of d&#39;s?</title>
      <link>https://www.jepusto.com/pet-peese-performance/</link>
      <pubDate>Thu, 27 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/pet-peese-performance/</guid>
      <description>


&lt;p&gt;Publication bias—or more generally, outcome reporting bias or dissemination bias—is recognized as a critical threat to the validity of findings from research syntheses. In the areas with which I am most familiar (education and psychology), it has become more or less a requirement for research synthesis projects to conduct analyses to detect the presence of systematic outcome reporting biases. Some analyses go further by trying correct for its distorting effects on average effect size estimates. Widely known analytic techniques for doing so include Begg and Mazumdar’s &lt;a href=&#34;https://dx.doi.org/10.2307/2533446&#34;&gt;rank-correlation test&lt;/a&gt;, the Trim-and-Fill technique proposed by &lt;a href=&#34;https://dx.doi.org/10.2307/2669529&#34;&gt;Duval and Tweedie&lt;/a&gt;, and &lt;a href=&#34;https://dx.doi.org/10.1136/bmj.315.7109.629&#34;&gt;Egger regression&lt;/a&gt; (in its &lt;a href=&#34;https://dx.doi.org/10.1186/1471-2288-9-2&#34;&gt;many variants&lt;/a&gt;). Another class of methods involves selection models (or weight function models), as proposed by &lt;a href=&#34;https://dx.doi.org/10.1007/BF02294384&#34;&gt;Hedges and Vevea&lt;/a&gt;, &lt;a href=&#34;https://dx.doi.org/10.1037/1082-989X.10.4.428&#34;&gt;Vevea and Woods&lt;/a&gt;, and others. As far as I can tell, selection models are well known among methodologists but very seldom applied due to their complexity and lack of ready-to-use software (though &lt;a href=&#34;https://CRAN.R-project.org/package=weightr&#34;&gt;an R package&lt;/a&gt; has recently become available). More recent proposals include the PET-PEESE technique introduced by &lt;a href=&#34;https://dx.doi.org/10.1002/jrsm.1095&#34;&gt;Stanley and Doucouliagos&lt;/a&gt;; Simonsohn, Nelson, and Simmon’s &lt;a href=&#34;https://dx.doi.org/10.1177/1745691614553988&#34;&gt;p-curve technique&lt;/a&gt;; Van Assen, Van Aert, and Wichert’s &lt;a href=&#34;http://dx.doi.org/10.1037/met0000025&#34;&gt;p-uniform&lt;/a&gt;, and others. The list of techniques grows by the day.&lt;/p&gt;
&lt;p&gt;Among these methods, Egger regression, PET, and PEESE are superficially quite appealing due to their simplicity. These methods each involve estimating a fairly simple meta-regression model, using as the covariate the sampling variance of the effect size or some transformation thereof. PET uses the standard error of the effect size as the regressor; PEESE uses the sampling variance (i.e., the squared standard error); PET-PEESE involves first testing whether the PET estimate is statistically significant, using PEESE if it is or PET otherwise. The intercept from one of these regressions is the average effect size estimate from a study with zero sampling variance; the estimated intercept is used as a “bias-corrected” estimator of the population average effect. These methods are also appealing due to their extensibility. Because they are just meta-regressions, it is comparatively easy to extend them to meta-regression models that control for further covariates, to use robust variance estimation to account for dependencies among effect size estimates, etc.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;http://datacolada.org/59&#34;&gt;a recent blog post&lt;/a&gt;, Uri Simonsohn reports some simulation evidence indicating that the PET-PEESE estimator can have large biases under certain conditions, &lt;em&gt;even in the absence of publication bias&lt;/em&gt;. The simulations are based on standardized mean differences from two-group experiments and involve simulating collections of studies that include many with small sample sizes, as might be found in certain areas of psychology. On the basis of these performance assessments, he argues that this purported cure is actually worse than the disease—that PET-PEESE should &lt;em&gt;not&lt;/em&gt; be used in meta-analyses of psychological research because it performs too poorly to be trusted. In &lt;a href=&#34;http://datacolada.org/wp-content/uploads/2017/04/Response-by-Joe-Hilgard-to-Colada-59.pdf&#34;&gt;a response to Uri’s post&lt;/a&gt;, &lt;a href=&#34;http://crystalprisonzone.blogspot.com/&#34;&gt;Joe Hilgard&lt;/a&gt; suggests that some simple modifications to the method can improve its performance. Specifically, Joe suggests using a function of sample size as the covariate (in place of the standard error or sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;), and also using PET or PEESE as stand-alone estimators, rather than using them contingent on a significance test.&lt;/p&gt;
&lt;p&gt;In this post, I follow up Joe’s suggestions while replicating and expanding upon Uri’s simulations, to try and provide a fuller picture of the relative performance of these estimators. In brief, the simulations show that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tests for small-sample bias that use PET or PEESE can have wildly incorrect type-I error rates in the absence of publication bias. Don’t use them.&lt;/li&gt;
&lt;li&gt;The sample-size variants of PET and PEESE &lt;strong&gt;do&lt;/strong&gt; maintain the correct type-I error rates in the absence of publication bias.&lt;/li&gt;
&lt;li&gt;The sample-size variants of PET and PEESE are exactly unbiased in the absence of publication bias.&lt;/li&gt;
&lt;li&gt;However, these adjusted estimators still have a cost, being less precise than the conventional fixed-effect estimator.&lt;/li&gt;
&lt;li&gt;In the presence of varying degrees of publication bias, none of the estimators consistently out-perform the others. If you really really need to use a regression-based correction, the sample-size variant of PEESE seems like it might be a reasonable default method, but it’s still really pretty rough.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;why-use-sample-size&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why use sample size?&lt;/h1&gt;
&lt;p&gt;To see why it makes sense to use a function of sample size as the covariate for PET-PEESE analyses, rather than using the standard error of the effect size estimate, let’s look at the formulas. Say that we have a standardized mean difference estimate from a two-group design (without covariates) with sample sizes &lt;span class=&#34;math inline&#34;&gt;\(n_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_1\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_1 - \bar{y}_0}{s_p},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_1\)&lt;/span&gt; are the sample means within each group and &lt;span class=&#34;math inline&#34;&gt;\(s_p^2\)&lt;/span&gt; is the pooled sample variance. Following convention, we’ll assume that the outcomes are normally distributed within each group, and the groups have common variance. The exact sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is a rather complicated formula, but one which can be approximated reasonably well as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(d) \approx \frac{n_0 + n_1}{n_0 n_1} + \frac{\delta^2}{2(n_0 + n_1)},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; is the &lt;em&gt;true&lt;/em&gt; standardized mean difference parameter. This formula is a delta-method approximation. The first term captures the variance of the numerator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, so it gets at how precisely the &lt;em&gt;unstandardized&lt;/em&gt; difference in means is estimated. The second term captures the variance of the denominator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, so it gets at how precisely the &lt;em&gt;scale&lt;/em&gt; of the outcome is estimated. The second term also involves the unknown parameter &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;, which must be estimated in practice. The conventional formula for the estimated sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; substitutes &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; in place of &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V = \frac{n_0 + n_1}{n_0 n_1} + \frac{d^2}{2(n_0 + n_1)}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In PET-PEESE analysis, &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; or its square root is used as a covariate in a regression of the effect sizes, as a means of adjusting for publication bias. There are two odd things about this. First, publication bias is about the statistical significance of the group differences, but statistical significance &lt;strong&gt;&lt;em&gt;does not depend on the scale of the outcome&lt;/em&gt;&lt;/strong&gt;. The test of the null hypothesis of no differences between groups is &lt;strong&gt;&lt;em&gt;not&lt;/em&gt;&lt;/strong&gt; based on &lt;span class=&#34;math inline&#34;&gt;\(d / \sqrt{V}\)&lt;/span&gt;. Instead, it is a function of the &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; statistic:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
t = d / \sqrt{\frac{n_0 + n_1}{n_0 n_1}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Consequently, it makes sense to use &lt;strong&gt;&lt;em&gt;only the first term of &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt; as a covariate for purposes of detecting publication biases.&lt;/p&gt;
&lt;p&gt;The second odd thing is that &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; is generally going to be correlated with &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; because we have to use &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; to calculate &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;. As &lt;a href=&#34;http://datacolada.org/wp-content/uploads/2017/04/Response-by-Joe-Hilgard-to-Colada-59.pdf&#34;&gt;Joe explained in his response to Uri&lt;/a&gt;, this means that there will be a non-zero correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; (or between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{V}\)&lt;/span&gt;) except in some very specific cases, even in the absence of any publication bias. Pretty funky.&lt;/p&gt;
&lt;p&gt;This second problem with regression tests for publication bias has been recognized for a while in the literature (e.g., &lt;a href=&#34;https://dx.doi.org/10.1002/sim.698&#34;&gt;Macaskill, Walter, &amp;amp; Irwig, 2001&lt;/a&gt;; &lt;a href=&#34;https://dx.doi.org/10.1001/jama.295.6.676&#34;&gt;Peters et al., 2006&lt;/a&gt;; &lt;a href=&#34;https://dx.doi.org/10.1186/1471-2288-9-2&#34;&gt;Moreno et al., 2009&lt;/a&gt;), but most of the work here has focused on other effect size measures, like odds ratios, that are relevant in clinical medicine. The behavior of these estimators might well differ for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;’s because the dependence between the effect measure and its variance has a different structure.&lt;/p&gt;
&lt;p&gt;Below I’ll investigate how this stuff works with standardized mean differences, which haven’t been studied as extensively as odds ratios. Actually, I know of only two simulation studies that examined the performance of PET-PEESE methods with standardized mean difference estimates: &lt;a href=&#34;http://dx.doi.org/10.2139/ssrn.2659409&#34;&gt;Inzlicht, Gervais, and Berkman (2015)&lt;/a&gt; and &lt;a href=&#34;https://dx.doi.org/10.1177/1948550617693062&#34;&gt;Stanley (2017)&lt;/a&gt;. (Know of others? Leave a comment!) Neither considered using sample-size variants of PET-PEESE. The only source I know of that &lt;em&gt;did&lt;/em&gt; consider this is this &lt;a href=&#34;http://willgervais.com/blog/2015/6/29/pet-peese-vs-peters&#34;&gt;blog post from Will Gervais&lt;/a&gt;, which starts out optimistic about the sample-size variants but ends on a discouraged note. The simulations below build upon Will’s work, as well as Uri’s, by 1) considering a more extensive set of data-generating processes and 2) examining accuracy in addition to bias.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulation model&lt;/h1&gt;
&lt;p&gt;The simulations are based on the following data-generating model, which closely follows &lt;a href=&#34;http://datacolada.org/59&#34;&gt;the structure that Uri used&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Per-cell sample size is generated as &lt;span class=&#34;math inline&#34;&gt;\(n = 12 + B (n_{max} - 12)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(B \sim Beta(\alpha, \beta)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_{max}\)&lt;/span&gt; is the maximum observed sample size. I take &lt;span class=&#34;math inline&#34;&gt;\(n_{max} = 50\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(120\)&lt;/span&gt; and look at three sample size distributions (note that these distributions are pre-selection, so the observed sample size distributions will deviate from these if there is selective publication):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha = \beta = 1\)&lt;/span&gt; corresponds to a uniform distribution on &lt;span class=&#34;math inline&#34;&gt;\([12,n_{max}]\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha = 1, \beta = 3\)&lt;/span&gt; is a distribution with more small studies; and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha = 3, \beta = 1\)&lt;/span&gt; is a distribution with more large studies.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;True effects are simulated as &lt;span class=&#34;math inline&#34;&gt;\(\delta \sim N(\mu, \sigma^2)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(\mu = 0, 0.1, 0.2, ..., 1.0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.0, 0.1, 0.2, 0.4\)&lt;/span&gt;. Note that the values of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; are &lt;em&gt;standard deviations&lt;/em&gt; of the true effects, with &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.0\)&lt;/span&gt; corresponding to the constant effect model and &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.4\)&lt;/span&gt; corresponding to rather substantial effect heterogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Standardized mean difference effect size estimates are generated as in a two-group between-subjects experiment with equal per-cell sample sizes. I do this by taking &lt;span class=&#34;math inline&#34;&gt;\(t = D / \sqrt{S / [2(n - 1)]}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(D \sim N(\delta \sqrt{n / 2}, 1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S \sim \chi^2_{2(n - 1)}\)&lt;/span&gt;, then calculating&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
  d = \left(1 - \frac{3}{8 n - 9}\right) \times \sqrt{\frac{2}{n}} \times t.
  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(That first term is Hedges’ &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; correction, cuz that’s how I roll.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Observed effects are filtered based on statistical significance. Let &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; be the p-value corresponding to the observed &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; and the one-tailed hypothesis test of &lt;span class=&#34;math inline&#34;&gt;\(\delta \leq 0\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .025\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is observed with probability 1. If &lt;span class=&#34;math inline&#34;&gt;\(p \geq .025\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is observed with probability &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;. Noted that this mechanism corresponds to filtering based on two-sided hypothesis tests, where effects are filtered if they are statistically non-significant effects or statistically significant but in the wrong direction. I look at three scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi = 1.0\)&lt;/span&gt; corresponds to no selective publication (all simulated effects are observed);&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi = 0.2\)&lt;/span&gt; corresponds to an intermediate degree of selective publication (some but not non-significant effects are observed); and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi = 0.0\)&lt;/span&gt; corresponds to very strong selective publication (only statistically significant effects are observed).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Each meta-analysis includes a total of &lt;span class=&#34;math inline&#34;&gt;\(k = 100\)&lt;/span&gt; observed studies. Note that in scenarios with publication bias, more (sometimes many more) than 100 studies are generated in order to get 100 observed effects.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each simulated meta-sample, I calculated the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the usual fixed-effect meta-analytic average (I skipped random effects for simplicity);&lt;/li&gt;
&lt;li&gt;the PET estimator (including intercept and slope);&lt;/li&gt;
&lt;li&gt;the PEESE estimator (including intercept and slope);&lt;/li&gt;
&lt;li&gt;PET-PEESE, which is equal to the PEESE intercept if &lt;span class=&#34;math inline&#34;&gt;\(H_0: \beta_0 \leq 0\)&lt;/span&gt; is rejected at the 10% level, and is otherwise equal to the PET intercept (this definition follows &lt;a href=&#34;https://dx.doi.org/10.1177/1948550617693062&#34;&gt;Stanley, 2017&lt;/a&gt;);&lt;/li&gt;
&lt;li&gt;the modified PET estimator, which I’ll call “SPET” for “sample-size PET” (suggestions for better names welcome);&lt;/li&gt;
&lt;li&gt;the modified PEESE estimator, which I’ll call “SPEESE”; and&lt;/li&gt;
&lt;li&gt;SPET-SPEESE, which follows the same conditional logic as PET-PEESE.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Simulation results are summarized across 4000 replications. The R code for all this &lt;a href=&#34;https://www.jepusto.com/R/PET-PEESE-performance-simulations.R&#34;&gt;lives here&lt;/a&gt;. Complete numerical results &lt;a href=&#34;https://www.jepusto.com/files/PET-PEESE-Simulation-Results.Rdata&#34;&gt;live here&lt;/a&gt;. Code for creating the graphs below &lt;a href=&#34;https://www.jepusto.com/R/PET-PEESE-performance-graphs.R&#34;&gt;lives here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;div id=&#34;false-positive-rates-for-publication-bias-detection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;False-positive rates for publication bias detection&lt;/h3&gt;
&lt;p&gt;First, let’s consider the performance of PET and PEESE as tests for detecting publication bias. Here, a statistically significant estimate for the coefficient on the SE (for PET) or on &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; (for PEESE) is taken as evidence of small-sample bias. For that logic to hold, the tests should maintain the nominal error rates in the absence of publication bias.&lt;/p&gt;
&lt;p&gt;The figure below depicts the Type-I error rates of the PET and PEESE tests when &lt;span class=&#34;math inline&#34;&gt;\(\pi = 1\)&lt;/span&gt; (so no publication bias at all), for a one-sided test of &lt;span class=&#34;math inline&#34;&gt;\(H_0: \beta_1 \leq 0\)&lt;/span&gt; at the nominal level of &lt;span class=&#34;math inline&#34;&gt;\(\alpha = .05\)&lt;/span&gt;. Rejection rates are plotted for varying true mean effects, levels of heterogeneity, and sample size distributions. Separate colors are used for maximum sample sizes of 50 or 120.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/PET-PEESE-performance_files/figure-html/PET-PEESE-rejection-rates-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both tests are horribly mis-calibrated, tending to reject the null hypothesis far more often than they should. This happens because there is a non-zero correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;, even in the absence of publication bias. Thus, it does not follow that rejecting &lt;span class=&#34;math inline&#34;&gt;\(H_0: \beta_1 \leq 0\)&lt;/span&gt; implies rejection of the hypothesis that there is no publication bias. (Sorry, that’s at least a triple negative!)&lt;/p&gt;
&lt;p&gt;Here’s the same graph, but using the SPET and SPEESE estimators:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/PET-PEESE-performance_files/figure-html/SPET-SPEESE-rejection-rates-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, this may be the World’s Most Boring Figure, but it does make clear that both the SPET and SPEESE tests maintain the correct Type-I error rate. (Any variation in rejection rates is just Monte Carlo error.) Thus, it seems pretty clear that if we want to test for small-sample bias, SPET or SPEESE should be used rather than PET or PEESE.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bias-of-bias-corrected-estimators&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bias of bias-corrected estimators&lt;/h3&gt;
&lt;p&gt;Now let’s consider the performance of these methods as estimators of the population mean effect. &lt;a href=&#34;http://datacolada.org/59&#34;&gt;Uri’s analysis&lt;/a&gt; focused on the bias of the estimators, meaning the difference between the average value of the estimator (across repeated samples) and the true parameter. The plot below depicts the expected level of PET, PEESE, and PET-PEESE as a function of the true mean effect, using the uniform distribution of studies and a maximum sample size of &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/PET-PEESE-performance_files/figure-html/bias-of-PET-PEESE-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All three of these estimators are pretty bad in terms of bias. In the absence of publication bias, they consistently &lt;em&gt;under&lt;/em&gt;-estimate the true mean effect. With intermediate or strong publication bias, PET and PET-PEESE have a consistent downward bias. As an unconditional estimator, PEESE tends to have a positive bias when the true effect is small, but this decreases and becomes negative as the true effect increases. For all three estimators, bias increases as the degree of heterogeneity increases.&lt;/p&gt;
&lt;p&gt;Here is how these estimators compare to the modified SPET, SPEESE, and SPET-SPEESE estimators, as well as to the usual fixed-effect average with no correction for publication bias:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/PET-PEESE-performance_files/figure-html/bias-of-SPET-SPEESE-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the left column, we see that SPET and SPEESE are exactly unbiased (and SPET-SPEESE is nearly so) in the absence of selective publication. So is regular old fixed effect meta-analysis, of course. In the middle and right columns, studies are selected based partially or fully on statistical significance, and things get messy. Overall, there’s no consistent winner between PEESE versus SPEESE. At small or moderate levels of between-study heterogeneity, and when the true mean effect is small, PEESE, SPEESE, and SPET-SPEESE have fairly similar biases, but PEESE appears to have a slight edge. This seems to me to be nothing but a fortuitous accident, in that the bias induced by the correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; just happens to work in the right direction. Then, as the true mean effect increases, SPEESE and SPET-SPEESE start to edge out PEESE. This makes sense because the bias induced by the correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; will be larger when the true effect sizes are larger.&lt;br /&gt;
These trends seem mostly to hold for the other sample size distributions I examined too, although the biases of PEESE and PET-PEESE aren’t as severe when the maximum sample size is larger. You can see for yourself here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-1.png&#34;&gt;Uniform distribution of studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-2.png&#34;&gt;More small studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-3.png&#34;&gt;More small studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-4.png&#34;&gt;More large studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-5.png&#34;&gt;More large studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;accuracy-of-bias-corrected-estimators&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Accuracy of bias-corrected estimators&lt;/h3&gt;
&lt;p&gt;Bias isn’t everything, of course. Now let’s look at the overall accuracy of these estimators, as measured by root mean squared error (RMSE). RMSE is a function of both bias and sampling variance, and so is one way to weigh an estimator that is biased but fairly precise against an estimator that is perfectly unbiased but noisy. The following chart plots the RMSE of all of the estimators (following the same layout as above, just with a different vertical axis):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.jepusto.com/post/PET-PEESE-performance_files/figure-html/RMSE-plots-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Starting in the left column where there’s no selective publication, we can see that the normal fixed-effect average has the smallest RMSE (and so is most accurate). The next most accurate is SPEESE, which uniformly beats out PEESE, PET-PEESE, SPET, and SPET-SPEESE. It’s worth noting, though, that there is a fairly large penalty for using SPEESE when it is unnecessary: even with a quite large sample of 100 studies, SPEESE still has twice the RMSE of the FE estimator.&lt;/p&gt;
&lt;p&gt;The middle column shows these estimators’ RMSE when there is an intermediate degree of selective publication. Because of the “fortuitous accident” of how the correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; affects the PEESE estimator, it is more accurate than SPEESE for small values of the true mean effect. Its advantage is larger when heterogeneity is larger, and heterogeneity also affects the point (i.e., what true mean effect) at which SPEESE catches up with PEESE. Then at larger true mean effects, the accuracy of SPEESE continues to improve while the accuracy of PEESE degrades. It is also interesting to note that at this intermediate degree of selective publication, none of the other bias-correction estimators (PET-PEESE, SPET, SPET-SPEESE) compete with PEESE and SPEESE.&lt;/p&gt;
&lt;p&gt;Finally, the right column plots RMSE when there’s strong selective publication, so only statistically significant effects appear. Just as in the middle column, PEESE edges out SPEESE for smaller values of the true mean effect. For very small true effects, both of these estimators are edged out by PET-PEESE and SPET-SPEESE. This only holds over a very small range for the true mean effect though, and for true effects above that range these conditional estimators perform poorly—consistently worse than just using PEESE or SPEESE.&lt;/p&gt;
&lt;p&gt;Here are charts for the other sample size distributions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-RMSE-plots-1.png&#34;&gt;Uniform distribution of studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-RMSE-plots-2.png&#34;&gt;More small studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-RMSE-plots-3.png&#34;&gt;More small studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-RMSE-plots-4.png&#34;&gt;More large studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jepusto.com/rmarkdown-libs/figure-html4/more-RMSE-plots-5.png&#34;&gt;More large studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The trends that I’ve noted mostly seem to hold for the other sample size distributions (but correct me if you disagree! I’m getting kind of bleary-eyed at the moment…). One difference worth noting is that when the sample size distribution skews towards having more large studies, the accuracy of the regular fixed-effect estimator improves a bit. At intermediate degrees of selective publication, the fixed-effect estimator is &lt;em&gt;consistently&lt;/em&gt; more accurate than SPEESE, and mostly more accurate than PEESE too. With strong selective publication, though, the FE estimator blows up just as before.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions-caveats-further-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions, caveats, further thoughts&lt;/h1&gt;
&lt;p&gt;Where does this leave us? The one thing that seems pretty clear is that if the meta-analyst’s goal is to test for potential small-sample bias, then SPET or SPEESE should be used rather than PET or PEESE. Beyond that, we’re in a bit of a morass. None of the estimators consistently out-performs the others across the conditions of the simulation. It’s only under certain conditions that any of the bias-correction methods are more accurate than using the regular FE estimator, and those conditions aren’t easy to identify in a real data analysis because they depend on the degree of publication bias.&lt;/p&gt;
&lt;div id=&#34;caveats&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Caveats&lt;/h3&gt;
&lt;p&gt;These findings are also pretty tentative because of the limitations of the simulation conditions examined here. The distribution of sample sizes seems to affect the relative accuracy of the estimators to a certain degree, but I’ve only looked at a limited set of possibilities, and also limited consideration to rather large meta-samples of 100 studies.&lt;/p&gt;
&lt;p&gt;Another caveat is that the simulations are based on &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; estimates from a two-group, between-subjects design with no covariates. In many applications, there is considerably more diversity in study designs. A given meta-analysis might include two-group, post-test only designs as well as between-subjects designs with a pre-test covariate or with repeated measures, as well as two-group designs with multiple (or multi-dimensional) outcomes. All of this introduces further layers of complexity into the relationship between sample size, effect magnitude, and selective publication.&lt;/p&gt;
&lt;p&gt;A further, quite important caveat is that selective publication is not the only possible explanation for a correlation between effect size and sample sizes. &lt;a href=&#34;http://datacolada.org/58&#34;&gt;In another recent post&lt;/a&gt;, Uri sketches a scenario where investigators choose sample size to achieve adequate power (so following best practice!) for predicted effect sizes. If 1) true effects are heterogeneous and 2) investigators’ predictions are correlated with true effect sizes, then a meta-analysis will have effect size estimates that are correlated with sample size even in the absence of publication bias. A &lt;a href=&#34;http://bayesfactor.blogspot.com/2016/01/asymmetric-funnel-plots-without.html&#34;&gt;blog post by Richard Morey&lt;/a&gt; illustrates another possibility that leads to effect-sample size correlation, in which resource constraints induce negative correlation between sample size and the reliability of the outcome measure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hold-me-hostage&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Hold me hostage&lt;/h3&gt;
&lt;p&gt;It seems to me that one lesson we can draw from this is that these regression-based corrections are pretty meager as analytic methods. We need to understand the &lt;em&gt;mechanism&lt;/em&gt; of selective publication in order to be able to correct for its consequences, but the regression-based corrections don’t provide direct information here (even though their performance depends on it!). I think this speaks to the need for methods that directly model the mechanism, which means turning to selection models and studying the distribution of p-values. Also, without bringing in other pieces of information (like p-values), it seems more or less impossible to tease apart selective publication from other possible explanations for effect-sample size correlation.&lt;/p&gt;
&lt;p&gt;If I had to pick one of the regression-based bias-correction method to use in an application—as in, if you handcuffed me to my laptop and threatened to not let me go until I analyzed your effect sizes—then on the basis of these simulation exercises, I think I would probably go with SPEESE as a default, and perhaps also report PEESE, but I wouldn’t bother with any of the others. Even though SPEESE is less accurate than PEESE and some other estimators under certain conditions, on a practical level it seems kind of silly to use different estimators when testing for publication bias versus trying to correct for it. And whatever advantage that regular PEESE has over SPEESE strikes me as kind of like cheating—it relies on an induced correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; to gain an accuracy advantage under certain conditions, but that correlation causes big problems under other conditions.&lt;/p&gt;
&lt;p&gt;Even if you chained me to the laptop, I would also definitely include a caution that these estimators should be interpreted more as sensitivity analyses than as bias-corrected estimates of the overall mean effect. This is roughly in line with the conclusions of &lt;a href=&#34;http://dx.doi.org/10.2139/ssrn.2659409&#34;&gt;Inzlicht, Gervais, and Berkman (2015)&lt;/a&gt;. From their abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our simulations revealed that not one of the bias-correction techniques revealed itself superior in all conditions, with corrections performing adequately in some situations but inadequately in others. Such a result implies that meta-analysts ought to present a range of possible effect sizes and to consider them all as being possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Their conclusion was in reference to PET, PEESE, and PET-PEESE. Unfortunately, the tweaks of SPET and SPEESE don’t clarify the situation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;outstanding-questions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Outstanding questions&lt;/h3&gt;
&lt;p&gt;These exercises have left me wondering about a couple of things, which I’ll just mention briefly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I haven’t calculated confidence interval coverage levels for these simulations. I should probably add that but need to move on at the moment.&lt;/li&gt;
&lt;li&gt;The ever-popular Trim-and-Fill procedure is based on the assumption that a funnel plot will be symmetric in the absence of publication bias. This assumption won’t hold if there’s correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;, and so it would be interesting to see if using a function of sample size (i.e., just the first term of &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;) could improve the performance of Trim-and-Fill.&lt;/li&gt;
&lt;li&gt;Under the model examined here, the bias in PET, PEESE, SPET, and SPEESE comes from the fact that the relevant regression relationships aren’t actually linear under selective publication. I do wonder whether using some more flexible sort of regression model (perhaps including a non-linear term) could reduce bias. The trick would be to find something that’s still constrained enough so that bias improvements aren’t swamped by increased variance.&lt;/li&gt;
&lt;li&gt;Many of the applications that I am familiar with involve syntheses where some studies contribute multiple effect size estimates, which might also be inter-correlated. Very little work has examined how regression corrections like PET-PEESE perform in such settings (the only study I know of is &lt;a href=&#34;http://www.economics-ejournal.org/economics/discussionpapers/2015-9&#34;&gt;Reed, 2015&lt;/a&gt;, which involves a specialized and I think rather unusual data-generating model). For that matter, I don’t know of any work that looks at other publication bias correction methods either. Or what selective publication even means in this setting. Somebody should really work on that.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New working paper: Using log response ratios for meta-analyzing SCDs with behavioral outcomes</title>
      <link>https://www.jepusto.com/using-log-response-ratios/</link>
      <pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/using-log-response-ratios/</guid>
      <description>


&lt;p&gt;One of the papers that came out of my dissertation work (&lt;a href=&#34;https://www.jepusto.com/files/Measurement-comparable-ES.pdf&#34;&gt;Pustejovsky, 2015&lt;/a&gt;) introduced an effect size metric called the &lt;strong&gt;log response ratio&lt;/strong&gt; (or LRR) for use in meta-analysis of single-case research—particularly for single-case studies that measure behavioral outcomes through systematic direct observation. The original paper was pretty technical since it focused mostly on a formal measurement model for behavioral observation data. I’ve just completed a tutorial paper that demonstrates how to use the LRR for meta-analyzing single-case studies with behavioral outcomes. In this paper, I’ve tried to present the methods in as accessible a manner as I could muster, to provide a sort of “user’s guide” for researchers wanting to apply the LRR for their own work. You can find the &lt;a href=&#34;https://osf.io/4fe6u/&#34;&gt;working paper&lt;/a&gt; and &lt;a href=&#34;https://osf.io/c3fe9/&#34;&gt;supplementary materials&lt;/a&gt; (including data and replication code) on the Open Science Framework. I would welcome your feedback and questions about this work!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional assessment-based interventions for students with or at-risk for high incidence disabilities: Field-testing single-case synthesis methods</title>
      <link>https://www.jepusto.com/publication/fabi-meta-analysis/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/fabi-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research synthesis and meta-analysis of single-case designs</title>
      <link>https://www.jepusto.com/publication/meta-analysis-of-scd/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/meta-analysis-of-scd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Alternative formulas for the standardized mean difference</title>
      <link>https://www.jepusto.com/alternative-formulas-for-the-smd/</link>
      <pubDate>Fri, 03 Jun 2016 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/alternative-formulas-for-the-smd/</guid>
      <description>


&lt;p&gt;The standardized mean difference (SMD) is surely one of the best known and most widely used effect size metrics used in meta-analysis. In generic terms, the SMD parameter is defined as the difference in population means between two groups (often this difference represents the effect of some intervention), scaled by the population standard deviation of the outcome metric. Estimates of the SMD can be obtained from a wide variety of experimental designs, ranging from simple, completely randomized designs, to repeated measures designs, to cluster-randomized trials.&lt;/p&gt;
&lt;p&gt;There’s some nuance involved in figuring out how to calculate estimates of the SMD from each design, mostly to do with exactly what sort of standard deviation to use in the denominator of the effect size. I’ll leave that discussion for another day. Here, I’d like to look at the question of how to estimate the sampling variance of the SMD. An estimate of the sampling variance is needed in order to meta-analyze a collection of effect sizes, and so getting the variance calculations right is an important (and sometimes time consuming) part of any meta-analysis project. However, the standard textbook treatments of effect size calculations cover this question only for a limited number of simple cases. I’d like to suggest a different, more general way of thinking about it, which provides a way to estimate the SMD and its variance in some non-standard cases (and also leads to slight differences from conventional formulas for the standard ones). All of this will be old hat for seasoned synthesists, but I hope it might be useful for students and researchers just getting started with meta-analysis.&lt;/p&gt;
&lt;p&gt;To start, let me review (regurgitate?) the standard presentation.&lt;/p&gt;
&lt;div id=&#34;smd-from-a-simple-independent-groups-design&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;SMD from a simple, independent groups design&lt;/h3&gt;
&lt;p&gt;Textbook presentations of the SMD estimator almost always start by introducing the estimator in the context of a &lt;strong&gt;simple, independent groups design&lt;/strong&gt;. Call the groups T and C, the sample sizes &lt;span class=&#34;math inline&#34;&gt;\(n_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_C\)&lt;/span&gt;, the sample means &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_C\)&lt;/span&gt;, and the sample variances &lt;span class=&#34;math inline&#34;&gt;\(s_T^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_C^2\)&lt;/span&gt;. A basic moment estimator of the SMD is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_T - \bar{y}_C}{s_p}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(s_p^2 = \frac{\left(n_T - 1\right)s_T^2 + \left(n_C - 1\right) s_C^2}{n_T + n_C - 2}\)&lt;/span&gt; is a pooled estimator of the population variance. The standard estimator for the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = \frac{n_T + n_C}{n_T n_C} + \frac{d^2}{2\left(n_T + n_C - 2\right)},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or some slight variant thereof. This estimator is based on a delta-method approximation for the asymptotic variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It is well known that &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; has a small sample bias that depends on sample sizes. Letting&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
J(x) = 1 - \frac{3}{4x - 1},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the bias-corrected estimator is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
g = J\left(n_T + n_C - 2\right) \times d,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and is often referred to as Hedges’ &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; because it was proposed in &lt;a href=&#34;http://doi.org/10.3102/10769986006002107&#34;&gt;Hedges (1981)&lt;/a&gt;. Some meta-analysts use &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt;, but with &lt;span class=&#34;math inline&#34;&gt;\(d^2\)&lt;/span&gt; replaced by &lt;span class=&#34;math inline&#34;&gt;\(g^2\)&lt;/span&gt;, as an estimator of the large-sample variance of &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;; others use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_g = J^2\left(n_T + n_C - 2\right) \left(\frac{n_T + n_C}{n_T n_C} + \frac{g^2}{2\left(n_T + n_C - 2\right)}\right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.3102/1076998606298034&#34;&gt;Viechtbauer (2007)&lt;/a&gt; provides further details on variance estimation and confidence intervals for the SMD in this case.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-general-formula-for-g-and-its-sampling-variance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A general formula for &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; and its sampling variance&lt;/h3&gt;
&lt;p&gt;The above formulas are certainly useful, but in practice meta-analyses often include studies that use other, more complex designs.
Good textbook presentations also cover computation of &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; and its variance for some other cases (e.g., Borenstein, 2009, also covers one-group pre/post designs and analysis of covariance). Less careful presentations only cover the simple, independent groups design and thus may inadvertently leave the impression that the variance estimator &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; given above applies in general. With other types of studies, &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; can be a wildly biased estimator of the actual sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, because it is derived under the assumption that the numerator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is estimated as the difference in means of two simple random samples. In some designs (e.g., ANCOVA designs, randomized block designs, repeated measures designs), the treatment effect estimate will be much more precise than this; in other designs (e.g., cluster-randomized trials), it will be less precise.&lt;/p&gt;
&lt;p&gt;Here’s what I think is a more useful way to think about the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. Let’s suppose that we have an unbiased estimator for the difference in means that goes into the numerator of the SMD. Call this estimator &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, its sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(b)\)&lt;/span&gt;, and its standard error &lt;span class=&#34;math inline&#34;&gt;\(se_{b}\)&lt;/span&gt;. Also suppose that we have an unbiased (or reasonably close-to-unbiased) estimator of the population variance of the outcome, the square root of which goes into the denominator of the SMD. Call this estimator &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;, with expectation &lt;span class=&#34;math inline&#34;&gt;\(\text{E}\left(S^2\right) = \sigma^2\)&lt;/span&gt; and sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(S^2)\)&lt;/span&gt;. Finally, suppose that &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; are independent (which will often be a pretty reasonable assumption). A delta-method approximation for the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d = b / S\)&lt;/span&gt; is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(d\right) \approx \frac{\text{Var}(b)}{\sigma^2} + \frac{\delta^2}{2 \nu},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\nu = 2 \left[\text{E}\left(S^2\right)\right]^2 / \text{Var}\left(S^2\right)\)&lt;/span&gt;. Plugging in sample estimates of the relevant parameters provides a reasonable estimator for the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = \left(\frac{se_b}{S}\right)^2 + \frac{d^2}{2 \nu}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This estimator has two parts. The first part involves &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt;, which is just the standard error of &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, but re-scaled into standard deviation units; this part captures the variability in &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; from its numerator. This scaled standard error can be calculated directly if an article reports &lt;span class=&#34;math inline&#34;&gt;\(se_b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The second part of &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(d^2 / (2 \nu)\)&lt;/span&gt;, which captures the variability in &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; due to its denominator. More precise estimates of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; will have larger degrees of freedom, so that the second part will be smaller. For some designs, the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; depend only on sample sizes, and thus can be calculated exactly. For some other designs, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; must be estimated.&lt;/p&gt;
&lt;p&gt;The same degrees of freedom can also be used in the small-sample correction for the bias of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, as given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
g = J(\nu) \times d.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This small-sample correction is based on a Satterthwaite-type approximation to the distribution of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Here’s another way to express the variance estimator for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = d^2 \left(\frac{1}{t^2} + \frac{1}{2 \nu}\right),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is the test statistic corresponding to the hypothesis test for no difference between groups. I’ve never seen that formula in print before, but it could be convenient if an article reports the &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; statistic (or &lt;span class=&#34;math inline&#34;&gt;\(F = t^2\)&lt;/span&gt; statistic).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;non-standard-estimators-of-d&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Non-standard estimators of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The advantage of this formulation of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; is that it can be applied in quite a wide variety of circumstances, including cases that aren’t usually covered in textbook treatments. Rather than having to use separate formulas for every combination of design and analytic approach under the sun, the same formulas apply throughout. What changes are the components of the formulas: the scaled standard error &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt; and the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. The general formulation also makes it easier to swap in different estimates of &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;—i.e., if you estimate the numerator a different way but keep the denominator the same, you’ll need a new scaled standard error but can still use the same degrees of freedom. A bunch of examples:&lt;/p&gt;
&lt;div id=&#34;independent-groups-with-different-variances&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Independent groups with different variances&lt;/h4&gt;
&lt;p&gt;Suppose that we’re looking at two independent groups but do not want to assume that their variances are the same. In this case, it would make sense to standardize the difference in means by the control group standard deviation (without pooling), so that &lt;span class=&#34;math inline&#34;&gt;\(d = \left(\bar{y}_T - \bar{y}_C\right) / s_C\)&lt;/span&gt;. Since &lt;span class=&#34;math inline&#34;&gt;\(s_C^2\)&lt;/span&gt; has &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C - 1\)&lt;/span&gt; degrees of freedom, the small-sample bias correction will then need to be &lt;span class=&#34;math inline&#34;&gt;\(J(n_C - 1)\)&lt;/span&gt;. The scaled standard error will be&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{s_C} = \sqrt{\frac{s_T^2}{s_C^2 n_T} + \frac{1}{n_C}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is then everything that we need to calculate &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(V_g\)&lt;/span&gt;, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-independent-groups&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Multiple independent groups&lt;/h4&gt;
&lt;p&gt;Suppose that the study involves &lt;span class=&#34;math inline&#34;&gt;\(K - 1\)&lt;/span&gt; treatment groups, 1 control group, and &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; total participants. If the meta-analysis will include SMDs comparing &lt;em&gt;each&lt;/em&gt; treatment group to the control group, it would make sense to pool the sample variance across all &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; groups rather than just the pair of groups, so that a common estimate of scale is used across all the effect sizes. The pooled standard deviation is then calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
s_p^2 = \frac{1}{N - K} \sum_{k=0}^K (n_k - 1) s_k^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a comparison between treatment group &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and the control group, we would then use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_k - \bar{y}_C}{s_p}, \qquad \nu = N - K, \qquad \frac{se_b}{s_p} = \sqrt{\frac{1}{n_C} + \frac{1}{n_k}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(n_k\)&lt;/span&gt; is the sample size for treatment group &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; (cf. Gleser &amp;amp; Olkin, 2009).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;single-group-pre-test-post-test-design&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Single group, pre-test post-test design&lt;/h4&gt;
&lt;p&gt;Suppose that a study involves taking pre-test and post-test measurements on a single group of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; participants. Borenstein (2009) recommends calculating the standardized mean difference for this study as the difference in means between the post-test and pre-test, scaled by the pooled (across pre- and post-test measurements) standard deviation. With obvious notation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_{post} - \bar{y}_{pre}}{s_p}, \qquad \text{where} \qquad s_p^2 = \frac{1}{2}\left(s_{pre}^2 + s_{post}^2\right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In this design,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{s_p} = \sqrt{\frac{2(1 - r)}{n}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the sample correlation between the pre- and post-tests. The remaining question is what to use for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. Borenstein (2009) uses &lt;span class=&#34;math inline&#34;&gt;\(\nu = n - 1\)&lt;/span&gt;. My previous post &lt;a href=&#34;https://www.jepusto.com/distribution-of-sample-variances/&#34;&gt;on the sampling covariance of sample variances&lt;/a&gt; gave the result that &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(s_p^2) = \sigma^4 (1 + \rho^2) / (n - 1)\)&lt;/span&gt;, which would instead suggest using&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu = \frac{2 (n - 1)}{1 + r^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This formula will tend to give slightly larger degrees of freedom, but probably won’t be that discrepant from Borenstein’s approach except in quite small samples. It would be interesting to investigate which approach is better in small samples (i.e., leading to less biased estimates of the SMD and more accurate estimates of sampling variance, and by how much), although its possible than neither is all that good because the variance estimator itself is based on a large-sample approximation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-group-pre-test-post-test-design-ancova-estimation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Two group, pre-test post-test design: ANCOVA estimation&lt;/h4&gt;
&lt;p&gt;Suppose that a study involves taking pre-test and post-test measurements on two groups of participants, with sample sizes &lt;span class=&#34;math inline&#34;&gt;\(n_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_C\)&lt;/span&gt; respectively. One way to analyze this design is via ANCOVA using the pre-test measure as the covariate, so that the treatment effect estimate is the difference in adjusted post-test means. In this design, the scaled standard error will be approximately&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{S} = \sqrt{ \frac{(n_C + n_T)(1 - r^2)}{n_C n_T} },
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the pooled, within-group sample correlation between the pre-test and the post-test measures (this approximation assumes that the pre-test SMD between groups is relatively small). Alternately, if &lt;span class=&#34;math inline&#34;&gt;\(se_b\)&lt;/span&gt; is provided then the scaled standard error could be calculated directly.&lt;/p&gt;
&lt;p&gt;Borenstein (2009) suggests calculating &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; as the difference in adjusted means, scaled by the pooled sample variances on the post-test measures. The post-test pooled sample variance will have the same degrees of freedom as in the two-sample t-test case: &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;. (Borenstein instead uses &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2 - q\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; is the number of covariates in the analysis, but this won’t usually make much difference unless the total sample size is quite small.)&lt;/p&gt;
&lt;p&gt;Scaling by the pooled post-test sample variance isn’t the only reasonable way to estimate the SMD though. If the covariate is a true pre-test, then why not scale by the pooled pre-test sample variance instead? To do so, you would need to calculate &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt; directly and use &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;. If it is reasonable to assume that the pre- and post-test population variances are equal, then another alternative would be to pool across the pre-test &lt;em&gt;and&lt;/em&gt; post-test sample variances in each group. Using this approach, you would again need to calculate &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt; directly and then use &lt;span class=&#34;math inline&#34;&gt;\(\nu = 2(n_C + n_T - 2) / (1 + r^2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-group-pre-test-post-test-design-repeated-measures-estimation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Two group, pre-test post-test design: repeated measures estimation&lt;/h4&gt;
&lt;p&gt;Another way to analyze the data from the same type of study design is to use repeated measures ANOVA. I’ve recently encountered a number of studies that use this approach (here’s a recent example from &lt;a href=&#34;http://dx.doi.org/10.1371/journal.pone.0154075&#34;&gt;a highly publicized study in PLOS ONE&lt;/a&gt;—see Table 2). The studies I’ve seen typically report the sample means and variances in each group and at each time point, from which the difference in change scores can be calculated. Let &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{gt}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_{gt}^2\)&lt;/span&gt; denote the sample mean and sample variance in group &lt;span class=&#34;math inline&#34;&gt;\(g = T, C\)&lt;/span&gt; at time &lt;span class=&#34;math inline&#34;&gt;\(t = 0, 1\)&lt;/span&gt;. The numerator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; would then be calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
b = \left(\bar{y}_{T1} - \bar{y}_{T0}\right) - \left(\bar{y}_{C1} - \bar{y}_{C0}\right),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which has sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(b) = 2(1 - \rho)\sigma^2\left(n_C + n_T \right) / (n_C n_T)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is the correlation between the pre-test and the post-test measures. Thus, the scaled standard error is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{S} = \sqrt{\frac{2(1 - r)(n_C + n_T)}{n_C n_T}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As with ANCOVA, there are several potential options for calculating the denominator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using the pooled sample variances on the post-test measures, with &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using the pooled sample variances on the pre-test measures, with &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;; or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using the pooled sample variances at both time points and in both groups, i.e.,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
  S^2 = \frac{(n_C - 1)(s_{C0}^2 + s_{C1}^2) + (n_T - 1)(s_{T0}^2 + s_{T1}^2)}{2(n_C + n_T - 2)},
  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\nu = 2(n_C + n_T - 2) / (1 + r^2)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The range of approaches to scaling is the same as for ANCOVA. This makes sense because both analyses are based on data from the same study design, so the parameter of interest should be the same (i.e., the target parameter should not change based on the analytic method). Note that all of these approaches are a bit different than the effect size estimator proposed by &lt;a href=&#34;http://doi.org/10.1037//1082-989X.7.1.105&#34;&gt;Morris and DeShon (2002)&lt;/a&gt; for the two-group, pre-post design; their approach does not fit into my framework because it involves taking a difference between standardized effect sizes (and therefore involves two separate estimates of scale, rather than just one).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;randomized-trial-with-longitudinal-follow-up&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Randomized trial with longitudinal follow-up&lt;/h4&gt;
&lt;p&gt;Many independent-groups designs—especially randomized trials in field settings—involve repeated, longitudinal follow-up assessments. An increasingly common approach to analysis of such data is through hierarchical linear models, which can be used to account for the dependence structure among measurements taken on the same individual. In this setting, &lt;a href=&#34;http://doi.org/10.1037/a0014699&#34;&gt;Feingold (2009)&lt;/a&gt; proposes that the SMD be calculated as the model-based estimate of the treatment effect at the final follow-up time, scaled by the within-groups variance of the outcome at that time point. Let &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; denote the estimated difference in slopes (change per unit time) between groups in a linear growth model, &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; denote the duration of the study, and &lt;span class=&#34;math inline&#34;&gt;\(s_{pF}^2\)&lt;/span&gt; denote the pooled sample variance of the outcome at the final time point. For this model, Feingold (2009) proposes to calculate the standardized mean difference as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{F \hat\beta_1}{s_{pF}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In a later paper, &lt;a href=&#34;http://doi.org/10.1037/a0037721&#34;&gt;Feingold (2015)&lt;/a&gt; proposes that the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; be estimated as &lt;span class=&#34;math inline&#34;&gt;\(F \times se_{\hat\beta_1} / s_{pF}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(se_{\hat\beta_1}\)&lt;/span&gt; is the standard error of the estimated slope. My framework suggests that a better estimate of the sampling variance, which accounts for the uncertainty of the scale estimate, would be to use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = \left(\frac{F \times se_{\hat\beta_1}}{s_{pF}}\right)^2 + \frac{d^2}{2 \nu},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_T + n_C - 2\)&lt;/span&gt;. The same &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; could be used to bias-correct the effect size estimate.&lt;/p&gt;
&lt;p&gt;If estimates of the variance components of the HLM are reported, one could use them to construct a model-based estimate of the scale parameter in the denominator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. I explored this approach in a paper that uses HLM to model single-case designs, which are a certain type of longitudinal experiment that typically involve a very small number of participants (&lt;a href=&#34;http://doi.org/10.3102/1076998614547577&#34;&gt;Pustejovsky, Hedges, &amp;amp; Shadish, 2014&lt;/a&gt;). Estimates of the scale parameter can usually be written as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
S_{model}^2 = \mathbf{r}&amp;#39;\boldsymbol\omega,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\omega\)&lt;/span&gt; is a vector of all the variance components in the model and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{r}\)&lt;/span&gt; is a vector of weights that depend on the model specification and length of follow-up. This estimate of scale will usually be more precise than &lt;span class=&#34;math inline&#34;&gt;\(s_{pF}^2\)&lt;/span&gt; because it makes use of all of the data (and modeling assumptions). However, it can be challenging to determine appropriate degrees of freedom for &lt;span class=&#34;math inline&#34;&gt;\(S_{model}^2\)&lt;/span&gt;. For single-case designs, I used estimates of &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\boldsymbol\omega)\)&lt;/span&gt; based on the inverse of the expected information matrix—call the estimate &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_{\boldsymbol\omega}\)&lt;/span&gt;—in which case&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu = \frac{2 S_{model}^4}{\mathbf{r}&amp;#39; \mathbf{V}_{\boldsymbol\omega} \mathbf{r}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;However, most published articles will not provide estimates of the sampling variances of the variance components—in fact, a lot of software for estimating HLMs does not even provide these. It would be useful to work out some reasonable approximations for the degrees of freedom in these models—approximations that can be calculated based on the information that’s typically available—and to investigate the extent to which there’s any practical benefit to using &lt;span class=&#34;math inline&#34;&gt;\(S_{model}^2\)&lt;/span&gt; over &lt;span class=&#34;math inline&#34;&gt;\(s_{pF}^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cluster-randomized-trials&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Cluster-randomized trials&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.3102/1076998606298043&#34;&gt;Hedges (2007)&lt;/a&gt; addresses estimation of standardized mean differences for cluster-randomized trials, in which the units of measurement are nested within higher-level clusters that comprise the units of randomization. Such designs involve two variance components (within- and between-cluster variance), and thus there are three potential approaches to scaling the treatment effect: standardize by the total variance (i.e., the sum of the within- and between-cluster components), standardize by the within-cluster variance, or standardize by the between-cluster variance. Furthermore, some of the effect sizes can be estimated in several different ways, each with a different sampling variance. &lt;a href=&#34;http://doi.org/10.3102/1076998606298043&#34;&gt;Hedges (2007)&lt;/a&gt; gives sampling variance estimates for each estimator of each effect size, but they all follow the same general formula as given above. (The appendix of the article actually gives the same formula as above, but using a more abstract formulation.)&lt;/p&gt;
&lt;p&gt;For example, suppose the target SMD parameter uses the total variance and that we have data from a two-level, two-arm cluster randomized trial with &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; clusters, &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations per cluster, and total sample sizes in each arm of &lt;span class=&#34;math inline&#34;&gt;\(N_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_C\)&lt;/span&gt;, respectively. Let &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; be the between-cluster variance, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; be the within-cluster variance, and &lt;span class=&#34;math inline&#34;&gt;\(\rho = \tau^2 / (\tau^2 + \sigma^2)\)&lt;/span&gt;. The target parameter is &lt;span class=&#34;math inline&#34;&gt;\(\delta = \left(\mu_T - \mu_C\right) / \left(\tau^2 + \sigma^2\right)\)&lt;/span&gt;. The article assumes that the treatment effect will be estimated by the difference in grand means, &lt;span class=&#34;math inline&#34;&gt;\(\bar{\bar{y}}_T - \bar{\bar{y}}_C\)&lt;/span&gt;. Letting &lt;span class=&#34;math inline&#34;&gt;\(S_B^2\)&lt;/span&gt; be the pooled sample variance of the cluster means within each arm and &lt;span class=&#34;math inline&#34;&gt;\(S_W^2\)&lt;/span&gt; be the pooled within-cluster sample variance, the total variance is estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
S_{total}^2 = S_B^2 + \frac{n - 1}{n} S_W^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;An estimate of the SMD is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \left(\bar{\bar{y}}_T - \bar{\bar{y}}_C \right) / \sqrt{S_{total}^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The scaled standard error of &lt;span class=&#34;math inline&#34;&gt;\(\bar{\bar{y}}_T - \bar{\bar{y}}_C\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
se_b = \sqrt{\left(\frac{N_C + N_T}{N_C N_T}\right)\left[1 + (n - 1)\rho\right]}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The appendix of the article demonstrates that &lt;span class=&#34;math inline&#34;&gt;\(\text{E}\left(S_{total}^2\right) = \tau^2 + \sigma^2\)&lt;/span&gt; and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left( S_{total}^2 \right) = \frac{2}{n^2}\left(\frac{(n \tau^2 + \sigma^2)^2}{M - 2} + \frac{(n - 1)^2 \sigma^4}{N_C + N_T - M}\right),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;by which it follows that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu = \frac{n^2 M (M - 2)}{M[(n - 1)\rho + 1]^2 + (M - 2)(n - 1)(1 - \rho)^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Substituting &lt;span class=&#34;math inline&#34;&gt;\(se_b / S_{total}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; into the formula for &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; gives the same as Expression (14) in the article.&lt;/p&gt;
&lt;p&gt;A limitation of &lt;a href=&#34;http://doi.org/10.3102/1076998606298043&#34;&gt;Hedges (2007)&lt;/a&gt; is that it only covers the case where the treatment effect is estimated by the difference in grand means (although it does cover the case of unequal cluster sizes, which gets quite messy). In practice, every cluster-randomized trial I’ve ever seen uses baseline covariates to adjust the mean difference (often based on a hierarchical linear model) and improve the precision of the treatment effect estimate. The SMD estimate should also be based on this covariate-adjustment estimate, scaled by the total variance &lt;em&gt;without adjusting for the covariate&lt;/em&gt;. An advantage of the general formulation given above is that its clear how to estimate the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. I would guess that it will often be possible to calculate the scaled standard error directly, given the standard error of the covariate-adjusted treatment effect estimate. And since &lt;span class=&#34;math inline&#34;&gt;\(S_{total}\)&lt;/span&gt; would be estimated just as before, its degrees of freedom remain the same.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.3102/1076998610376617&#34;&gt;Hedges (2011)&lt;/a&gt; discusses estimation of SMDs in three-level cluster-randomized trials—an even more complicated case. However, the general approach is the same; all that’s needed are the scaled standard error and the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; of whatever combination of variance components go into the denominator of the effect size. In both the two-level and three-level cases, the degrees of freedom get quite complicated in unbalanced samples and are probably not calculable from the information that is usually provided in an article. Hedges (2007, 2011) comments on a couple of cases where more tractable approximations can be used, although it seems like there might be room for further investigation here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Closing thoughts&lt;/h3&gt;
&lt;p&gt;I think this framework is useful in that it unifies a large number of cases that have been treated separately, and can also be applied (more-or-less immediately) to &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; estimators that haven’t been widely considered before, such as the &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; that involves scaling by the pooled pre-and-post, treatment-and-control sample variance. I hope it also illustrates that, while the point estimator &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; can be applied across a large number of study designs, the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; depends on the details of the design and estimation methods. The same is true for other families of effect sizes as well. For example, in other work I’ve demonstrated that the sampling variance of the correlation coefficient depends on the design from which the correlations are estimated (&lt;a href=&#34;http://doi.org/10.1037/a0033788&#34;&gt;Pustejovsky, 2014&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;If you have read this far, I’d love to get your feedback about whether you think this is a useful way to organize the calculations of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; estimators. Is this helpful? Or nothing you didn’t already know? Or still more complicated than it should be? Leave a comment!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Borenstein, M. (2009). Effect sizes for continuous data. In H. M. Cooper, L. V Hedges, &amp;amp; J. C. Valentine (Eds.), The Handbook of Research Synthesis and Meta-Analysis (pp. 221–236). New York, NY: Russell Sage Foundation.&lt;/p&gt;
&lt;p&gt;Feingold, A. (2009). Effect sizes for growth-modeling analysis for controlled clinical trials in the same metric as for classical analysis. Psychological Methods, 14(1), 43–53. &lt;a href=&#34;doi:10.1037/a0014699&#34; class=&#34;uri&#34;&gt;doi:10.1037/a0014699&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Feingold, A. (2015). Confidence interval estimation for standardized effect sizes in multilevel and latent growth modeling. Journal of Consulting and Clinical Psychology, 83(1), 157–168. &lt;a href=&#34;doi:10.1037/a0037721&#34; class=&#34;uri&#34;&gt;doi:10.1037/a0037721&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gleser, L. J., &amp;amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp;amp; J. C. Valentine (Eds.), The Handbook of Research Synthesis and Meta-Analysis (2nd ed., pp. 357–376). New York, NY: Russell Sage Foundation.&lt;/p&gt;
&lt;p&gt;Hedges, L. V. (2007). Effect sizes in cluster-randomized designs. Journal of Educational and Behavioral Statistics, 32(4), 341–370. &lt;a href=&#34;doi:10.3102/1076998606298043&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998606298043&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hedges, L. V. (2011). Effect sizes in three-level cluster-randomized experiments. Journal of Educational and Behavioral Statistics, 36(3), 346–380. &lt;a href=&#34;doi:10.3102/1076998610376617&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998610376617&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Morris, S. B., &amp;amp; DeShon, R. P. (2002). Combining effect size estimates in meta-analysis with repeated measures and independent-groups designs. Psychological Methods, 7(1), 105–125. &lt;a href=&#34;doi:10.1037//1082-989X.7.1.105&#34; class=&#34;uri&#34;&gt;doi:10.1037//1082-989X.7.1.105&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pustejovsky, J. E. (2014). Converting from d to r to z when the design uses extreme groups, dichotomization, or experimental control. Psychological Methods, 19(1), 92–112. &lt;a href=&#34;doi:10.1037/a0033788&#34; class=&#34;uri&#34;&gt;doi:10.1037/a0033788&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pustejovsky, J. E., Hedges, L. V, &amp;amp; Shadish, W. R. (2014). Design-comparable effect sizes in multiple baseline designs: A general modeling framework. Journal of Educational and Behavioral Statistics, 39(5), 368–393. &lt;a href=&#34;doi:10.3102/1076998614547577&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998614547577&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Viechtbauer, W. (2007). Approximate confidence intervals for standardized effect sizes in the two-independent and two-dependent samples design. Journal of Educational and Behavioral Statistics, 32(1), 39–60. &lt;a href=&#34;doi:10.3102/1076998606298034&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998606298034&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>wildmeta</title>
      <link>https://www.jepusto.com/software/wildmeta/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/software/wildmeta/</guid>
      <description>&lt;p&gt;An R package for conducting hypothesis tests of meta-regression models using cluster wild bootstrapping, based on methods examined in 
&lt;a href=&#34;https://www.jepusto.com/publication/cluster-wild-bootstrap-for-meta-analysis/&#34;&gt;Joshi, Pustejovsky, and Beretvas (2021)&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Small-sample adjustments for tests of moderators and model fit using robust variance estimation in meta-regression</title>
      <link>https://www.jepusto.com/publication/rve-for-meta-regression/</link>
      <pubDate>Tue, 15 Dec 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/rve-for-meta-regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Special Education Pro-Sem</title>
      <link>https://www.jepusto.com/sped-pro-sem-again/</link>
      <pubDate>Tue, 24 Nov 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/sped-pro-sem-again/</guid>
      <description>


&lt;p&gt;Yesterday evening I again had the pleasure of visiting Dr. Barnes’ pro seminar for first year students in Special Education, where I shared some of my work on research synthesis and meta-analysis of single-case research. &lt;a href=&#34;https://www.jepusto.com/files/Barnes-Pro-Sem-2015-11.pdf&#34;&gt;Here are the slides&lt;/a&gt; from my presentation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Correlations between standardized mean differences</title>
      <link>https://www.jepusto.com/correlations-between-smds/</link>
      <pubDate>Thu, 17 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/correlations-between-smds/</guid>
      <description>


&lt;p&gt;Several students and colleagues have asked me recently about an issue that comes up in multivariate meta-analysis when some of the studies include multiple treatment groups and multiple outcome measures. In this situation, one might want to include effect size estimates for each treatment group and each outcome measure. In order to do so in fully multivariate meta-analysis, estimates of the covariances among all of these efffect sizes are needed. The covariance among effect sizes arises for several reasons:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For a single outcome measure, effect sizes based on different treatment groups compared to a common control group will be correlated because the same control group data is used to calculate both effect sizes;&lt;/li&gt;
&lt;li&gt;Effect sizes based on a single treatment group and a single control group, but for different outcome measures, will be correlated because the outcomes are measured on the same set of units (in both the treatment group and the control group).&lt;/li&gt;
&lt;li&gt;Effect sizes based on different treatment groups and for different outcome measures will be correlated because the outcomes are measured on the same set of units in the control group (though not in the treatment group).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For standardized mean difference (SMD) measures of effect size, formulas for the covariance are readily available for the first two cases (see e.g., Gleser &amp;amp; Olkin, 2009), but not for the third case. Below I review the formulas for the covariance between SMDs in the first two cases and provide a formula for the third case.&lt;/p&gt;
&lt;div id=&#34;notation-and-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Notation and Model&lt;/h1&gt;
&lt;p&gt;Suppose that the experiment has a control group that includes &lt;span class=&#34;math inline&#34;&gt;\(n_0\)&lt;/span&gt; units and &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; treatment groups that include &lt;span class=&#34;math inline&#34;&gt;\(n_1,...,n_T\)&lt;/span&gt; units, respectively. Also suppose that &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; outcome measures are made on each unit in each group. The formulas below assume that the data follow a one-way MANOVA model. Let &lt;span class=&#34;math inline&#34;&gt;\(y_{ijt}\)&lt;/span&gt; denote the score for unit &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in group &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Then I assume that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijt} = \mu_{jt} + \epsilon_{ijt},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the errors are multi-variate normally distributed with mean zero, variance that can differ across outcome but not across treatment group, and correlation that is constant across treatment groups, i.e. &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}\left(\epsilon_{ijt}\right) = \sigma^2_j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}\left(\epsilon_{ijt}, \epsilon_{ikt} \right) = \rho_{jk}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Denote the mean score on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in group &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{jt}\)&lt;/span&gt; and the standard deviation of the scores on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in group &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(s_{jt}\)&lt;/span&gt;, both for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t = 0,...,T\)&lt;/span&gt; (with &lt;span class=&#34;math inline&#34;&gt;\(t = 0\)&lt;/span&gt; corresponding to the control group). Also required are estimates of the correlations among outcome measures 1 through &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt;, after partialling out differences between treatment groups. Let &lt;span class=&#34;math inline&#34;&gt;\(r_{jk}\)&lt;/span&gt; denote the partial correlation between measure &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and measure &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J - 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = j + 1,...,J\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;With multiple treatment groups, one might wonder how best to compute the standard deviation for purposes of scaling the treatment effect estimates. In their discussion of SMDs from multiple treatment studies, Gleser and Olkin (2009) assume (though they don’t actually state outright) that the standard deviation will be pooled across all &lt;span class=&#34;math inline&#34;&gt;\(T + 1\)&lt;/span&gt; groups. The pooled standard deviation for outcome &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; is calculated as the square root of the pooled variance,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s_{jP}^2 = \frac{1}{N - T - 1} \sum_{t=0}^T (n_t - 1)s_{jt}^2,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(N = \sum_{t=0}^T n_t\)&lt;/span&gt;. The standardized mean difference for treatment &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is then estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d_{jt} = \frac{\bar{y}_{jt} - \bar{y}_{j0}}{s_{jP}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t = 1,...,T\)&lt;/span&gt;. The conventional estimate of the large-sample variance of &lt;span class=&#34;math inline&#34;&gt;\(d_{jt}\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Var}(d_{jt}) \approx \frac{1}{n_0} + \frac{1}{n_t} + \frac{d_{jt}^2}{2 (N - T - 1)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;covariances&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Covariances&lt;/h1&gt;
&lt;p&gt;For SMDs based on a common outcome measure and a common control group, but different treatment groups, the large-sample covariance between the effect size estimates can be estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{ju}) \approx \frac{1}{n_0} + \frac{d_{jt} d_{ju}}{2 (N - T - 1)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above differs slightly from Gleser and Olkin (2009, Formula 19.19) because it uses the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(N - T - 1\)&lt;/span&gt; in the denominator of the second term, rather than the total sample size. If the total sample size is larger relative to the number of treatment groups, the discrepancy should be minor.&lt;/p&gt;
&lt;p&gt;SMDs based on a single treatment group but for different outcome measures follow a structure that is essentially equivalent to what Gleser and Olkin (2009) call a “multiple-endpoint” study. The large-sample covariance between the effect size estimates can be estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{kt}) \approx r_{jk} \left(\frac{1}{n_0} + \frac{1}{n_t}\right) + \frac{r_{jk}^2 d_{jt} d_{kt}}{2 (N - T - 1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(cf. Gleser &amp;amp; Olkin, 2009, Formula 19.19). Note that if the degrees of freedom are large relative to &lt;span class=&#34;math inline&#34;&gt;\(d_{jt}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d_{kt}\)&lt;/span&gt;, then the correlation between the effect sizes will be approximately equal to &lt;span class=&#34;math inline&#34;&gt;\(\text{Cor}(d_{jt},d_{kt}) \approx r_{jk}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, the large-sample covariance between SMDs based on different treatment groups and different outcome measures can be estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{ku}) \approx \frac{r_{jk}}{n_0} + \frac{r_{jk}^2 d_{jt} d_{ku}}{2 (N - T - 1)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is similar to the previous formula, but does not include the term corresponding to the covariance between different outcome measures in a common treatment group.&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(r_{jj} = 1\)&lt;/span&gt; is used for the correlation of an outcome measure with itself, all of the above formulas (including the variance of &lt;span class=&#34;math inline&#34;&gt;\(d_{jt}\)&lt;/span&gt;) can be expressed compactly as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{ku}) \approx r_{jk} \left(\frac{1}{n_0} + \frac{I(t = u)}{n_t}\right) + \frac{r_{jk}^2 d_{jt} d_{ku}}{2 (N - T - 1)},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(I(A)\)&lt;/span&gt; is equal to one if &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is true and equal to zero otherwise.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Gleser, L. J., &amp;amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp;amp; J. C. Valentine (Eds.), The Handbook of Research Synthesis and Meta-Analysis (2nd ed., pp. 357-376). New York, NY: Russell Sage Foundation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A meta-analytic approach to examine the relationship between religion/spirituality and mental health in cancer</title>
      <link>https://www.jepusto.com/publication/religion-spirituality-mental-health/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/religion-spirituality-mental-health/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A meta-analytic review of religious or spiritual involvement and social health among cancer patients</title>
      <link>https://www.jepusto.com/publication/religion-spirituality-social-health/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/religion-spirituality-social-health/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Religion, spirituality, and physical health in cancer patients: A meta-analysis</title>
      <link>https://www.jepusto.com/publication/religion-spirituality-physical-health/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/religion-spirituality-physical-health/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The clubSandwich package for meta-analysis with RVE</title>
      <link>https://www.jepusto.com/clubsandwich-for-rve-meta-analysis/</link>
      <pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/clubsandwich-for-rve-meta-analysis/</guid>
      <description>


&lt;p&gt;I’ve recently been working on small-sample correction methods for hypothesis tests in linear regression models with cluster-robust variance estimation. My colleague (and grad-schoolmate) Beth Tipton has developed small-sample adjustments for t-tests (of single regression coefficients) in the context of meta-regression models with robust variance estimation, and together we have developed methods for multiple-contrast hypothesis tests. We have an R package (called &lt;code&gt;clubSandwich&lt;/code&gt;) that implements all this stuff, not only for meta-regression models but also for other models and contexts where cluster-robust variance estimation is often used.&lt;/p&gt;
&lt;p&gt;The alpha-version of the package is currently &lt;a href=&#34;https://github.com/jepusto/clubSandwich&#34;&gt;available on Github&lt;/a&gt;. See the Github README for instructions on how to install it in R. Below I demonstrate how to use the package to get robust variance estimates, t-tests, and F-tests, all with small-sample corrections. The example uses a dataset of effect sizes from a Campbell Collaboration &lt;a href=&#34;http://www.campbellcollaboration.org/lib/project/158/&#34;&gt;systematic review of dropout prevention programs&lt;/a&gt;, conducted by Sandra Jo Wilson and her colleagues.&lt;/p&gt;
&lt;p&gt;The original analysis included a meta-regression with covariates that capture methodological, participant, and program characteristics. I’ll use a regression specification that is similar to Model III from Wilson et al. (2011), but treat the &lt;code&gt;evaluator_independence&lt;/code&gt; and &lt;code&gt;implementation_quality&lt;/code&gt; variables as categorical rather than interval-level; the original analysis clustered at the level of the sample (some studies reported results from multiple samples), whereas I will cluster at the study level.
I fit the model two ways, first using the &lt;code&gt;robumeta&lt;/code&gt; package and then using &lt;code&gt;metafor&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;robumeta-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;robumeta model&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(width=150)
library(robumeta)
library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(dropoutPrevention)

m3_robu &amp;lt;- robu(LOR1 ~ study_design + attrition + group_equivalence + adjusted
                + outcome + evaluator_independence
                + male_pct + white_pct + average_age
                + implementation_quality + program_site + duration + service_hrs, 
                data = dropoutPrevention, studynum = studyID, var.eff.size = varLOR, 
                modelweights = &amp;quot;HIER&amp;quot;)
print(m3_robu)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Hierarchical Effects Model with Small-Sample Corrections 
## 
## Model: LOR1 ~ study_design + attrition + group_equivalence + adjusted + outcome + evaluator_independence + male_pct + white_pct + average_age + implementation_quality + program_site + duration + service_hrs 
## 
## Number of clusters = 152 
## Number of outcomes = 385 (min = 1 , mean = 2.53 , median = 1 , max = 30 )
## Omega.sq = 0.24907 
## Tau.sq = 0.1024663 
## 
##                                                 Estimate   StdErr t-value  dfs    P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1                                 X.Intercept.  0.016899 0.615399  0.0275 16.9 0.97841541 -1.28228  1.31608    
## 2          study_designNon.random..non.matched -0.002626 0.185142 -0.0142 40.5 0.98875129 -0.37667  0.37141    
## 3                       study_designRandomized -0.086872 0.140044 -0.6203 38.6 0.53869676 -0.37024  0.19650    
## 4                                    attrition  0.118889 0.247228  0.4809 15.5 0.63732597 -0.40666  0.64444    
## 5                            group_equivalence  0.502463 0.195838  2.5657 28.7 0.01579282  0.10174  0.90318  **
## 6                        adjustedadjusted.data -0.322480 0.125413 -2.5713 33.8 0.01470796 -0.57741 -0.06755  **
## 7                              outcomeenrolled  0.097059 0.139842  0.6941 16.5 0.49727848 -0.19862  0.39274    
## 8                            outcomegraduation  0.147643 0.134938  1.0942 30.2 0.28253825 -0.12786  0.42315    
## 9                        outcomegraduation.ged  0.258034 0.169134  1.5256 16.3 0.14632629 -0.10006  0.61613    
## 10 evaluator_independenceIndirect..influential -0.765085 0.399109 -1.9170  6.2 0.10212896 -1.73406  0.20389    
## 11              evaluator_independencePlanning -0.920874 0.346536 -2.6574  5.6 0.04027061 -1.78381 -0.05794  **
## 12              evaluator_independenceDelivery -0.916673 0.304303 -3.0124  4.7 0.03212299 -1.71432 -0.11903  **
## 13                                    male_pct  0.167965 0.181538  0.9252 16.4 0.36824526 -0.21609  0.55202    
## 14                                   white_pct  0.022915 0.149394  0.1534 21.8 0.87950385 -0.28704  0.33287    
## 15                                 average_age  0.037102 0.027053  1.3715 21.2 0.18458247 -0.01913  0.09333    
## 16     implementation_qualityPossible.problems  0.411779 0.128898  3.1946 26.7 0.00358205  0.14714  0.67642 ***
## 17  implementation_qualityNo.apparent.problems  0.658570 0.123874  5.3164 34.6 0.00000635  0.40699  0.91015 ***
## 18                           program_sitemixed  0.444384 0.172635  2.5741 28.6 0.01550504  0.09109  0.79768  **
## 19                program_siteschool.classroom  0.426658 0.159773  2.6704 37.4 0.01115192  0.10303  0.75028  **
## 20    program_siteschool..outside.of.classroom  0.262517 0.160519  1.6354 30.1 0.11236814 -0.06525  0.59028    
## 21                                    duration  0.000427 0.000873  0.4895 36.7 0.62736846 -0.00134  0.00220    
## 22                                 service_hrs -0.003434 0.005012 -0.6852 36.7 0.49752503 -0.01359  0.00672    
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---
## Note: If df &amp;lt; 4, do not trust the results&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that &lt;code&gt;robumeta&lt;/code&gt; produces small-sample corrected standard errors and t-tests, and so there is no need to repeat those calculations with &lt;code&gt;clubSandwich&lt;/code&gt;. The &lt;code&gt;evaluator_independence&lt;/code&gt; variable has four levels, and it might be of interest to test whether the average program effects differ by the degree of evaluator independence. The null hypothesis in this case is that the 10th, 11th, and 12th regression coefficients are all equal to zero. A small-sample adjusted F-test for this hypothesis can be obtained as follows.
(The &lt;code&gt;vcov = &#34;CR2&#34;&lt;/code&gt; option means that the standard errors will be corrected using the bias-reduced linearization method proposed by McCaffrey, Bell, and Botts, 2001.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Wald_test(m3_robu, constraints = 10:12, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Test    F d.f.  p.val
##   HTZ 2.78 16.8 0.0732&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the &lt;code&gt;Wald_test&lt;/code&gt; function provides an F-type test with degrees of freedom estimated using the approximate Hotelling’s &lt;span class=&#34;math inline&#34;&gt;\(T^2_Z\)&lt;/span&gt; method. The test has less than 17 degrees of freedom, even though there are 152 independent studies in the data, and has a p-value of .07, so not-quite-significant at conventional levels. The low degrees of freedom are a consequence of the fact that one of the levels of &lt;code&gt;evaluator independence&lt;/code&gt; has only a few effect sizes in it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(dropoutPrevention$evaluator_independence)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##           Independent Indirect, influential              Planning              Delivery 
##                     6                    33                    43                   303&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;metafor-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;metafor model&lt;/h4&gt;
&lt;p&gt;Our package also works with models fit using the &lt;code&gt;metafor&lt;/code&gt; package. Here I re-fit the same regression specification, but use REML to estimate the variance components (&lt;code&gt;robumeta&lt;/code&gt; uses a method-of-moments estimator) and use a somewhat different weighting scheme than that used in &lt;code&gt;robumeta&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
m3_metafor &amp;lt;- rma.mv(LOR1 ~ study_design + attrition + group_equivalence + adjusted
                      + outcome + evaluator_independence
                      + male_pct + white_pct + average_age
                      + implementation_quality + program_site + duration + service_hrs, 
                      V = varLOR, random = list(~ 1 | studyID, ~ 1 | studySample),
                     data = dropoutPrevention)
summary(m3_metafor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 385; method: REML)
## 
##    logLik   Deviance        AIC        BIC       AICc 
## -489.0357   978.0714  1026.0714  1119.5371  1029.6217   
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed       factor 
## sigma^2.1  0.2274  0.4769    152     no      studyID 
## sigma^2.2  0.1145  0.3384    317     no  studySample 
## 
## Test for Residual Heterogeneity:
## QE(df = 363) = 1588.4397, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:22):
## QM(df = 21) = 293.8694, p-val &amp;lt; .0001
## 
## Model Results:
## 
##                                              estimate      se     zval    pval    ci.lb    ci.ub 
## intrcpt                                        0.5296  0.7250   0.7304  0.4651  -0.8915   1.9506      
## study_designNon-random, non-matched           -0.0494  0.1722  -0.2871  0.7741  -0.3870   0.2881      
## study_designRandomized                         0.0653  0.1628   0.4010  0.6884  -0.2538   0.3843      
## attrition                                     -0.1366  0.2429  -0.5623  0.5739  -0.6126   0.3395      
## group_equivalence                              0.4071  0.1573   2.5877  0.0097   0.0988   0.7155   ** 
## adjustedadjusted data                         -0.3581  0.1532  -2.3371  0.0194  -0.6585  -0.0578    * 
## outcomeenrolled                               -0.2831  0.0771  -3.6709  0.0002  -0.4343  -0.1320  *** 
## outcomegraduation                             -0.0913  0.0657  -1.3896  0.1646  -0.2201   0.0375      
## outcomegraduation/ged                          0.6983  0.0805   8.6750  &amp;lt;.0001   0.5406   0.8561  *** 
## evaluator_independenceIndirect, influential   -0.7530  0.4949  -1.5214  0.1282  -1.7230   0.2171      
## evaluator_independencePlanning                -0.7700  0.4869  -1.5814  0.1138  -1.7242   0.1843      
## evaluator_independenceDelivery                -1.0016  0.4600  -2.1774  0.0294  -1.9033  -0.1000    * 
## male_pct                                       0.1021  0.1715   0.5951  0.5518  -0.2341   0.4382      
## white_pct                                      0.1223  0.1804   0.6777  0.4979  -0.2313   0.4758      
## average_age                                    0.0061  0.0291   0.2091  0.8344  -0.0509   0.0631      
## implementation_qualityPossible problems        0.4738  0.1609   2.9445  0.0032   0.1584   0.7892   ** 
## implementation_qualityNo apparent problems     0.6318  0.1471   4.2965  &amp;lt;.0001   0.3436   0.9201  *** 
## program_sitemixed                              0.3289  0.2413   1.3631  0.1729  -0.1440   0.8019      
## program_siteschool classroom                   0.2920  0.1736   1.6821  0.0926  -0.0482   0.6321    . 
## program_siteschool, outside of classroom       0.1616  0.1898   0.8515  0.3945  -0.2104   0.5337      
## duration                                       0.0013  0.0009   1.3423  0.1795  -0.0006   0.0031      
## service_hrs                                   -0.0003  0.0047  -0.0654  0.9478  -0.0096   0.0090      
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;metafor&lt;/code&gt; produces model-based standard errors, t-tests, and confidence intervals. The &lt;code&gt;coef_test&lt;/code&gt; function from &lt;code&gt;clubSandwich&lt;/code&gt; will calculate robust standard errors and robust t-tests for each of the coefficients:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_test(m3_metafor, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                          Coef.  Estimate       SE  t-stat  d.f. p-val (Satt) Sig.
## 1                                      intrcpt  0.529569 0.724851  0.7306 20.08      0.47347     
## 2          study_designNon-random, non-matched -0.049434 0.204152 -0.2421 58.42      0.80952     
## 3                       study_designRandomized  0.065272 0.149146  0.4376 53.17      0.66342     
## 4                                    attrition -0.136575 0.306429 -0.4457 10.52      0.66485     
## 5                            group_equivalence  0.407108 0.210917  1.9302 23.10      0.06595    .
## 6                        adjustedadjusted data -0.358124 0.136132 -2.6307 43.20      0.01176    *
## 7                              outcomeenrolled -0.283124 0.237199 -1.1936  7.08      0.27108     
## 8                            outcomegraduation -0.091295 0.091465 -0.9981  9.95      0.34188     
## 9                        outcomegraduation/ged  0.698328 0.364882  1.9138  8.02      0.09188    .
## 10 evaluator_independenceIndirect, influential -0.752994 0.447670 -1.6820  6.56      0.13929     
## 11              evaluator_independencePlanning -0.769968 0.403898 -1.9063  6.10      0.10446     
## 12              evaluator_independenceDelivery -1.001648 0.355989 -2.8137  4.89      0.03834    *
## 13                                    male_pct  0.102055 0.148410  0.6877  9.68      0.50782     
## 14                                   white_pct  0.122255 0.141470  0.8642 16.88      0.39961     
## 15                                 average_age  0.006084 0.033387  0.1822 15.79      0.85772     
## 16     implementation_qualityPossible problems  0.473789 0.148660  3.1871 22.44      0.00419   **
## 17  implementation_qualityNo apparent problems  0.631842 0.138073  4.5761 28.68      &amp;lt; 0.001  ***
## 18                           program_sitemixed  0.328941 0.196848  1.6710 27.47      0.10607     
## 19                program_siteschool classroom  0.291952 0.146014  1.9995 42.70      0.05195    .
## 20    program_siteschool, outside of classroom  0.161640 0.171700  0.9414 29.27      0.35420     
## 21                                    duration  0.001270 0.000978  1.2988 31.96      0.20332     
## 22                                 service_hrs -0.000309 0.004828 -0.0641 49.63      0.94915&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that &lt;code&gt;coef_test&lt;/code&gt; assumed that it should cluster based on &lt;code&gt;studyID&lt;/code&gt;, which is the outer-most random effect in the metafor model. This can also be specified explicitly by including the option &lt;code&gt;cluster = dropoutPrevention$studyID&lt;/code&gt; in the call.&lt;/p&gt;
&lt;p&gt;The F-test for degree of evaluator independence uses the same syntax as before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Wald_test(m3_metafor, constraints = 10:12, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Test    F d.f.  p.val
##   HTZ 2.71 18.3 0.0753&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Despite some differences in weighting schemes, the p-value is very close to the result obtained using &lt;code&gt;robumeta&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Meta-sandwich with extra mustard</title>
      <link>https://www.jepusto.com/robust-meta-analysis-3/</link>
      <pubDate>Sat, 26 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/robust-meta-analysis-3/</guid>
      <description>


&lt;p&gt;In an earlier post about sandwich standard errors for multi-variate meta-analysis, I &lt;a href=&#34;https://www.jepusto.com/Robust-meta-analysis-1/&#34;&gt;mentioned&lt;/a&gt; that Beth Tipton has recently proposed small-sample corrections for the covariance estimators and t-tests, based on the bias-reduced linearization approach of &lt;a href=&#34;http://www.amstat.org/sections/SRMS/Proceedings/y2001/Proceed/00264.pdf&#34;&gt;McCaffrey, Bell, and Botts (2001)&lt;/a&gt;.
You can find her forthcoming paper on the adjustments &lt;a href=&#34;http://dx.doi.org/10.1037/met0000011&#34;&gt;here&lt;/a&gt;.
My understanding is that these small-sample corrections are important because the uncorrected sandwich estimators can lead to under-statement of uncertainty and inflated type I error rates when a given meta-regression coefficient is estimated from only a small or moderately sized sample of independent studies (or clusters of studies).
Moreover, it can be difficult to determine exactly when you have a large enough sample to trust the uncorrected sandwiches.&lt;/p&gt;
&lt;p&gt;I wanted to try out these small-sample corrected sandwich estimators for a meta-analyses project that I’m working on. Beth and one of her students have written an R package called &lt;a href=&#34;http://cran.r-project.org/web/packages/robumeta/index.html&#34;&gt;robumeta&lt;/a&gt; that implements the sandwich covariance estimator and small-sample corrections as described in her paper.
However, for my project I want to use the &lt;a href=&#34;http://www.metafor-project.org/&#34;&gt;metafor package&lt;/a&gt;, which doesn’t provide these methods.
I’ve therefore created a set of functions that implement the sandwich covariance estimators and small-sample corrections for models estimated using the &lt;code&gt;rma.mv&lt;/code&gt; function in &lt;code&gt;metafor&lt;/code&gt;.
Here is &lt;a href=&#34;https://gist.github.com/jepusto/11302318&#34;&gt;the complete code&lt;/a&gt;. Sorry, there’s no further documentation at the moment (beyond the rest of this post).&lt;/p&gt;
&lt;div id=&#34;consistency-with-robumeta&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Consistency with robumeta&lt;/h3&gt;
&lt;p&gt;In order to check that the functions are correct, I compared the results generated by &lt;code&gt;robumeta&lt;/code&gt; with the results from &lt;code&gt;metafor&lt;/code&gt; plus my functions. Here’s one example (I looked at a few others as well). First, the robumeta results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(robumeta)
data(hierdat)

robu_hier &amp;lt;- robu(effectsize ~ males + binge,
            data = hierdat, modelweights = &amp;quot;HIER&amp;quot;,
            studynum = studyid,
            var.eff.size = var, small = TRUE)
robu_hier&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Hierarchical Effects Model with Small-Sample Corrections 
## 
## Model: effectsize ~ males + binge 
## 
## Number of clusters = 15 
## Number of outcomes = 68 (min = 1 , mean = 4.53 , median = 2 , max = 29 )
## Omega.sq = 0.1146972 
## Tau.sq = 0.06797866 
## 
##                Estimate  StdErr t-value  dfs P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1 X.Intercept.  -0.0989 0.32140  -0.308 1.79 0.79045  -1.6511   1.4533    
## 2        males   0.0020 0.00441   0.454 1.88 0.69689  -0.0182   0.0222    
## 3        binge   0.6799 0.12156   5.594 4.18 0.00439   0.3482   1.0117 ***
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---
## Note: If df &amp;lt; 4, do not trust the results&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To maintain consistency, I first need to calculate the approximate weights used in &lt;code&gt;robumeta&lt;/code&gt; and then fit the model in &lt;code&gt;metafor&lt;/code&gt; using these fixed weights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::source_gist(id = &amp;quot;11302318&amp;quot;, filename = &amp;quot;metafor-BRL.R&amp;quot;)

hierdat$var_HTJ &amp;lt;- hierdat$var + as.numeric(robu_hier$mod_info$omega.sq) + as.numeric(robu_hier$mod_info$tau.sq)

meta_hier &amp;lt;- rma.mv(yi = effectsize ~ males + binge, 
                V = var_HTJ, 
                data = hierdat, method = &amp;quot;FE&amp;quot;)
meta_hier$cluster &amp;lt;- hierdat$studyid

RobustResults(meta_hier)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate  Std. Error    t value       df    Pr(&amp;gt;|t|)
## intrcpt -0.098869582 0.321400179 -0.3076214 1.788350 0.790446059
## males    0.002002043 0.004410552  0.4539212 1.879142 0.696887075
## binge    0.679929801 0.121556887  5.5935111 4.182783 0.004385654&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The estimated covariance matrices match:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(sandwich(meta_hier, meat.=meatBRL), 
          robu_hier$VR.r, 
          check.attributes=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can also be verified that the p-values based on the Satterthwaite degrees of freedom agree.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-with-metafor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use with metafor&lt;/h3&gt;
&lt;p&gt;Of course, the point of writing functions that work with &lt;code&gt;rma.mv&lt;/code&gt; objects is not to replicate &lt;code&gt;robumeta&lt;/code&gt; results, but to take advantage of &lt;code&gt;metafor&lt;/code&gt;’s flexibility. Rather than estimate the model with &lt;code&gt;robumeta&lt;/code&gt;, typically one would estimate the variance components in &lt;code&gt;metafor&lt;/code&gt; and then calculate the sandwich covariance estimates and small-sample corrections. For instance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_REML &amp;lt;- rma.mv(yi = effectsize ~ males + binge, 
                V = var, random = list(~ 1 | esid, ~ 1 | studyid), 
                data = hierdat,
                method = &amp;quot;REML&amp;quot;)
meta_REML&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 68; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2.1  0.1566  0.3957     68     no     esid 
## sigma^2.2  0.0000  0.0000     15     no  studyid 
## 
## Test for Residual Heterogeneity:
## QE(df = 65) = 297.0172, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 27.2659, p-val &amp;lt; .0001
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb   ci.ub 
## intrcpt   -0.1118  0.2474  -0.4520  0.6513  -0.5966  0.3730      
## males      0.0022  0.0034   0.6467  0.5178  -0.0044  0.0088      
## binge      0.6744  0.1313   5.1349  &amp;lt;.0001   0.4170  0.9319  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults(meta_REML)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate  Std. Error    t value       df    Pr(&amp;gt;|t|)
## intrcpt -0.111796564 0.318156355 -0.3513888 1.794988 0.762200367
## males    0.002173683 0.004380026  0.4962718 1.882842 0.671549040
## binge    0.674435042 0.121660936  5.5435628 4.167780 0.004585142&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One advantage here is that it’s possible to compare the model-based standard errors to the robust ones. In this instance, the two are fairly similar. However, the degrees of freedom estimated in the robust results indicate that the model-based standard errors (based on normal approximations) may be much too narrow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;differences-between-robumeta-and-my-implementation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Differences between robumeta and my implementation&lt;/h3&gt;
&lt;p&gt;There are two important differences between the approach implemented in &lt;code&gt;robumeta&lt;/code&gt; and the approach based on &lt;code&gt;metafor&lt;/code&gt; and the code that I’ve provided. The first is that &lt;code&gt;robumeta&lt;/code&gt; uses moment estimators for the variance components, whereas &lt;code&gt;metafor&lt;/code&gt; uses restricted- or full maximum likelihood. The estimated between-study heterogeneity (and for the hierarchical effects model, the within-study heterogeneity as well) will therefore differ to some degree.&lt;/p&gt;
&lt;p&gt;The second, and perhaps more crucial, distinction has to do with the choice of weights. Weights are used for two purposes: to estimate the fixed effects and to calculate the small-sample correction. The &lt;code&gt;robumeta&lt;/code&gt; package uses diagonal weights for both purposes. Using diagonal weights in calculating the fixed effects means that the resulting point estimates will be equivalent to those from a weighted ordinary least squares regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;WOLS &amp;lt;- lm(effectsize ~ males + binge, data = hierdat, weights = 1 / var_HTJ)
coef(WOLS)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  (Intercept)        males        binge 
## -0.098869582  0.002002043  0.679929801&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(coef(WOLS), as.numeric(robu_hier$b.r), check.attributes = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A subtler point is that &lt;code&gt;robumeta&lt;/code&gt; uses the inverse weights for purposes of calculating the small sample-correction. The small sample correction involves choosing a “working” or “target” covariance matrix towards which to adjust the sandwich estimator. If the working covariance model is correct, then the BRL covariance estimator is exactly unbiased. The working matrix is also used to determine the Satterthwaite degrees of freedom. In &lt;code&gt;robumeta&lt;/code&gt;, the working covariance matrix is taken to be inverse of the weights, which is also a diagonal matrix. Thus, the BRL correction amounts to assuming independence among all of the effect sizes. This may sound somewhat counter-intuitive, but some simulation results (reported in Beth’s paper, referenced above) suggest that the resulting estimators perform well even when the working independence assumption is not correct.&lt;/p&gt;
&lt;p&gt;In contrast to the &lt;code&gt;robumeta&lt;/code&gt; weights, &lt;code&gt;metafor&lt;/code&gt; calculates the fixed effects based on a weighting matrix that is exactly inverse variance for given estimates of the variance components. Typically, the weighting matrix will be block-diagonal but may have off-diagonal entries corresponding to effect sizes drawn from the same study. Furthermore, my implementation of BRL uses the estimated covariance matrix derived from the posited random effects structure; in other words, the working covariance structure is taken to be the same as the model specified in the &lt;code&gt;metafor&lt;/code&gt; call. This seems sensible to me, although I do not have any evidence regarding its performance relative to the alternatives. It is possible that any gains in asymptotic efficiency from using exactly inverse variance weights are outweighed by some sort of instability in small samples. It’s also possible that the performance of the different approaches to weighting might depend on which variance component estimators are used (i.e., MOM vs. REML).&lt;/p&gt;
&lt;p&gt;Neither implementation that I’ve described above is fully general. Following the generalized estimating equation framework, a fully general implementation would allow the user to specify an arbitrary weight matrix in addition to a working covariance structure. The weighting matrix would be used for purposes of estimating the fixed effects. The working covariance model would be estimated (based on MOM or REML or what-not) and then used for purposes of BRL adjustment. Of course, this fully general formulation may well be more complicated than what most analysts would actually need or use (especially for linear mixed models), except perhaps when dealing with complex survey data.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Another meta-sandwich</title>
      <link>https://www.jepusto.com/robust-meta-analysis-2/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/robust-meta-analysis-2/</guid>
      <description>


&lt;p&gt;In &lt;a href=&#34;https://www.jepusto.com/Robust-meta-analysis-1/&#34;&gt;a previous post&lt;/a&gt;, I provided some code to do robust variance estimation with &lt;code&gt;metafor&lt;/code&gt; and &lt;code&gt;sandwich&lt;/code&gt;.
Here’s another example, replicating some more of the calculations from &lt;a href=&#34;http://doi.org/10.1002/jrsm.1091&#34;&gt;Tanner-Smith &amp;amp; Tipton (2013)&lt;/a&gt;.
(&lt;a href=&#34;https://gist.github.com/jepusto/11147304&#34;&gt;See here&lt;/a&gt; for the complete code.)&lt;/p&gt;
&lt;p&gt;As a starting point, here are the results produced by the &lt;code&gt;robumeta&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(robumeta)

data(corrdat)
rho &amp;lt;- 0.8

HTJ &amp;lt;- robu(effectsize ~ males + college + binge,
            data = corrdat, 
            modelweights = &amp;quot;CORR&amp;quot;, rho = rho,
            studynum = studyid,
            var.eff.size = var, small = FALSE)
HTJ&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Correlated Effects Model  
## 
## Model: effectsize ~ males + college + binge 
## 
## Number of studies = 39 
## Number of outcomes = 172 (min = 1 , mean = 4.41 , median = 4 , max = 18 )
## Rho = 0.8 
## I.sq = 75.08352 
## Tau.sq = 0.1557714 
## 
##                Estimate  StdErr t-value dfs P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1 X.Intercept.  0.31936 0.27784   1.149  35   0.258  -0.2447  0.88340    
## 2        males -0.00331 0.00376  -0.882  35   0.384  -0.0109  0.00431    
## 3      college  0.41226 0.18685   2.206  35   0.034   0.0329  0.79159  **
## 4        binge  0.13774 0.12586   1.094  35   0.281  -0.1178  0.39326    
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To exactly re-produce the results with &lt;code&gt;metafor&lt;/code&gt;, I’ll need to use the weights proposed by HTJ. In their approach to the correlated effects case, effect size &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; receives weight equal to &lt;span class=&#34;math inline&#34;&gt;\(\left[\left(v_{\cdot j} + \hat\tau^2\right)(1 + (k_j - 1) \rho)\right]^{-1}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(v_{\cdot j}\)&lt;/span&gt; is the average sampling variance of the effect sizes from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt; is an estimate of the between-study variance, &lt;span class=&#34;math inline&#34;&gt;\(k_j\)&lt;/span&gt; is the number of correlated effects in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is a user-specified value of the intra-study correlation. However, it appears that &lt;code&gt;robumeta&lt;/code&gt; actually uses a slightly different set weights, which are equivalent to taking &lt;span class=&#34;math inline&#34;&gt;\(\rho = 1\)&lt;/span&gt;. I calculate the latter weights, fit the model in &lt;code&gt;metafor&lt;/code&gt;, and output the robust standard errors and &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-tests:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::source_gist(id = &amp;quot;11144005&amp;quot;, filename = &amp;quot;metafor-sandwich.R&amp;quot;)

corrdat &amp;lt;- within(corrdat, {
  var_mean &amp;lt;- tapply(var, studyid, mean)[studyid]
  k &amp;lt;- table(studyid)[studyid]
  var_HTJ &amp;lt;- as.numeric(k * (var_mean + as.numeric(HTJ$mod_info$tau.sq)))
})

meta1 &amp;lt;- rma.mv(effectsize ~ males + college + binge, 
                V = var_HTJ, 
                data = corrdat, method = &amp;quot;FE&amp;quot;)
meta1$cluster &amp;lt;- corrdat$studyid
RobustResults(meta1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##           Estimate Std. Error t value Pr(&amp;gt;|t|)  
## intrcpt  0.3193586  0.2778360  1.1494  0.25816  
## males   -0.0033143  0.0037573 -0.8821  0.38374  
## college  0.4122631  0.1868489  2.2064  0.03401 *
## binge    0.1377393  0.1258637  1.0944  0.28127  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One could specify a similar (though not exactly identical model) in &lt;code&gt;metafor&lt;/code&gt; as follows. In the HTJ approach, &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; represents the total correlation induced by both the within-study sampling error and intra-study correlation in true effects. In contrast, the &lt;code&gt;metafor&lt;/code&gt; approach would take &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; to be correlation due to within-study sampling error alone. I’ll first need to create a block-diagonal covariance matrix given a user-specified value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Matrix)
equicorr &amp;lt;- function(x, rho) {
  corr &amp;lt;- rho + (1 - rho) * diag(nrow = length(x))
  tcrossprod(x) * corr 
} 
covMat &amp;lt;- as.matrix(bdiag(with(corrdat, tapply(var_mean, studyid, equicorr, rho = 0.8, simplify = FALSE))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Passing this block-diagonal covariance matrix to &lt;code&gt;rma.mv&lt;/code&gt;, I now estimate the model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_{ij} = \mathbf{X}_{ij} \beta + \nu_i + e_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Var(\nu_i) = \sigma^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Var(e_{ij}) = v_{ij}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(Cor(e_{ij}, e_{ik}) = \rho\)&lt;/span&gt;. Note that &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; is now estimated via REML.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta2 &amp;lt;- rma.mv(yi = effectsize ~ males + college + binge, 
                V = covMat, random = ~ 1 | studyid, 
                data = corrdat,
                method = &amp;quot;REML&amp;quot;)
c(sigma.sq = meta2$sigma2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  sigma.sq 
## 0.2477825&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between-study heterogeneity estimate is considerably larger than the moment estimate from &lt;code&gt;robumeta&lt;/code&gt;. Together with the difference in weighting, this leads to some changes in the coefficient estimates and their estimated precision:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults(meta2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##           Estimate Std. Error t value Pr(&amp;gt;|t|)   
## intrcpt -0.8907096  0.4148219 -2.1472 0.038783 * 
## males    0.0163074  0.0055805  2.9222 0.006052 **
## college  0.3180139  0.2273396  1.3988 0.170658   
## binge   -0.0984026  0.0897269 -1.0967 0.280265   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is important to keep in mind that the estimate of between-study heterogeneity depends on the posited model for the covariance structure, including the assumed value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. HTJ recommend conducting sensitivity analysis across a range of values for the within-study effect correlation. Re-calculating the value of &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; between 0.0 and 0.9 yields the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sigma2 &amp;lt;- function(rho) {
  covMat &amp;lt;- as.matrix(bdiag(with(corrdat, tapply(var_mean, studyid, equicorr, rho = rho, simplify = FALSE))))
  rma.mv(yi = effectsize ~ males + college + binge, 
                  V = covMat, random = ~ 1 | studyid, 
                  data = corrdat,
                  method = &amp;quot;REML&amp;quot;)$sigma2
}
rho_sens &amp;lt;- seq(0,0.9,0.1)
sigma2_sens &amp;lt;- sapply(rho_sens, sigma2)
cbind(rho = rho_sens, sigma2 = round(sigma2_sens, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       rho sigma2
##  [1,] 0.0 0.2519
##  [2,] 0.1 0.2513
##  [3,] 0.2 0.2507
##  [4,] 0.3 0.2502
##  [5,] 0.4 0.2497
##  [6,] 0.5 0.2492
##  [7,] 0.6 0.2487
##  [8,] 0.7 0.2482
##  [9,] 0.8 0.2478
## [10,] 0.9 0.2474&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between-study heterogeneity is quite insensitive to the assumed value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The difference between the results based on &lt;code&gt;metafor&lt;/code&gt; versus on &lt;code&gt;robumeta&lt;/code&gt; appears to be due to the subtle difference in the weighting approach: &lt;code&gt;metafor&lt;/code&gt; uses block-diagonal weights that contain off-diagonal terms for effects drawn from a common study, whereas &lt;code&gt;robumeta&lt;/code&gt; uses entirely diagonal weights.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A meta-sandwich</title>
      <link>https://www.jepusto.com/robust-meta-analysis-1/</link>
      <pubDate>Mon, 21 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/robust-meta-analysis-1/</guid>
      <description>


&lt;p&gt;A common problem arising in many areas of meta-analysis is how to synthesize a set of effect sizes when the set includes multiple effect size estimates from the same study. It’s often not possible to obtain all of the information you’d need in order to estimate the sampling covariances between those effect sizes, yet without that information, established approaches to modeling dependent effect sizes become inaccurate. &lt;a href=&#34;http://doi.org/10.1002/jrsm.5&#34;&gt;Hedges, Tipton, &amp;amp; Johnson&lt;/a&gt; (2010, HTJ hereafter) proposed the use of cluster-robust standard errors for multi-variate meta-analysis. (These are also called “sandwich” standard errors, which is up there on the list of great and evocative names for statistical procedures.) The great advantage of the sandwich approach is that it permits valid inferences for average effect sizes and meta-regression coefficients even if you don’t have correct covariance estimates (or variance estimates, for that matter).&lt;/p&gt;
&lt;p&gt;I recently heard from &lt;a href=&#34;http://blogs.cuit.columbia.edu/let2119/&#34;&gt;Beth Tipton&lt;/a&gt; (who’s a graduate-school buddy) that she and her student have written an &lt;a href=&#34;http://cran.r-project.org/web/packages/robumeta/index.html&#34;&gt;R package&lt;/a&gt; implementing the HTJ methods, including moment estimators for the between-study variance components. I want to try out the cluster-robust standard errors for a project I’m working on, but I also need to use REML estimators rather than the moment estimators. It turns out, it’s easy enough to do that by writing a couple of short functions. Here’s how.&lt;/p&gt;
&lt;p&gt;First, the &lt;a href=&#34;http://cran.r-project.org/web/packages/metafor/index.html&#34;&gt;metafor package&lt;/a&gt; contains a very rich suite of meta-analytic methods, including for multi-variate meta-analysis. The only thing it lacks is sandwich standard errors. However, the &lt;a href=&#34;http://cran.r-project.org/web/packages/sandwich/index.html&#34;&gt;sandwich package&lt;/a&gt; provides an efficient, well-structured framework for calculating all sorts of robust standard errors. All that’s needed are a few functions to make the packages talk to each other. Each of the functions described below takes as input a fitted multi-variate meta-analysis model, which is represented in R by an object of class &lt;code&gt;rma.mv&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First load up the packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
library(sandwich)
library(lmtest)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I need a &lt;code&gt;bread&lt;/code&gt; method for objects of class &lt;code&gt;rma.mv&lt;/code&gt;, which is a function that returns the &lt;span class=&#34;math inline&#34;&gt;\(p \times p\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{m \left(\sum_{i=1}^m \mathbf{X}_j&amp;#39; \mathbf{W}_j \mathbf{X}_j\right)^{-1}}\)&lt;/span&gt;. The bread function is straight-forward because it is just a multiple of the model-based covariance matrix, which &lt;code&gt;rma.mv&lt;/code&gt; objects store in the &lt;code&gt;vb&lt;/code&gt; component:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bread.rma.mv &amp;lt;- function(obj) {
  cluster &amp;lt;- findCluster(obj)
  length(unique(cluster)) * obj$vb  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also need an &lt;code&gt;estfun&lt;/code&gt; method for objects of class &lt;code&gt;rma.mv&lt;/code&gt;, which is a function that returns an &lt;span class=&#34;math inline&#34;&gt;\(m \times p\)&lt;/span&gt; matrix where row &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is equal to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{e}_j&amp;#39; \mathbf{W}_j \mathbf{X}_j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,m\)&lt;/span&gt;. The necessary pieces for the &lt;code&gt;estfun&lt;/code&gt; method can also be pulled out of the components of &lt;code&gt;rma.mv&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;estfun.rma.mv &amp;lt;- function(obj) {
  cluster &amp;lt;- droplevels(as.factor(findCluster(obj)))
  res &amp;lt;- residuals(obj)
  WX &amp;lt;- chol2inv(chol(obj$M)) %*% obj$X
  rval &amp;lt;- by(cbind(res, WX), cluster, 
             function(x) colSums(x[,1] * x[,-1, drop = FALSE]))
  rval &amp;lt;- matrix(unlist(rval), length(unique(cluster)), obj$p, byrow=TRUE)
  colnames(rval) &amp;lt;- colnames(obj$X)
  rval
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The remaining question is how to determine which of the components in the model should be used to define independent clusters. This is a little bit tricky because there are several different methods of specifying random effects in the &lt;code&gt;rma.mv&lt;/code&gt; function. One way involves providing a list of formulas, each containing a factor associated with a unique random effect, such as &lt;code&gt;random = list( ~ 1 | classroom, ~ 1 | school)&lt;/code&gt;. If this method of specifying random effects is used, the &lt;code&gt;rma.mv&lt;/code&gt; object will have the component &lt;code&gt;withS&lt;/code&gt; set to &lt;code&gt;TRUE&lt;/code&gt;, and my approach is to simply take the factor with the smallest number of unique levels. This is perhaps a little bit presumptious, because the &lt;code&gt;withS&lt;/code&gt; method could potentially be used to specify arbitrary random effects, where one level is not strictly nested inside another. However, probably the most common use will involve nested factors, so my assumption seems like a good starting point at least.&lt;/p&gt;
&lt;p&gt;Another approach to specifying random effects is to use a formula of the form &lt;code&gt;random = inner | outer&lt;/code&gt;, in which case the &lt;code&gt;rma.mv&lt;/code&gt; object will have the component &lt;code&gt;withG&lt;/code&gt; set to &lt;code&gt;TRUE&lt;/code&gt;. Here, it seems reasonable to use the &lt;code&gt;outer&lt;/code&gt; factor for defining clusters. If both the &lt;code&gt;withS&lt;/code&gt; and &lt;code&gt;withG&lt;/code&gt; methods are used together, I’ll assume that the &lt;code&gt;withS&lt;/code&gt; factors contain the outermost level.&lt;/p&gt;
&lt;p&gt;Finally, if &lt;code&gt;rma.mv&lt;/code&gt; is used to estimate a fixed effects model without any random components, the clustering factor will have to be manually added to the &lt;code&gt;rma.mv&lt;/code&gt; object in a component called &lt;code&gt;cluster&lt;/code&gt;. For example, if you want to cluster on the variable &lt;code&gt;studyID&lt;/code&gt; in the dataframe &lt;code&gt;dat&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma_fit$cluster &amp;lt;- dat$studyID&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s code that implements these assumptions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;findCluster &amp;lt;- function(obj) {
  if (is.null(obj$cluster)) {
    if (obj$withS) {
      r &amp;lt;- which.min(obj$s.nlevels)
      cluster &amp;lt;- obj$mf.r[[r]][[obj$s.names[r]]]
    } else if (obj$withG) {
      cluster &amp;lt;- obj$mf.r[[1]][[obj$g.names[2]]]
    } else {
        stop(&amp;quot;No clustering variable specified.&amp;quot;)
    }
  } else {
    cluster &amp;lt;- obj$cluster
  }
  cluster
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these three functions, you can then use &lt;code&gt;metafor&lt;/code&gt; to fit a random effects model, &lt;code&gt;sandwich&lt;/code&gt; to calculate the standard errors, and functions like &lt;code&gt;coeftest&lt;/code&gt; from the package &lt;code&gt;lmtest&lt;/code&gt; to run &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-tests. As a little bonus, here’s a function for probably the most common case of how you’d use the sandwich standard errors:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults &amp;lt;- function(obj, adjust = TRUE) {
  cluster &amp;lt;- findCluster(obj)  
  vcov. &amp;lt;- sandwich(obj, adjust = adjust)
  df. &amp;lt;- length(unique(cluster)) - obj$p
  coeftest(obj, vcov. = vcov., df = df.)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://gist.github.com/jepusto/11144005&#34;&gt;See here&lt;/a&gt; for a file containing the full code.&lt;/p&gt;
&lt;div id=&#34;example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.1002/jrsm.1091&#34;&gt;Tanner-Smith &amp;amp; Tipton (2013)&lt;/a&gt; provide an application of the cluster-robust method to a fictional dataset with 68 effect sizes nested within 15 studies. They call this a “hierarchical” dependence example because each effect size estimate is drawn from an independent sample, but dependence is induced because the experiments were all done in the same lab. For comparison purposes, here are the results produced by &lt;code&gt;robumeta&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(robumeta)
data(hierdat)

HTJ &amp;lt;- robu(effectsize ~ 1,
       data = hierdat, modelweights = &amp;quot;HIER&amp;quot;,
       studynum = studyid,
       var.eff.size = var, small = FALSE)
HTJ&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Hierarchical Effects Model  
## 
## Model: effectsize ~ 1 
## 
## Number of clusters = 15 
## Number of outcomes = 68 (min = 1 , mean = 4.53 , median = 2 , max = 29 )
## Omega.sq = 0.1560802 
## Tau.sq = 0.06835547 
## 
##                Estimate StdErr t-value dfs  P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1 X.Intercept.     0.25 0.0598    4.18  14 0.000925    0.122    0.378 ***
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To exactly re-produce the results with &lt;code&gt;metafor&lt;/code&gt;, I’ll need to use the weights proposed by HTJ. In their approach, effect size &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; receives weight equal to &lt;span class=&#34;math inline&#34;&gt;\(\left(v_{ij} + \hat\omega^2 + \hat\tau^2\right)^{-1}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(v_{ij}\)&lt;/span&gt; is the sampling variance of the effect size, &lt;span class=&#34;math inline&#34;&gt;\(\hat\omega^2\)&lt;/span&gt; is an estimate of the between-sample within-study variance, and &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt; is an estimate of the between-study variance. After calculating these weights, I fit the model in metafor, calculate the sandwich covariance matrix, and replay the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hierdat$var_HTJ &amp;lt;- hierdat$var + HTJ$mod_info$omega.sq + HTJ$mod_info$tau.sq # calculate weights&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in hierdat$var + HTJ$mod_info$omega.sq: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in hierdat$var + HTJ$mod_info$omega.sq + HTJ$mod_info$tau.sq: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta1 &amp;lt;- rma.mv(yi = effectsize ~ 1, V = var_HTJ, data = hierdat, method = &amp;quot;FE&amp;quot;)
meta1$cluster &amp;lt;- hierdat$studyid # add clustering variable to the fitted model
RobustResults(meta1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##         Estimate Std. Error t value  Pr(&amp;gt;|t|)    
## intrcpt 0.249826   0.059762  4.1803 0.0009253 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The HTJ weights are not the only alternative–one could instead use weights that are exactly inverse variance under the posited model. For effect &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, these weights would be closer to &lt;span class=&#34;math inline&#34;&gt;\(\left(v_{ij} + \hat\omega^2 + k_j \hat\tau^2 \right)^{-1}\)&lt;/span&gt;. For &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2 &amp;gt; 0\)&lt;/span&gt;, the inverse-variance weights put proportionately less weight on studies containing many effects. These weights can be calculated in &lt;code&gt;metafor&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta2 &amp;lt;- rma.mv(yi = effectsize ~ 1, V = var, 
                 random = list(~ 1 | esid, ~ 1 | studyid), 
                 sigma2 = c(HTJ$mod_info$omega.sq, HTJ$mod_info$tau.sq),
                 data = hierdat)
RobustResults(meta2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##         Estimate Std. Error t value Pr(&amp;gt;|t|)   
## intrcpt 0.264422   0.086688  3.0503 0.008645 **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Curiously, the robust standard error increases under a weighting scheme that is more efficient if the model is correct.&lt;/p&gt;
&lt;p&gt;Finally, &lt;code&gt;metafor&lt;/code&gt; provides ML and REML estimators for the between-sample and between-study random effects (the HTJ moment estimators are not available though). Here are the results based on REML estimators and the corresponding inverse-variance weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta3 &amp;lt;- rma.mv(yi = effectsize ~ 1, V = var, 
                 random = list(~ 1 | esid, ~ 1 | studyid), 
                 data = hierdat,
                method = &amp;quot;REML&amp;quot;)
meta3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 68; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2.1  0.2263  0.4757     68     no     esid 
## sigma^2.2  0.0000  0.0000     15     no  studyid 
## 
## Test for Heterogeneity:
## Q(df = 67) = 370.1948, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.2501  0.0661  3.7822  0.0002  0.1205  0.3797  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults(meta3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##         Estimate Std. Error t value  Pr(&amp;gt;|t|)    
## intrcpt 0.250071   0.059796  4.1821 0.0009222 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between-study variance estimate is tiny, particularly when compared to the between-sample within-study estimate. Despite the difference in variance estimates, the average effect size estimate is nearly identical to the estimate based on the HTJ approach.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gist.github.com/jepusto/11143798&#34;&gt;See here&lt;/a&gt; for the full code to reproduce this example.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;notes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;p&gt;It would be straight-forward to add a few more functions that provide robust standard errors for univariate meta-analysis models as well. All that it would take is to write &lt;code&gt;bread&lt;/code&gt; and &lt;code&gt;estfun&lt;/code&gt; methods for the class &lt;code&gt;rma.uni&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Also, Beth &lt;a href=&#34;https://www.sree.org/conferences/2014s/program/downloads/abstracts/1089.pdf&#34;&gt;has recently proposed&lt;/a&gt;
small-sample corrections to the cluster-robust estimators, based on the bias-reduced linearization (BRL) approach of &lt;a href=&#34;http://www.amstat.org/sections/SRMS/Proceedings/y2001/Proceed/00264.pdf&#34;&gt;McCaffrey, Bell, &amp;amp; Botts (2001)&lt;/a&gt;. It seems to me that these small-sample corrections could also be implemented using an approach similar to what I’ve done here, by building out the &lt;code&gt;estfun&lt;/code&gt; method to provide BRL results. It would take a little more thought, but actually it would be worth doing–and treating the general case–because BRL seems like it would be useful for all sorts of models besides multi-variate meta-analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Special Education Pro-Sem</title>
      <link>https://www.jepusto.com/sped-pro-sem/</link>
      <pubDate>Thu, 10 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/sped-pro-sem/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://www.edb.utexas.edu/education/departments/sped/about/fac_dir/barnes/&#34;&gt;Dr. Marcia Barnes&lt;/a&gt; from the department of Special Education invited me to visit her pro-seminar this afternoon and talk about some of my work on meta-analytic methods for single-case research. Thanks very much to the students for asking such thoughtful and engaging questions. &lt;a href=&#34;https://www.jepusto.com/files/Barnes-Pro-Sem-2014-04-10.pdf&#34;&gt;Here are the slides&lt;/a&gt;, which include some additional material that we didn’t get to talk about.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Converting from d to r to z when the design uses extreme groups, dichotomization, or experimental control</title>
      <link>https://www.jepusto.com/publication/converting-from-d-to-r-to-z/</link>
      <pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/publication/converting-from-d-to-r-to-z/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Another project idea: Meta-analytic methods for correlational data</title>
      <link>https://www.jepusto.com/another-project-idea/</link>
      <pubDate>Fri, 13 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://www.jepusto.com/another-project-idea/</guid>
      <description>


&lt;p&gt;Several different approaches have been proposed for meta-analysis of correlation coefficients. One of the major differences between approaches is the choice of scale: whether effect sizes should be analyzed on the Pearson-r scale or first transformed to the Fisher-z scale. This project will study methods for modeling correlation coefficients on the r scale in the presence of between-study effect heterogeneity. Specific topics include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;refined methods for variance estimation;&lt;/li&gt;
&lt;li&gt;hierarchical modeling to capture differences between distinct operationalizations of the same construct; and&lt;/li&gt;
&lt;li&gt;application to a large correlational meta-analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This project would be appropriate for a Quantitative Methods graduate student with interests in meta-analysis and hierarchical models.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
