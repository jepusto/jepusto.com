<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Non-Overlap Measures | James E. Pustejovsky</title>
    <link>http://localhost:4321/tags/non-overlap-measures/</link>
      <atom:link href="http://localhost:4321/tags/non-overlap-measures/index.xml" rel="self" type="application/rss+xml" />
    <description>Non-Overlap Measures</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2024</copyright><lastBuildDate>Fri, 29 Apr 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:4321/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Non-Overlap Measures</title>
      <link>http://localhost:4321/tags/non-overlap-measures/</link>
    </image>
    
    <item>
      <title>Multi-level meta-analysis of single-case experimental designs using robust variance estimation</title>
      <link>http://localhost:4321/publication/sced-mlma-rve/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/sced-mlma-rve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Procedural sensitivities of effect sizes for single-case designs with behavioral outcome measures</title>
      <link>http://localhost:4321/publication/procedural-sensitivities-of-scd-effect-sizes/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/procedural-sensitivities-of-scd-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Single-case synthesis tools II: Comparing overlap measures and parametric effect sizes for synthesizing antecedent sensory-based interventions</title>
      <link>http://localhost:4321/publication/scd-synthesis-tools-ii/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/scd-synthesis-tools-ii/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New paper: procedural sensitivities of effect size measures for SCDs</title>
      <link>http://localhost:4321/procedural-sensitivities-paper/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/procedural-sensitivities-paper/</guid>
      <description>


&lt;p&gt;I’m very happy to share that my article “Procedural sensitivities of effect sizes for single-case designs with directly observed behavioral outcome measures” has been accepted at &lt;em&gt;Psychological Methods&lt;/em&gt;. There’s no need to delay in reading it, since you can check out the &lt;a href=&#34;https://psyarxiv.com/vxa86&#34;&gt;pre-print&lt;/a&gt; and &lt;a href=&#34;https://osf.io/hkzsm/&#34;&gt;supporting materials&lt;/a&gt;. Here’s the abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A wide variety of effect size indices have been proposed for quantifying the magnitude of treatment effects in single-case designs. Commonly used measures include parametric indices such as the standardized mean difference, as well as non-overlap measures such as the percentage of non-overlapping data, improvement rate difference, and non-overlap of all pairs. Currently, little is known about the properties of these indices when applied to behavioral data collected by systematic direct observation, even though systematic direct observation is the most common method for outcome measurement in single-case research. This study uses Monte Carlo simulation to investigate the properties of several widely used single-case effect size measures when applied to systematic direct observation data. Results indicate that the magnitude of the non-overlap measures and of the standardized mean difference can be strongly influenced by procedural details of the study’s design, which is a significant limitation to using these indices as effect sizes for meta-analysis of single-case designs. A less widely used parametric index, the log-response ratio, has the advantage of being insensitive to sample size and observation session length, although its magnitude is influenced by the use of partial interval recording.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This paper was a long time coming. The core idea came out of a grant proposal I wrote during the summer of 2014, which I fleshed out for a &lt;a href=&#34;http://localhost:4321/files/AERA-2015-poster-Non-overlap-measures.pdf&#34;&gt;poster presented at AERA&lt;/a&gt; in April of 2015. After finishing a draft of the paper, I tried to publish it in a special education journal, reasoning that the main audience for the paper is researchers interested in meta-analyzing single case research studies that are commonly used in some parts of special education. That turned out to be a non-starter. Four rejection letters later, I re-worked the paper a bit to give more technical details, then submitted it to a more methods-ish journal. This yielded an R&amp;amp;R, I revised the paper extensively, resubmitted it, and it was declined. Buying in fully to the sunk costs fallacy, I sent the paper to Psychological Methods. This time, I received very extensive and helpful feedback from several anonymous reviewers and an associate editor (thank you, anonymous peers!), which helped me to revise the paper yet again, and this time it was accepted. Sixth time is the charm, as they say.&lt;/p&gt;
&lt;p&gt;Here’s the complete time-line of submissions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;August 5, 2015: submitted to journal #1 (special education)&lt;/li&gt;
&lt;li&gt;August 28, 2015: desk reject decision from journal #1&lt;/li&gt;
&lt;li&gt;September 3, 2015: submitted to journal #2 (special education)&lt;/li&gt;
&lt;li&gt;November 6, 2015: reject decision (after peer review) from journal #2&lt;/li&gt;
&lt;li&gt;November 18, 2015: submitted to journal #3 (special education)&lt;/li&gt;
&lt;li&gt;November 22, 2015: desk reject decision from journal #3 as not appropriate for their audience. I was grateful to get a quick decision.&lt;/li&gt;
&lt;li&gt;November 23, 2015: submitted to journal #4 (special education)&lt;/li&gt;
&lt;li&gt;February 17, 2016: reject decision (after peer review) from journal #4&lt;/li&gt;
&lt;li&gt;April 19, 2016: submitted to journal #5 (methods)&lt;/li&gt;
&lt;li&gt;August 16, 2016: revise-and-resubmit decision from journal #5&lt;/li&gt;
&lt;li&gt;October 14, 2016: re-submitted to journal #5&lt;/li&gt;
&lt;li&gt;February 2, 2017: reject decision from journal #5&lt;/li&gt;
&lt;li&gt;May 10, 2017: submitted to &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;September 1, 2017: revise-and-resubmit decision from &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;September 26, 2017: re-submitted to &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;November 22, 2017: conditional acceptance&lt;/li&gt;
&lt;li&gt;December 6, 2017: re-submitted with minor revisions&lt;/li&gt;
&lt;li&gt;January 10, 2018: accepted at &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Tau-U?</title>
      <link>http://localhost:4321/what-is-tau-u/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/what-is-tau-u/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://dx.doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber (2011)&lt;/a&gt; proposed the Tau-U index—actually several indices, rather—as effect size measures for single-case designs. The original paper describes several different indices that involve corrections for trend during the baseline phase, treatment phase, both phases, or neither phase. Without correcting for trends in either phase, the index is equal to the Mann-Whitney &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; statistic calculated by comparing every pair of observations containing one point from each phase, scaled by the total number of such pairs. This version, which I’ll call just “Tau”, is simply a &lt;a href=&#34;http://localhost:4321/NAP-SEs-and-CIs&#34;&gt;linear re-scaling of the NAP statistic&lt;/a&gt; to the range [-1,1].&lt;/p&gt;
&lt;p&gt;To correct for baseline trend, the original paper proposes to calculate Kendall’s rank correlation (&lt;span class=&#34;math inline&#34;&gt;\(\tau_A\)&lt;/span&gt;) between the phase A outcome data and the session numbers and use the result to make an adjustment to Tau. The other analyses presented in the original paper (incorporating adjustments for time trends during the treatment phase) are not presented in subsequent review papers, nor are they implemented in &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;the web-calculator&lt;/a&gt; created by the authors, and so I won’t discuss them further here. Instead, in this post I will examine the calculation of the version of Tau-U that incorporates a baseline trend correction. This version seems to be the most widely applied in practice (likely due to the availability of the web-calculator) and is presented in several review papers by the same authors. It turns out though, that the definition of the index has shifted from the original paper to subsequent presentations.&lt;/p&gt;
&lt;p&gt;To make this concrete, let me first define a couple of things. Suppose that we have data from the baseline and treatment phases for a single case, where the baseline phase has &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; observations and treatment phase has &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations. Let &lt;span class=&#34;math inline&#34;&gt;\(y^A_1,...,y^A_m\)&lt;/span&gt; denote the baseline phase data and &lt;span class=&#34;math inline&#34;&gt;\(y^B_1,...,y^B_n\)&lt;/span&gt; denote the treatment phase data. Let &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; denote Kendall’s S statistic calculated for the comparison between phases and &lt;span class=&#34;math inline&#34;&gt;\(S_A\)&lt;/span&gt; denote Kendall’s S statistic calculated on the baseline trend. More precisely,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
S_P &amp;amp;= \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) - I\left(y^B_j &amp;lt; y^A_i\right)\right] \\
S_A &amp;amp;= \sum_{i=1}^{m - 1} \sum_{j = i + 1}^m \left[I\left(y^A_j &amp;gt; y^A_i\right) - I\left(y^A_j &amp;lt; y^A_i\right)\right].
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; is calculated from &lt;span class=&#34;math inline&#34;&gt;\(m \times n\)&lt;/span&gt; pairs of observations, and Tau (without trend correction) is equal to &lt;span class=&#34;math inline&#34;&gt;\(\text{Tau} = S_P / (m n)\)&lt;/span&gt;. Furthermore, &lt;span class=&#34;math inline&#34;&gt;\(S_A\)&lt;/span&gt; is calculated from &lt;span class=&#34;math inline&#34;&gt;\(m (m - 1) / 2\)&lt;/span&gt; pairs of observations and Kendall’s rank correlation coefficient for the baseline phase observations is &lt;span class=&#34;math inline&#34;&gt;\(t_A = S_A / [m (m - 1) / 2]\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;the-original-version&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The original version&lt;/h2&gt;
&lt;p&gt;In the original paper, the authors explain that values of Tau-U can be calculated by adding or substracting values of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;, weighted by the corresponding number of pairs. Thus, Tau-U would be calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau-U} = \frac{S_P - S_A}{mn + m(m - 1) / 2} = \frac{2n}{2n + m - 1} \text{Tau} - \frac{m - 1}{2n + m - 1} t_A.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Both &lt;span class=&#34;math inline&#34;&gt;\(\text{Tau}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t_A\)&lt;/span&gt; have range [-1,1], and so Tau-U has the same range. This version of Tau-U can be calculated using &lt;a href=&#34;https://manolov.shinyapps.io/Overlap/&#34;&gt;this web app by Rumen Manolov&lt;/a&gt;, which is based on &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2842869/Tau_U.R&#34;&gt;this R code by Kevin Tarlow&lt;/a&gt;. (The app and the R script also provide the other variants of Tau-U described in &lt;a href=&#34;http://dx.doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber (2011)&lt;/a&gt;.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-revised-version&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The revised (?) version&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://dx.doi.org/10.1177/0145445511399147&#34;&gt;Parker, Vannest, and Davis (2011)&lt;/a&gt; reviewed nine different non-overlap indices for use with data from single-case designs, including Tau-U. Rather than describing all four variations from the original paper, the authors define the index as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tau-U (Parker et al., in press) extends [Tau] to control for undesirable positive baseline trend (monotonic trend). Monotonic trend is the upward progression of data points in any configuration, whether linear, curvilinear, or even in a mixed pattern of “fits and starts” (p. 11).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this and subsequent review articles, Tau-U seems to refer exclusively to the variant involving comparison between phases A and B, with an adjustment for phase A trend. That seems a sensible enough choice, which could have been due to space limitations, guidance from the journal editor, or further refinement of the methods (i.e., recognizing which of the variants would be most useful in application). However, the presentation of Tau-U in this article involved more than a change in emphasis—the definition of the index also changed. Following the notation above, Tau-U was now defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau-U} = \frac{S_P - S_A}{mn} = \text{Tau} - \frac{m - 1}{2n} t_A.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The logical range of this version of the index is from &lt;span class=&#34;math inline&#34;&gt;\(-(2n + m - 1) / (2n)\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\((2n + m - 1) / (2n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This is the version of Tau-U implemented in the &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;singlecaseresearch.org&lt;/a&gt; web calculator. It is also the version described in a later chapter by the same authors (&lt;a href=&#34;http://dx.doi.org/10.1037/14376-005&#34;&gt;Parker, Vannest, &amp;amp; Davis, 2014&lt;/a&gt;) and a review article by &lt;a href=&#34;http://dx.doi.org/10.1111/1467-8578.12091&#34;&gt;Rakap (2015)&lt;/a&gt;. &lt;a href=&#34;http://localhost:4321/Tau-U&#34;&gt;My previous post about Tau-U&lt;/a&gt; also presented this version of the index and noted that its magnitude is sensitive to the lengths of the baseline and treatment phases, which makes it rather difficult to interpret the Tau-U index as a measure of treatment effect magnitude.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparison&lt;/h2&gt;
&lt;p&gt;Here is an R function for calculating the original or revised versions of Tau-U:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Tau_U &amp;lt;- function(A_data, B_data, version = &amp;quot;revised&amp;quot;) {
    m &amp;lt;- length(A_data)
    n &amp;lt;- length(B_data)
    Q_A &amp;lt;- sapply(A_data, function(j) (j &amp;gt; A_data) - (j &amp;lt; A_data))
    Q_P &amp;lt;- sapply(B_data, function(j) (j &amp;gt; A_data) - (j &amp;lt; A_data))
    
    if (version==&amp;quot;original&amp;quot;) {
      (sum(Q_P) - sum(Q_A[upper.tri(Q_A)])) / (m * n + m * (m - 1) / 2)
    } else {
      (sum(Q_P) - sum(Q_A[upper.tri(Q_A)])) / (m * n)
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The papers I’ve mentioned above all provide examples of the calculation of Tau-U. The following table reports the data from each of these examples (&lt;a href=&#34;http://dx.doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber, 2011a&lt;/a&gt;; &lt;a href=&#34;http://dx.doi.org/10.1177/0145445511399147&#34;&gt;Parker, Vannest, and Davis, 2011b&lt;/a&gt;; &lt;a href=&#34;http://dx.doi.org/10.1037/14376-005&#34;&gt;Parker, Vannest, &amp;amp; Davis, 2014&lt;/a&gt;), along with the value of Tau-U based on the original and revised formulas. The differences in magnitude are non-trivial.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Source&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Phase A data&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Phase B data&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;original&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;revised&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2011a, Figure 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2, 3, 5, 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4, 5, 5, 7, 6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6500000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2011b, Figure 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20, 20, 26, 25, 22, 23&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28, 25, 24, 27, 30, 30, 29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5438596&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7380952&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2011b, Table 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3, 3, 4, 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4, 5, 6, 7, 7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4230769&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5500000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2014, Figure 4.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22, 21, 23, 23, 23, 22&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;24, 22, 23, 23, 24, 26, 25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4385965&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5952381&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;implications&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Implications&lt;/h2&gt;
&lt;p&gt;Rather than one effect size index called “Tau-U”, there are instead two different definitions, which can lead to quite different values of the index. Given this, researchers who apply Tau-U should endeavor to &lt;strong&gt;be clear and unambiguous about which version of the index they use&lt;/strong&gt;. This can be done by stating exactly which software routine, web-app, or formula was used in making the calculations. If the calculations are done using a computer script, then the script should be made available (e.g., through the &lt;a href=&#34;https://osf.io/&#34;&gt;Open Science Framework&lt;/a&gt;) so that other researchers can replicate the calculations.&lt;/p&gt;
&lt;p&gt;Furthermore, researchers need to &lt;strong&gt;be careful about applying interpretive guidelines for Tau-U&lt;/strong&gt;, since those guidelines will not apply uniformly across the different versions of the index.&lt;/p&gt;
&lt;p&gt;Finally, I would recommend that any researchers who conduct a meta-analysis of single-case research &lt;strong&gt;make available the raw data used for effect size calculations&lt;/strong&gt;, so that other researchers can scrutinize, replicate, and extend their analyses. The whole enterprise of research synthesis rests on the availability of data from primary studies (at least in summary form). It seems to me that meta-analysts thus have a duty to make the data that they assemble and organize readily accessible for others to use. Particularly in the context of meta-analysis of single-case research—where new methods are developing rapidly and there is not currently consensus around best practices—it seems especially appropriate and prudent to make one’s data available for future re-analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New working paper: Procedural sensitivities of SCD effect sizes</title>
      <link>http://localhost:4321/scd-effect-size-sensitivities/</link>
      <pubDate>Mon, 17 Oct 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/scd-effect-size-sensitivities/</guid>
      <description>


&lt;p&gt;I’ve just posted a new version of my working paper, &lt;em&gt;Procedural sensitivities of effect sizes for single-case designs with behavioral outcome measures&lt;/em&gt;. The abstract is below. This version is a major update of an &lt;a href=&#34;http://localhost:4321/files/Pustejovsky-2015-Nov-Non-overlap-measures.pdf&#34;&gt;earlier paper&lt;/a&gt; that focused only on the non-overlap measures. The new version also includes analysis of two other effect sizes (the within-case standardized mean difference and the log response ratio) as well as additional results and more succinct summaries of the main findings.&lt;/p&gt;
&lt;p&gt;The paper itself is available on the Open Science Framework (&lt;a href=&#34;https://osf.io/pxn24/&#34;&gt;here&lt;/a&gt;), as are the &lt;a href=&#34;https://osf.io/hkzsm/&#34;&gt;supplementary materials&lt;/a&gt; and &lt;a href=&#34;https://osf.io/j4gvt/&#34;&gt;Source code&lt;/a&gt;. I also created interaction versions of the graphics from the main paper and the supplementary materials, which can be viewed in &lt;a href=&#34;https://jepusto.shinyapps.io/SCD-effect-size-sensitivities/&#34;&gt;this shiny app&lt;/a&gt;. I would welcome any comments, questions, or feedback that readers may have.&lt;/p&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Abstract&lt;/h3&gt;
&lt;p&gt;A wide variety of effect size indices have been proposed for quantifying the magnitude of treatment effects in single-case designs. Commonly used measures include parametric indices such as the standardized mean difference, as well as non-overlap measures, such as the percentage of non-overlapping data, improvement rate difference, and non-overlap of all pairs. Currently, little is known about the properties of these indices when applied to behavioral data collected by systematic direct observation, even though systematic direct observation is the most common approach to outcome measurement in single-case research. This study uses computer simulation to investigate the properties of several single-case effect size measures when applied to systematic direct observation data. Results indicate that the magnitude of the non-overlap measures and of the standardized mean difference can be strongly influenced by procedural details of the study’s design, which is a significant limitation to using these indices as effect sizes for meta-analysis of single-case designs. A less widely used parametric index, the log-response ratio, has the advantage of being insensitive to sample size and observation session length, although its magnitude is influenced by the use of partial interval recording.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>SingleCaseES</title>
      <link>http://localhost:4321/software/singlecasees/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/singlecasees/</guid>
      <description>&lt;p&gt;An R package for calculating basic effect size indices for single-case designs, including several non-overlap measures and parametric effect size measures, and for estimating the gradual effects model developed by Swan and Pustejovsky (2017).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://CRAN.R-project.org/package=SingleCaseES&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/SingleCaseES&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Source code and installation instructions on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jepusto.shinyapps.io/SCD-effect-sizes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Single case effect size calculator&lt;/a&gt;: An interactive web application for calculating basic effect size indices.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jepusto.shinyapps.io/gem-scd/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gradual Effect Model calculator&lt;/a&gt;: An interactive web application for estimating effect sizes using the gradual effects model.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Tau-U</title>
      <link>http://localhost:4321/tau-u/</link>
      <pubDate>Wed, 23 Mar 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/tau-u/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber (2011)&lt;/a&gt; proposed Tau-U as an effect size measure for use in single-case designs that exhibit baseline trend. In their original paper, they actually conceptualize Tau-U as a family of four distinct indices, distinguished by a) whether the index includes an adjustment for the presence of baseline trend and b) whether the index incorporates information about trend during the intervention phase. However, in subsequent presentations the authors seem to have focused exclusively on the index that adjusts for baseline trend but not for intervention phase trend, and so I’ll do the same here. (This version is also the one available in the web-tool at &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;singlecaseresearch.org&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Tau-U is an elaboration on their previously proposed effect sizes &lt;a href=&#34;http://localhost:4321/NAP-SEs-and-CIs&#34;&gt;NAP and Tau&lt;/a&gt;, which do not account for baseline trends. The index is calculated as follows. Suppose that we have data from A and B phases from a single case, where the baseline phase has &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; observations and treatment phase has &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations. Let &lt;span class=&#34;math inline&#34;&gt;\(y^A_1,...,y^A_m\)&lt;/span&gt; denote the baseline phase data and &lt;span class=&#34;math inline&#34;&gt;\(y^B_1,...,y^B_n\)&lt;/span&gt; denote the treatment phase data. Tau-U is then calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau-U} = \frac{S_P - S_B}{mn}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; is Kendall’s S statistic calculated for the comparison between phases and &lt;span class=&#34;math inline&#34;&gt;\(S_B\)&lt;/span&gt; is Kendall’s S statistic calculated on the baseline trend. More precisely,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
S_P &amp;amp;= \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) - I\left(y^B_j &amp;lt; y^A_i\right)\right] \\
S_B &amp;amp;= \sum_{i=1}^{m - 1} \sum_{j = i + 1}^m \left[I\left(y^A_j &amp;gt; y^A_i\right) - I\left(y^A_j &amp;lt; y^A_i\right)\right].
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that the first term in Tau-U is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(\text{Tau} = S_P / (m n)\)&lt;/span&gt;, which in turn is a re-scaling of NAP. The second term is related to the rank-correlation between the measurement occasions and outcomes in the baseline phase. Subtracting the second from the first thus adjusts for baseline trend, in the sense that more pronounced baseline trends will lead to smaller values of Tau-U. But looking at the measure a bit more deeply, it has some very odd features. In this post, I’ll show that the distribution of Tau-U is sensitive to the number of observations in each phase.&lt;/p&gt;
&lt;div id=&#34;sample-size-sensitivity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sample size sensitivity&lt;/h2&gt;
&lt;p&gt;Consider first the logical range of Tau-U. The minimum and maximum possible values of &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; are &lt;span class=&#34;math inline&#34;&gt;\(-m n\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(m n\)&lt;/span&gt;; the minimum and maximum of &lt;span class=&#34;math inline&#34;&gt;\(S_B\)&lt;/span&gt; are &lt;span class=&#34;math inline&#34;&gt;\(-m (m-1) / 2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(m (m - 1) / 2\)&lt;/span&gt;. Consequently, the logical range of Tau-U is from &lt;span class=&#34;math inline&#34;&gt;\(-(2n + m - 1) / (2n)\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\((2n + m - 1) / (2n)\)&lt;/span&gt;. If the treatment phase is quite long compared to the baseline phase, then this range will be close to [-1, 1]. On the other hand, in a study with a baseline that is twice as long as the treatment phase, the range of Tau-U will be closer to [-2, 2]. That’s a very odd property.&lt;/p&gt;
&lt;p&gt;The average magnitude of Tau-U is similarly influenced by the lengths of each phase. To see this, it’s helpful to think first about its target parameter–the quantity that is estimated when calculating Tau-U based on a sample of data. Since Tau-U is not defined in parametric terms, I will assume that the Tau-U statistic is an unbiased estimator of its target parameter &lt;span class=&#34;math inline&#34;&gt;\(\tau_U = \text{E}\left(\text{Tau-U}\right)\)&lt;/span&gt;. It follows that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tau_U = \tau_P - \frac{m - 1}{2n} \tau_B,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau_P\)&lt;/span&gt; is Kendall’s rank correlation between the outcomes and an indicator for the treatment phase and &lt;span class=&#34;math inline&#34;&gt;\(\tau_B\)&lt;/span&gt; is Kendall’s rank correlation between the measurement occasions and outcomes during baseline:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tau_P &amp;amp;= \frac{1}{mn}\sum_{i=1}^m \sum_{j=1}^n \left[\text{Pr}\left(Y^B_j &amp;gt; Y^A_i\right) - \text{Pr}\left(Y^B_j &amp;lt; Y^A_i\right)\right] \\
\tau_B &amp;amp;= \frac{2}{m(m-1)} \sum_{i=1}^{m - 1} \sum_{j = i + 1}^m \left[\text{Pr}\left(Y^A_j &amp;gt; Y^A_i\right) - \text{Pr}\left(Y^A_j &amp;lt; Y^A_i\right)\right].
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now consider a positive a baseline trend, so that &lt;span class=&#34;math inline&#34;&gt;\(\tau_B &amp;gt; 0\)&lt;/span&gt;, and assume that &lt;span class=&#34;math inline&#34;&gt;\(\tau_P\)&lt;/span&gt; is constant. A longer baseline phase will then lead to smaller values of Tau-U (on average), while a longer treatment phase will lead to larger values of Tau-U (on average). Again, that’s really weird. This is not a good feature for an effect size measure because it means that Tau-U values from different cases are only on the same scale if the cases have identical baseline and treatment phase lengths. In a multiple baseline study, each case is necessarily observed for a different number of occasions in baseline (otherwise it wouldn’t be a multiple baseline). Thus, it seems inadvisable to use Tau-U to quantify the magnitude of treatment effects in a multiple baseline study.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sensitivity-under-a-parametric-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sensitivity under a parametric model&lt;/h2&gt;
&lt;p&gt;Things may be different if we allow for the magnitude of &lt;span class=&#34;math inline&#34;&gt;\(\tau_P\)&lt;/span&gt; to change along with the sample size. Such would be the case under a model where the intervention phase also exhibits a trend. For example, let’s suppose that the outcome follows a linear model with a non-zero trend and the intervention leads to an immediate shift in the outcome, as in the model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_t = \beta_0 + \beta_1 t + \beta_2 I(t &amp;gt; m) + \epsilon_t.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For simplicity, I’ll assume that the errors in this model are normally distributed with unit variance. Under this model,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tau_B &amp;amp;= \frac{4}{m (m - 1)} \left[\sum_{i=1}^{m-1} \sum_{j=i+1}^m \Phi\left[\beta_1\left(j - i\right) / \sqrt{2}\right]\right] - 1, \\
\tau_P &amp;amp;= \frac{2}{m n} \left[\sum_{i=1}^m \sum_{j=1}^n \Phi\left[\left(\beta_1 (m + j - i) + \beta_2\right) / \sqrt{2}\right]\right] - 1,
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\Phi()\)&lt;/span&gt; is the standard normal cumulative distribution function. I can use the above formulas to calculate the average value of Tau-U for various degrees of baseline trend &lt;span class=&#34;math inline&#34;&gt;\((\beta_1)\)&lt;/span&gt;, level shift &lt;span class=&#34;math inline&#34;&gt;\((\beta_2)\)&lt;/span&gt;, and phase lengths &lt;span class=&#34;math inline&#34;&gt;\((m,n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;E_TauU &amp;lt;- function(b1, b2, m, n) {
  tau_B &amp;lt;- sum(sapply(1:(m - 1), function(i) 
    sum(pnorm(b1 * ((i+1):m - i) / sqrt(2))))) * 4 / (m * (m - 1)) - 1
  tau_P &amp;lt;- sum(sapply(1:m, function(i) 
    sum(pnorm((b1 * (m + 1:n - i) + b2) / sqrt(2))))) * 2 / (m * n) - 1
  tau_P - tau_B * (m - 1) / (2 * n)
}

library(dplyr)
library(tidyr)
b1 &amp;lt;- c(-0.2, -0.1, 0, 0.1, 0.2)
b2 &amp;lt;- c(0, 0.5, 1.0, 2.0)
m &amp;lt;- c(5, 10, 15, 20)
n &amp;lt;- 5:20

expand.grid(b1 = b1, b2 = b2, m = m, n = n) %&amp;gt;%
  group_by(b1, b2, m, n) %&amp;gt;% 
  mutate(TauU = E_TauU(b1, b2, m, n)) -&amp;gt;
  TauU_values
ex &amp;lt;- filter(TauU_values, b1 == -0.2 &amp;amp; b2 == 0)


library(ggplot2)
ggplot(TauU_values, aes(n, TauU, color = factor(m))) + 
  facet_grid(b1 ~ b2, labeller = &amp;quot;label_both&amp;quot;) + 
  geom_line() + 
  labs(y = &amp;quot;Expected magnitude of Tau-U&amp;quot;, color = &amp;quot;m&amp;quot;) + 
  theme_bw() + theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Tau-U_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the figure above, each plot corresponds to a different value of the baseline slope (&lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, ranging from -0.2 in the top row to 0.2 in the bottom row) and treatment shift (&lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt;, ranging from 0 in the first column to 2 in the last column). Within each plot, the x axis corresponds to treatment phase length and the different lines correspond to different baseline phase lengths. The thing to note is that, when the baseline slope is non-zero, the expected value of Tau-U ranges quite widely within each plot, depending on the values of &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. For example, when &lt;span class=&#34;math inline&#34;&gt;\(\beta_2 = 0\)&lt;/span&gt; (in the first column), the data follow a simple linear trend with no shift. If the slope of the trend is equal to -0.2 (the first row), then the expected magnitude of Tau-U ranges from -0.8 to 0.3 depending on the phase lengths, which is quite a wide range.&lt;/p&gt;
&lt;p&gt;Generally, the degree of sample size sensitivity depends on the absolute magnitude of the baseline slope, with steeper slopes leading to increased sensitivity. For steeper values of slope, it appears that the degree to which the measure is affected by sample size even swamps the degree to which the measure is sensitive to the magnitude of the treatment effect. Very peculiar.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-final-thought&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A final thought&lt;/h2&gt;
&lt;p&gt;Of course, these results are contingent on the particular model under which I derived the expected magnitude of Tau-U. If the data followed some other model, such as a log-linear model with Poisson-distributed outcomes, then the behavior described above might change. Still, I think all of this raises the reasonable question: under what model (i.e., what sort of patterns of baseline trend, what sort of patterns of response to the intervention) does Tau-U provide a meaningful effect size measure that clearly quantifies the magnitude of treatment effects without being strongly affected by phase lengths? Unless and until such a model can be identified, I would be wary of interpreting Tau-U as a measure of treatment effect magnitude.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Standard errors and confidence intervals for NAP</title>
      <link>http://localhost:4321/nap-ses-and-cis/</link>
      <pubDate>Sun, 28 Feb 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/nap-ses-and-cis/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://doi.org/10.1016/j.beth.2008.10.006&#34;&gt;Parker and Vannest (2009)&lt;/a&gt; proposed non-overlap of all pairs (NAP) as an effect size index for use in single-case research. NAP is defined in terms of all pair-wise comparisons between the data points in two different phases for a given case (i.e., a treatment phase versus a baseline phase). For an outcome that is desirable to increase, NAP is the proportion of all such pair-wise comparisons where the treatment phase observation exceeds the baseline phase observation, with pairs that are exactly tied getting a weight of 1/2. NAP belongs to the family of non-overlap measures, which also includes the percentage of non-overlapping data, the improvement rate difference, and several other indices. It is exactly equivalent to &lt;a href=&#34;http://doi.org/10.2307/1165329&#34;&gt;Vargha and Delaney’s (2000)&lt;/a&gt; modified Common Language Effect Size and has been proposed as an effect size index in other contexts too (e.g., &lt;a href=&#34;http://doi.org/10.1002/sim.2256&#34;&gt;Acion, Peterson, Temple, &amp;amp; Arndt, 2006&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The developers of NAP have created a &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;web-based tool&lt;/a&gt; for calculating it (as well as several other non-overlap indices), and I have the impression that the tool is fairly widely used. For example, &lt;a href=&#34;http://doi.org/10.1007%2Fs10864-013-9189-x&#34;&gt;Roth, Gillis, and DiGennaro Reed (2014)&lt;/a&gt; and &lt;a href=&#34;http://doi.org/10.1007/s10803-015-2373-1&#34;&gt;Whalon, Conroy, Martinez, and Welch (2015)&lt;/a&gt; both used NAP in their meta-analyses of single-case research, and both noted that they used &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; for calculating the effect size measure. Given that the web tool is being used, it is worth scrutinizing the methods behind the calculations it reports. As of this writing, the standard error and confidence intervals reported along with the NAP statistic are incorrect, and should not be used. After introducing a bit of notation, I’ll explain why the existing methods are deficient. I’ll also suggest some methods for calculating standard errors and confidence intervals that are potentially more accurate.&lt;/p&gt;
&lt;div id=&#34;preliminaries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;Suppose that we have data from the baseline phase and treatment phase for a single case. Let &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; denote the number of baseline observations and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; denote the number of treatment phase observations. Let &lt;span class=&#34;math inline&#34;&gt;\(y^A_1,...,y^A_m\)&lt;/span&gt; denote the baseline phase data and &lt;span class=&#34;math inline&#34;&gt;\(y^B_1,...,y^B_n\)&lt;/span&gt; denote the treatment phase data. Then NAP is calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{NAP} = \frac{1}{m n} \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) + 0.5 I\left(y^B_j = y^A_i\right)\right]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;What is NAP an estimate of? The parameter of interest is the probability that a randomly selected treatment phase observation will exceed a randomly selected baseline phase observation (again, with an adjustment for ties):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\theta = \text{Pr}(Y^B &amp;gt; Y^A) + 0.5 \text{Pr}(Y^B = Y^A).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Vargha and Delaney call &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; the &lt;em&gt;measure of stochastic superiority&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;NAP is very closely related to another non-overlap index called Tau (&lt;a href=&#34;http://doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, &amp;amp; Sauber, 2011&lt;/a&gt;). Tau is nothing more than a linear re-scaling of NAP to the range of [-1, 1]:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau} = \frac{S}{m n} = 2 \times \text{NAP} - 1,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
S = \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) - I\left(y^B_j &amp;lt; y^A_i\right)\right].
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is Kendall’s S statistic, which is closely related to the Mann-Whitney &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; test.&lt;/p&gt;
&lt;p&gt;Here is an R function for calculating NAP:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NAP &amp;lt;- function(yA, yB) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  U &amp;lt;- sum(sapply(yA, function(i) sapply(yB, function(j) (j &amp;gt; i) + 0.5 * (j == i))))
  U / (m * n)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the data from the worked example in &lt;a href=&#34;http://doi.org/10.1016/j.beth.2008.10.006&#34;&gt;Parker and Vannest (2009)&lt;/a&gt;, the function result agrees with their reported NAP of 0.96:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;yA &amp;lt;- c(4, 3, 4, 3, 4, 7, 5, 2, 3, 2)
yB &amp;lt;- c(5, 9, 7, 9, 7, 5, 9, 11, 11, 10, 9)
NAP(yA, yB)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9636364&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-errors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Standard errors&lt;/h2&gt;
&lt;p&gt;The webtool at &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; reports a standard error for NAP (it is labelled as “SDnap”), which from what I can tell is based on the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{SE}_{\text{Tau}} = \sqrt{\frac{m + n + 1}{3 m n}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This formula appears to actually be the standard error for Tau, rather than for NAP. Since &lt;span class=&#34;math inline&#34;&gt;\(\text{NAP} = \left(\text{Tau} + 1\right) / 2\)&lt;/span&gt;, the standard error for NAP should be half as large:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{SE}_{null} = \sqrt{\frac{m + n + 1}{12 m n}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(cf. &lt;a href=&#34;http://dx.doi.org/10.1037/1082-989X.6.2.135&#34;&gt;Grissom &amp;amp; Kim, 2001, p. 141&lt;/a&gt;). However, even the latter formula is not always correct. It is valid only when the observations are all mutually independent and when the treatment phase data are drawn from the same distribution as the baseline phase data—that is, when the treatment has no effect on the outcome. I’ve therefore denoted it as &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;other-standard-error-estimators&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other standard error estimators&lt;/h3&gt;
&lt;p&gt;Because an equivalent effect size measure is used in other contexts like clinical medicine, there has actually been a fair bit of research into better approaches for assessing the uncertainty in NAP. &lt;a href=&#34;http://dx.doi.org/10.1148/radiology.143.1.7063747&#34;&gt;Hanley and McNeil (1982)&lt;/a&gt; proposed an estimator for the sampling variance of NAP that is designed for continuous outcome measures, where exact ties are impossible. Modifying it slightly (and in entirely ad hoc fashion) to account for ties, let&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Q_1 &amp;amp;= \frac{1}{m n^2}\sum_{i=1}^m \left[\sum_{j=1}^n I\left(y^B_j &amp;gt; y^A_i\right) + 0.5 I\left(y^B_j = y^A_i\right)\right]^2 \\
Q_2 &amp;amp;= \frac{1}{m^2 n}\sum_{j=1}^n \left[\sum_{i=1}^m I\left(y^B_j &amp;gt; y^A_i\right) + 0.5 I\left(y^B_j = y^A_i\right)\right]^2.
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Then the Hanley-McNeil variance estimator is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_{HM} = \frac{1}{mn} \left[\text{NAP}\left(1 - \text{NAP}\right) + (n - 1)\left(Q_1 - \text{NAP}^2\right) + (m - 1)\left(Q_2 - \text{NAP}^2\right)\right],
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{HM} = \sqrt{V_{HM}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The same authors also propose a different estimator, which is based on the assumption that the outcome data are exponentially distributed. Even though this is a strong and often inappropriate assumption, there is evidence that this estimator works even for other, non-exponential distributions. &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt; suggested a further modification of their estimator, and I’ll describe his version. Let &lt;span class=&#34;math inline&#34;&gt;\(h = (m + n) / 2 - 1\)&lt;/span&gt;. Then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_{New} = \frac{h}{mn} \text{NAP}\left(1 - \text{NAP}\right)\left[\frac{1}{h} + \frac{1 - \text{NAP}}{2 - \text{NAP}} + \frac{\text{NAP}}{1 + \text{NAP}}\right],
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{New} = \sqrt{V_{New}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Here are R functions to calculate each of these variance estimators.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_HM &amp;lt;- function(yA, yB) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  U &amp;lt;- sapply(yB, function(j) (j &amp;gt; yA) + 0.5 * (j == yA))
  t &amp;lt;- sum(U) / (m * n)
  Q1 &amp;lt;- sum(rowSums(U)^2) / (m * n^2)
  Q2 &amp;lt;- sum(colSums(U)^2) / (m^2 * n)
  (t * (1 - t) + (n - 1) * (Q1 - t^2) + (m - 1) * (Q2 - t^2)) / (m * n)
}

V_New &amp;lt;- function(yA, yB) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  t &amp;lt;- NAP(yA, yB)
  h &amp;lt;- (m + n) / 2 - 1
  t * (1 - t) * (1 + h * (1 - t) / (2 - t) + h * t / (1 + t)) / (m * n)
}

sqrt(V_HM(yA, yB))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.03483351&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(V_New(yA, yB))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04370206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the worked example dataset from Parker and Vannest, the Newcombe estimator yields a standard error that is about 25% larger than the Hanley-McNeil estimator. Both of these are substantially smaller than the null standard error, which in this example is &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null} = 0.129\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-small-simulation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A small simulation&lt;/h3&gt;
&lt;p&gt;Simulation methods can be used to examine how well these various standard error formulas estimate the actual sampling variation of NAP. For simplicity, I’ll simulate normally distributed data where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y^A \sim N(0, 1) \qquad \text{and} \qquad Y^B \sim N\left(\sqrt{2}\Phi^{-1}(\theta), 1\right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for varying values of the effect size estimand (&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;) and a couple of different sample sizes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_NAP &amp;lt;- function(delta, m, n, iterations) {
  NAPs &amp;lt;- replicate(iterations, {
    yA &amp;lt;- rnorm(m)
    yB &amp;lt;- rnorm(n, mean = delta)
    c(NAP = NAP(yA, yB), V_HM = V_HM(yA, yB), V_New = V_New(yA, yB))
  })
  data.frame(sd = sd(NAPs[&amp;quot;NAP&amp;quot;,]), 
             SE_HM = sqrt(mean(NAPs[&amp;quot;V_HM&amp;quot;,])), 
             SE_New = sqrt(mean(NAPs[&amp;quot;V_New&amp;quot;,])))
}

library(dplyr)
library(tidyr)
theta &amp;lt;- seq(0.5, 0.95, 0.05)
m &amp;lt;- c(5, 10, 15, 20, 30)
n &amp;lt;- c(5, 10, 15, 20, 30)

expand.grid(theta = theta, m = m, n = n) %&amp;gt;%
  group_by(theta, m, n) %&amp;gt;% 
  mutate(delta = sqrt(2) * qnorm(theta)) -&amp;gt;
  params 

params %&amp;gt;%
  do(sample_NAP(.$delta, .$m, .$n, iterations = 2000)) %&amp;gt;%
  mutate(se_null = sqrt((m + n + 1) / (12 * m * n))) %&amp;gt;%
  gather(&amp;quot;sd&amp;quot;,&amp;quot;val&amp;quot;, sd, SE_HM, SE_New, se_null) -&amp;gt;
  NAP_sim&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
ggplot(NAP_sim, aes(theta, val, color = sd)) + 
  facet_grid(n ~ m, labeller = &amp;quot;label_both&amp;quot;) + 
  geom_line() + 
  theme_bw() + theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/NAP-SEs-and-CIs_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the above figure, the actual sampling standard deviation of NAP (in red) and the value of &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt; (in purple) are plotted against the true value of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, with separate plots for various combinations of &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. The expected value of the standard errors &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{HM}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{New}\)&lt;/span&gt; (actually the square root of the expectation of the variance estimators) are depicted in green and blue, respectively. The value of &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt; agrees with the actual standard error when &lt;span class=&#34;math inline&#34;&gt;\(\delta = 0\)&lt;/span&gt;, but the two diverge when there is a positive treatment effect. It appears that &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{HM}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{New}\)&lt;/span&gt; both under-estimate the actual standard error when &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is equal to 5, and over-estimate for the largest values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. However, both of these estimators offer a marked improvement over &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;confidence-intervals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Confidence intervals&lt;/h2&gt;
&lt;p&gt;The webtool at &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; also reports 85% and 90% confidence intervals for NAP. These confidence intervals appear to have the same two problems as the standard errors. First, they are constructed as CIs for Tau rather than for NAP. For the &lt;span class=&#34;math inline&#34;&gt;\(100\% \times (1 - \alpha)\)&lt;/span&gt; CI, let &lt;span class=&#34;math inline&#34;&gt;\(z_{\alpha / 2}\)&lt;/span&gt; be the appropriate critical value from a standard normal distribution. The CIs reported by the webtool are given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau} \pm \text{SE}_{\text{Tau}} \times z_{\alpha / 2}. 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is probably just an oversight in the programming, which could be corrected by instead using&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{NAP} \pm \text{SE}_{null} \times z_{\alpha / 2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In parallel with the standard error formulas, I’ll call this formula the null confidence interval. Funnily enough, the upper bound of the null CI is the same as the upper bound of the Tau CI. However, the lower bound is going to be quite a bit larger than the lower bound for the Tau CI, so that the null CI will be much narrower.&lt;/p&gt;
&lt;p&gt;The second problem is that even the null CI has poor coverage properties because it is based on &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt;, which can drastically over-estimate the standard error of NAP for non-null values.&lt;/p&gt;
&lt;div id=&#34;other-confidence-intervals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other confidence intervals&lt;/h3&gt;
&lt;p&gt;As I noted above, there has been a fair amount of previous research into how to construct CIs for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, the parameter estimated by NAP. As is often the case with these sorts of problems, there are many different methods available, scattered across the literature. Fortunately, there are two (at least) fairly comprehensive simulation studies that compare the performance of various methods under a wide range of conditions. &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt; examined a range of methods based on inverting Wald-type test statistics (which give CIs of the form &lt;span class=&#34;math inline&#34;&gt;\(\text{estimate} \pm \text{SE} \times z_{\alpha / 2}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}\)&lt;/span&gt; is some standard error estimate) and score-based methods (in which the standard error is estimated using the candidate parameter value). Based on an extensive simulation, he suggested a score-based method in which the end-points of the CI are defined the values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; that satisfy:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
(\text{NAP} - \theta)^2 = \frac{z^2_{\alpha / 2} h \theta (1 - \theta)}{mn}\left[\frac{1}{h} + \frac{1 - \theta}{2 - \theta} + \frac{\theta}{1 + \theta}\right],
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(h = (m + n) / 2 - 1\)&lt;/span&gt;. This equation is a fourth-degree polynomial in &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, easily solved using a numerical root-finding algorithm.&lt;/p&gt;
&lt;p&gt;In a different simulation study, &lt;a href=&#34;http://dx.doi.org/10.1080/00273171.2012.658329&#34;&gt;Ruscio and Mullen (2012)&lt;/a&gt; examined the performance of a selection of different confidence intervals for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, including several methods not considered by Newcombe. Among the methods that they examined, they find that the bias-corrected, accelerated (BCa) bootstrap CI performs particularly well (and seems to outperform the score-based CI recommended by Newcombe).&lt;/p&gt;
&lt;p&gt;Neither &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt; nor &lt;a href=&#34;http://dx.doi.org/10.1080/00273171.2012.658329&#34;&gt;Ruscio and Mullen (2012)&lt;/a&gt; considered constructing a confidence interval by directly pivoting the Mann-Whitney U test (the same technique used to construct confidence intervals for the Hodges-Lehmann estimator of location shift), although it seems to me that this would be possible and potentially an attractive approach in the context of SCDs. The main caveat is that such a CI would require stronger distributional assumptions than those studied in the simulations, such as that the distributions of &lt;span class=&#34;math inline&#34;&gt;\(Y^A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y^B\)&lt;/span&gt; differ by an additive (or multiplicative) constant. In any case, it seems like it would be worth exploring this approach too.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-small-simulation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Another small simulation&lt;/h3&gt;
&lt;p&gt;Here is an R function for calculating several different CIs for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, including the null CI, Wald-type CIs based on &lt;span class=&#34;math inline&#34;&gt;\(V_{HM}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V_{New}\)&lt;/span&gt;, and the score-type CI recommended by &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt;. I haven’t programmed the BCa bootstrap because it would take a bit more thought to figure out how to simulate it efficiently.&lt;/p&gt;
&lt;p&gt;The following code simulates the coverage rates of nominal 90% CIs based on each of these methods, following the same simulation set-up as above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NAP_CIs &amp;lt;- function(yA, yB, alpha = .05) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  U &amp;lt;- sapply(yB, function(j) (j &amp;gt; yA) + 0.5 * (j == yA))
  t &amp;lt;- sum(U) / (m * n)
  
  # variance estimators
  V_null &amp;lt;- (m + n + 1) / (12 * m * n)
  
  Q1 &amp;lt;- sum(rowSums(U)^2) / (m * n^2)
  Q2 &amp;lt;- sum(colSums(U)^2) / (m^2 * n)
  V_HM &amp;lt;- (t * (1 - t) + (n - 1) * (Q1 - t^2) + (m - 1) * (Q2 - t^2)) / (m * n)
  
  h &amp;lt;- (m + n) / 2 - 1
  V_New &amp;lt;- t * (1 - t) * (1 + h * (1 - t) / (2 - t) + h * t / (1 + t)) / (m * n)
  
  # Wald-type confidence intervals
  z &amp;lt;- qnorm(1 - alpha / 2)
  SEs &amp;lt;- sqrt(c(null = V_null, HM = V_HM, Newcombe = V_New))
  Wald_lower &amp;lt;- t - z * SEs
  Wald_upper &amp;lt;- t + z * SEs
  
  # score-type confidence interval
  f &amp;lt;- function(x) m * n * (t - x)^2 * (2 - x) * (1 + x) - 
    z^2 * x * (1 - x) * (2 + h + (1 + 2 * h) * x * (1 - x))
  score_lower &amp;lt;- if (t &amp;gt; 0) uniroot(f, c(0, t))$root else 0
  score_upper &amp;lt;- if (t &amp;lt; 1) uniroot(f, c(t, 1))$root else 1
  list(NAP = t, 
       CI = data.frame(lower = c(Wald_lower, score = score_lower), 
                       upper = c(Wald_upper, score = score_upper)))
}

NAP_CIs(yA, yB)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $NAP
## [1] 0.9636364
## 
## $CI
##              lower     upper
## null     0.7106061 1.2166666
## HM       0.8953639 1.0319088
## Newcombe 0.8779819 1.0492908
## score    0.7499741 0.9950729&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_CIs &amp;lt;- function(delta, m, n, alpha = .05, iterations) {
  NAPs &amp;lt;- replicate(iterations, {
    yA &amp;lt;- rnorm(m)
    yB &amp;lt;- rnorm(n, mean = delta)
    NAP_CIs(yA, yB, alpha = alpha)
  }, simplify = FALSE)
  theta &amp;lt;- mean(sapply(NAPs, function(x) x$NAP))
  coverage &amp;lt;- rowMeans(sapply(NAPs, function(x) (x$CI$lower &amp;lt; theta) &amp;amp; (theta &amp;lt; x$CI$upper)))
  data.frame(CI = rownames(NAPs[[1]]$CI), coverage = coverage)
}

params %&amp;gt;% 
  do(sample_CIs(delta = .$delta, m = .$m, n = .$n, alpha = .10, iterations = 5000)) -&amp;gt;
  NAP_CI_sim&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(NAP_CI_sim, aes(theta, coverage, color = CI)) + 
  facet_grid(n ~ m, labeller = &amp;quot;label_both&amp;quot;, scales = &amp;quot;free_y&amp;quot;) + 
  geom_line() + 
  labs(y = &amp;quot;SE&amp;quot;) + 
  geom_hline(yintercept=.90, linetype=&amp;quot;dashed&amp;quot;) +
  theme_bw() + theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/NAP-SEs-and-CIs_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The figure above plots the coverage rates of several different confidence intervals for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;: the naive CI (in blue), the HM Wald CI (red), the Newcombe Wald CI (green), and the Newcombe score CI (purple). The dashed horizontal line is the nominal coverage rate of 90%. It can be seen that the null CI has the correct coverage only when &lt;span class=&#34;math inline&#34;&gt;\(\theta \leq .6\)&lt;/span&gt;; for larger values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, its coverage becomes too conservative (tending towards 100%). The Wald-type CIs have below-nominal coverage rates, which improve as the sample size in each phase increases but remain too liberal even at the largest sample size considered. Finally, Newcombe’s score CI maintains close-to-nominal coverage over a wider range of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; values. Although these CIs have below-nominal coverage for the smallest sample sizes, they generally have good coverage for &lt;span class=&#34;math inline&#34;&gt;\(\theta &amp;lt; .9\)&lt;/span&gt; and when the sample size in each phase is 10 or more. It is also notable that their coverage rates appear to become more accurate as the sample size in a given group increases, even if the sample size in the other group is fairly small and remains constant.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;caveats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Caveats&lt;/h2&gt;
&lt;p&gt;My aim in this post was to highlight the problems with how &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; calculates standard errors and CIs for the NAP statistic. Some of these issues could easily be resolved by correcting the relevant formulas so that they are appropriate for NAP rather than Tau. However, even with these corrections, better approaches exist for calculating standard errors and CIs. I’ve highlighted some promising ones above, which seem worthy of further investigation. But I should also emphasize that these methods do come with some important caveats too.&lt;/p&gt;
&lt;p&gt;First, all of the methods I’ve discussed are premised on having mutually independent observations. In the presence of serial correlation, I would anticipate that any of these standard errors will be too small and any of the confidence intervals will be too narrow. (This could readily be verified through simulation, although I have not done so here.)&lt;/p&gt;
&lt;p&gt;Second, my small simulations are based on the assumption of normally distributed, homoskedastic observations in each phase, which is not a particularly good model for the types of outcome measures commonly used in single case research. In some of my other work, I’ve developed statistical models for data collected by systematic direct observation of behavior, which is the most prevalent type of outcome data in single-case research. Before recommending any particular method, the performance of the standard error formulas (e.g., the Hanley-McNeil and Newcombe estimators) and CI methods (such as Newcombe’s score CI) should be examined under more realistic models for behavioral observation data.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
