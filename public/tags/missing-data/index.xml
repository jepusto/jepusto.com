<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>missing data | James E. Pustejovsky</title>
    <link>/tags/missing-data/</link>
      <atom:link href="/tags/missing-data/index.xml" rel="self" type="application/rss+xml" />
    <description>missing data</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2022</copyright><lastBuildDate>Wed, 22 Dec 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>missing data</title>
      <link>/tags/missing-data/</link>
    </image>
    
    <item>
      <title>Meta-analysis with robust variance estimation and multiply imputed covariates</title>
      <link>/rve-meta-analysis-with-mi/</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      <guid>/rve-meta-analysis-with-mi/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.1.5     v dplyr   1.0.5
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tibble&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyr&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metadat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;metadat&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;metafor&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: Matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;Matrix&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:tidyr&amp;#39;:
## 
##     expand, pack, unpack&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Loading the &amp;#39;metafor&amp;#39; package (version 3.0-2). For an
## introduction to the package please type: help(metafor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;metafor&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:metadat&amp;#39;:
## 
##     dat.hackshaw1998, dat.ishak2007, dat.konstantopoulos2011,
##     dat.lim2014, dat.maire2019, dat.moura2021, dat.raudenbush1985,
##     dat.riley2003&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mice)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;mice&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;mice&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     cbind, rbind&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mitools)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;mitools&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create missingness

set.seed(20211222)

dat_miss &amp;lt;- 
  dat.assink2016 %&amp;gt;%
  group_by(study) %&amp;gt;%
  mutate(
    pubstatus = if_else(rbinom(1L, 1L, 0.15) == 1L, NA_integer_, unique(pubstatus)),
    pubstatus = factor(pubstatus, levels = 0:1, labels = c(&amp;quot;unpublished&amp;quot;,&amp;quot;published&amp;quot;)),
    deltype = if_else(rbinom(n(), 1L, prob = plogis(-2.5 - 0.1 * year)) == 1L, NA_character_, deltype),
    deltype = factor(deltype)
  )

# Impute missing values 20 times

predMatrix &amp;lt;- make.predictorMatrix(dat_miss)
predMatrix[,c(&amp;quot;study&amp;quot;,&amp;quot;esid&amp;quot;,&amp;quot;id&amp;quot;)] &amp;lt;- 0 # don&amp;#39;t use study or esid or id for imputing

impMethod &amp;lt;- make.method(dat_miss)
impMethod&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     study      esid        id        yi        vi pubstatus      year   deltype 
##        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;  &amp;quot;logreg&amp;quot;        &amp;quot;&amp;quot; &amp;quot;polyreg&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp &amp;lt;- mice(dat_miss, m = 20, print = FALSE,
            predictorMatrix = predMatrix, 
            method=impMethod, seed = 20211222)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Number of logged events: 70&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit SCE+ model
fits &amp;lt;- with(imp, rma.mv(
  yi = yi, 
  V = impute_covariance_matrix(vi = vi, cluster = study, r = 0.6, subgroup = deltype),
  mods = ~ pubstatus + deltype + year,
  random = list(~ deltype | study, ~ deltype | id),
  struct = c(&amp;quot;DIAG&amp;quot;,&amp;quot;DIAG&amp;quot;)
))

# Get coefficients
coefs &amp;lt;- map(fits$analyses, coef)

# Get CR2 variance-covariance matrices
vcovs &amp;lt;- map(fits$analyses, vcovCR, type = &amp;quot;CR2&amp;quot;)

# Get denominator df from complete-data F-tests
q &amp;lt;- 2
dfs &amp;lt;- 
  map_dfr(fits$analyses, Wald_test, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(3:4), test = &amp;quot;HTZ&amp;quot;) %&amp;gt;%
  mutate(
    eta = df_denom + (q - 1)
  )
eta &amp;lt;- mean(dfs$eta)

# Combine imputed results
res &amp;lt;- MIcombine(results = coefs, variances = vcovs)
res$coefficients&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            intrcpt pubstatuspublished       deltypeovert      deltypecovert 
##         0.89897557        -0.55770641        -0.38101335        -0.46723794 
##               year 
##        -0.02576823&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res$variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                         intrcpt pubstatuspublished deltypeovert deltypecovert
## intrcpt             0.074539988       -0.083961053 -0.058577507  0.0010493986
## pubstatuspublished -0.083961053        0.103264126  0.067143252 -0.0032322609
## deltypeovert       -0.058577507        0.067143252  0.106429071 -0.0108120033
## deltypecovert       0.001049399       -0.003232261 -0.010812003  0.0321118999
## year                0.002758525       -0.004318211 -0.003867039  0.0002642098
##                             year
## intrcpt             0.0027585250
## pubstatuspublished -0.0043182112
## deltypeovert       -0.0038670392
## deltypecovert       0.0002642098
## year                0.0004815795&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Calculate manual HTZ test using averaged eta 
Cmat &amp;lt;- constrain_zero(3:4, coefs = res$coefficients)
Q &amp;lt;- t(Cmat %*% res$coefficients) %*% solve(Cmat %*% res$variance %*% t(Cmat)) %*% (Cmat %*% res$coefficients)
Fstat &amp;lt;- (eta - q + 1) / (eta * q) * as.numeric(Q)
p_val &amp;lt;- pf(Fstat, df1 = q, df2 = eta - q + 1, lower.tail = FALSE)
data.frame(Fstat = Fstat, df_num = q, df_denom = eta - q + 1, p_val = p_val)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Fstat df_num df_denom     p_val
## 1 3.003453      2 1.663534 0.2804675&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Pooling clubSandwich results across multiple imputations</title>
      <link>/mi-with-clubsandwich/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      <guid>/mi-with-clubsandwich/</guid>
      <description>


&lt;p&gt;A colleague recently asked me about how to apply cluster-robust hypothesis tests and confidence intervals, as calculated with the &lt;a href=&#34;https://CRAN.R-project.org/package=clubSandwich&#34;&gt;clubSandwich package&lt;/a&gt;, when dealing with multiply imputed datasets.
Standard methods (i.e., Rubin’s rules) for pooling estimates from multiple imputed datasets are developed under the assumption that the full-data estimates are approximately normally distributed. However, this might not be reasonable when working with test statistics based on cluster-robust variance estimators, which can be imprecise when the number of clusters is small or the design matrix of predictors is unbalanced in certain ways. &lt;a href=&#34;https://doi.org/10.1093/biomet/86.4.948&#34;&gt;Barnard and Rubin (1999)&lt;/a&gt; proposed a small-sample correction for tests and confidence intervals based on multiple imputed datasets. In this post, I’ll show how to implement their technique using the output of &lt;code&gt;clubSandwich&lt;/code&gt;, with multiple imputations generated using the &lt;a href=&#34;https://cran.r-project.org/package=mice&#34;&gt;&lt;code&gt;mice&lt;/code&gt; package&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setup&lt;/h3&gt;
&lt;p&gt;To begin, let me create missingness in a dataset containing multiple clusters of observations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mlmRev)
library(mice)
library(dplyr)

data(bdf)

bdf &amp;lt;- bdf %&amp;gt;%
  select(schoolNR, IQ.verb, IQ.perf, sex, ses, langPRET, aritPRET, aritPOST) %&amp;gt;%
  mutate(
    schoolNR = factor(schoolNR),
    sex = as.numeric(sex)
    ) %&amp;gt;%
  filter(as.numeric(schoolNR) &amp;lt;= 30) %&amp;gt;%
  droplevels()

bdf_missing &amp;lt;- 
  bdf %&amp;gt;% 
  select(-schoolNR) %&amp;gt;%
  ampute(run = TRUE)

bdf_missing &amp;lt;- 
  bdf_missing$amp %&amp;gt;%
  mutate(schoolNR = bdf$schoolNR)

summary(bdf_missing)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     IQ.verb         IQ.perf            sex             ses       
##  Min.   : 4.00   Min.   : 5.333   Min.   :1.000   Min.   :10.00  
##  1st Qu.:10.50   1st Qu.: 9.333   1st Qu.:1.000   1st Qu.:20.00  
##  Median :11.50   Median :10.667   Median :1.000   Median :27.00  
##  Mean   :11.72   Mean   :10.733   Mean   :1.462   Mean   :28.58  
##  3rd Qu.:13.00   3rd Qu.:12.333   3rd Qu.:2.000   3rd Qu.:38.00  
##  Max.   :18.00   Max.   :16.667   Max.   :2.000   Max.   :50.00  
##  NA&amp;#39;s   :37      NA&amp;#39;s   :39       NA&amp;#39;s   :40      NA&amp;#39;s   :37     
##     langPRET        aritPRET        aritPOST        schoolNR  
##  Min.   :15.00   Min.   : 1.00   Min.   : 2.00   40     : 35  
##  1st Qu.:30.00   1st Qu.: 9.00   1st Qu.:12.00   54     : 31  
##  Median :34.00   Median :11.00   Median :18.00   55     : 30  
##  Mean   :33.87   Mean   :11.64   Mean   :17.57   38     : 28  
##  3rd Qu.:39.00   3rd Qu.:14.00   3rd Qu.:23.00   1      : 25  
##  Max.   :48.00   Max.   :20.00   Max.   :30.00   18     : 24  
##  NA&amp;#39;s   :32      NA&amp;#39;s   :31      NA&amp;#39;s   :36      (Other):354&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’ll use &lt;code&gt;mice&lt;/code&gt; to create 10 multiply imputed datasets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Impute_bdf &amp;lt;- mice(bdf_missing, m=10, meth=&amp;quot;norm.nob&amp;quot;, seed=24)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Am I imputing while ignoring the hierarchical structure of the data? Yes, yes I am. Is this is a good way to do imputation? Probably not. But this is a quick and dirty example, so we’re going to have to live with it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model&lt;/h3&gt;
&lt;p&gt;Suppose that the goal of our analysis is to estimate the coefficients of the following regression model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{aritPOST}_{ij} = \beta_0 + \beta_1 \text{aritPRET}_{ij} + \beta_2 \text{langPRET}_{ij} + \beta_3 \text{sex}_{ij} + \beta_4 \text{SES}_{ij} + e_{ij},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; indexes students and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes schools, and where we allow for the possibility that errors from the same cluster are correlated in an unspecified way. With complete data, we could estimate the model by ordinary least squares and then use &lt;code&gt;clubSandwich&lt;/code&gt; to get standard errors that are robust to within-cluster dependence and heteroskedasticity. The code for this is as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_full &amp;lt;- lm(aritPOST ~ aritPRET + langPRET + sex + ses, data = bdf)
coef_test(lm_full, cluster = bdf$schoolNR, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         Coef. Estimate     SE t-stat d.f. p-val (Satt) Sig.
## 1 (Intercept)  -2.1921 1.3484 -1.626 22.9       0.1177     
## 2    aritPRET   1.0053 0.0833 12.069 23.4       &amp;lt;0.001  ***
## 3    langPRET   0.2758 0.0294  9.371 24.1       &amp;lt;0.001  ***
## 4         sex  -1.2040 0.4706 -2.559 23.8       0.0173    *
## 5         ses   0.0233 0.0266  0.876 20.5       0.3909&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If cluster dependence were no concern, we could simply use the model-based standard errors and test statistics. The &lt;code&gt;mice&lt;/code&gt; package provides functions that will fit the model to each imputed dataset and then combine them by Rubin’s rules. The code is simply:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(data = Impute_bdf, 
     lm(aritPOST ~ aritPRET + langPRET + sex + ses)
     ) %&amp;gt;%
  pool() %&amp;gt;%
  summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          term    estimate  std.error statistic       df      p.value
## 1 (Intercept) -2.28650029 1.11111424 -2.057844 417.9634 4.022469e-02
## 2    aritPRET  0.97135842 0.07152843 13.580033 250.9260 0.000000e+00
## 3    langPRET  0.27866679 0.03722404  7.486205 308.6377 7.474021e-13
## 4         sex -1.06494919 0.41317983 -2.577447 272.5258 1.047928e-02
## 5         ses  0.03220417 0.02142008  1.503457 124.5671 1.352524e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this approach ignores the possibility of correlation in the errors of units in the same cluster, which is clearly a concern in this dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ratio of CRVE to conventional variance estimates
diag(vcovCR(lm_full, cluster = bdf$schoolNR, type = &amp;quot;CR2&amp;quot;)) / 
  diag(vcov(lm_full))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (Intercept)    aritPRET    langPRET         sex         ses 
##   1.5296837   1.5493134   0.6938735   1.4567650   2.0053186&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we need a way to pool results based on the cluster-robust variance estimators, while also accounting for the relatively small number of clusters in this dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;barnard-rubin-1999&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Barnard &amp;amp; Rubin (1999)&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.1093/biomet/86.4.948&#34;&gt;Barnard and Rubin (1999)&lt;/a&gt; proposed a small-sample correction for tests and confidence intervals based on multiple imputed datasets that seems to work in this context. Rather than using large-sample normal approximations for inference, they derive an approximate degrees-of-freedom that combines uncertainty in the standard errors calculated from each imputed dataset with between-imputation uncertainty. The method is as follows.&lt;/p&gt;
&lt;p&gt;Suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; imputed datasets. Let &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_{(j)}\)&lt;/span&gt; be the estimated regression coefficient from imputed dataset &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, with (in this case cluster-robust) sampling variance estimate &lt;span class=&#34;math inline&#34;&gt;\(V_{(j)}\)&lt;/span&gt;. Further, let &lt;span class=&#34;math inline&#34;&gt;\(\eta_{(j)}\)&lt;/span&gt; be the degrees of freedom corresponding to &lt;span class=&#34;math inline&#34;&gt;\(V_{(j)}\)&lt;/span&gt;. To combine these estimates, calculate the averages across multiply imputed datasets:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\bar\beta = \frac{1}{m}\sum_{j=1}^m \hat\beta_{(j)}, \qquad \bar{V} = \frac{1}{m}\sum_{j=1}^m V_{(j)}, \qquad \bar\eta = \frac{1}{m}\sum_{j=1}^m \eta_{(j)}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Also calculate the between-imputation variance&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
B = \frac{1}{m - 1} \sum_{j=1}^m \left(\hat\beta_{(j)} - \bar\beta\right)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And then combine the between- and within- variance estimates using Rubin’s rules:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_{total} = \bar{V} + \frac{m + 1}{m} B.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The degrees of freedom associated with &lt;span class=&#34;math inline&#34;&gt;\(V_{total}\)&lt;/span&gt; modify the estimated complete-data degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\bar\eta\)&lt;/span&gt; using quantities that depend on the fraction of missing information in a coefficient. The fraction of missing information is given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\gamma_m = \frac{(m+1)B}{m V_{total}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The degrees of freedom are then given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu_{total} = \left(\frac{1}{\nu_m} + \frac{1}{\nu_{obs}}\right)^{-1},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu_m = \frac{(m - 1)}{\hat\gamma_m^2}, \quad \text{and} \quad \nu_{obs} = \frac{\bar\eta (\bar\eta + 1) (1 - \hat\gamma)}{\bar\eta + 3}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Hypothesis tests and confidence intervals are based on the approximation&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\bar\beta - \beta_0}{\sqrt{V_{total}}} \ \stackrel{\cdot}{\sim} \ t(\nu_{total})
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;implementation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Implementation&lt;/h3&gt;
&lt;p&gt;Here is how to carry out these calculations using the results of &lt;code&gt;clubSandwich::coef_test&lt;/code&gt; and a bit of &lt;code&gt;dplyr&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit results with clubSandwich standard errors

models_robust &amp;lt;- with(data = Impute_bdf, 
                      lm(aritPOST ~ aritPRET + langPRET + sex + ses) %&amp;gt;% 
                         coef_test(cluster=bdf$schoolNR, vcov=&amp;quot;CR2&amp;quot;)
                      ) 


# pool results with clubSandwich standard errors

robust_pooled &amp;lt;- 
  models_robust$analyses %&amp;gt;%
  
  # add coefficient names as a column
  lapply(function(x) {
    x$coef &amp;lt;- row.names(x)
    x
  }) %&amp;gt;%
  bind_rows() %&amp;gt;%
  as.data.frame() %&amp;gt;%
  
  # summarize by coefficient
  group_by(coef) %&amp;gt;%
  summarise(
    m = n(),
    B = var(beta),
    beta_bar = mean(beta),
    V_bar = mean(SE^2),
    eta_bar = mean(df)
  ) %&amp;gt;%
  
  mutate(
    
    # calculate intermediate quantities to get df
    V_total = V_bar + B * (m + 1) / m,
    gamma = ((m + 1) / m) * B / V_total,
    df_m = (m - 1) / gamma^2,
    df_obs = eta_bar * (eta_bar + 1) * (1 - gamma) / (eta_bar + 3),
    df = 1 / (1 / df_m + 1 / df_obs),
    
    # calculate summary quantities for output
    se = sqrt(V_total),
    t = beta_bar / se,
    p_val = 2 * pt(abs(t), df = df, lower.tail = FALSE),
    crit = qt(0.975, df = df),
    lo95 = beta_bar - se * crit,
    hi95 = beta_bar + se * crit
  )

robust_pooled %&amp;gt;%
  select(coef, est = beta_bar, se, t, df, p_val, lo95, hi95, gamma) %&amp;gt;%
  mutate_at(vars(est:gamma), round, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 9
##   coef           est    se     t    df p_val   lo95   hi95 gamma
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) -2.29  1.34  -1.70  20.4 0.104 -5.08   0.51  0.039
## 2 aritPRET     0.971 0.092 10.5   19.0 0      0.778  1.16  0.076
## 3 langPRET     0.279 0.036  7.71  19.5 0      0.203  0.354 0.106
## 4 ses          0.032 0.03   1.09  16.3 0.292 -0.03   0.095 0.117
## 5 sex         -1.06  0.472 -2.26  19.6 0.036 -2.05  -0.08  0.089&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is instructive to compare the calculated &lt;code&gt;df&lt;/code&gt; to &lt;code&gt;eta_bar&lt;/code&gt; and &lt;code&gt;df_m&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;robust_pooled %&amp;gt;%
  select(coef, df, df_m, eta_bar) %&amp;gt;%
  mutate_at(vars(df, df_m, eta_bar), round, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 4
##   coef           df  df_m eta_bar
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)  20.4 6006.    23  
## 2 aritPRET     19   1550.    22.5
## 3 langPRET     19.5  806.    24.1
## 4 ses          16.3  657.    20.7
## 5 sex          19.6 1138.    23.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, &lt;code&gt;eta_bar&lt;/code&gt; is the average of the complete data degrees of freedom, and it can be seen that the total degrees of freedom are somewhat less than the average complete-data degrees of freedom. This is by construction. Further &lt;code&gt;df_m&lt;/code&gt; is the conventional degrees of freedom used in multiple-imputation, which assume that the complete-data estimates are normally distributed, and in this example they are way far off.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further thoughts&lt;/h3&gt;
&lt;p&gt;How well does this method perform in practice? I’m not entirely sure—I’m just trusting that Barnard and Rubin’s approximation is sound and would work in this setting (I mean, they’re smart people!). Are there other, better approaches? Totally possible. I have done zero literature review beyond the Barnard and Rubin paper. In any case, exploring the performance of this method (and any other alternatives) seems like it would make for a very nice student project.&lt;/p&gt;
&lt;p&gt;There’s also the issue of how to do tests of multi-dimensional constraints (i.e., F-tests). The &lt;code&gt;clubSandwich&lt;/code&gt; package implements Wald-type tests for multi-dimensional constraints, using a small-sample correction that we developed (&lt;a href=&#34;http://journals.sagepub.com/doi/abs/10.3102/1076998615606099&#34;&gt;Tipton &amp;amp; Pustejovsky, 2015&lt;/a&gt;; &lt;a href=&#34;http://www.tandfonline.com/doi/full/10.1080/07350015.2016.1247004&#34;&gt;Pustejovsky &amp;amp; Tipton, 2016&lt;/a&gt;). But it would take some further thought to figure out how to handle multiply imputed data with this type of test…&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
