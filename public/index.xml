<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>James E. Pustejovsky</title>
    <link>http://localhost:4321/</link>
      <atom:link href="http://localhost:4321/index.xml" rel="self" type="application/rss+xml" />
    <description>James E. Pustejovsky</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2024</copyright><lastBuildDate>Fri, 17 May 2024 09:30:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:4321/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>James E. Pustejovsky</title>
      <link>http://localhost:4321/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>http://localhost:4321/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>http://localhost:4321/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>http://localhost:4321/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>http://localhost:4321/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Model-Building Considerations in Meta-Analysis of Dependent Effect Sizes</title>
      <link>http://localhost:4321/talk/vive-2024-dependent-effects/</link>
      <pubDate>Fri, 17 May 2024 09:30:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/vive-2024-dependent-effects/</guid>
      <description>&lt;p&gt;In fields ranging from Education to Economics to Ecology, meta-analysts often encounter complicated data structures, in which some or all primary studies include multiple effect size estimates. These estimates may be correlated because they are based on data from a common sample or a partially overlapping sample, or may be statistically dependent due to use of common study operations. A broad analytic strategy for dealing with such data is to specify a &amp;ldquo;working model&amp;rdquo; to roughly characterize the dependence structure, then use robust inference strategies that work well even if the working model is mis-specified relative to the true data-generating process. Although the technical and computational aspects of this strategy are now well developed, questions remain about how to apply it effectively in practice. In this talk, I will examine two practical questions related to how to build models for meta-analyses involving dependent effect sizes. First, I will illustrate some connections between working models and simpler, ad hoc techniques for dealing with effect size multiplicity, arguing that these connections provide useful heuristics to guide specification of random effects structures in multi-level and multi-variate meta-analysis. Second, I will describe some analytic strategies for conducting equity-related moderator analyses, where predictors involve personal characteristics of the primary study participants that can vary both within and between studies. I distinguish between direct evidence and contextual evidence about equity of impacts and show that the choice of working model can be consequential for analyses involving direct evidence. Throughout, I will highlight some open issues and practical challenges involved in modeling dependent effect sizes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian estimation of between-case standardized mean differences: A simulation study</title>
      <link>http://localhost:4321/talk/aera-2024-bayes-bcsmd/</link>
      <pubDate>Fri, 12 Apr 2024 15:30:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2024-bayes-bcsmd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Distribution of the number of significant effect sizes</title>
      <link>http://localhost:4321/distribution-of-significant-effects/</link>
      <pubDate>Thu, 28 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/distribution-of-significant-effects/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://localhost:4321/number-of-significant-effects/&#34;&gt;A while back&lt;/a&gt;, I posted the outline of a problem about the number of significant effect size estimates in a study that reports multiple outcomes. This problem interests me because it connects to the issue of selective reporting of study results, which creates problems for meta-analysis.
Here, I’ll re-state the problem in slightly more general terms and then make some notes about what’s going on.&lt;/p&gt;
&lt;p&gt;Consider a study that assesses some effect size across &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; different outcomes. (We’ll be thinking about one study at a time here, so no need to index the study as we would in a meta-analysis problem.) Let &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; denote the effect size estimate for outcome &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, let &lt;span class=&#34;math inline&#34;&gt;\(V_i\)&lt;/span&gt; denote the sampling variance of the effect size estimate for outcome &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt; denote the true effect size parameter for corresponding to outcome &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. Assume that the study outcomes &lt;span class=&#34;math inline&#34;&gt;\(\left[T_i\right]_{i=1}^m\)&lt;/span&gt; follow a correlated-and-hierarchical effects model, in which
&lt;span class=&#34;math display&#34;&gt;\[T_i = \mu + u + v_i + e_i,\]&lt;/span&gt;
where the study-level error &lt;span class=&#34;math inline&#34;&gt;\(u \sim N\left(0,\tau^2\right)\)&lt;/span&gt;, the effect-specific error &lt;span class=&#34;math inline&#34;&gt;\(v_i \stackrel{iid}{\sim} N\left(0, \omega^2\right)\)&lt;/span&gt;, and the vector of sampling errors &lt;span class=&#34;math inline&#34;&gt;\(\left[e_i\right]_{i=1}^m\)&lt;/span&gt; is multivariate normal with mean &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{0}\)&lt;/span&gt;, known variances &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(e_i) = \sigma^2\)&lt;/span&gt;, and compound symmetric correlation structure &lt;span class=&#34;math inline&#34;&gt;\(\text{cor}(e_h, e_i) = \rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Define &lt;span class=&#34;math inline&#34;&gt;\(A_i\)&lt;/span&gt; as an indicator that is equal to one if &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; is statistically significant at level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; based on a one-sided test, and otherwise equal to zero. (Equivalently, let &lt;span class=&#34;math inline&#34;&gt;\(A_i\)&lt;/span&gt; be equal to one if the effect is statistically significant at level &lt;span class=&#34;math inline&#34;&gt;\(2 \alpha\)&lt;/span&gt; and in the theoretically expected direction.) Formally,
&lt;span class=&#34;math display&#34;&gt;\[A_i = I\left(\frac{T_i}{\sigma} &amp;gt; q_\alpha \right)\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(q_\alpha = \Phi^{-1}(1 - \alpha)\)&lt;/span&gt; is the critical value from a standard normal distribution (e.g., &lt;span class=&#34;math inline&#34;&gt;\(q_{.05} = 1.645\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(q_{.025} = 1.96\)&lt;/span&gt;). Let &lt;span class=&#34;math inline&#34;&gt;\(N_A = \sum_{i=1}^m A_i\)&lt;/span&gt; denote the total number of statistically significant effect sizes in the study. The question is: what is the distribution of &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;compound-symmetry-to-the-rescue&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compound symmetry to the rescue&lt;/h2&gt;
&lt;p&gt;As I noted in the previous post, this set-up means that the effect size estimates have a compound symmetric distribution. We can make this a bit more explicit by writing the sampling errors in terms of the sum of a component that’s common acrosss outcomes and a component that’s specific to each outcome. Thus, let &lt;span class=&#34;math inline&#34;&gt;\(e_i = f + g_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(f \sim N\left(0, \rho \sigma^2 \right)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(g_i \stackrel{iid}{\sim} N \left(0, (1 - \rho) \sigma^2\right)\)&lt;/span&gt;. Let me also define &lt;span class=&#34;math inline&#34;&gt;\(\zeta = \mu + u + f\)&lt;/span&gt; as the conditional mean of the effects. It then follows that the effect size estimates are &lt;em&gt;conditionally independent&lt;/em&gt;, given the common components:
&lt;span class=&#34;math display&#34;&gt;\[
\left(T_i | \zeta \right) \stackrel{iid}{\sim} N\left(\zeta, \omega^2 + (1 - \rho) \sigma^2\right)
\]&lt;/span&gt;
Furthermore, the conditional probability of a significant effect is
&lt;span class=&#34;math display&#34;&gt;\[
\text{Pr}(A_i = 1 | \zeta) = \Phi\left(\frac{\zeta - q_{\alpha} \sigma}{\sqrt{\omega^2 + (1 - \rho)\sigma^2}}\right)
\]&lt;/span&gt;
and &lt;span class=&#34;math inline&#34;&gt;\(A_1,...,A_m\)&lt;/span&gt; are mutually independent, conditional on &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt;. Therefore, the conditional distribution of &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt; is binomial,
&lt;span class=&#34;math display&#34;&gt;\[
\left(N_A | \zeta\right) \sim Bin(m, \pi)
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
\pi = \Phi\left(\frac{\zeta - q_{\alpha} \sigma}{\sqrt{\omega^2 + (1 - \rho)\sigma^2}}\right).
\]&lt;/span&gt;
What about the unconditional distribution?&lt;/p&gt;
&lt;p&gt;To get rid of the &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt;, we need to integrate over its distribution, which leads to
&lt;span class=&#34;math display&#34;&gt;\[
\text{Pr}(N_A = a) = \text{E}\left[\text{Pr}\left(N_A | \zeta\right)\right] = \int f_{N_A}\left(a | \zeta, \omega, \sigma, \rho, m\right) \times f_\zeta(\zeta | \mu, \tau, \sigma, \rho) \ d \zeta,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(f_{N_A}\left(a | \zeta, \omega, \sigma, \rho \right)\)&lt;/span&gt; is a binomial density with size &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and probability &lt;span class=&#34;math inline&#34;&gt;\(\pi = \pi(\zeta, \omega, \sigma, \rho)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(f_\zeta(\zeta | \mu, \tau, \sigma, \rho)\)&lt;/span&gt; is a normal density with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and variance &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 + \rho \sigma^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This distribution is what you might call a binomial-normal convolution or a random-intercept probit model (where the random intercept is &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt;). As far as I know, the distribution cannot be evaluated analytically but instead must be calculated using some sort of numerical integration routine. Here is &lt;a href=&#34;http://localhost:4321/distribution-of-significant-effects-graph/&#34;&gt;an interactive graph of the probability mass function&lt;/a&gt; (the probability points are calculated using Gaussian quadrature).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;just-the-moments-please&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Just the moments, please&lt;/h2&gt;
&lt;p&gt;If all we care about is the expectation of &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt;, we don’t need to bother with all the conditioning business and can just look at the marginal distribution of the effect size estimates taken individually. Marginally, &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; is normally distributed with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and variance &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 + \omega^2 + \sigma^2\)&lt;/span&gt;, so &lt;span class=&#34;math inline&#34;&gt;\(\text{Pr}(A_i = 1) = \psi\)&lt;/span&gt;, where
&lt;span class=&#34;math display&#34;&gt;\[
\psi = \Phi\left(\frac{\mu - q_{\alpha} \sigma}{\sqrt{\tau^2 + \omega^2 + \sigma^2}}\right).
\]&lt;/span&gt;
By the linearity of expectations,
&lt;span class=&#34;math display&#34;&gt;\[
\text{E}(N_A) = \sum_{i=1}^m \text{E}(A_i) = m \psi.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can also get an approximation for the variance of &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt; by working with its conditional distribution above. By the rule of variance decomposition,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{Var}(N_A) &amp;amp;= \text{E}\left[\text{Var}\left(N_A | \zeta\right)\right] + \text{Var}\left[\text{E}\left(N_A | \zeta\right)\right] \\
&amp;amp;= m \times \text{E}\left[\pi (1 - \pi)\right] + m^2 \times \text{Var}\left[\pi\right]\\
&amp;amp;= m \times \text{E}\left[\pi\right] \left(1 - \text{E}\left[\pi\right]\right) + m (m - 1) \times \text{Var}\left[\pi\right],
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; is, as defined above, a function of &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt; and thus a random variable. Now, &lt;span class=&#34;math inline&#34;&gt;\(\text{E}(\pi) = \psi\)&lt;/span&gt; and we can get something close to &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\pi)\)&lt;/span&gt; using a first-order approximation:
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(\pi\right) \approx \left(\left.\frac{\delta \pi}{\delta \zeta}\right|_{\zeta = \mu}\right)^2 \times \text{Var}\left(\zeta\right) = \left[\phi\left(\frac{\mu - q_{\alpha} \sigma}{\sqrt{\omega^2 + (1 - \rho)\sigma^2}}\right)\right]^2 \times \frac{\tau^2 + \rho \sigma^2}{\omega^2 + (1 - \rho)\sigma^2}.
\]&lt;/span&gt;
Thus,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{Var}(N_A) \approx m \times \psi \left(1 - \psi\right) + m (m - 1) \times \left[\phi\left(\frac{\mu - q_{\alpha} \sigma}{\sqrt{\omega^2 + (1 - \rho)\sigma^2}}\right)\right]^2 \times \frac{\tau^2 + \rho \sigma^2}{\omega^2 + (1 - \rho)\sigma^2}.
\end{aligned}
\]&lt;/span&gt;
If the amount of common variation is small, so &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; is near zero and &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is near zero, then the contribution of the second term will be small, and &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt; will act more or less like a binomial random variable with size &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and probability &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt;. On the other hand, if the amount of independent variation in the effect sizes is small, so &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; is near zero and &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is near 1, then the term on the right will approach &lt;span class=&#34;math inline&#34;&gt;\(m(m - 1)\psi(1 - \psi)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}\left(N_A\right)\)&lt;/span&gt; will approach &lt;span class=&#34;math inline&#34;&gt;\(m^2 \psi(1 - \psi)\)&lt;/span&gt;, or the variance of &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; times a single Bernoulli variate. So you could say that &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt; has anywhere between &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; variate’s worth of information in it, depending on the degree of correlation between the effect size estimates.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Approximating the distribution of cluster-robust Wald statistics</title>
      <link>http://localhost:4321/cluster-robust-wald-statistics/</link>
      <pubDate>Sun, 24 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/cluster-robust-wald-statistics/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\cor{{\text{cor}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;
In &lt;a href=&#34;http://doi.org/10.3102/1076998615606099&#34;&gt;Tipton and Pustejovsky (2015)&lt;/a&gt;, we examined several different small-sample approximations for cluster-robust Wald test statistics, which are like &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; statistics but based on cluster-robust variance estimators. These statistics are, frankly, kind of weird and awkward to work with, and the approximations that we examined were far from perfect. In this post, I will look in detail at the robust Wald statistic for a simple but common scenario: a one-way ANOVA problem with clusters of dependent observations.&lt;/p&gt;
&lt;p&gt;Consider a setup where clusters can be classified into one of &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; categories, with each cluster of observations falling into a single category. Let &lt;span class=&#34;math inline&#34;&gt;\(\bs\mu = \left[\mu_c \right]_{c=1}^C\)&lt;/span&gt; denote the means of these categories. Suppose we have an estimator of those means &lt;span class=&#34;math inline&#34;&gt;\(\bs{\hat\mu} = \left[\hat\mu_c\right]_{c=1}^C\)&lt;/span&gt; and a corresponding cluster-robust variance estimator &lt;span class=&#34;math inline&#34;&gt;\(\bm{V}^R = \bigoplus_{c=1}^C V^R_c\)&lt;/span&gt;. Note that &lt;span class=&#34;math inline&#34;&gt;\(\bm{V}^R\)&lt;/span&gt; is diagonal because the estimators for each category are independent.
Assume that the robust variance estimator is unbiased so &lt;span class=&#34;math inline&#34;&gt;\(\E\left(V^R_c\right) = \Var\left( \hat\mu_c \right) = \psi_c\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(c = 1,...,C\)&lt;/span&gt;.
Let &lt;span class=&#34;math inline&#34;&gt;\(\bs\Psi = \bigoplus_{c=1}^C \psi_c\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Suppose that we want to test the null hypothesis that that means of the categories are all equal, &lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1 = \mu_2 = \cdots = \mu_C\)&lt;/span&gt;. We can express this null using a &lt;span class=&#34;math inline&#34;&gt;\(q \times C\)&lt;/span&gt; contrast matrix &lt;span class=&#34;math inline&#34;&gt;\(\bm{C} = \left[-\bm{1}_q \ \bm{I}_q \right]\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(q = C - 1\)&lt;/span&gt;. The null hypothesis is then &lt;span class=&#34;math inline&#34;&gt;\(\bm{C} \bs\mu = \bm{0}_q\)&lt;/span&gt;. The corresponding cluster-robust Wald statistic is
&lt;span class=&#34;math display&#34;&gt;\[
Q = \bs{\hat\mu}&amp;#39; \bm{C}&amp;#39; \left(\bm{C} \bm{V}^R \bm{C}&amp;#39;\right)^{-1} \bm{C} \bs{\hat\mu}.
\]&lt;/span&gt;
Under the null hypothesis, the distribution of &lt;span class=&#34;math inline&#34;&gt;\(Q\)&lt;/span&gt; will converge to a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2_q\)&lt;/span&gt; as the number of clusters in each category grows large. However, with a limited number of clusters in some of the categories, this approximate reference distribution is not very accurate and tests based on it can have wildly inflated type I error rates.&lt;/p&gt;
&lt;p&gt;In the paper, we considered several different ways of approximating the distribution of &lt;span class=&#34;math inline&#34;&gt;\(Q\)&lt;/span&gt; that work at smaller sample sizes.
One class of approaches to approximating the sampling distribution of &lt;span class=&#34;math inline&#34;&gt;\(Q\)&lt;/span&gt; is to use a Hotelling’s &lt;span class=&#34;math inline&#34;&gt;\(T^2\)&lt;/span&gt; distribution with degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;. Given the degrees of freedom, Hotelling’s &lt;span class=&#34;math inline&#34;&gt;\(T^2\)&lt;/span&gt; is a multiple of an &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; distribution:
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\eta - q + 1}{\eta q} Q \sim F(q, \eta - q + 1).
\]&lt;/span&gt;
The question is then how to determine &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Several of the approaches that we considered are based on representing the &lt;span class=&#34;math inline&#34;&gt;\(Q\)&lt;/span&gt; statistic as
&lt;span class=&#34;math display&#34;&gt;\[
Q = \bm{z}&amp;#39; \bm{D}^{-1} \bm{z},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\bs\Omega = \bm{C} \bs\Psi \bm{C}&amp;#39;\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bm{z} = \bs\Omega^{-1/2}\bm{C}\hat\mu_c\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bm{G} = \bs\Omega^{-1/2} \bm{C}\)&lt;/span&gt;, and
&lt;span class=&#34;math display&#34;&gt;\[
\bm{D} = \bm{G} \bm{V}^R \bm{G}&amp;#39;.
\]&lt;/span&gt;
The various approaches we considered involve different ways of approximating the sampling distribution of &lt;span class=&#34;math inline&#34;&gt;\(\bm{D}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;One of the approximations involves finding degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; by following a strategy suggested by Zhang (&lt;a href=&#34;https://doi.org/10.1016/j.jspi.2011.07.023&#34;&gt;2012&lt;/a&gt;, &lt;a href=&#34;https://doi.org/10.14419/ijasp.v1i2.908&#34;&gt;2013&lt;/a&gt;). These degrees of freedom are given by
&lt;span class=&#34;math display&#34;&gt;\[
\eta_Z = \frac{q(q + 1)}{\sum_{s=1}^q \sum_{t = 1}^q \Var(d_{st})},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(d_{st}\)&lt;/span&gt; is the entry in row &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;, column &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(\bm{D}\)&lt;/span&gt;. To find &lt;span class=&#34;math inline&#34;&gt;\(\eta_Z\)&lt;/span&gt;, we can compute the denominator using general formulas given in the paper. However, with a bit of analysis we can find a much simpler expression for the special case of one-way ANOVA.&lt;/p&gt;
&lt;p&gt;Before going further, it’s useful to observe that &lt;span class=&#34;math inline&#34;&gt;\(\bm{D}\)&lt;/span&gt; is invariant to linear transformations of &lt;span class=&#34;math inline&#34;&gt;\(\bm{C}\)&lt;/span&gt;. In particular, an equivalent way to write the null hypothesis is as &lt;span class=&#34;math inline&#34;&gt;\(H_0: \bs\Psi_{\circ}^{-1/2} \bm{C} = \bm{0}_q\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\bs\Psi_{\circ} = \bigoplus_{c=2}^C \psi_c\)&lt;/span&gt; is the diagonal of the true sampling variances of categories 2 through &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt;, omitting the first category. Thus, let me redefine
&lt;span class=&#34;math display&#34;&gt;\[
\bs\Omega = \bs\Psi_{\circ}^{-1/2} \bm{C} \bs\Psi \bm{C}&amp;#39;\bs\Psi_{\circ}^{-1/2},
\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\bm{z} = \bs\Omega^{-1/2}\bs\Psi_{\circ}^{-1/2}\bm{C}\hat\mu_c\)&lt;/span&gt;, and
&lt;span class=&#34;math display&#34;&gt;\[
\bm{G} = \bs\Omega^{-1/2} \bs\Psi_{\circ}^{-1/2} \bm{C}.
\]&lt;/span&gt;
This transformation of the constraint matrix will make it possible to find a closed-form expression for &lt;span class=&#34;math inline&#34;&gt;\(\bs\Omega^{-1/2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now, observe that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\bs\Omega &amp;amp;= \bs\Psi_{\circ}^{-1/2} \bm{C} \bs\Psi \bm{C}&amp;#39;\bs\Psi_{\circ}^{-1/2} \\
&amp;amp;= \bs\Psi_{\circ}^{-1/2} \left(\bs\Psi_{\circ} + \psi_1 \bm{1}_q \bm{1}_q&amp;#39;\right)\bs\Psi_{\circ}^{-1/2} \\
&amp;amp;= \bm{I}_q + \psi_1 \bm{f} \bm{f}&amp;#39;,
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\bm{f} = \bs\Psi_{\circ}^{-1/2} \bm{1}_q = \left[ \psi_c^{-1/2}\right]_{c = 2}^C\)&lt;/span&gt;. From the &lt;a href=&#34;\bs\Psi_%7B\circ%7D%5E%7B-1/2%7D&#34;&gt;Woodbury identity&lt;/a&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\bs\Omega^{-1} = \bm{I} - \frac{1}{W} \bm{f} \bm{f}&amp;#39;,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(W = \sum_{c=1}^C \frac{1}{\psi_c}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.1137/22M1471559&#34;&gt;Fasi, Higham, and Liu (2023)&lt;/a&gt; provide formulas for &lt;span class=&#34;math inline&#34;&gt;\(p^{th}\)&lt;/span&gt; roots of low-rank updates to scaled identity matrices. Their results provide a neat closed-form expression for &lt;span class=&#34;math inline&#34;&gt;\(\bs\Omega^{-1/2}\)&lt;/span&gt;. From their Equation (1.9),
&lt;span class=&#34;math display&#34;&gt;\[
\bs\Omega^{-1/2} = \mathbf{I}_q - \kappa \ \bm{f} \bm{f}&amp;#39;,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\kappa = \frac{\sqrt{\psi_1}}{W \sqrt{\psi_1} + \sqrt{W}}\)&lt;/span&gt;.
Further, we can write the &lt;span class=&#34;math inline&#34;&gt;\(q \times C\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\bm{G}\)&lt;/span&gt; as
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\bm{G} &amp;amp;= \bs\Omega^{-1/2} \bs\Psi_{\circ}^{-1/2} \bm{C} \\
&amp;amp;= \left( \mathbf{I}_q - \kappa \ \bm{f} \bm{f}&amp;#39; \right) \bs\Psi_{\circ}^{-1/2} \left[-\bm{1}_q, \ \bm{I}_q \right] \\
&amp;amp;= \left[\frac{\kappa(W \psi_1 - 1) - \psi_1}{\psi_1} \bm{f},  \left( \mathbf{I}_q - \kappa \ \bm{f} \bm{f}&amp;#39; \right) \bs\Psi_{\circ}^{-1/2}\right],
\end{aligned}
\]&lt;/span&gt;
with entries given by
&lt;span class=&#34;math display&#34;&gt;\[
g_{sc} = \begin{cases}
\frac{\kappa(W \psi_1 - 1) - \psi_1}{\psi_1 \sqrt{\psi_{s+1}}} &amp;amp; \text{if} \quad c = 1 \\
\frac{I(s+1 = c)}{\sqrt{\psi_{c}}} - \frac{\kappa}{\psi_c \sqrt{\psi_{s+1}}} &amp;amp; \text{if} \quad c &amp;gt; 1.
\end{cases}
\]&lt;/span&gt;
Because &lt;span class=&#34;math inline&#34;&gt;\(\bm{D} = \bm{G} \bm{V}^R \bm{G}&amp;#39;\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bm{V}^R\)&lt;/span&gt; is diagonal, we can write the entries of &lt;span class=&#34;math inline&#34;&gt;\(\bm{D}\)&lt;/span&gt; as
&lt;span class=&#34;math display&#34;&gt;\[
d_{st} = \sum_{c=1}^C g_{sc} g_{tc} V^R_c.
\]&lt;/span&gt;
And because the variance estimators for each category are independent,
&lt;span class=&#34;math display&#34;&gt;\[
\Var(d_{st}) = \sum_{c=1}^C g_{sc}^2 g_{tc}^2 \Var(V^R_c).
\]&lt;/span&gt;
In &lt;a href=&#34;http://localhost:4321/publication/power-approximations-for-dependent-effects/&#34;&gt;prior work&lt;/a&gt;, we derived expressions for the Satterthwaite degrees of freedom for variances of average effect sizes, and the same formulas can be applied here with the category-specific &lt;span class=&#34;math inline&#34;&gt;\(V^R_c\)&lt;/span&gt;. Let me write &lt;span class=&#34;math inline&#34;&gt;\(\nu_c = 2\left[\E(V^R_c)\right]^2 / \Var(V^R_c)\)&lt;/span&gt; for the degrees of freedom corresponding to category &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;. Then
&lt;span class=&#34;math display&#34;&gt;\[
\Var(d_{st}) = 2 \sum_{c=1}^C g_{sc}^2 g_{tc}^2 \frac{\psi_c^2}{\nu_c}.
\]&lt;/span&gt;
We can use this to obtain an expression for Zhang’s approximate degrees of freedom:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
q(q + 1)\eta_Z^{-1} &amp;amp;= \sum_{s=1}^q \sum_{t = 1}^q \Var(d_{st}) \\
&amp;amp;= 2\sum_{s=1}^q \sum_{t = 1}^q \sum_{c=1}^C g_{sc}^2 g_{tc}^2 \frac{\psi_c^2}{\nu_c} \\
&amp;amp;= 2\sum_{c=1}^C \frac{\psi_c^2}{\nu_c} \left(\sum_{s=1}^q g_{sc}^2\right)^2.
\end{aligned}
\]&lt;/span&gt;
Now, all we need to do is simplify…
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\sum_{s=1}^q g_{s1}^2 &amp;amp;= \sum_{s=1}^q \frac{\left(\kappa(W \psi_1 - 1) - \psi_1\right)^2}{\psi_1^2 \psi_{s+1}} \\
&amp;amp;= \frac{\left(\kappa(W \psi_1 - 1) - \psi_1\right)^2}{\psi_1^2} \sum_{c=2}^C \frac{1}{\psi_{s+1}} \\
&amp;amp;= \frac{\left(\kappa(W \psi_1 - 1) - \psi_1\right)^2}{\psi_1^2} \frac{(W \psi_1 - 1)}{\psi_1} \\
&amp;amp;= \text{...a bunch of tedious algebra...} \\
&amp;amp;= \frac{1}{\psi_1^2} \left(\psi_1 - \frac{1}{W}\right)
\end{aligned}
\]&lt;/span&gt;
and, for &lt;span class=&#34;math inline&#34;&gt;\(c = 2,...,C\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\sum_{s=1}^q g_{sc}^2 &amp;amp;= \sum_{s=1}^q \left(\frac{I(s+1 = c)}{\sqrt{\psi_{c}}} - \frac{\kappa}{\psi_c \sqrt{\psi_{s+1}}}\right)^2 \\
&amp;amp;= \frac{1}{\psi_c} - \frac{2 \kappa}{\psi_c^2} + \frac{\kappa^2}{\psi_c^2}\sum_{s=1}^q \frac{1}{\psi_{s+1}} \\
&amp;amp;= \frac{1}{\psi_c} - \frac{2 \kappa}{\psi_c^2} + \frac{\kappa^2}{\psi_c^2}\frac{(W \psi_1 - 1)}{\psi_1} \\
&amp;amp;= \text{...a bunch of tedious algebra...} \\
&amp;amp;= \frac{1}{\psi_c^2} \left(\psi_c - \frac{1}{W}\right)
\end{aligned}
\]&lt;/span&gt;
Thus,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
q(q + 1)\eta_Z^{-1} &amp;amp;= 2\sum_{c=1}^C \frac{\psi_c^2}{\nu_c} \left(\sum_{s=1}^q g_{sc}^2\right)^2 \\
&amp;amp;= 2\sum_{c=1}^C \frac{1}{\nu_c \psi_c^2}\left(\psi_c - \frac{1}{W}\right)^2 \\
&amp;amp;= 2\sum_{c=1}^C \frac{1}{\nu_c}\left(1 - \frac{1}{\psi_c W}\right)^2
\end{aligned}
\]&lt;/span&gt;
or, rearranging,
&lt;span class=&#34;math display&#34;&gt;\[
\eta_Z = \frac{C(C - 1)}{2 \sum_{c=1}^C \frac{1}{\nu_c}\left(1 - \frac{1}{\psi_c W}\right)^2}.
\]&lt;/span&gt;
It’s a surprisingly clean formula!
Once these degrees of freedom are calculated, the degrees of freedom for the reference &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; distribution would be &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta_Z - q + 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In the paper, we also considered two other degrees of freedom approximations, which involve not only the variances of &lt;span class=&#34;math inline&#34;&gt;\(d_{st}\)&lt;/span&gt; but also the covariances between entries. In principle, one could follow similar algebra to get expressions for these other degrees of freedom as well. However, our simulations indicated that the other degrees of freedom approximations tend to be overly conservative and produce type-I error rates way below the nominal level (essentially, hardly ever rejecting the null) and less accurate than HTZ. So, there’s not much reason to work through them unless you find algebra enjoyable for its own sake.&lt;/p&gt;
&lt;p&gt;A further question about this cluster-robust Wald statistic is how to approximate its sampling distribution under specific alternative hypotheses. In other words, given a vector of means &lt;span class=&#34;math inline&#34;&gt;\(\mu_1,...,\mu_C\)&lt;/span&gt; where the null does not hold, plus some information to determine &lt;span class=&#34;math inline&#34;&gt;\(\psi_c\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\nu_c\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(c = 1,...,C\)&lt;/span&gt;, how could we approximate the distribution of &lt;span class=&#34;math inline&#34;&gt;\(Q\)&lt;/span&gt;? We need something like a non-central Hotelling’s &lt;span class=&#34;math inline&#34;&gt;\(T^2\)&lt;/span&gt; distribution…&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Equivalences between ad hoc strategies and meta-analytic models for dependent effect sizes</title>
      <link>http://localhost:4321/publication/equivalences-between-ad-hoc-strategies-and-models/</link>
      <pubDate>Thu, 07 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/equivalences-between-ad-hoc-strategies-and-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>generalized Poisson versus double Poisson</title>
      <link>http://localhost:4321/generalized-poisson-vs-double-poisson/</link>
      <pubDate>Wed, 06 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/generalized-poisson-vs-double-poisson/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(patchwork)   # composing figures
library(rstan)       # Stan interface to R
library(brms)        # fitting generalized linear models
library(bayesplot)   # Examine fitted models
library(loo)         # Model fit measures&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_qr &amp;lt;- &amp;quot;
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}

int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&amp;quot;
writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_qr, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;GPO-rng.stan&amp;quot;)
expose_stan_functions(&amp;quot;GPO-rng.stan&amp;quot;)
gpo_rng_sampler &amp;lt;- function(N, mu, phi) {
  replicate(N, gpo_rng(mu = mu, phi = phi))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The research project for which we need these distributions involves models that are quite a bit more involved than the simple GLM that I simulated above. We’re especially interested in hierarchical models that allow for cluster-level heterogeneity in both the mean and the dispersion parameter of the distribution. These models go under the heading of generalized additive models for location, scale, and shape (GAMLSS) and have been developed in the likelihood framework with the &lt;a href=&#34;https://www.gamlss.com/&#34;&gt;gamlss package&lt;/a&gt; and in the Bayesian framework with the [bamlss package].&lt;/p&gt;
&lt;p&gt;I’ll test out my generalized Poisson implementation by simulating data from a model that has random variation in the means and in the variances. The data-generating process is as follows:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
N_j &amp;amp;\sim 1 + Pois(15) \\
\ln \mu_j &amp;amp;\sim N(3.5, \ 1) \\
\ln \phi_j &amp;amp;\sim N(0.15, \ 0.15) \\
Y_{ij} &amp;amp;\sim GPO(\mu_j, \phi_j) \quad \text{for} \quad i = 1,...,N_j
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;all for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;. The specified distribution of &lt;span class=&#34;math inline&#34;&gt;\(\phi_j\)&lt;/span&gt;’s leads to dispersions ranging from about 0.61 to 1.22, with a median of 0.86 and and IQR of 0.78 to 0.95.&lt;/p&gt;
&lt;p&gt;Here’s a simulation from the model with &lt;span class=&#34;math inline&#34;&gt;\(J = 80\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(20231205)
J &amp;lt;- 80

dat &amp;lt;- 
  tibble(
    ID = 1:J, 
    N = 1L + rpois(J, lambda = 15), 
    log_mu = rnorm(J, mean = 3.5, sd = 1), 
    log_phi = rnorm(J, mean = 0.15, sd = 0.15)
  ) %&amp;gt;%
  mutate(
    Y = pmap(list(N = N, mu = exp(log_mu), phi = exp(log_phi)), gpo_rng_sampler)
  ) %&amp;gt;%
  unnest(Y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let me try fitting some models. I’ll first try fitting some GLMMs, which include random intercepts on the mean term but not on the dispersions. Just for kicks, I’ll use both the generalized Poisson (i.e., the true distribution) and the double Poisson (which is mis-specified).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_gpo &amp;lt;- &amp;quot;
real gpo_lpmf(int X, real mu, real phi) {
  real ans;
  real m = mu / (1 - inv(sqrt(phi)));
  real z = X + sqrt(phi) * (mu - X);
  if (phi &amp;gt; 1 &amp;amp;&amp;amp; X &amp;gt; m)
    ans = negative_infinity();
  else 
    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);
  return ans;
}
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}
int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&amp;quot;
generalized_Poisson &amp;lt;- custom_family(
  &amp;quot;gpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)

generalized_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_gpo, block = &amp;quot;functions&amp;quot;)

phi_prior &amp;lt;- prior(exponential(1), class = &amp;quot;phi&amp;quot;)

# Fit GPO model with mean random effects
glmm_gpo &amp;lt;- brm(
  Y ~ 1 + (1 | ID),
  data = dat,
  family = generalized_Poisson,
  stanvars = generalized_Poisson_stanvars,
  prior = phi_prior,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4,
  control = list(adapt_delta = 0.80)
)

expose_functions(glmm_gpo, vectorize = TRUE)

log_lik_gpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  gpo_lpmf(y, mu, phi)
}

posterior_predict_gpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  gpo_rng(mu, phi)
}

summary(glmm_gpo)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gpo 
##   Links: mu = log; phi = identity 
## Formula: Y ~ 1 + (1 | ID) 
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.03      0.08     0.89     1.22 1.01      184      392
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     3.31      0.11     3.07     3.52 1.06      120      203
## 
## Family Specific Parameters: 
##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## phi     1.09      0.05     1.01     1.18 1.00     3276     4630
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_dpo &amp;lt;- &amp;quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
int dpo_quantile(real p, real mu, real phi, int maxval) {
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int q = 0;
  while (cdf_vec[q + 1] &amp;lt; p) {
      q += 1;
    }
  return q;
}
int dpo_rng(real mu, real phi, int maxval) {
  real p = uniform_rng(0,1);
  int x = dpo_quantile(p, mu, phi, maxval);
  return x;
}
&amp;quot;
double_Poisson &amp;lt;- custom_family(
  &amp;quot;dpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)

double_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_dpo, block = &amp;quot;functions&amp;quot;)

# Fit DPO model with mean random effects
glmm_dpo &amp;lt;- brm(
  Y ~ 1 + (1 | ID),
  data = dat,
  family = double_Poisson,
  stanvars = double_Poisson_stanvars,
  prior = phi_prior,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4,
  control = list(adapt_delta = 0.80)
)

expose_functions(glmm_dpo, vectorize = TRUE)

log_lik_dpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  dpo_lpmf(y, mu, phi)
}

posterior_predict_dpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  if (is.null(maxval)) maxval &amp;lt;- 20 * mu / min(phi, 1)
  dpo_rng(mu, phi, maxval = maxval)
}


summary(glmm_dpo)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: dpo 
##   Links: mu = log; phi = identity 
## Formula: Y ~ 1 + (1 | ID) 
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.05      0.09     0.91     1.25 1.02      150      209
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     3.31      0.12     3.08     3.54 1.12       30      179
## 
## Family Specific Parameters: 
##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## phi     1.08      0.04     0.99     1.17 1.00     1435     2708
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll now fit the actual data-generating model, which has random dispersion terms in addition to the random intercepts on the mean. I’ll also try out the same model specification, but with the double Poisson distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit GPO model with mean and dispersion random effects
gamlss_gpo &amp;lt;- brm(
  bf(
    Y ~ 1 + (1 | a | ID),
    phi ~ 1 + (1 | a | ID)
  ),
  data = dat,
  family = generalized_Poisson,
  stanvars = generalized_Poisson_stanvars,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4
)

summary(gamlss_gpo)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gpo 
##   Links: mu = log; phi = log 
## Formula: Y ~ 1 + (1 | a | ID) 
##          phi ~ 1 + (1 | a | ID)
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##                              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)                    1.04      0.08     0.90     1.22 1.00      577
## sd(phi_Intercept)                0.21      0.07     0.04     0.34 1.00     1987
## cor(Intercept,phi_Intercept)     0.22      0.24    -0.26     0.70 1.00     6380
##                              Tail_ESS
## sd(Intercept)                    1282
## sd(phi_Intercept)                1909
## cor(Intercept,phi_Intercept)     3532
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept         3.31      0.11     3.08     3.53 1.02      225      593
## phi_Intercept     0.11      0.05     0.02     0.22 1.00     5237     5580
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit DPO model with mean and dispersion random effects
gamlss_dpo &amp;lt;- brm(
  bf(
    Y ~ 1 + (1 | a | ID),
    phi ~ 1 + (1 | a | ID)
  ),
  data = dat,
  family = double_Poisson,
  stanvars = double_Poisson_stanvars,
  warmup = 1000,
  iter = 3000,
  chains = 4, 
  cores = 4
)

summary(gamlss_dpo)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: dpo 
##   Links: mu = log; phi = log 
## Formula: Y ~ 1 + (1 | a | ID) 
##          phi ~ 1 + (1 | a | ID)
##    Data: dat (Number of observations: 1213) 
##   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 80) 
##                              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)                    1.04      0.09     0.88     1.24 1.02      413
## sd(phi_Intercept)                0.19      0.08     0.03     0.33 1.00     1209
## cor(Intercept,phi_Intercept)     0.39      0.26    -0.10     0.91 1.00     2846
##                              Tail_ESS
## sd(Intercept)                     795
## sd(phi_Intercept)                1115
## cor(Intercept,phi_Intercept)     1588
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept         3.31      0.13     3.06     3.56 1.03      112      191
## phi_Intercept     0.09      0.05    -0.00     0.19 1.00     3386     5390
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We get some rather odd results. The simpler GLMMs have better fit (as indicated by LOOIC) than the GAMLSS models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_comparison &amp;lt;- loo(glmm_gpo, glmm_dpo, gamlss_gpo, gamlss_dpo)
loo_comparison$diffs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            elpd_diff se_diff
## gamlss_gpo  0.0       0.0   
## gamlss_dpo -1.3       0.9   
## glmm_gpo   -2.4       2.9   
## glmm_dpo   -3.9       2.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of the models also estimate some degree of over-dispersion (&lt;span class=&#34;math inline&#34;&gt;\(\phi &amp;lt; 1\)&lt;/span&gt;) on average. Curious.&lt;/p&gt;
&lt;div id=&#34;colophon&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Colophon&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19045)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] gamlss.dist_6.0-3   MASS_7.3-57         loo_2.5.1          
##  [4] bayesplot_1.9.0     brms_2.18.0         Rcpp_1.0.10        
##  [7] rstan_2.26.23       StanHeaders_2.26.27 patchwork_1.1.3    
## [10] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0      
## [13] dplyr_1.1.2         purrr_1.0.2         readr_2.1.4        
## [16] tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3      
## [19] tidyverse_2.0.0    
## 
## loaded via a namespace (and not attached):
##   [1] TH.data_1.1-2        colorspace_2.1-0     RcppEigen_0.3.3.9.2 
##   [4] ellipsis_0.3.2       ggridges_0.5.3       estimability_1.3    
##   [7] markdown_1.7         QuickJSR_1.0.5       base64enc_0.1-3     
##  [10] rstudioapi_0.15.0    farver_2.1.1         DT_0.29             
##  [13] fansi_1.0.4          mvtnorm_1.1-3        bridgesampling_1.1-2
##  [16] codetools_0.2-18     splines_4.2.2        cachem_1.0.6        
##  [19] knitr_1.40           shinythemes_1.2.0    jsonlite_1.8.4      
##  [22] shiny_1.7.4          compiler_4.2.2       emmeans_1.7.3       
##  [25] backports_1.4.1      Matrix_1.6-3         fastmap_1.1.0       
##  [28] cli_3.6.1            later_1.3.0          htmltools_0.5.4     
##  [31] prettyunits_1.1.1    tools_4.2.2          igraph_1.3.5        
##  [34] coda_0.19-4          gtable_0.3.4         glue_1.6.2          
##  [37] reshape2_1.4.4       posterior_1.3.1      jquerylib_0.1.4     
##  [40] vctrs_0.6.3          nlme_3.1-157         blogdown_1.10       
##  [43] crosstalk_1.2.0      tensorA_0.36.2       xfun_0.40           
##  [46] ps_1.6.0             timechange_0.2.0     mime_0.12           
##  [49] miniUI_0.1.1.1       lifecycle_1.0.3      gtools_3.9.3        
##  [52] zoo_1.8-10           scales_1.2.1         colourpicker_1.1.1  
##  [55] hms_1.1.3            promises_1.2.0.1     Brobdingnag_1.2-9   
##  [58] parallel_4.2.2       sandwich_3.0-1       inline_0.3.19       
##  [61] shinystan_2.6.0      yaml_2.3.5           gridExtra_2.3       
##  [64] sass_0.4.5           stringi_1.7.12       dygraphs_1.1.1.6    
##  [67] checkmate_2.1.0      pkgbuild_1.3.1       rlang_1.1.1         
##  [70] pkgconfig_2.0.3      matrixStats_0.62.0   BH_1.78.0-0         
##  [73] distributional_0.3.1 evaluate_0.18        lattice_0.20-45     
##  [76] rstantools_2.2.0     htmlwidgets_1.6.2    processx_3.7.0      
##  [79] tidyselect_1.2.0     plyr_1.8.8           magrittr_2.0.3      
##  [82] bookdown_0.26        R6_2.5.1             generics_0.1.3      
##  [85] multcomp_1.4-23      pillar_1.9.0         withr_2.5.0         
##  [88] xts_0.12.1           survival_3.4-0       abind_1.4-5         
##  [91] crayon_1.5.2         utf8_1.2.3           tzdb_0.3.0          
##  [94] rmarkdown_2.18       grid_4.2.2           callr_3.7.2         
##  [97] threejs_0.3.3        digest_0.6.30        xtable_1.8-4        
## [100] httpuv_1.6.8         RcppParallel_5.1.5   stats4_4.2.2        
## [103] munsell_0.5.0        bslib_0.4.2          shinyjs_2.1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Implementing Consul&#39;s generalized Poisson distribution in Stan</title>
      <link>http://localhost:4321/generalized-poisson-in-stan/</link>
      <pubDate>Wed, 06 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/generalized-poisson-in-stan/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a project I am working on, we are using &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; to fit generalized random effects location-scale models to a bunch of count data.
In &lt;a href=&#34;http://localhost:4321/double-poisson-in-Stan/&#34;&gt;a previous post&lt;/a&gt;, I walked through our implementation of &lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron’s (1986)&lt;/a&gt; double-Poisson distribution, which we are interested in using because it allows for both over- and under-dispersion relative to the Poisson distribution.
Another distribution with these properties is the generalized Poisson distribution described by &lt;a href=&#34;https://doi.org/10.1080/00401706.1973.10489112&#34;&gt;Consul and Jain (1973)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this post, I’ll walk through my implementation of the GPO in Stan.
The &lt;a href=&#34;https://cran.r-project.org/package=gamlss.dist&#34;&gt;&lt;code&gt;gamlss.dist&lt;/code&gt; package&lt;/a&gt; provides a full set of distributional functions for the generalized Poisson distribution, including a sampler, but the functions are configured to only allow for over-dispersion. Since I’m interested in allowing for under-dispersion as well, I’ll need to write my own functions. As in my previous post, I can validate my Stan functions against the functions from &lt;code&gt;gamlss.dist&lt;/code&gt; (although only for over-dispersion scenarios).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(patchwork)   # composing figures
library(gamlss.dist) # DPO distribution functions
library(rstan)       # Stan interface to R
library(brms)        # fitting generalized linear models
library(bayesplot)   # Examine fitted models
library(loo)         # Model fit measures&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-generalized-poisson&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The generalized Poisson&lt;/h2&gt;
&lt;p&gt;Consul and Jain’s generalized Poisson distribution is a discrete distribution for non-negative counts, with support &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{S}_X = \{0, 1, 2, 3, ...\}\)&lt;/span&gt;.
The mean-variance relationship of the generalized Poisson is constant; for &lt;span class=&#34;math inline&#34;&gt;\(X \sim GPO(\mu, \phi)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{E}(X) = \mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(X) = \mu / \phi\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(0 &amp;lt; \phi &amp;lt; 1\)&lt;/span&gt;; the expectation and variance are not exact but are close approximations when there is underdispersion, so &lt;span class=&#34;math inline&#34;&gt;\(\phi &amp;gt; 1\)&lt;/span&gt;. Thus, like the double-Poisson distribution, the generalized Poisson satisfies the assumptions of a quasi-Poisson generalized linear model (at least approximately).&lt;/p&gt;
&lt;p&gt;The density of the generalized Poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and inverse-disperson &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
f(x | \mu, \phi) = \mu \sqrt{\phi} \left( x + \sqrt{\phi}(\mu - x) \right)^{x-1} \frac{\exp \left[-\left( x + \sqrt{\phi}(\mu - x)\right)\right]}{x!}.
\]&lt;/span&gt;
We then have
&lt;span class=&#34;math display&#34;&gt;\[
\ln f(x | \mu, \phi) = \frac{1}{2} \ln \phi + \ln \mu + (x - 1) \ln \left( x + \sqrt{\phi}(\mu - x) \right) - \left( x + \sqrt{\phi}(\mu - x) \right) - \ln \left(x!\right).
\]&lt;/span&gt;
Using the GPO with under-dispersed data is a little bit more controversial (by statistical standards) than using the DPO.
This is because, for parameter values corresponding to under-dispersion, its probability mass function becomes negative for large counts. In particular, note that for values &lt;span class=&#34;math inline&#34;&gt;\(x &amp;gt; \frac{\mu\sqrt\phi}{\sqrt\phi - 1}\)&lt;/span&gt;, the quantity &lt;span class=&#34;math inline&#34;&gt;\(x + \sqrt{\phi}(\mu - x)\)&lt;/span&gt; becomes negative, and so &lt;span class=&#34;math inline&#34;&gt;\(f(x| \mu, \phi)\)&lt;/span&gt; is no longer a proper probability.
Consul suggested handling this situation by truncating the distribution at &lt;span class=&#34;math inline&#34;&gt;\(m = \left\lfloor \frac{\mu\sqrt\phi}{\sqrt\phi - 1}\right\rfloor\)&lt;/span&gt;. However, doing so makes the distribution only an approximation, such that &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is no longer exactly the mean and &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is no longer exactly the inverse dispersion.
For modest under-dispersion of no less than 60% of the mean, &lt;span class=&#34;math inline&#34;&gt;\(1 &amp;lt; \phi &amp;lt; 5 / 3\)&lt;/span&gt; and the truncation point is fairly extreme, with &lt;span class=&#34;math inline&#34;&gt;\(m \approx 4.4 \mu\)&lt;/span&gt;, so I’m not too worried about this issue.
We’ll see how it plays out in application, of course.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;log-of-the-probability-mass-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Log of the probability mass function&lt;/h1&gt;
&lt;p&gt;Here’s a Stan function implementing the lpmf, with the truncation bit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_lpmf &amp;lt;- &amp;quot;
real gpo_lpmf(int X, real mu, real phi) {
  real ans;
  real m = mu / (1 - inv(sqrt(phi)));
  real z = X + sqrt(phi) * (mu - X);
  if (phi &amp;gt; 1 &amp;amp;&amp;amp; X &amp;gt; m)
    ans = negative_infinity();
  else 
    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);
  return ans;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check that this is accurate, I’ll compare the Stan function to the corresponding function from &lt;code&gt;gamlss.dist&lt;/code&gt; for a couple of different parameter values and for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,100\)&lt;/span&gt;. If my function is accurate, my calculated log-probabilities should be equal to the results from &lt;code&gt;gamlss.dist::dGPO&lt;/code&gt;. Note that the &lt;code&gt;gamlss.dist&lt;/code&gt; function uses a different parameterization for the dispersion, with &lt;span class=&#34;math inline&#34;&gt;\(\sigma = \frac{\phi^{-1/2} - 1}{\mu}\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_lpmf, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;GPO-lpmf.stan&amp;quot;)
expose_stan_functions(&amp;quot;GPO-lpmf.stan&amp;quot;)

test_lpmf &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
    X = 0:100
  ) %&amp;gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    gamlss_lpmf = dGPO(x = X, mu = mu, sigma = sigma, log = TRUE),
    my_lpmf = pmap_dbl(.l = list(X = X, mu = mu, phi = phi), .f = gpo_lpmf),
    diff = my_lpmf - gamlss_lpmf
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_lpmf, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Checks out. Onward!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quantile-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quantile function&lt;/h1&gt;
&lt;p&gt;I’ll next implement the generalized Poisson quantile function, taking advantage of a recurrence relationship for sequential values. Note that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(0 | \mu, \phi) &amp;amp;= \exp \left(-\mu \sqrt{\phi}\right) \\
f(x | \mu, \phi) &amp;amp;= f(x - 1 | \mu, \phi) \times \frac{\left(x + \sqrt{\phi}(\mu - x)\right)^{x - 1}}{\left(x - 1 + \sqrt{\phi}(\mu - (x - 1))\right)^{x - 2}} \times \frac{\exp(\sqrt{\phi} - 1)}{x}
\end{aligned}
\]&lt;/span&gt;
where the second expression holds for &lt;span class=&#34;math inline&#34;&gt;\(x \geq 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The function below computes the quantile given a value &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; by computing the cumulative distribution function until &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is exceeded:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_quantile &amp;lt;- &amp;quot; 
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If my quantile function is accurate, it should match the value computed from &lt;code&gt;gamlss.dist::qDPO()&lt;/code&gt; exactly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_quantile, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;GPO-quantile.stan&amp;quot;)
expose_stan_functions(&amp;quot;GPO-quantile.stan&amp;quot;)

test_quantile &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
  ) %&amp;gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    p = map(1:n(), ~ runif(100)),
  ) %&amp;gt;%
  unnest(p) %&amp;gt;%
  mutate(
    my_q = pmap_dbl(list(p = p, mu = mu, phi = phi), .f = gpo_quantile),
    gamlss_q = qGPO(p, mu = mu, sigma = sigma),
    diff = my_q - gamlss_q
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_quantile, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/check-quantile-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I should enter this figure in the competition for the world’s most boring statistical graphic.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sampler&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sampler&lt;/h1&gt;
&lt;p&gt;The last thing I’ll need is a sampler, which I’ll implement by generating random points from a uniform distribution, then computing the generalized Poisson quantiles of these random points. My implementation just generates a single random variate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_qr &amp;lt;- &amp;quot;
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}

int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check this function, I’ll generate some large samples from the generalized Poisson with a few different parameter sets. If the sampler is working properly, the empirical cumulative distribution should line up closely with the cumulative distribution computed using &lt;code&gt;gamlss.dist::pGPO()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_qr, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;GPO-rng.stan&amp;quot;)
expose_stan_functions(&amp;quot;GPO-rng.stan&amp;quot;)

gpo_rng_sampler &amp;lt;- function(N, mu, phi) {
  replicate(N, gpo_rng(mu = mu, phi = phi))
}

test_rng &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = seq(0.1, 0.9, 0.1),
  ) %&amp;gt;%
  mutate(
    sigma = (phi^(-1/2) - 1) / mu,
    x = pmap(.l = list(N = 10000, mu = mu, phi = phi), .f = gpo_rng_sampler),
    tb = map(x, ~ as.data.frame(table(.x)))
  ) %&amp;gt;%
  dplyr::select(-x) %&amp;gt;%
  group_by(mu, phi) %&amp;gt;%
  unnest(tb) %&amp;gt;%
  mutate(
    .x = as.integer(levels(.x))[.x],
    Freq_cum = cumsum(Freq) / 10000,
    gamlss_F = pGPO(q = .x, mu = mu, sigma = sigma)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_rng, aes(gamlss_F, Freq_cum, color = factor(phi))) + 
  geom_abline(slope = 1, color = &amp;quot;blue&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) + 
  geom_point() + geom_line() +  
  facet_grid(phi ~ mu, labeller = &amp;quot;label_both&amp;quot;) + 
  theme_minimal() + 
  labs(x = &amp;quot;Theoretical cdf (gamlss.dist)&amp;quot;, y = &amp;quot;Empirical cdf (my function)&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/check-rng-plot-1.png&#34; width=&#34;672&#34; /&gt;
Another approach to checking the sampler is to simulate a bunch of observations and check whether the empirical mean and variance match the theoretical moments. I’ll do this as well, using some values of &lt;span class=&#34;math inline&#34;&gt;\(\phi &amp;gt; 1\)&lt;/span&gt; to test whether the sampler still works when there’s under-dispersion.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test_moments &amp;lt;- 
  expand_grid(
    mu = c(5, 10, 20, 40, 60),
    phi = seq(1, 2, 0.1),
  ) %&amp;gt;%
  mutate(
    x = pmap(.l = list(N = 1e5, mu = mu, phi = phi), .f = gpo_rng_sampler),
    M = map_dbl(x, mean),
    S = map_dbl(x, sd),
    M_ratio = M / mu,
    S_ratio = S / sqrt(mu / phi)
  ) %&amp;gt;%
  dplyr::select(-x) %&amp;gt;%
  pivot_longer(ends_with(&amp;quot;_ratio&amp;quot;),names_to = &amp;quot;moment&amp;quot;,values_to = &amp;quot;ratio&amp;quot;) %&amp;gt;%
  mutate(
    moment = factor(moment, levels = c(&amp;quot;M_ratio&amp;quot;, &amp;quot;S_ratio&amp;quot;), labels = c(&amp;quot;Sample mean&amp;quot;, &amp;quot;Standard deviation&amp;quot;)),
    mu = factor(mu)
  )

ggplot(test_moments, aes(phi, ratio, color = mu)) + 
  geom_point() + geom_line() + 
  facet_wrap(~ moment) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/test-sample-moments-1.png&#34; width=&#34;768&#34; /&gt;
Looks like the sample moments closely match the parameter values, with deviations that look pretty much like random error. Nice!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-custom-distribution-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using the custom distribution functions&lt;/h1&gt;
&lt;p&gt;To finish out my tests of these functions, I’ll try out a small simulation. Following my &lt;a href=&#34;http://localhost:4321/Double-Poisson-in-Stan/&#34;&gt;previous post&lt;/a&gt;, I’ll generate data based on a generalized linear model with a single predictor &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, where the outcome &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; follows a generalized Poisson distribution conditional on &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The data-generating process is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
X &amp;amp;\sim \Gamma(6,2) \\
Y|X &amp;amp;\sim GPO(\mu(X), \phi) \\
\log \mu(X) &amp;amp;= 2 + 0.3 \times X
\end{aligned}
\]&lt;/span&gt;
with the dispersion parameter set to &lt;span class=&#34;math inline&#34;&gt;\(\phi = 6/10\)&lt;/span&gt; so that the outcome is &lt;em&gt;over&lt;/em&gt;-dispersed. I’m looking at over-dispersion here so that the negative binomial has a chance to keep up, since it doesn’t allow for any degree of under-dispersion.&lt;/p&gt;
&lt;p&gt;The following code generates a large sample from the data-generating process:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(20231206)
N &amp;lt;- 1500
X &amp;lt;- rgamma(N, shape = 6, rate = 2)
mu &amp;lt;- exp(2 + 0.3 * X)
phi &amp;lt;- 6 / 10
Y &amp;lt;- map_dbl(mu, gpo_rng, phi = phi)
dat &amp;lt;- data.frame(X = X, Y = Y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what the sample looks like, along with a smoothed regression estimated using a basic cubic spline:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat, aes(X, Y)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = &amp;#39;gam&amp;#39;, formula = y ~ s(x, bs = &amp;quot;cs&amp;quot;)) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/glm-scatterplot-1.png&#34; width=&#34;576&#34; /&gt;
Here is a fit using quasi-likelihood estimation of a log-linear model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quasi_fit &amp;lt;- glm(Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
summary(quasi_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.3261  -0.9290  -0.0912   0.7371   5.0944  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 1.981959   0.020609   96.17   &amp;lt;2e-16 ***
## X           0.306733   0.005525   55.52   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 1.680427)
## 
##     Null deviance: 7248.1  on 1499  degrees of freedom
## Residual deviance: 2520.5  on 1498  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This approach recovers the data-generating parameters quite well, with a dispersion estimate of 1.68 compared to the true dispersion parameter of 1.67.&lt;/p&gt;
&lt;div id=&#34;candidate-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Candidate models&lt;/h2&gt;
&lt;p&gt;Now let me fit the same generalized linear model but assuming that the outcome follow a couple of different distributions, including a true Poisson (with unit dispersion), a negative binomial, the double-Poisson distribution from the previous post, and the generalized Poisson distribution. Here goes!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Poisson_fit &amp;lt;- 
  brm(
    Y ~ X, family = poisson(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 2500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;negbin_fit &amp;lt;- 
  brm(
    Y ~ X, family = negbinomial(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 2500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_dpo &amp;lt;- &amp;quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
int dpo_quantile(real p, real mu, real phi, int maxval) {
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int q = 0;
  while (cdf_vec[q + 1] &amp;lt; p) {
      q += 1;
    }
  return q;
}
int dpo_rng(real mu, real phi, int maxval) {
  real p = uniform_rng(0,1);
  int x = dpo_quantile(p, mu, phi, maxval);
  return x;
}
&amp;quot;
double_Poisson &amp;lt;- custom_family(
  &amp;quot;dpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)

double_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_dpo, block = &amp;quot;functions&amp;quot;)

phi_prior &amp;lt;- prior(exponential(1), class = &amp;quot;phi&amp;quot;)

DPO_fit &amp;lt;- 
  brm(
    Y ~ X, family = double_Poisson,
    prior = phi_prior,
    stanvars = double_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 2500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )

expose_functions(DPO_fit, vectorize = TRUE)

log_lik_dpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  dpo_lpmf(y, mu, phi)
}

posterior_predict_dpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  if (is.null(maxval)) maxval &amp;lt;- 20 * mu / min(phi, 1)
  dpo_rng(mu, phi, maxval = maxval)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_gpo &amp;lt;- &amp;quot;
real gpo_lpmf(int X, real mu, real phi) {
  real ans;
  real m = mu / (1 - inv(sqrt(phi)));
  real z = X + sqrt(phi) * (mu - X);
  if (phi &amp;gt; 1 &amp;amp;&amp;amp; X &amp;gt; m)
    ans = negative_infinity();
  else 
    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);
  return ans;
}
int gpo_quantile(real p, real mu, real phi) {
  int q = 0;
  real phi_sqrt = sqrt(phi);
  real mu_phi_sqrt = mu * phi_sqrt;
  real m;
  if (phi &amp;gt; 1) 
    m = mu / (1 - inv(phi_sqrt));
  else 
    m = positive_infinity();
  real lpmf = - mu_phi_sqrt;
  real cdf = exp(lpmf);
  real ln_inc;
  while (cdf &amp;lt; p &amp;amp;&amp;amp; q &amp;lt; m) {
    q += 1;
    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);
    lpmf += ln_inc;    
    cdf += exp(lpmf);
  }
  return q;
}
int gpo_rng(real mu, real phi) {
  real p = uniform_rng(0,1);
  int x = gpo_quantile(p, mu, phi);
  return x;
}
&amp;quot;
generalized_Poisson &amp;lt;- custom_family(
  &amp;quot;gpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)

generalized_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_gpo, block = &amp;quot;functions&amp;quot;)

phi_prior &amp;lt;- prior(exponential(1), class = &amp;quot;phi&amp;quot;)

GPO_fit &amp;lt;- 
  brm(
    Y ~ X, family = generalized_Poisson,
    prior = phi_prior,
    stanvars = generalized_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 2500, 
    chains = 4, 
    cores = 4,
    seed = 20231204
  )

expose_functions(GPO_fit, vectorize = TRUE)

log_lik_gpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  gpo_lpmf(y, mu, phi)
}

posterior_predict_gpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  gpo_rng(mu, phi)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model comparison&lt;/h2&gt;
&lt;p&gt;Here is a comparison of LOOIC for all of the models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_comparison &amp;lt;- loo(Poisson_fit, negbin_fit, DPO_fit, GPO_fit)
loo_comparison$diffs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             elpd_diff se_diff
## DPO_fit        0.0       0.0 
## GPO_fit       -2.9       2.8 
## negbin_fit    -8.9       4.4 
## Poisson_fit -120.7      20.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model based on the double-Poisson distribution fits equally well to the true data-generating process here, suggesting that there’s really just not enough information to distriguish between the two models. The negative binomial distribution fit is substantially worse, and the Poisson distribution fit is awful.&lt;/p&gt;
&lt;p&gt;Here’s the posterior for the dispersion (i.e., &lt;span class=&#34;math inline&#34;&gt;\(1 / \phi\)&lt;/span&gt;) based on the GPO and DPO models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_scheme_set(&amp;quot;green&amp;quot;)
GPO_dispersion &amp;lt;- 
  mcmc_areas(GPO_fit, pars = &amp;quot;phi&amp;quot;, transformations = \(x) 1 / x) + 
  theme_minimal() + 
  ggtitle(&amp;quot;Generalized Poisson&amp;quot;)

color_scheme_set(&amp;quot;brightblue&amp;quot;)
DPO_dispersion &amp;lt;- 
  mcmc_areas(DPO_fit, pars = &amp;quot;phi&amp;quot;, transformations = \(x) 1 / x) + 
  theme_minimal() + 
  ggtitle(&amp;quot;Double Poisson&amp;quot;)

DPO_dispersion / GPO_dispersion &amp;amp; 
  xlim(1.5, 2.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/dispersion-comparison-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Right on par. To get a better sense of model fit, I’ll run some posterior predictive checks, using the quasi-likelihood dispersion as a summary statistic:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yrep_Poisson &amp;lt;- posterior_predict(Poisson_fit, ndraws = 500) 
Yrep_negbin &amp;lt;- posterior_predict(negbin_fit, ndraws = 500)
Yrep_dpo &amp;lt;- posterior_predict(DPO_fit, ndraws = 500)
Yrep_gpo &amp;lt;- posterior_predict(GPO_fit, ndraws = 500)

dispersion_coef &amp;lt;- function(y) {
  quasi_fit &amp;lt;- glm(y ~ dat$X, family = quasipoisson(link = &amp;quot;log&amp;quot;))
  sum(residuals(quasi_fit, type = &amp;quot;pearson&amp;quot;)^2) / quasi_fit$df.residual
}

color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_disp &amp;lt;- ppc_stat(dat$Y, Yrep_Poisson, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
negbin_disp &amp;lt;- ppc_stat(dat$Y, Yrep_negbin, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;brightblue&amp;quot;)
dpo_disp &amp;lt;- ppc_stat(dat$Y, Yrep_dpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Double Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
gpo_disp &amp;lt;- ppc_stat(dat$Y, Yrep_gpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Generalized Poisson&amp;quot;)

Poisson_disp / negbin_disp / dpo_disp / gpo_disp &amp;amp;
  theme_minimal() &amp;amp; 
  xlim(c(0.8, 2.1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/ppc-dispersion-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both the double Poisson and the generalized Poisson models generate data with levels of dispersion similar to the observed data. The negative binomial distribution is not noticeably worse.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;marginal-posterior-predictive-densities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Marginal posterior predictive densities&lt;/h2&gt;
&lt;p&gt;Here’s some rootograms for the posterior predictive density of the raw outcomes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_Poisson, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Poisson&amp;quot;)
color_scheme_set(&amp;quot;purple&amp;quot;)
negbin_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_negbin, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Negative-binomial&amp;quot;)
color_scheme_set(&amp;quot;brightblue&amp;quot;)
dpo_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_dpo, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Double Poisson&amp;quot;)
color_scheme_set(&amp;quot;green&amp;quot;)
gpo_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_gpo, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Generalized Poisson&amp;quot;)

Poisson_root / negbin_root / dpo_root / gpo_root &amp;amp;
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/ppd-1.png&#34; width=&#34;672&#34; /&gt;
You can see from these that the Poisson model maybe expects slightly fewer low counts and slightly fewer high counts than are present in the observed data. However, the figure doesn’t really capture the degree of mis-fit that is apparent with the dispersion summary statistics. I think this is because the distribution of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; changes so much depending on the value of the predictor &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posterior-predictive-residual-densities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Posterior predictive residual densities&lt;/h2&gt;
&lt;p&gt;One way to focus in on the distributional assumption is to examine the distribution of residuals rather than raw outcomes. I’ll do that here by looking the deviance residuals from the quasi-Poisson GLM model, treating the calculation of the residuals as merely a transformation of the raw data. Here are some posterior predictive density plots of these deviance residuals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# quasi-Poisson deviance residuals
dat$resid &amp;lt;- residuals(quasi_fit)

# function to calculate quasi-Poisson deviance residuals
quasi_residuals &amp;lt;- function(y) as.numeric(residuals(glm(y ~ dat$X, family = quasipoisson(link = &amp;quot;log&amp;quot;))))

# transform posterior predictive data into residuals
R &amp;lt;- 50
resid_Poisson &amp;lt;- apply(Yrep_Poisson[1:R,], 1, quasi_residuals) |&amp;gt; t()
resid_negbin &amp;lt;- apply(Yrep_negbin[1:R,], 1, quasi_residuals) |&amp;gt; t()
resid_dpo &amp;lt;- apply(Yrep_dpo[1:R,], 1, quasi_residuals) |&amp;gt; t()
resid_gpo &amp;lt;- apply(Yrep_gpo[1:R,], 1, quasi_residuals) |&amp;gt; t()

# make density plots
color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_Poisson) + labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
negbin_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_negbin) + labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;brightblue&amp;quot;)
dpo_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_dpo) + labs(title = &amp;quot;Double Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
gpo_resid_density &amp;lt;- ppc_dens_overlay(dat$resid, resid_gpo) + labs(title = &amp;quot;Generalized Poisson&amp;quot;)

Poisson_resid_density / negbin_resid_density / dpo_resid_density / gpo_resid_density &amp;amp;
  theme_minimal() &amp;amp; 
  xlim(c(-3.5, 3.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/ppd-residuals-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s quite a bit clearer from these plots that the DPO and GPO models are closer to replicating the distribution of the data than the Poisson model.
The negative binomial model is not obviously mis-specified either.&lt;/p&gt;
&lt;p&gt;A notable difference between the negative binomial versus the DPO and GPO distributions is in the form of the mean-variance relationship.
For the negative binomial, the variance increases with the square of the mean, whereas for the DPO and GPO, the variance increases in constant proportion to the mean.
The residual posterior density plots above don’t really capture these mean-variance relationships in an obvious way.
I took one more crack at a posterior predictive check to get at this.
Below is a figure showing the loess smooth of the squared residuals versus &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; based on the posterior predictive distributions versus the real data. I couldn’t find an easy way to do this with the &lt;code&gt;bayesplot&lt;/code&gt; functions I’ve used above, so I had to bang it out in regular &lt;code&gt;ggplot&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X_grid &amp;lt;- seq(min(dat$X), max(dat$X), length.out = 200)

smooth_square_resid &amp;lt;- function(r, x_dat, X_pred = X_grid) {
  loess_fit &amp;lt;- loess(I(r^2) ~ x_dat)
  predict(loess_fit, newdata = data.frame(x_dat = X_pred))
}

dat$sm &amp;lt;- smooth_square_resid(r = dat$resid, x_dat = dat$X, X_pred = dat$X)

smooth_square_resid_ppcs &amp;lt;- function(R, x_dat, X_pred = X_grid) {
  smooth_list &amp;lt;- apply(R, 1, smooth_square_resid, x_dat = dat$X, X_pred = X_pred, simplify = FALSE)
  tibble(
    group = 1:length(smooth_list),
    X = rep(list(X_pred), length(smooth_list)),
    sm = smooth_list
  )
}

smooth_MV &amp;lt;- 
  list(
    Poisson = resid_Poisson, 
    `Negative binomial` = resid_negbin,
    `Double Poisson` = resid_dpo,
    `Generalized Poisson` = resid_gpo
  ) %&amp;gt;%
  map_dfr(smooth_square_resid_ppcs, x_dat = dat$X, .id = &amp;quot;distribution&amp;quot;) %&amp;gt;%
  unnest(X, sm) %&amp;gt;%
  mutate(
    distribution = factor(distribution, levels = c(&amp;quot;Poisson&amp;quot;, &amp;quot;Negative binomial&amp;quot;,&amp;quot;Double Poisson&amp;quot;, &amp;quot;Generalized Poisson&amp;quot;))
  )

ggplot(smooth_MV, aes(X, sm, group = group, color = distribution)) + 
  geom_line(alpha = 0.4) + 
  geom_line(data = dat, aes(X, sm, group = NULL), color = &amp;quot;black&amp;quot;, linewidth = 1.25) + 
  scale_color_manual(values = c(&amp;quot;grey&amp;quot;,&amp;quot;purple&amp;quot;,&amp;quot;lightblue&amp;quot;,&amp;quot;lightgreen&amp;quot;)) + 
  scale_y_continuous(limits = c(0, 9), breaks = seq(0,8,2), expand = expansion(0,0)) + 
  facet_wrap(~ distribution, ncol = 1) + 
  theme_minimal() + 
  theme(legend.position = &amp;quot;none&amp;quot;) + 
  labs(y = &amp;quot;Loess smooth of squared residuals&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Generalized-Poisson-in-Stan_files/figure-html/ppd-residual-smooth-1.png&#34; width=&#34;576&#34; /&gt;
Aha! Here we can clearly see that the negative binomial model generates residuals that have more curvature to the mean-variance relationship, and so don’t really fit with the observed data. The double Poisson and generalized Poisson both generate residuals that match the observed mean-variance relationship decently well.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;colophon&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Colophon&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19045)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] loo_2.5.1           bayesplot_1.9.0     brms_2.18.0        
##  [4] Rcpp_1.0.10         rstan_2.26.23       StanHeaders_2.26.27
##  [7] gamlss.dist_6.0-3   MASS_7.3-57         patchwork_1.1.3    
## [10] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0      
## [13] dplyr_1.1.2         purrr_1.0.2         readr_2.1.4        
## [16] tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3      
## [19] tidyverse_2.0.0    
## 
## loaded via a namespace (and not attached):
##   [1] TH.data_1.1-2        colorspace_2.1-0     RcppEigen_0.3.3.9.2 
##   [4] ellipsis_0.3.2       ggridges_0.5.3       estimability_1.3    
##   [7] markdown_1.7         QuickJSR_1.0.5       base64enc_0.1-3     
##  [10] rstudioapi_0.15.0    farver_2.1.1         DT_0.29             
##  [13] fansi_1.0.4          mvtnorm_1.1-3        splines_4.2.2       
##  [16] bridgesampling_1.1-2 codetools_0.2-18     cachem_1.0.6        
##  [19] knitr_1.40           shinythemes_1.2.0    jsonlite_1.8.4      
##  [22] shiny_1.7.4          compiler_4.2.2       emmeans_1.7.3       
##  [25] backports_1.4.1      Matrix_1.6-3         fastmap_1.1.0       
##  [28] cli_3.6.1            later_1.3.0          htmltools_0.5.4     
##  [31] prettyunits_1.1.1    tools_4.2.2          igraph_1.3.5        
##  [34] coda_0.19-4          gtable_0.3.4         glue_1.6.2          
##  [37] reshape2_1.4.4       posterior_1.3.1      jquerylib_0.1.4     
##  [40] vctrs_0.6.3          nlme_3.1-157         blogdown_1.10       
##  [43] crosstalk_1.2.0      tensorA_0.36.2       xfun_0.40           
##  [46] ps_1.6.0             timechange_0.2.0     mime_0.12           
##  [49] miniUI_0.1.1.1       lifecycle_1.0.3      gtools_3.9.3        
##  [52] zoo_1.8-10           scales_1.2.1         colourpicker_1.1.1  
##  [55] hms_1.1.3            promises_1.2.0.1     Brobdingnag_1.2-9   
##  [58] parallel_4.2.2       sandwich_3.0-1       inline_0.3.19       
##  [61] shinystan_2.6.0      yaml_2.3.5           gridExtra_2.3       
##  [64] sass_0.4.5           stringi_1.7.12       highr_0.9           
##  [67] dygraphs_1.1.1.6     checkmate_2.1.0      pkgbuild_1.3.1      
##  [70] rlang_1.1.1          pkgconfig_2.0.3      matrixStats_0.62.0  
##  [73] BH_1.78.0-0          distributional_0.3.1 evaluate_0.18       
##  [76] lattice_0.20-45      labeling_0.4.3       rstantools_2.2.0    
##  [79] htmlwidgets_1.6.2    processx_3.7.0       tidyselect_1.2.0    
##  [82] plyr_1.8.8           magrittr_2.0.3       bookdown_0.26       
##  [85] R6_2.5.1             generics_0.1.3       multcomp_1.4-23     
##  [88] mgcv_1.8-41          pillar_1.9.0         withr_2.5.0         
##  [91] xts_0.12.1           survival_3.4-0       abind_1.4-5         
##  [94] crayon_1.5.2         utf8_1.2.3           tzdb_0.3.0          
##  [97] rmarkdown_2.18       grid_4.2.2           callr_3.7.2         
## [100] threejs_0.3.3        digest_0.6.30        xtable_1.8-4        
## [103] httpuv_1.6.8         RcppParallel_5.1.5   stats4_4.2.2        
## [106] munsell_0.5.0        bslib_0.4.2          shinyjs_2.1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>High replicability of newly-discovered social-behavioral findings is achievable.</title>
      <link>http://localhost:4321/publication/decline-effects/</link>
      <pubDate>Thu, 09 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/decline-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Discussion of Stabilizing measures to reconcile accuracy and equity in performance measurement</title>
      <link>http://localhost:4321/talk/sree-2023-stabilizing-performance-measures-discussion/</link>
      <pubDate>Fri, 29 Sep 2023 16:30:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sree-2023-stabilizing-performance-measures-discussion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Equity-related moderator analysis in syntheses of dependent effect sizes: Conceptual and statistical considerations</title>
      <link>http://localhost:4321/talk/sree-2023-equity-related-moderator-analysis/</link>
      <pubDate>Wed, 27 Sep 2023 16:15:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sree-2023-equity-related-moderator-analysis/</guid>
      <description>&lt;h1 id=&#34;backgroundcontext&#34;&gt;Background/Context&lt;/h1&gt;
&lt;p&gt;In meta-analyses examining educational interventions, researchers seek to understand the distribution of intervention impacts, in order to draw generalizations about what works, for whom, and under what conditions. One common way to examine equity implications in such reviews is through moderator analysis, which involves modeling how intervention effect sizes vary depending on the characteristics of primary study participants. For example, one might estimate associations between effect size and the percentage of the primary study participants who were from a rural school, from a low-income family, identified as a specific racial or ethnic group, or designated as an English Language Learner. Such moderator analyses can provide insights about the populations and contexts where an intervention is more or less effective—that is, they can address questions of who benefits and how the effects of an educational intervention are distributed.&lt;/p&gt;
&lt;p&gt;Meta-analyses of educational interventions often include primary studies that report multiple relevant effect size estimates, such for more than one measure of an outcome construct, at multiple time-points, for multiple versions of an intervention, or for different sub-groups of participants. This leads to a data structure where the effects from a given study are correlated, necessitating the use of statistical methods that are appropriate for dependent observations. Methodological research in this area has provided estimation and inference methods that which can handle dependent effect sizes, including multi-level meta-analyses (Van den Noortgate et al., 2013, 2015), robust variance estimation (Hedges et al., 2010), and combinations thereof (Fernández-Castilla et al., 2020; Pustejovsky &amp;amp; Tipton, 2022). However, there has been much less attention to the specific forms of moderator analysis that are of interest in practice.&lt;/p&gt;
&lt;h1 id=&#34;purposeobjectiveresearch-question&#34;&gt;Purpose/Objective/Research Question&lt;/h1&gt;
&lt;p&gt;We aim to identify conceptual and statistical considerations for moderator analysis of equity-related variables in meta-analyses involving dependent effect sizes. Specifically, we distinguish between direct evidence and contextual evidence about equity of impacts and show that the choice of meta-analytic model can be consequential for analyses involving direct evidence. We then examine how meta-analysts currently conduct equity-related moderator analyses, by reviewing completed research synthesis projects funded by the Institute of Education Sciences (IES) over the period of 2002 to 2018. We find that most projects do not distinguish between direct and contextual evidence and use analytic approaches that are inefficient for synthesizing direct evidence.
Conceptual Considerations&lt;/p&gt;
&lt;p&gt;Moderator analyses of equity-related variables can be carried out by regressing effect size estimates on predictors encoding participant characteristics. Consider a synthesis in which some primary studies contribute multiple effect sizes. In this data structure, a predictor might represent a study-level characteristic or one that varies across the effects within a given study. The level of variation is especially salient for analysis of equity-related variables because study-level characteristics and effect-level characteristics represent qualitatively different types of evidence. For study-level predictors, associations with effect size pertain to the study’s context and are not necessarily indicative of individual-level variation in impacts. Thus, interpretation is challenging because studies vary in many ways, with many possible sources of confounding. For effect-level predictors, within-study variation represents direct evidence about individual-level moderation (e.g., a comparison of impacts between low-income and higher-income participants in the same study), unconfounded by study-level characteristics.&lt;/p&gt;
&lt;p&gt;We describe different strategies for separately investing direct and contextual evidence about moderation, including a) decomposing the predictor into study-level average and within-study centered components or b) inclusion of the raw predictor and the study-level average in a meta-regression. Although strategy (a) has been recommended previously in the context of meta-analysis of dependent effects (Tanner-Smith &amp;amp; Tipton, 2014), our presentation makes explicit the connection to equity-related moderator analysis and specifies the data requirements for applying it.&lt;/p&gt;
&lt;h1 id=&#34;statistical-considerations&#34;&gt;Statistical Considerations&lt;/h1&gt;
&lt;p&gt;Meta-regression with dependent effect sizes involves choosing a working model for the dependence structure, which determines the set of weights used for estimating the meta-regression. Several different working models have been proposed, including correlated effects and hierarchical effects models (Hedges et al., 2010), a correlated-and-hierarchical effects model (Pustejovsky &amp;amp; Tipton, 2022) and the multi-level meta-analysis model (Van den Noortgate et al., 2013, 2015). Ad hoc strategies, such as aggregating effects to the study level or ignoring dependence, can also be understood as working models.&lt;/p&gt;
&lt;p&gt;Previous research and guidance about the choice of working model has argued that the choice of working model is fairly inconsequential so long as the working model is roughly similar the true dependence structure (Hedges et al., 2010; Tanner-Smith et al., 2016; Tanner-Smith &amp;amp; Tipton, 2014). In the appendix, we examine the exact weights assigned by a variety of different working models to studies with direct evidence and contextual evidence. Contrary to past guidance, we find that different working models can lead to quite different weighting—particularly for direct evidence (i.e., study mean-centered predictors).&lt;/p&gt;
&lt;h1 id=&#34;current-practice&#34;&gt;Current Practice&lt;/h1&gt;
&lt;p&gt;To understand current practices for analysis of equity-related moderator variables, we reviewed completed meta-analysis projects funded by IES over the period of 2002 to 2018. We identified grants that (a) had journal articles reporting a meta-analysis, (b) were not methodological, and (c) were not training programs. A search of the IES website for project descriptions that included the word “meta-analysis” returned 80 results, of which 25 met inclusion criteria. Table 1 summarizes the approaches to moderator analyses used in these projects. Most projects reported some form of meta-regression analysis, but very few described a centering strategy and only one project used study-mean centering. Notably, the correlated effects and hierarchical effects working models were commonly used, yet these models involve inefficient weighting of direct evidence.&lt;/p&gt;
&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;In light of this review of current practice, the conceptual and statistical considerations that we describe suggest that there is substantial room for improvement in how meta-analysts conduct moderation analysis, particularly for equity-related variables where individual-level variation is of primary interest. Even under this simple—simplistic, even—conception of equity, bringing systematic review and meta-analysis methods to bear to address inequities in the education system will require not only improving analytic practices, but also changing how primary investigations frame questions, collect data, and report findings.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Implementing Efron&#39;s double Poisson distribution in Stan</title>
      <link>http://localhost:4321/double-poisson-in-stan/</link>
      <pubDate>Fri, 15 Sep 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/double-poisson-in-stan/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a project I am working on, we are using &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; to fit generalized random effects location-scale models to a bunch of count data. We’re interested in using the double-Poisson distribution, as described by &lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron (1986)&lt;/a&gt;.
This is an interesting distribution because it admits for both over- and under-dispersion relative to the Poisson distribution, whereas most of the conventional alternatives such as the negative binomial distribution or Poisson-normal mixture distribution allow only for over-dispersion.
The double-Poisson distribution is not implemented in Stan, so we’ve had to write our own distribution function. That’s fine and not particularly difficult. What’s a bit more of a challenge is writing Stan functions to generate random samples from the double-Poisson, so that we can generate posterior predictive checks.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; In this post, I’ll walk through the implementation of the custom distribution functions needed to use the double-Poisson in Stan.
The &lt;a href=&#34;https://cran.r-project.org/package=gamlss.dist&#34;&gt;&lt;code&gt;gamlss.dist&lt;/code&gt; package&lt;/a&gt; provides a full set of distributional functions for the double-Poisson distribution, including a sampler. Thus, I can validate my Stan functions against the functions from &lt;code&gt;gamlss.dist&lt;/code&gt;.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(patchwork)   # composing figures
library(gamlss.dist) # DPO distribution functions
library(rstan)       # Stan interface to R
library(brms)        # fitting generalized linear models
library(bayesplot)   # Examine fitted models
library(loo)         # Model fit measures&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-double-poisson&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The double-Poisson&lt;/h2&gt;
&lt;p&gt;The double-Poisson distribution is a discrete distribution for non-negative counts, with support &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{S}_X = \{0, 1, 2, 3, ...\}\)&lt;/span&gt;.
The mean-variance relationship of the double-Poisson is approximately constant; for &lt;span class=&#34;math inline&#34;&gt;\(X \sim DPO(\mu, \phi)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{E}(X) \approx \mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(X) \approx \mu / \phi\)&lt;/span&gt;, so that the double-Poisson distribution approximately satisfies the assumptions of a quasi-Poisson generalized linear model (although not quite exactly so).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron (1986)&lt;/a&gt; gives the following expression for the density of the double-Poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and inverse-disperson &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
f(x | \mu, \phi) = \frac{\phi^{1/2} e^{-\phi \mu}}{c(\mu,\phi)} \left(\frac{e^{-x} x^x}{x!}\right) \left(\frac{e \mu}{x}\right)^{\phi x},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(c(\mu,\phi)\)&lt;/span&gt; is a scaling constant to ensure that the density sums to one, which is closely approximated by
&lt;span class=&#34;math display&#34;&gt;\[
c(\mu, \phi) \approx 1 + \frac{1 - \phi}{12 \mu \phi}\left(1 + \frac{1}{\mu \phi}\right).
\]&lt;/span&gt;
We then have
&lt;span class=&#34;math display&#34;&gt;\[
\ln f(x | \mu, \phi) = \frac{1}{2} \ln \phi - \phi \mu - \ln c(\mu, \phi) + x (\phi + \phi \ln \mu - 1) + (1 - \phi) x \ln(x) - \ln \left(x!\right),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(0 \times \ln (0)\)&lt;/span&gt; is evaluated as 0.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;log-of-the-probability-mass-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Log of the probability mass function&lt;/h1&gt;
&lt;p&gt;For purposes of using this distribution in Stan, it’s sufficient to provide the log of the probability mass function up to a constant—there’s no need to normalize it to sum to one. Thus, we can ignore the &lt;span class=&#34;math inline&#34;&gt;\(c(\mu, \phi)\)&lt;/span&gt; term above. Here’s a Stan function implementing the lpmf:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_lpmf &amp;lt;- &amp;quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check that this is accurate, I’ll compare the Stan function to the corresponding function from &lt;code&gt;gamlss.dist&lt;/code&gt; for a couple of different parameter values and for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,100\)&lt;/span&gt;. If my function is accurate, the calculated log-probabilities should differ by a constant value for each set of parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_lpmf, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-lpmf.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-lpmf.stan&amp;quot;)

test_lpmf &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
    X = 0:100
  ) %&amp;gt;%
  mutate(
    gamlss_lpmf = dDPO(x = X, mu = mu, sigma = 1 / phi, log = TRUE),
    my_lpmf = pmap_dbl(.l = list(X = X, mu = mu, phi = phi), .f = dpo_lpmf),
    diff = my_lpmf - gamlss_lpmf
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_lpmf, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Checks out. Onward!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cumulative-distribution-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Cumulative distribution function&lt;/h1&gt;
&lt;p&gt;I’ll next implement a function to evaluate the cumulative distriution function over a range of values. This is an expensive calculation, but it can be improved a little bit by noting the relationship between sequential values of the probability mass function. Letting &lt;span class=&#34;math inline&#34;&gt;\(d = \exp \left(\phi + \phi \ln \mu - 1 \right)\)&lt;/span&gt;, observe that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(0 | \mu, \phi) &amp;amp;= \frac{\phi^{1/2} e^{-\phi \mu}}{c(\mu,\phi)} \\
f(1 | \mu, \phi) &amp;amp;= f(0 | \mu, \phi) \times d \\
f(x | \mu, \phi) &amp;amp;= f(x - 1 | \mu, \phi) \times d \times \frac{\exp\left[(1 - \phi)(x - 1)\left(\ln(x) - \ln(x - 1)\right) \right]}{x^\phi}
\end{aligned}
\]&lt;/span&gt;
where the last expression holds for &lt;span class=&#34;math inline&#34;&gt;\(x \geq 2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The function below computes the cumulative distribution function over the range &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,m\)&lt;/span&gt; as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compute &lt;span class=&#34;math inline&#34;&gt;\(f(x | \mu, \phi)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,1,2,...\)&lt;/span&gt;, without the scaling constant &lt;span class=&#34;math inline&#34;&gt;\(c(\mu, \phi)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Take &lt;span class=&#34;math inline&#34;&gt;\(F(0 | \mu, \phi) = f(0 | \mu, \phi)\)&lt;/span&gt; and accumulate &lt;span class=&#34;math inline&#34;&gt;\(F(x | \mu, \phi) = F(x - 1 | \mu, \phi) + f(x | \mu, \phi)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x = 0,...,m\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Check if &lt;span class=&#34;math inline&#34;&gt;\(f(x | \mu, \phi) / F(x | \mu, \phi)\)&lt;/span&gt; is small (less than &lt;span class=&#34;math inline&#34;&gt;\(10^{-8}\)&lt;/span&gt;), in which case accumulation stops at the value &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The normalized cumulative distribution function will then be &lt;span class=&#34;math inline&#34;&gt;\(F(x | \mu, \phi) / F(n | \mu, \phi)\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_cdf &amp;lt;- &amp;quot; 
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check that this is accurate, I’ll again compare the Stan function to the corresponding function from &lt;code&gt;gamlss.dist&lt;/code&gt;. If my function is accurate, the computed cdf values should be proportional to the cdf calculated from &lt;code&gt;gamlss.dist::pDPO()&lt;/code&gt; and the ratio should be very close to 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_cdf, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-cdf.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-cdf.stan&amp;quot;)

test_cdf &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
  ) %&amp;gt;%
  mutate(
    maxval = 20 * mu / pmin(1, phi),
    my_cdf = pmap(.l = list(mu = mu, phi = phi, maxval = maxval), .f = dpo_cdf)
  ) %&amp;gt;%
  unnest(my_cdf) %&amp;gt;%
  filter(!is.nan(my_cdf)) %&amp;gt;%
  group_by(mu, phi) %&amp;gt;%
  mutate(
    q = row_number() - 1L,
    gamlss_cdf = pDPO(q = q, mu = mu, sigma = 1 / phi),
    ratio = my_cdf / gamlss_cdf
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_cdf, aes(factor(phi), ratio, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  ylim(1 + c(-1e-6, 1e-6)) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Still on track here (although you might wonder—would I be sharing this post if I couldn’t get the function working?).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quantile-function-and-sampler&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quantile function and sampler&lt;/h1&gt;
&lt;p&gt;The main other thing we need is a function for generating random samples from the double-Poisson. The &lt;code&gt;gamlss.dist&lt;/code&gt; package has the function &lt;code&gt;rDPO()&lt;/code&gt; for this purpose. It’s implemented using the standard inversion method, by calculating quantiles of the double-Poisson corresponding to a random sample from a uniform distribution. Just for funzies, I’ll implement the same approach using Stan.&lt;/p&gt;
&lt;p&gt;The function below calculates quantiles by finding the minimum value of &lt;span class=&#34;math inline&#34;&gt;\(q \geq 0\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(F(q + 1 | \mu, \phi) \geq p\)&lt;/span&gt; for a specified probability &lt;span class=&#34;math inline&#34;&gt;\(p \in [0, 1]\)&lt;/span&gt;. It is vectorized over &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and solves for &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; by starting with the smallest &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and continuing through the largest value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_quantile &amp;lt;- &amp;quot; 
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
array[] int dpo_quantiles(vector p, real mu, real phi, int maxval) {
  int N = rows(p);
  array[N] int qs;
  array[N] int indices = sort_indices_asc(p);
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int j = 0;
  for (i in indices) {
    while (cdf_vec[j + 1] &amp;lt; p[i]) {
      j += 1;
    }
    qs[i] = j;
  }
  return qs;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If my quantile function is accurate, it should match the value computed from &lt;code&gt;gamlss.dist::qDPO()&lt;/code&gt; exactly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_quantile, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-quantile.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-quantile.stan&amp;quot;)

test_quantile &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
  ) %&amp;gt;%
  mutate(
    maxval = 20 * mu / pmin(1, phi),
    p = map(1:n(), ~ runif(100)),
    my_q = pmap(.l = list(p = p, mu = mu, phi = phi, maxval = maxval), .f = dpo_quantiles),
    gamlss_q = pmap(.l = list(p = p, mu = mu, sigma = 1 / phi), .f = qDPO)
  ) %&amp;gt;%
  unnest(c(p, my_q, gamlss_q)) %&amp;gt;%
  mutate(
    diff = my_q - gamlss_q
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_quantile, aes(factor(phi), diff, color = factor(phi))) + 
  geom_boxplot() + 
  facet_wrap( ~ mu, labeller = &amp;quot;label_both&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;phi&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Phew, still got it!&lt;/p&gt;
&lt;p&gt;The last piece of the puzzle is to write a sampler by generating random points from a uniform distribution, then computing the double-Poisson quantiles of these random points. I will implement this two ways: first with an argument for the number of random variates to generate and then, more simply, to generate a single random variate.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stancode_qr &amp;lt;- &amp;quot;
real dpo_lpmf(int X, real mu, real phi) {
  real ans;
  real A = inv(2) * log(phi) - phi * mu;
  if (X == 0)
    ans = A;
  else
    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);
  return ans;
}
vector dpo_cdf(real mu, real phi, int maxval) {
  real d = exp(phi * (1 + log(mu)) - 1);
  real prob;
  int n = maxval + 1;
  vector[n] cdf;
  cdf[1] = sqrt(phi) * exp(-mu * phi);
  prob = cdf[1] * d;
  cdf[2] = cdf[1] + prob;
  for (i in 2:maxval) {
    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);
    cdf[i + 1] = cdf[i] + prob;
    if (prob / cdf[i + 1] &amp;lt; 1e-8) {
      n = i + 1;
      break;
    }
  }
  return cdf / cdf[n];
}
array[] int dpo_quantiles(vector p, real mu, real phi, int maxval) {
  int N = rows(p);
  array[N] int qs;
  array[N] int indices = sort_indices_asc(p);
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int j = 0;
  for (i in indices) {
    while (cdf_vec[j + 1] &amp;lt; p[i]) {
      j += 1;
    }
    qs[i] = j;
  }
  return qs;
}
array[] int dpo_sample_rng(int n, real mu, real phi, int maxval) {
  vector[n] p;
  for (i in 1:n) {
    p[i] = uniform_rng(0,1);
  }
  array[n] int x = dpo_quantiles(p, mu, phi, maxval);
  return x;
}
int dpo_quantile(real p, real mu, real phi, int maxval) {
  vector[maxval + 1] cdf_vec = dpo_cdf(mu, phi, maxval);
  int q = 0;
  while (cdf_vec[q + 1] &amp;lt; p) {
      q += 1;
    }
  return q;
}
int dpo_rng(real mu, real phi, int maxval) {
  real p = uniform_rng(0,1);
  int x = dpo_quantile(p, mu, phi, maxval);
  return x;
}
&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check this function, I’ll generate some large samples from the double-Poisson with a few different parameter sets. If the sampler is working properly, the empirical cumulative distribution should line up closely with the cumulative distribution computed using &lt;code&gt;gamlss.dist::pDPO()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(paste(&amp;quot;functions {&amp;quot;, stancode_qr, &amp;quot;}&amp;quot;, sep = &amp;quot;\n&amp;quot;), &amp;quot;DPO-rng.stan&amp;quot;)
expose_stan_functions(&amp;quot;DPO-rng.stan&amp;quot;)

test_rng &amp;lt;- 
  expand_grid(
    mu = c(2, 5, 10, 20),
    phi = c(0.1, 0.2, 0.5, 1, 2, 5, 10),
  ) %&amp;gt;%
  mutate(
    x = pmap(.l = list(n = 10000, mu = mu, phi = phi, maxval = 5000), .f = dpo_sample_rng),
    tb = map(x, ~ as.data.frame(table(.x)))
  ) %&amp;gt;%
  dplyr::select(-x) %&amp;gt;%
  group_by(mu, phi) %&amp;gt;%
  unnest(tb) %&amp;gt;%
  mutate(
    .x = as.integer(levels(.x))[.x],
    Freq_cum = cumsum(Freq) / 10000,
    gamlss_F = pDPO(q = .x, mu = mu, sigma = 1 / phi)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_rng, aes(gamlss_F, Freq_cum, color = factor(phi))) + 
  geom_abline(slope = 1, color = &amp;quot;blue&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) + 
  geom_point() + geom_line() +  
  facet_grid(phi ~ mu, labeller = &amp;quot;label_both&amp;quot;) + 
  theme_minimal() + 
  labs(x = &amp;quot;Theoretical cdf (gamlss.dist)&amp;quot;, y = &amp;quot;Empirical cdf (my function)&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks pretty good, no?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-custom-distribution-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using the custom distribution functions&lt;/h1&gt;
&lt;p&gt;To finish out my tests of these functions, let me demonstrate their use in an actual estimation problem. I’ll generate data based on a simple generalized linear model with a single predictor &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, where the outcome &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; follows a double-Poisson distribution conditional on &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The data-generating process is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
X &amp;amp;\sim N(0, 1) \\
Y|X &amp;amp;\sim DPO(\mu(X), \phi) \\
\log \mu(X) &amp;amp;= 2 + 0.3 \times X
\end{aligned}
\]&lt;/span&gt;
To make things interesting, I’ll set the dispersion parameter to &lt;span class=&#34;math inline&#34;&gt;\(1 / \phi = 0.6\)&lt;/span&gt; so that the outcome is &lt;em&gt;under&lt;/em&gt;-dispersed relative to the Poisson.&lt;/p&gt;
&lt;p&gt;The following code generates a large sample from the data-generating process. To keep things R-centric, I use &lt;code&gt;gamlss.dist::rDPO&lt;/code&gt; to generate the outcome.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(20230913)
N &amp;lt;- 600
X &amp;lt;- rnorm(N)
mu &amp;lt;- exp(2 + 0.3 * X)
phi_inv &amp;lt;- 0.6
Y &amp;lt;- rDPO(N, mu = mu, sigma = phi_inv)
dat &amp;lt;- data.frame(X = X, Y = Y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what the sample looks like, along with a smoothed regression estimated using a basic cubic spline:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat, aes(X, Y)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = &amp;#39;gam&amp;#39;, formula = y ~ s(x, bs = &amp;quot;cs&amp;quot;)) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;comparison-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparison models&lt;/h2&gt;
&lt;p&gt;Before using the custom distribution, I’ll fit a couple of out-of-the-box models that are useful points of comparison.
Surely the simplest, quickest, and dirtiest way to estimate such a regression is with a generalized linear model, using the “quasi-Poisson” family to allow for non-unit dispersion. In R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quasi_fit &amp;lt;- glm(Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
summary(quasi_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = Y ~ X, family = quasipoisson(link = &amp;quot;log&amp;quot;), data = dat)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.77671  -0.58205  -0.03293   0.49158   2.52711  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  1.98784    0.01219  163.03   &amp;lt;2e-16 ***
## X            0.29276    0.01178   24.85   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 0.6324771)
## 
##     Null deviance: 777.74  on 599  degrees of freedom
## Residual deviance: 384.90  on 598  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This approach recovers the data-generating parameters quite well, with a dispersion estimate of 0.632 compared to the true dispersion parameter of 0.6.&lt;/p&gt;
&lt;p&gt;Now let me fit the same generalized linear model but assuming that the outcome follows a true Poisson distribution (with unit dispersion). I’ll fit the model in a Bayesian framework with the &lt;code&gt;brms&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Poisson_fit &amp;lt;- 
  brm(
    Y ~ X, family = poisson(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20230913
  )

summary(Poisson_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: poisson 
##   Links: mu = log 
## Formula: Y ~ X 
##    Data: dat (Number of observations: 600) 
##   Draws: 4 chains, each with iter = 1500; warmup = 500; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.99      0.02     1.96     2.02 1.00     2733     2582
## X             0.29      0.01     0.26     0.32 1.00     2705     2485
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This specification recovers the intercept and slope parameters well too, but doesn’t provide any estimate of dispersion.&lt;/p&gt;
&lt;p&gt;As an alternative, I’ll also fit the model using the negative binomial distribution, which is a generalization of the Poisson that allows for over-dispersion (but not under-dispersion):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;negbin_fit &amp;lt;- 
  brm(
    Y ~ X, family = negbinomial(link = &amp;quot;log&amp;quot;),
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20230913
  )

summary(negbin_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: negbinomial 
##   Links: mu = log; shape = identity 
## Formula: Y ~ X 
##    Data: dat (Number of observations: 600) 
##   Draws: 4 chains, each with iter = 1500; warmup = 500; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.99      0.02     1.96     2.02 1.00     3571     3057
## X             0.29      0.01     0.26     0.32 1.00     3696     3141
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape   313.78    130.37   136.26   622.52 1.00     3132     3122
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;brms&lt;/code&gt; package implements the negative binomial using the rate parameterization, so the &lt;code&gt;shape&lt;/code&gt; parameter corresponds to the inverse dispersion. Thus, a large shape parameter (as in the above fit) implies dispersion that is very close to one (i.e., close to the Poisson).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;double-poisson-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Double-Poisson model&lt;/h2&gt;
&lt;p&gt;Now I’ll fit the same model as previously but using my custom-built double-Poisson distribution. Following &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_customfamilies.html&#34;&gt;Paul Buerkner’s vignette&lt;/a&gt; on using custom distributions in &lt;code&gt;brms&lt;/code&gt;, I’ll first specify the custom family object for the double-Poisson:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;double_Poisson &amp;lt;- custom_family(
  &amp;quot;dpo&amp;quot;, dpars = c(&amp;quot;mu&amp;quot;,&amp;quot;phi&amp;quot;),
  links = c(&amp;quot;log&amp;quot;,&amp;quot;log&amp;quot;),
  lb = c(0, 0), ub = c(NA, NA),
  type = &amp;quot;int&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I set the defaults to use a log-link for the mean (just as with the Poisson and negative binomial families) and a log-link for the inverse-dispersion.
Next, I’ll create an object to add the custom stan code from above into the code created by &lt;code&gt;brm&lt;/code&gt; for fitting the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;double_Poisson_stanvars &amp;lt;- stanvar(scode = stancode_qr, block = &amp;quot;functions&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll also need to specify a prior to use for the &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; parameter of the double-Poisson distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;phi_prior &amp;lt;- prior(exponential(1), class = &amp;quot;phi&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’m ready to fit the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DPO_fit &amp;lt;- 
  brm(
    Y ~ X, family = double_Poisson,
    prior = phi_prior,
    stanvars = double_Poisson_stanvars,
    data = dat, 
    warmup = 500, 
    iter = 1500, 
    chains = 4, 
    cores = 4,
    seed = 20230913
  )

summary(DPO_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: dpo 
##   Links: mu = log; phi = identity 
## Formula: Y ~ X 
##    Data: dat (Number of observations: 600) 
##   Draws: 4 chains, each with iter = 1500; warmup = 500; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.99      0.01     1.96     2.01 1.00     3468     3162
## X             0.29      0.01     0.27     0.32 1.00     3745     2786
## 
## Family Specific Parameters: 
##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## phi     1.55      0.09     1.38     1.73 1.00     3814     2780
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The regression coefficient estimates are basically identical to those from the Poisson and negative-binomial models, estimated with slightly better precision than with the Poisson or negative binomial families. However, we get a posterior for &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; that corresponds to &lt;em&gt;under&lt;/em&gt;-dispersion. Here’s the posterior for the dispersion (i.e., &lt;span class=&#34;math inline&#34;&gt;\(1 / \phi\)&lt;/span&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mcmc_areas(DPO_fit, pars = &amp;quot;phi&amp;quot;, transformations = \(x) 1 / x) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/DPO-dispersion-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model comparison&lt;/h2&gt;
&lt;p&gt;I’d like to get a sense of how much better the double-Poisson model does with capturing the real data-generating process compared to the simple Poisson model or the negative binomial model. There’s a wide range of diagnostics that can inform such comparisons. I’ll consider the leave-one-out information criteria (LOOIC) and also look at some posterior predictive checks.&lt;/p&gt;
&lt;p&gt;To calculate LOOIC for the double-Poisson model, I first need to provide a &lt;code&gt;log_lik&lt;/code&gt; function that &lt;code&gt;brms&lt;/code&gt; can use&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. Here’s code, using the Stan function from above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;expose_functions(DPO_fit, vectorize = TRUE)
log_lik_dpo &amp;lt;- function(i, prep) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  y &amp;lt;- prep$data$Y[i]
  dpo_lpmf(y, mu, phi)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can then compute LOOIC for all three models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo(DPO_fit, Poisson_fit, negbin_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Output of model &amp;#39;DPO_fit&amp;#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1305.7 16.9
## p_loo         2.9  0.2
## looic      2611.5 33.8
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &amp;lt; 0.5).
## See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
## 
## Output of model &amp;#39;Poisson_fit&amp;#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1330.0 11.3
## p_loo         1.3  0.1
## looic      2660.1 22.6
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &amp;lt; 0.5).
## See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
## 
## Output of model &amp;#39;negbin_fit&amp;#39;:
## 
## Computed from 4000 by 600 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -1333.2 11.1
## p_loo         1.3  0.1
## looic      2666.3 22.2
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &amp;lt; 0.5).
## See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
## 
## Model comparisons:
##             elpd_diff se_diff
## DPO_fit       0.0       0.0  
## Poisson_fit -24.3       6.1  
## negbin_fit  -27.4       6.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By these measures, the double-Poisson model has substantially better fit than either of the other models.&lt;/p&gt;
&lt;p&gt;To do posterior predictive checks, I need to provide a &lt;code&gt;posterior_predict&lt;/code&gt; function that &lt;code&gt;brms&lt;/code&gt; can use. I’ll again do an implementation that uses my custom &lt;code&gt;dpo_rng()&lt;/code&gt; from Stan.&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_predict_dpo &amp;lt;- function(i, prep, maxval = NULL, ...) {
  mu &amp;lt;- brms::get_dpar(prep, &amp;quot;mu&amp;quot;, i = i)
  phi &amp;lt;- brms::get_dpar(prep, &amp;quot;phi&amp;quot;, i = i)
  if (is.null(maxval)) maxval &amp;lt;- 20 * mu / min(phi, 1)
  dpo_rng(mu, phi, maxval = maxval)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Functions in hand, I can now compute posterior predictions for the double-Poisson model and make pretty pictures of them, along with corresponding plots for the Poisson and negative-binomial models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yrep_Poisson &amp;lt;- posterior_predict(Poisson_fit, draws = 400) 
color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_Poisson, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Poisson&amp;quot;)

Yrep_negbin &amp;lt;- posterior_predict(negbin_fit, draws = 400)
color_scheme_set(&amp;quot;green&amp;quot;)
negbin_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_negbin, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Negative-binomial&amp;quot;)

Yrep_dpo &amp;lt;- posterior_predict(DPO_fit, draws = 400)
color_scheme_set(&amp;quot;purple&amp;quot;)
dpo_root &amp;lt;- ppc_rootogram(dat$Y, Yrep_dpo, style = &amp;quot;hanging&amp;quot;) + labs(title = &amp;quot;Double-Poisson&amp;quot;)

dpo_root / Poisson_root / negbin_root &amp;amp;
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/ppd-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The differences in predicted frequencies are not that obvious from these plots. The main notable difference is that the Poisson and negative-binomial distributions predict more small counts (in the range of 0 to 3) than are observed, whereas the double-Poisson does better at matching the observed frequency in this range.&lt;/p&gt;
&lt;p&gt;I think the lack of glaring differences in the above plots happens because I’m just looking at the marginal distribution of the outcome, and the (explained) variation due to the predictor dampens the degree of under-dispersion. To see this, I’ll create some plots that are grouped by quintiles of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat$g &amp;lt;- cut(dat$X, breaks = quantile(dat$X, seq(0,1,0.2)), include.lowest = TRUE)

color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_bars &amp;lt;- ppc_bars_grouped(
  dat$Y, Yrep_Poisson, dat$g, 
  prob = 0.5, 
  facet_args = list(ncol = 5)
) + 
  labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
negbin_bars &amp;lt;- ppc_bars_grouped(
  dat$Y, Yrep_negbin, dat$g, 
  prob = 0.5, 
  facet_args = list(ncol = 5)
) + 
  labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
dpo_bars &amp;lt;- ppc_bars_grouped(
  dat$Y, Yrep_dpo, dat$g, 
  prob = 0.5, 
  facet_args = list(ncol = 5)
) + 
  labs(title = &amp;quot;Double-Poisson&amp;quot;)

dpo_bars / Poisson_bars / negbin_bars &amp;amp;
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/ppd-grouped-1.png&#34; width=&#34;1152&#34; /&gt;
Still kind of subtle, I suppose, but you can see more clearly that the double-Poisson does a better job than the other distributions at matching the modes (peaks) of the empirical distribution in each of these subgroups.&lt;/p&gt;
&lt;p&gt;One last approach is to look directly at the degree of dispersion in the posterior predictive distributions relative to the actual data. I’ll calculate this dispersion by re-fitting the quick-and-dirty quasi-poisson model in each sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dispersion_coef &amp;lt;- function(y) {
  quasi_fit &amp;lt;- glm(y ~ dat$X, family = quasipoisson(link = &amp;quot;log&amp;quot;))
  sum(residuals(quasi_fit, type = &amp;quot;pearson&amp;quot;)^2) / quasi_fit$df.residual
}

color_scheme_set(&amp;quot;blue&amp;quot;)
Poisson_disp &amp;lt;- ppc_stat(dat$Y, Yrep_Poisson, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Poisson&amp;quot;)

color_scheme_set(&amp;quot;green&amp;quot;)
negbin_disp &amp;lt;- ppc_stat(dat$Y, Yrep_negbin, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Negative-binomial&amp;quot;)

color_scheme_set(&amp;quot;purple&amp;quot;)
dpo_disp &amp;lt;- ppc_stat(dat$Y, Yrep_dpo, stat = dispersion_coef, binwidth = 0.02) + 
  labs(title = &amp;quot;Double-Poisson&amp;quot;)

dpo_disp / Poisson_disp / negbin_disp &amp;amp;
  theme_minimal() &amp;amp; 
  xlim(c(0.45, 1.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Double-Poisson-in-Stan_files/figure-html/ppc-dispersion-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From this, we can clearly see that the Poisson and negative binomial model generate data with approximately unit dispersion, which doesn’t match at all with the degree of dispersion in the observed data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;kudos&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Kudos&lt;/h1&gt;
&lt;p&gt;So there you have it. It’s really quite feasible to build models with custom distributions. Efron (1986) also describes a double-binomial distribution (as an approximation to the “quasi-binomial” family of generalized linear models), which you could play with implementing for yourself, dear reader, if you are in the mood.
Major kudos to &lt;a href=&#34;https://paul-buerkner.github.io/&#34;&gt;Paul Buerkner&lt;/a&gt; for &lt;a href=&#34;https://paul-buerkner.github.io/brms/&#34;&gt;&lt;code&gt;brms&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://jgabry.github.io/&#34;&gt;Jonah Gabry&lt;/a&gt; and collaborators for &lt;a href=&#34;https://mc-stan.org/bayesplot/&#34;&gt;&lt;code&gt;bayesplot&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&#34;https://mc-stan.org/about/team/&#34;&gt;the incredible team of folks&lt;/a&gt; developing &lt;a href=&#34;https://mc-stan.org/&#34;&gt;&lt;code&gt;Stan&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;colophon&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Colophon&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19045)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.utf8 
## [2] LC_CTYPE=English_United States.utf8   
## [3] LC_MONETARY=English_United States.utf8
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] loo_2.5.1           bayesplot_1.9.0     brms_2.18.0        
##  [4] Rcpp_1.0.10         rstan_2.26.23       StanHeaders_2.26.27
##  [7] gamlss.dist_6.0-3   MASS_7.3-57         patchwork_1.1.1    
## [10] forcats_0.5.1       stringr_1.5.0       dplyr_1.1.2        
## [13] purrr_1.0.2         readr_2.1.2         tidyr_1.3.0        
## [16] tibble_3.2.1        ggplot2_3.4.0       tidyverse_1.3.1    
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.4.2         backports_1.4.1      RcppEigen_0.3.3.9.2 
##   [4] plyr_1.8.8           igraph_1.3.5         splines_4.2.2       
##   [7] crosstalk_1.2.0      TH.data_1.1-2        rstantools_2.2.0    
##  [10] inline_0.3.19        digest_0.6.30        htmltools_0.5.4     
##  [13] fansi_1.0.4          magrittr_2.0.3       BH_1.78.0-0         
##  [16] checkmate_2.1.0      tzdb_0.3.0           modelr_0.1.8        
##  [19] RcppParallel_5.1.5   matrixStats_0.62.0   xts_0.12.1          
##  [22] sandwich_3.0-1       timechange_0.2.0     prettyunits_1.1.1   
##  [25] colorspace_2.1-0     rvest_1.0.2          haven_2.5.0         
##  [28] xfun_0.34            callr_3.7.2          crayon_1.5.2        
##  [31] jsonlite_1.8.4       survival_3.4-0       zoo_1.8-10          
##  [34] glue_1.6.2           gtable_0.3.1         emmeans_1.7.3       
##  [37] distributional_0.3.1 pkgbuild_1.3.1       abind_1.4-5         
##  [40] scales_1.2.1         mvtnorm_1.1-3        DBI_1.1.2           
##  [43] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.2.2        
##  [46] DT_0.23              htmlwidgets_1.6.2    httr_1.4.3          
##  [49] threejs_0.3.3        posterior_1.3.1      ellipsis_0.3.2      
##  [52] pkgconfig_2.0.3      farver_2.1.1         sass_0.4.5          
##  [55] dbplyr_2.1.1         utf8_1.2.3           tidyselect_1.2.0    
##  [58] labeling_0.4.2       rlang_1.1.1          reshape2_1.4.4      
##  [61] later_1.3.0          munsell_0.5.0        cellranger_1.1.0    
##  [64] tools_4.2.2          cachem_1.0.6         cli_3.6.1           
##  [67] generics_0.1.3       broom_0.8.0          ggridges_0.5.3      
##  [70] evaluate_0.18        fastmap_1.1.0        yaml_2.3.5          
##  [73] processx_3.7.0       knitr_1.40           fs_1.6.1            
##  [76] nlme_3.1-157         mime_0.12            xml2_1.3.3          
##  [79] compiler_4.2.2       shinythemes_1.2.0    rstudioapi_0.13     
##  [82] reprex_2.0.1         bslib_0.4.2          stringi_1.7.12      
##  [85] highr_0.9            ps_1.6.0             blogdown_1.10       
##  [88] Brobdingnag_1.2-9    lattice_0.20-45      Matrix_1.5-1        
##  [91] markdown_1.7         shinyjs_2.1.0        tensorA_0.36.2      
##  [94] vctrs_0.6.3          pillar_1.9.0         lifecycle_1.0.3     
##  [97] jquerylib_0.1.4      bridgesampling_1.1-2 estimability_1.3    
## [100] httpuv_1.6.8         QuickJSR_1.0.5       R6_2.5.1            
## [103] bookdown_0.26        promises_1.2.0.1     gridExtra_2.3       
## [106] codetools_0.2-18     colourpicker_1.1.1   gtools_3.9.3        
## [109] assertthat_0.2.1     withr_2.5.0          shinystan_2.6.0     
## [112] multcomp_1.4-23      mgcv_1.8-41          parallel_4.2.2      
## [115] hms_1.1.3            grid_4.2.2           coda_0.19-4         
## [118] rmarkdown_2.18       shiny_1.7.4          lubridate_1.9.2     
## [121] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;To be clear up front, what I present is more complicated than really necessary because of these existing R functions to simulate values from the double-Poisson—we can just use the functions from &lt;code&gt;gamlss.dist&lt;/code&gt; for purposes of posterior predictive checks (about which more below).
I’m trying to work in Stan to the maximum extent possible solely as an excuse to learn more about the language, which I haven’t used much up until today.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I should also note that the &lt;a href=&#34;http://www.bamlss.org/index.html&#34;&gt;&lt;code&gt;bamlss&lt;/code&gt; package&lt;/a&gt; provides similar functionality and can be combined with &lt;code&gt;gamlss.dist&lt;/code&gt; to accomplish basically the same thing as I’m going to do here.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;The simpler version is what’s needed for generating posterior predictive checks, the fancy version is just to show off how clever I am.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Rather than exposing and calling the Stan function, one could just re-implement the log likelihood in R. (Probably the easier way in practice, but again I’m trying to learn me some Stan here…)&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Of course, I could have saved a bunch of trouble by just using &lt;code&gt;gamlss.dist::rDPO()&lt;/code&gt; instead.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Conducting power analysis for meta-analysis of dependent effect sizes: Common guidelines and an introduction to the POMADE R package</title>
      <link>http://localhost:4321/publication/conducting-pomade/</link>
      <pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/conducting-pomade/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The efficacy of combining cognitive training and non-invasive brain stimulation: A transdiagnostic systematic review and meta-analysis</title>
      <link>http://localhost:4321/publication/efficacy-of-combining-cognitive-training-and-nibs/</link>
      <pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/efficacy-of-combining-cognitive-training-and-nibs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Systematic review of variables related to instruction in augmentative and alternative communication implementation: Group and single-case design</title>
      <link>http://localhost:4321/publication/aac-group-and-scd/</link>
      <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/aac-group-and-scd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Determining the Timing of Phase Changes: Some Statistical Perspective</title>
      <link>http://localhost:4321/talk/wiscc-2023/</link>
      <pubDate>Thu, 18 May 2023 09:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/wiscc-2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Field Experiments in Education Research</title>
      <link>http://localhost:4321/teaching/field-experiments/</link>
      <pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/teaching/field-experiments/</guid>
      <description>&lt;p&gt;How effective is tutoring for improving the mathematics performance of students from economically disadvantaged backgrounds? Does participating in mindfulness training during school improve the mental health and wellbeing of adolescents? Does peer observation of teaching have beneficial effects on student learning? What are the benefits and costs of reducing class sizes in the elementary grades? Such questions focus on understanding the causal effects of an intervention (program, practice, or policy) on educational outcomes, and are often of central interest to educational leaders and policy-makers, program developers, and researchers. Randomized experiments are one way to investigate questions about causal impacts, and indeed, are often accorded a special status due to their potential for clearly identifying causal relationships. Although once rare in education research, randomized experiments conducted in naturalistic educational settings have grown increasingly common and prominent over the past two decades. Planning and conducting such studies involve a unique set of challenges, and their findings have a distinctive profile of advantages and limitations.&lt;/p&gt;
&lt;p&gt;This course will cover the design, analysis, and interpretation of randomized field experiments in education research. We will examine the theoretical, statistical, and pragmatic considerations involved in such studies, from articulating a theory of change and selecting outcome measurements, to choosing an experimental design and analytic strategy, to addressing questions of generalizability. Our focus will be on designs most commonly used in educational settings, such as block-randomized or cluster-randomized experiments, and the implementation challenges that arise in such settings, such as non-compliance, attrition, and interference. By the end of the course, students should be able to contribute to the design and planning of a randomized experiment in a realistic field setting, to critically assess reported findings from field experiments, and to make informed judgments about the role of randomized field experiments within education research.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-711-021-Field-Experiments-2023-Spring-syllabus.pdf&#34;&gt;2023 (Spring) syllabus&lt;/a&gt; and 
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-711-021-Field-Experiments-2023-Spring-reading-list.pdf&#34;&gt;reading list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Calculating Effect Sizes for Single-Case Research: An Introduction to the SingleCaseES and scdhlm Web Applications and R Packages</title>
      <link>http://localhost:4321/talk/small-is-beautiful-2023-workshop/</link>
      <pubDate>Wed, 26 Apr 2023 11:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/small-is-beautiful-2023-workshop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect size measures for single-case research: Conceptual, practical, and statistical considerations</title>
      <link>http://localhost:4321/talk/small-is-beautiful-2023-keynote/</link>
      <pubDate>Tue, 25 Apr 2023 08:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/small-is-beautiful-2023-keynote/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Empirical benchmarks for between-case standardized mean differences from single-case multiple baseline designs examining academic interventions.</title>
      <link>http://localhost:4321/talk/aera-2023-bcsmd-benchmarks/</link>
      <pubDate>Sun, 16 Apr 2023 11:40:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2023-bcsmd-benchmarks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Discussion of ‘Moving from What Works to What Replicates: Promoting the Systematic Replication of Results.’</title>
      <link>http://localhost:4321/talk/aera-2023-replication-discussion/</link>
      <pubDate>Sat, 15 Apr 2023 14:50:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2023-replication-discussion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Clustered bootstrapping for selective reporting models in meta-analysis with dependent effects</title>
      <link>http://localhost:4321/talk/esmarconf2023-clustered-bootstrap-selection-model/</link>
      <pubDate>Thu, 30 Mar 2023 08:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/esmarconf2023-clustered-bootstrap-selection-model/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cluster-Bootstrapping a meta-analytic selection model</title>
      <link>http://localhost:4321/cluster-bootstrap-selection-model/</link>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/cluster-bootstrap-selection-model/</guid>
      <description>
&lt;script src=&#34;http://localhost:4321/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;http://localhost:4321/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;style type=&#34;text/css&#34;&gt;
.greybox {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 60%;
  padding: 1em;
  background: lightgrey;
  border: 2px solid darkgrey;
  border-radius: 1px;
  font-size: 0.75em;
}
&lt;/style&gt;
&lt;div class=&#34;greybox&#34;&gt;
&lt;p&gt;The research reported here was supported, in whole or in part, by the Institute of Education Sciences, U.S. Department of Education, through grant R305D220026 to the American Institutes for Research. The opinions expressed are those of the authors and do not represent the views of the Institute or the U.S. Department of Education.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;
Selective reporting of study results is a big concern for meta-analysts. By selective reporting, we mean the phenomenon where affirmative findings—that is, statistically significant findings in the theoretically expected direction—are more likely to be reported and more likely to be available for a systematic review compared to non-affirmative findings. Selective reporting arises due to biases in the publication process, on the part of journals, editors, and reviewers, as well as strategic decisions on part of the authors &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-rothstein2006publication&#34; role=&#34;doc-biblioref&#34;&gt;Rothstein et al., 2006&lt;/a&gt;; &lt;a href=&#34;#ref-sutton2009publication&#34; role=&#34;doc-biblioref&#34;&gt;Sutton, 2009&lt;/a&gt;)&lt;/span&gt;. Research synthesists worry about selective reporting because it can distort the evidence base available for meta-analysis, almost like a fun-house mirror distorts your appearance, leading to inflation of average effect size estimates and biased estimates of heterogeneity.&lt;/p&gt;
&lt;p&gt;If you read the meta-analysis methods literature, you will find scores of tools available to investigate and adjust for the biases created by selective reporting. Well known and widely used methods include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;graphical representations like funnel plots and contour-enhanced funnel plots &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Sterne2011recommendations&#34; role=&#34;doc-biblioref&#34;&gt;Sterne et al., 2011&lt;/a&gt;; &lt;a href=&#34;#ref-sterne2001funnel&#34; role=&#34;doc-biblioref&#34;&gt;Sterne &amp;amp; Egger, 2001&lt;/a&gt;)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;tests for selective reporting (or at least funnel plot asymmetry) like Egger’s regression &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-egger1997bias&#34; role=&#34;doc-biblioref&#34;&gt;Egger et al., 1997&lt;/a&gt;)&lt;/span&gt; or Begg and Mazumdar’s rank correlation test &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-begg1994operating&#34; role=&#34;doc-biblioref&#34;&gt;Begg &amp;amp; Mazumdar, 1994&lt;/a&gt;)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;bias-adjustment methods like PET-PEESE &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-stanley2008metaregression&#34; role=&#34;doc-biblioref&#34;&gt;Stanley, 2008&lt;/a&gt;; &lt;a href=&#34;#ref-stanley2014metaregression&#34; role=&#34;doc-biblioref&#34;&gt;Stanley &amp;amp; Doucouliagos, 2014&lt;/a&gt;)&lt;/span&gt;, Trim-and-Fill &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-duval2000nonparametric&#34; role=&#34;doc-biblioref&#34;&gt;Duval &amp;amp; Tweedie, 2000&lt;/a&gt;)&lt;/span&gt;, and selection models &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hedges2005selection&#34; role=&#34;doc-biblioref&#34;&gt;Hedges &amp;amp; Vevea, 2005&lt;/a&gt;)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;p-value diagnostics like p-curve &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-simonsohn2014pcurve&#34; role=&#34;doc-biblioref&#34;&gt;Simonsohn et al., 2014&lt;/a&gt;)&lt;/span&gt;, p-uniform &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-vanaert2016conducting&#34; role=&#34;doc-biblioref&#34;&gt;Aert et al., 2016&lt;/a&gt;; &lt;a href=&#34;#ref-VanAssen2015meta&#34; role=&#34;doc-biblioref&#34;&gt;Assen et al., 2015&lt;/a&gt;)&lt;/span&gt;, and the test of excess significance &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-ioannidis2007exploratory&#34; role=&#34;doc-biblioref&#34;&gt;Ioannidis &amp;amp; Trikalinos, 2007&lt;/a&gt;)&lt;/span&gt;; and&lt;/li&gt;
&lt;li&gt;sensitivity analyses based on various forms of selection models &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Copas2001sensitivity&#34; role=&#34;doc-biblioref&#34;&gt;Copas &amp;amp; Shi, 2001&lt;/a&gt;; &lt;a href=&#34;#ref-mathur2020sensitivity&#34; role=&#34;doc-biblioref&#34;&gt;Mathur &amp;amp; VanderWeele, 2020&lt;/a&gt;; &lt;a href=&#34;#ref-vevea2005publication&#34; role=&#34;doc-biblioref&#34;&gt;Vevea &amp;amp; Woods, 2005&lt;/a&gt;)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, nearly all of the statistical methods here have the limitation that they are premised on observing independent effect sizes. That presents a problem for meta-analyses in education, psychology, and other social science fields, where it is very common to have meta-analyses involving &lt;em&gt;dependent&lt;/em&gt; effect sizes.&lt;/p&gt;
&lt;p&gt;Dependent effects occur in meta-analyses of group comparisons when primary studies report effects for multiple correlated measures of an outcome, at multiple points in time, or for multiple treatment groups compared to the same control group &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Becker2000multivariate&#34; role=&#34;doc-biblioref&#34;&gt;Becker, 2000&lt;/a&gt;)&lt;/span&gt;. Dependent effects are also common in meta-analyses of correlational effect sizes, where primary studies report more than one relevant correlation coefficient based on the same sample of participants. Methods such as multi-level meta-analysis &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-VandenNoortgate2013threelevel&#34; role=&#34;doc-biblioref&#34;&gt;Van den Noortgate et al., 2013&lt;/a&gt;)&lt;/span&gt; and robust variance estimation &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Hedges2010robust&#34; role=&#34;doc-biblioref&#34;&gt;Hedges et al., 2010&lt;/a&gt;)&lt;/span&gt; are available to accommodate dependent effects when summarizing findings across studies or investigating moderators of effect size using meta-regression, but these techniques have yet to be extended to methods for testing or correcting bias due to selective reporting. Consequently, it’s pretty common to see research synthesis papers that use very sophisticated models for part of the analysis, but then use kludgey, awkward, or hacky approaches when it comes time to investigating selective reporting &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-rodgers2020evaluating&#34; role=&#34;doc-biblioref&#34;&gt;Rodgers &amp;amp; Pustejovsky, 2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Along with &lt;a href=&#34;https://www.air.org/mosaic&#34;&gt;a group of our colleagues&lt;/a&gt; from the American Institutes for Research, we are currently working on a project to develop better methods for investigating selective reporting issues in meta-analyses of dependent effect sizes.
In this post, we will share an early peek under the hood at one little piece of what we’re studying, by sketching out what we think is a promising and pragmatic method for examining selective reporting while &lt;em&gt;also&lt;/em&gt; accounting for effect size dependency. The method is to use a cluster-level bootstrap, which involves re-sampling clusters of observations (i.e., the set of multiple effect size estimates reported within a given primary study) to approximate the sampling distribution of an estimator &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-boos2003introduction&#34; role=&#34;doc-biblioref&#34;&gt;Boos, 2003&lt;/a&gt;; &lt;a href=&#34;#ref-cameron2008bootstrap&#34; role=&#34;doc-biblioref&#34;&gt;Cameron et al., 2008&lt;/a&gt;)&lt;/span&gt;. To illustrate this technique, we will demonstrate how to bootstrap a Vevea-Hedges selection model.&lt;/p&gt;
&lt;p&gt;Selection models comprise a large class of models that have two parts: a model describing the evidence-generation process and a model describing the process by which evidence is reported &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hedges2005selection&#34; role=&#34;doc-biblioref&#34;&gt;Hedges &amp;amp; Vevea, 2005&lt;/a&gt;)&lt;/span&gt;. Vevea-Hedges selection models &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hedges1992modeling&#34; role=&#34;doc-biblioref&#34;&gt;Hedges, 1992&lt;/a&gt;; &lt;a href=&#34;#ref-Hedges1996estimating&#34; role=&#34;doc-biblioref&#34;&gt;Hedges &amp;amp; Vevea, 1996&lt;/a&gt;; &lt;a href=&#34;#ref-vevea1995general&#34; role=&#34;doc-biblioref&#34;&gt;Vevea &amp;amp; Hedges, 1995&lt;/a&gt;)&lt;/span&gt; involve a random effects meta-regression model for the evidence-generation process and a step function for the reporting process. With a step function, we assume that the probability that an effect size estimate is observed depends on the range in which its p-value falls. For instance, effects with &lt;span class=&#34;math inline&#34;&gt;\(.01 &amp;lt; p \leq .05\)&lt;/span&gt; might have some probability &lt;span class=&#34;math inline&#34;&gt;\(\lambda_1\)&lt;/span&gt; of being reported, effects with &lt;span class=&#34;math inline&#34;&gt;\(.05 &amp;lt; p \leq .10\)&lt;/span&gt; might have some other probability &lt;span class=&#34;math inline&#34;&gt;\(\lambda_2\)&lt;/span&gt;, and effects with &lt;span class=&#34;math inline&#34;&gt;\(.10 &amp;lt; p\)&lt;/span&gt; might have some other probability &lt;span class=&#34;math inline&#34;&gt;\(\lambda_3\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Because the Vevea-Hedges model and other selection models separate the data-generation process into these two distinct stages, their parameters have clear interpretations and they can be used to generate bias-adjusted estimates of the distribution of effect sizes and to test for selective reporting issues. The only problem is that available implementations of selection models do not account for effect size dependency—but that’s where cluster bootstrapping could potentially help.&lt;/p&gt;
&lt;div id=&#34;disclaimer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;To be clear, this post is based on work in progress. The cluster-bootstrap selection model that we’re going to demonstrate is an &lt;em&gt;experimental&lt;/em&gt; and &lt;em&gt;exploratory&lt;/em&gt; technique. We’re currently studying its properties and performance using Monte Carlo simulations, but we don’t have formal results to share yet. In the spirit of open and collaborative science, we wrote this post to demonstrate our approach to coding the method, in case others would like to experiment with the technique. Given that there are so few methods available for investigating selective reporting in meta-analyses with dependent effect sizes, we think this method is worth playing with and investigating further, and we would be happy to have others try it out as well. But, if you do so, please treat the results as tentative until we learn more about when the methods work well enough to trust the results.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An Example&lt;/h2&gt;
&lt;p&gt;For demonstrating this method, we will use data from a recent meta-analysis by Lehmann and colleagues &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-lehmann2018metaanalysis&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; that examined the effects of the color red on attractiveness judgments. The data is available via the &lt;a href=&#34;https://wviechtb.github.io/metadat/reference/dat.lehmann2018.html&#34;&gt;&lt;code&gt;metadat&lt;/code&gt;&lt;/a&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-metadat&#34; role=&#34;doc-biblioref&#34;&gt;White et al., 2022&lt;/a&gt;)&lt;/span&gt;. The dataset includes 81 effect sizes from 41 unique studies. You can browse the data for yourself here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metadat)   # for the example dataset
library(tidyverse) # for tidying
library(janitor)   # for tidying variable names
library(metafor)   # for meta-analysis
library(boot)      # for bootstrapping
library(tictoc)    # for keeping time

lehmann_dat &amp;lt;- 
  dat.lehmann2018 %&amp;gt;%
  clean_names() %&amp;gt;%
  mutate(study = str_split_fixed(short_title, pattern = &amp;quot;-&amp;quot;, n = 2)[, 1]) %&amp;gt;%
  arrange(study) %&amp;gt;%
  select(study, presentation = stimuli_presentation, yi, vi, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped table-hover&#34; style=&#34;font-size: 10px; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
study
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
presentation
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
yi
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
vi
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
short_title
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
full_citation
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
pr_publication
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
source_type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
preregistered
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
moderator_group
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
context
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
gender
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_contrast
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_form
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
photo_type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
photo_similarity
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_type
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_items
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_scale
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_scale_bottom
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
dv_scale_top
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
location
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
continent
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
participants
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
participant_notes
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
design
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_majority
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_majority_detail
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_stim
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
eth_match
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_age
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_age
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_red
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_control
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_original
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
color_match
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
presentation_control
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_m
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
red_sd
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_m
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_sd
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
sd_diff
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
rm_r
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
control_attractiveness
&lt;/th&gt;
&lt;th style=&#34;text-align:left;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
notes
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
total_sample_size
&lt;/th&gt;
&lt;th style=&#34;text-align:right;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
pooled
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Banas, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Banas, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Banas, K. (2014, July 7). Replication of Elliot et al. (2010) for CREP at the University of Edinburgh. Retrieved from osf.io/cvdpw
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Scotland
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berthold, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berthold, 2013 - Exp 1 - In Group
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berthold, A. (2013). Unpublished data
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow, M.G., Taylor, G. &amp;amp; Underwood, M. (2013). Context-moderated effect of color on physiological and self-report measures of emotional response. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(37.43/59.24/47.63)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(36.68/34.86/87.99)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow et al., 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigelow, M.G., Taylor, G. &amp;amp; Underwood, M. (2013). Context-moderated effect of color on physiological and self-report measures of emotional response. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(37.43/59.24/47.63)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab(36.68/34.86/87.99)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, C. (2014, August 4). Replication of Elliot et al. (2010). Red, rank, and romance in women viewing men. Retrieved from osf.io/tx2u5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, German translation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not part of CREP because Used white as control condition, dropped yellow as not an original control color, age not included because separated into categories (&amp;lt;25, 26-40, &amp;gt;=41)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
149
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, 2015 - Class Exp
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blech, C. (2015). Unpublished data from a class experiment
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adults
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31.40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Boelk &amp;amp; Madden, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Boelk &amp;amp; Madden, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Boelk, K., &amp;amp; Madden, W. (2014, August 5). Fork of Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Retrieved from osf.io/zf7c9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Buechner et al., 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Buechner et al., 2015 - Exp 1 - Prideful Pose
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Buechner, V. L., Maier, M. A., Lichtenfeld, S., &amp;amp; Elliot, A. J. (2015). Emotion Expression and Color: Their Joint Influence on Perceived Attractiveness and Social Position. Current Psychology, 34(2), 422-433. &lt;a href=&#34;http://doi.org/10.1007/s12144-014-9266-x&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1007/s12144-014-9266-x&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Dot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
High School
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16.88
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.9, 59.7, 25.7)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(49.2, 60.2, 278.2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello J., Groeneboom L. &amp;amp; Pollet T. (2017). Romantic red: Do red products enhance the attractiveness of the consumer? Unpublished masters degree manuscript, University of Leiden
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Item
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
129
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello et al., 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Costello J., Groeneboom L. &amp;amp; Pollet T. (2017). Romantic red: Do red products enhance the attractiveness of the consumer? Unpublished masters degree manuscript, University of Leiden
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Item
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
140
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.37
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same filters applied as in Exp 1 (excluded homosexual and preferred not to answer). Control combines blue and green
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
207
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Maier, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Maier, 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Maier, M. a. (2013). The red-attractiveness effect, applying the Ioannidis and Trikalinos (2007b) test, and the broader scientific context: a reply to Francis (2013). Journal of Experimental Psychology. General, 142(1), 297-300. &lt;a href=&#34;http://doi.org/10.1037/a0029592&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0029592&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(42.6, 45.2, 15.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(43.0, -, 296.7)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
144
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.97
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(46.1, 51.2, 29.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(46.1, 51.0, 147.6)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 58.7, 30.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 52.6)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.77
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(45.9, 54.8, 32.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(46.0, 54.9, 283.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.75
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(55.5, 78.0, 28.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot &amp;amp; Niesta, 2008 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., &amp;amp; Niesta, D. (2008). Romantic red: red enhances men’s attraction to women. Journal of Personality and Social Psychology, 95(5), 1150-1164. &lt;a href=&#34;http://doi.org/10.1037/0022-3514.95.5.1150&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/0022-3514.95.5.1150&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2008.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.3, 58.8, 29.9)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
df doesn’t match sample size
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mehrabian &amp;amp; Blum’s Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinese
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinese
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinese
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.60
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.3, 51.7, 30.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.5, 51.6, 136.6)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.21
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(49.6, 58.8, 30.4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
df doesn’t match sample size
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maner et al perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(54.8, 43.2, 30.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(55.1, 43.7, 283.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2010 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Red, rank, and romance in women viewing men. Journal of Experimental Psychology: General, 139(3), 399-417. &lt;a href=&#34;http://doi.org/10.1037/a0019689&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1037/a0019689&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.46
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(49.6, 58.8, 30.4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sample size taken from Francis, t(df) seems to be using ANOVA df for post-hoc, age data for both male and female participants (separate was not provided)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot et al., 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elliot, A. J., Tracy, J. L., Pazda, A. D., &amp;amp; Beall, A. T. (2013). Red enhances women’s attractiveness to men: First evidence suggesting universality. Journal of Experimental Social Psychology, 49(1), 165-168. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2012.07.017&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2012.07.017&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burkina Faso
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Africa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adults
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Black
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Black
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Black
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.80
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(42.7, 51.5, 20.4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(43.4, 51.5, 269.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Frazier, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Frazier, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Frazier, A. (2014, November 13). Fork of Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Retrieved from osf.io/u0mig
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.90
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gilston &amp;amp; Privitera, 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gilston &amp;amp; Privitera, 2016 - Exp 1 - Healthy
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gilston, A., &amp;amp; Privitera, G. J. (2015). A ‘Healthy’ Color: Information About Healthy Eating Attenuates the ‘Red Effect.’ Global Journal of Health Science, 8(1), 56-61. &lt;a href=&#34;https://doi.org/10.5539/gjhs.v8n1p56&#34; class=&#34;uri&#34;&gt;https://doi.org/10.5539/gjhs.v8n1p56&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gueguen, 2012
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gueguen, 2012 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gueguen, N. (2012). Color and Women Attractiveness: When Red Clothed Women Are Perceived to Have More Intense Sexual Intent. The Journal of Social Psychology, 152(3), 261-265. &lt;a href=&#34;http://doi.org/10.1080/00224545.2011.605398&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1080/00224545.2011.605398&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2012.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
France
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control is average of blue, white, and green
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
120
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger, V. M., Goldbach, L., Carbon, C.-C., Allgemeine, A., Psychologie, E., &amp;amp; Note, A. (2015). Men in red: A reexamination of the red-attractiveness effect. Psychonomic Bulletin &amp;amp; Review, 55(4), 1-6. &lt;a href=&#34;http://doi.org/10.3758/s13423-015-0866-8&#34; class=&#34;uri&#34;&gt;http://doi.org/10.3758/s13423-015-0866-8&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, German translation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CIE-Lab(50, 51, 30)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.98
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger et al. 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Hesslinger, V. M., Goldbach, L., Carbon, C.-C., Allgemeine, A., Psychologie, E., &amp;amp; Note, A. (2015). Men in red: A reexamination of the red-attractiveness effect. Psychonomic Bulletin &amp;amp; Review, 55(4), 1-6. &lt;a href=&#34;http://doi.org/10.3758/s13423-015-0866-8&#34; class=&#34;uri&#34;&gt;http://doi.org/10.3758/s13423-015-0866-8&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, German translation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.60
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CIE-Lab(50, 51, 30)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Johnson et al., 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Johnson et al., 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Johnson, K., Meltzer, A., &amp;amp; Grahe, J. E. (2015, October 12). Fork of Elliot, A. J., Niesta Kayser, D., Greitemeyer, T., Lichtenfeld, S., Gramzow, R. H., Maier, M. A., &amp;amp; Liu, H. (2010). Retrieved from osf.io/ictud
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.94
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.92
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.99
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yellow group also run, but not included
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Khislavsky, 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Khislavsky, 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Khislavsky, A. (2016, March 14). Replication of Elliot et al. (2010). Red, rank, and romance in women viewing men. Retrieved from osf.io/f2udj
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not reviewed by CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
187
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015 - Exp 1 - Heterosexual
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, F. (2015). Wahrgenommene Attraktivitaet und sexuelle Orientierung: Die Wirkung von Rot und Farbpraeferenzen (Perceived attractiveness and sexual orientation: The effects of red and color preferences). Wiesbaden: Springer. doi: 10.1007/978-3-658-08405-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.83
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Cross-gender rating (females rating males). Age includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
161
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015 - Exp 1 - Heterosexual
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, F. (2015). Wahrgenommene Attraktivitaet und sexuelle Orientierung: Die Wirkung von Rot und Farbpraeferenzen (Perceived attractiveness and sexual orientation: The effects of red and color preferences). Wiesbaden: Springer. doi: 10.1007/978-3-658-08405-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Monograph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Cross-gender rating (males rating females). Age includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
105
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, 2015 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kirsch, F. (2015). Wahrgenommene Attraktivitaet und sexuelle Orientierung: Die Wirkung von Rot und Farbpraeferenzen (Perceived attractiveness and sexual orientation: The effects of red and color preferences). Wiesbaden: Springer. doi: 10.1007/978-3-658-08405-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Monograph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Means are only for cross-gender rating (males rating females)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Legate et al., 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Legate et al., 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Legate, N., Baciu, C., Horne, L. M., Fiol, S., Paniagua, D., Muqeet, M., &amp;amp; Zachocki, E. (2015, June 27). Replication of Elliot et al. (2010) at IIT. Retrieved from osf.io/zih7c
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (21 white, 16 asian)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2015 - Class Exp
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White/Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.3, 58.2, 29.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.49
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
116
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White/Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38.32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
114
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
130
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
244
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2015 - Class Exp
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33.88
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
102
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35.85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
104
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
106
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
210
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman, 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lehmann &amp;amp; Calin-Jageman (2017) Is red really romantic? Direct replications suggest little to no effect of the color red on perceived attractiveness for men and women. Social Psychology.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.3, 58.2, 29.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lin, 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lin, 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lin, H. (2014). Red-colored products enhance the attractiveness of women. Displays, 35(4), 202-205. &lt;a href=&#34;http://doi.org/10.1016/j.displa.2014.05.009&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.displa.2014.05.009&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Item
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Taiwan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.39
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control condition is blue; silver condition is dropped as it is not an original control color
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maves &amp;amp; Nadler, 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maves &amp;amp; Nadler, 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Maves, M., &amp;amp; Nadler, J. T. (2016, June 2). Data and Analysis. Retrieved from osf.io/9bm8v
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CREP
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.86
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.48
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, 59.6, 31.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~LCh(50.0, -, 69.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
130
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015 - Exp 1 - Masculine Face
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., &amp;amp; Trujillo, A. (2015), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara &amp;amp; Trujillo, 2015 - Exp 2 - Masculine Face
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., &amp;amp; Trujillo, A. (2015), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28.23
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 2 - Long Shirt
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 2 - Tank Top
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 1 - Long Shirt
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 1 - Tank Top
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 3 - Tank Top
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.83
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
106
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara et al., 2016 - Exp 3 - Long Shirt
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
O’Mara, E. M., Kershaw, C., Receveur, A., Hunt, C., Askar, S., Ballas, T., Farmer, C., O’Koon, B., Stitzel, C., Vavro, C., &amp;amp; Wilhoit, S. (2016), unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.97
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.77
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
120
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2012
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.09
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2012 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A. D., Elliot, A. J., &amp;amp; Greitemeyer, T. (2012). Sexy red: Perceived sexual receptivity mediates the red-attraction relation in men viewing woman. Journal of Experimental Social Psychology, 48(3), 787-790. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2011.12.009&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2011.12.009&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2012.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Austria
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(40.6, 40.4, 20.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(40.3, 41.2, 146.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2014 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A. D., Elliot, A. J., &amp;amp; Greitemeyer, T. (2014). Perceived sexual receptivity and fashionableness: Separate paths linking red and black to perceived attractiveness. Color Research &amp;amp; Application, 39(2), 208-212. &lt;a href=&#34;http://doi.org/10.1002/col.21804&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1002/col.21804&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not specified
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unknown
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (170 white, 142 Asian)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
109
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
125
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
234
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A., Thorstenson &amp;amp; Elliot, A. (2017). Unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single Item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lab study
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
red LCh(42.00, 57.92, 348.89), green LCh(41.50, 56.71, 92.17)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
115
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
115
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
115
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.31
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda et al., 2017 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pazda, A., Thorstenson &amp;amp; Elliot, A. (2017). Unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2017.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single Item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
red LCh(42.00, 57.92, 348.89), green LCh(41.50, 56.71, 92.17)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
228
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
228
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.87
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
228
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.34
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016 - Exp 1 - Short Term
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn, L. S., Roberts, S. C., &amp;amp; Pollet, T. V. (2016). Revisiting the Red Effect on Attractiveness and Sexual Receptivity: No Effect of the Color Red on Human Mate Preferences. Evolutionary Psychology, 14(4). &lt;a href=&#34;http://doi.org/10.1177/1474704916673841&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/1474704916673841&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn et al., 2016 - Exp 2 - Short Term
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Peperkoorn, L. S., Roberts, S. C., &amp;amp; Pollet, T. V. (2016). Revisiting the Red Effect on Attractiveness and Sexual Receptivity: No Effect of the Color Red on Human Mate Preferences. Evolutionary Psychology, 14(4). &lt;a href=&#34;http://doi.org/10.1177/1474704916673841&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/1474704916673841&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mturk
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pollet, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pollet, 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pollet T. (2013). Unpublished data
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Netherlands
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Primarily dutch nationality
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28.40
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Only blue control color used as other control colors were not in original
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009 - Exp 1 - High Arousal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, M. A. (2009). The influence of the amygdala and color on judgments of attractiveness. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2009.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(185, 26, 23)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(216,216,216)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, 2009 - Exp 1 - Low Arousal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Purdy, M. A. (2009). The influence of the amygdala and color on judgments of attractiveness. UNC Asheville Journal, Undergraduate Research Program, Asheville, NC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2009.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(185, 26, 23)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(216,216,216)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.47
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.36
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.21
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Green/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Different between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.38
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.82
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.88
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts et al., 2010 - Exp 3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Roberts, S. C., Owen, R. C., &amp;amp; Havlicek, J. (2010). Distinguishing between Perceiver and Wearer Effects in Clothing Color-Associated Attributions. Evolutionary Psychology, 8(3), 350-364. &lt;a href=&#34;http://doi.org/10.1177/147470491000800304&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491000800304&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item rating of attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
England
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Noted in manuscript all caucasian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.75
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age range includes both male and female participants.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.74
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013 - Exp 1 - Adults Rate Young
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz, S., &amp;amp; Singer, M. (2013). Romantic red revisited: Red enhances men’s attraction to young, but not menopausal women. Journal of Experimental Social Psychology, 49(1), 161-164. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2012.08.004&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2012.08.004&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adults
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lum: 35.2, Chroma: 39.3, Hue no specified
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz &amp;amp; Singer, 2013 - Exp 1 - UGrads Rate Young
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Schwarz, S., &amp;amp; Singer, M. (2013). Romantic red revisited: Red enhances men’s attraction to young, but not menopausal women. Journal of Experimental Social Psychology, 49(1), 161-164. &lt;a href=&#34;http://doi.org/10.1016/j.jesp.2012.08.004&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1016/j.jesp.2012.08.004&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lum: 35.2, Chroma: 39.3, Hue no specified
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.68
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, T., &amp;amp; Klement, V. (2015). The Impact of the Colour Red on Attractiveness Perception. In 4th Advanced Research in Scientific Areas (pp. 20-24). &lt;a href=&#34;http://doi.org/10.18638/arsa.2015.4.1.799&#34; class=&#34;uri&#34;&gt;http://doi.org/10.18638/arsa.2015.4.1.799&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived Attractiveness, subscale of Haselton und Gangestad (2006)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(255.0.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(0.139.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt &amp;amp; Klement, 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, T., &amp;amp; Klement, V. (2015). The Impact of the Colour Red on Attractiveness Perception. In 4th Advanced Research in Scientific Areas (pp. 20-24). &lt;a href=&#34;http://doi.org/10.18638/arsa.2015.4.1.799&#34; class=&#34;uri&#34;&gt;http://doi.org/10.18638/arsa.2015.4.1.799&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived Attractiveness, subscale of Haselton und Gangestad (2006)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.70
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(255.0.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(0.139.0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, 2015 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Seibt, T. (2015). Romantic Red Effect in the Attractiveness Perception. In Hassacc (pp. 31-34). &lt;a href=&#34;http://doi.org/10.18638/hassacc.2015.3.1.186&#34; class=&#34;uri&#34;&gt;http://doi.org/10.18638/hassacc.2015.3.1.186&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Green
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived Attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
25.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Stefan &amp;amp; Gueguen, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Stefan &amp;amp; Gueguen, 2013 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Stefan J. &amp;amp; Gueguen, N. (2013). Unpublished data.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Full Body
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
France
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads and Grads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81.33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26.87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Data provided by Elliot
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Two-year class project posted on OSF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
102
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Latino
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.37
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age recorded as dichotomy (younger then 20, older than 20) so not included
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.75
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan et al., 2016 - Exp 2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sullivan, J., Amaral Lavoie, E., Bays, R. B., Fontana, S., Goodkind, R., Johnson, R., … Lavoie, M. (2016, April 4). Replication of Elliot et al., 2010: Red, Rank, and Romance. Retrieved from osf.io/pm7fx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2016.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unpublished/Online
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Age recorded as dichotomy (younger then 20, older than 20) so not included
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wartenberg et al., 2011
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wartenberg et al., 2011 - Exp 1 - In Group
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wartenberg, W., Hoepfner, T., Potthast, P., &amp;amp; Mirau, A. (2011). If you wear red on a date, you will please your mate. Proceedings of Empiriepraktikumskongress, 6th, Aug. 7, pp 26-27. University of Jena, Germany.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2011.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Conference Proceedings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Germany
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Europe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No Data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.86
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.29
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Translation of summary provided by Elliot; within subjects info still needed
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014 - Exp 1 - Feminine Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen, F., Zuo, B., Wu, Y., Sun, S., &amp;amp; Liu, K. (2014). Red is Romantic, but Only for Feminine Females: Sexual Dimorphism Moderates Red Effect on Sexual Attraction. Evolutionary Psychology, 12(4), 719-735. &lt;a href=&#34;http://doi.org/10.1177/147470491401200404&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491401200404&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, extracted factor
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.1, 57.7, 27.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.6, 57.6, 278.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control is average of blue and white conditions; only normalized scores provided. Age range includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paper
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen et al., 2014 - Exp 1 - Masculine Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wen, F., Zuo, B., Wu, Y., Sun, S., &amp;amp; Liu, K. (2014). Red is Romantic, but Only for Feminine Females: Sexual Dimorphism Moderates Red Effect on Sexual Attraction. Evolutionary Psychology, 12(4), 719-735. &lt;a href=&#34;http://doi.org/10.1177/147470491401200404&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1177/147470491401200404&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2014.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Females
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Clothing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness, extracted factor
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Asian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.1, 57.7, 27.8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(51.6, 57.6, 278.3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Control is average of blue and white conditions; only normalized scores provided. Age range includes participants in all conditions.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013 - Exp 1 - All
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams, C. L. &amp;amp; Neelon, M. (2013). Conditional beauty: The impact of emotionally linked images on the red effect in sexual attraction. Psi Chi Journal of Psychological Research, 18(1), 10-19.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (noted by authors)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(183,70,60)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(76,105,200)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.64
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Data provided by Elliot
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.08
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams &amp;amp; Neelon, 2013 - Exp 2 - Positive and Neutral
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Williams, C. L. &amp;amp; Neelon, M. (2013). Conditional beauty: The impact of emotionally linked images on the red effect in sexual attraction. Psi Chi Journal of Psychological Research, 18(1), 10-19.
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2013.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Perceived attractiveness
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Between Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White (noted by authors)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Matched
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(183,70,60)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RGB(76,105,200)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.69
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Data provided by Elliot
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015 - Exp 1 - More Attractive
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, S. G. (2015). The effect of red on male perceptions of female attractiveness: Moderation by baseline attractiveness of female faces. European Journal of Social Psychology, 45(2), 146-151. &lt;a href=&#34;http://doi.org/10.1002/ejsp.2098&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1002/ejsp.2098&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.90
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.7, 84.6, 34.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.6, -, 265.5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.86
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.84
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Screen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, 2015 - Exp 2 - More Attractive
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Young, S. G. (2015). The effect of red on male perceptions of female attractiveness: Moderation by baseline attractiveness of female faces. European Journal of Social Psychology, 45(2), 146-151. &lt;a href=&#34;http://doi.org/10.1002/ejsp.2098&#34; class=&#34;uri&#34;&gt;http://doi.org/10.1002/ejsp.2098&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Journal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Not Pre-Registered
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Romantic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Males
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue/Gray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Background
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Head Shot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Same between conditions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Single item
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
USA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
North America
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Students
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Undergrads
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Within Subjects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mixed
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
White
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mis-match
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.7, 84.6, 34.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LCh(62.7, 84.6, 34.1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
No
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Yes
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.07
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.98
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Blue and Gray ratings averaged, then compared to red; original data provided
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.09
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;preliminary-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Preliminary Analysis&lt;/h3&gt;
&lt;p&gt;As a little warm-up exercise, here is a basic random effects meta-analysis of these data, fit via the &lt;a href=&#34;https://wviechtb.github.io/metafor/&#34;&gt;metafor&lt;/a&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Viechtbauer2010conducting&#34; role=&#34;doc-biblioref&#34;&gt;Viechtbauer, 2010&lt;/a&gt;)&lt;/span&gt;. We use cluster-robust standard errors to account for effect size dependency.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Estimate random effects model
RE_mod &amp;lt;- rma.uni(yi, vi = vi, data = lehmann_dat, method = &amp;quot;ML&amp;quot;)

# Calculate cluster-robust standard errors
RE_robust &amp;lt;- robust(RE_mod, cluster = study, clubSandwich = TRUE)
RE_robust&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 81; tau^2 estimator: ML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.1009 (SE = 0.0245)
## tau (square root of estimated tau^2 value):      0.3176
## I^2 (total heterogeneity / total variability):   81.54%
## H^2 (total variability / sampling variability):  5.42
## 
## Test for Heterogeneity:
## Q(df = 80) = 246.9683, p-val &amp;lt; .0001
## 
## Number of estimates:   81
## Number of clusters:    41
## Estimates per cluster: 1-6 (mean: 1.98, median: 1)
## 
## Model Results:
## 
## estimate      se¹    tval¹     df¹    pval¹   ci.lb¹   ci.ub¹     
##   0.2069  0.0569   3.6331   23.41   0.0014   0.0892   0.3245   ** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## 1) results based on cluster-robust inference (var-cov estimator: CR2,
##    approx t-test and confidence interval, df: Satterthwaite approx)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The random effects model indicates an average effect size of about 0.21 standard deviations and substantial heterogeneity, with &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.32\)&lt;/span&gt;. The cluster-robust standard error is about 27% bigger than the model-based standard error (not shown) because the latter does not account for dependent effect sizes.&lt;/p&gt;
&lt;p&gt;Here is a contour-enhanced funnel plot of the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funnel(RE_mod, refline = 0, level=c(90, 95, 99), shade=c(&amp;quot;white&amp;quot;, &amp;quot;gray55&amp;quot;, &amp;quot;gray75&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/cluster-bootstrap-selection-model_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The funnel plot shows some asymmetry, suggesting that there is reason to be concerned about selective reporting bias in these data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-selection-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A Selection Model&lt;/h3&gt;
&lt;p&gt;For starters, we will fit a very simple selection model, with a single step in the probability of reporting at &lt;span class=&#34;math inline&#34;&gt;\(\alpha = .025\)&lt;/span&gt;. This is what’s come to be called the &lt;em&gt;three-parameter selection model&lt;/em&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcshane2016adjusting&#34; role=&#34;doc-biblioref&#34;&gt;McShane et al., 2016&lt;/a&gt;)&lt;/span&gt;. The step is defined in terms of a one-sided p-value, so &lt;span class=&#34;math inline&#34;&gt;\(\alpha = .025\)&lt;/span&gt; corresponds to the point where an effect size estimate in the theoretically expected direction would have a regular, two-sided p-value of .05, right at the mystical threshold of statistical significance. We fit the model using &lt;code&gt;metafor&lt;/code&gt;’s &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/selmodel.html&#34;&gt;&lt;code&gt;selmodel()&lt;/code&gt;&lt;/a&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RE_sel &amp;lt;- selmodel(RE_mod, type = &amp;quot;stepfun&amp;quot;, steps = .025)
RE_sel&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 81; tau^2 estimator: ML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.0811 (SE = 0.0261)
## tau (square root of estimated tau^2 value):      0.2848
## 
## Test for Heterogeneity:
## LRT(df = 1) = 37.3674, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub    
##   0.1328  0.0655  2.0267  0.0427  0.0044  0.2612  * 
## 
## Test for Selection Model Parameters:
## LRT(df = 1) = 1.7646, p-val = 0.1840
## 
## Selection Model Results:
## 
##                      k  estimate      se     zval    pval   ci.lb   ci.ub    
## 0     &amp;lt; p &amp;lt;= 0.025  25    1.0000     ---      ---     ---     ---     ---    
## 0.025 &amp;lt; p &amp;lt;= 1      56    0.5485  0.2495  -1.8097  0.0703  0.0594  1.0375  . 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The selection parameter represents the probability that an effect size estimate that is not in the theoretically expected direction or not statistically significant at the conventional level would be included in the synthesis, relative to the probability that an affirmative, statistically significant effect size estimate would be included. In this example, the probability of selection is estimated as 0.55, meaning only about 55% of the non-significant results that we would expect were generated are actually reported. Adjusting for this selection bias, the model estimates an overall average effect size of 0.13 SD—smaller than the unadjusted random effects estimate—with heterogeneity of &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.28\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The problem with this analysis is that the selection model is set up under the assumption that the effect size estimates are all independent. As a result, the reported standard errors are probably smaller than they should be and the confidence intervals are narrower than they should be. We’ll use cluster bootstrapping to get standard errors and confidence intervals that should better account for effect size dependency.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;cluster-bootstrapping-a-selection-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cluster Bootstrapping a Selection Model&lt;/h2&gt;
&lt;p&gt;In R, the &lt;a href=&#34;https://cran.r-project.org/web/packages/boot/boot.pdf&#34;&gt;&lt;code&gt;boot&lt;/code&gt;&lt;/a&gt; package provides tools for running a variety of different bootstrap techniques and obtaining confidence intervals based on bootstrap distributions &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-boot&#34; role=&#34;doc-biblioref&#34;&gt;Canty &amp;amp; Ripley, 2021&lt;/a&gt;)&lt;/span&gt;. It’s been around for ages and has some very nice features, but it requires a bit of trickery to use it for cluster bootstrapping. The main challenge is that the package functionality is set up under the assumption that every row of the dataset should be treated as an independent observation. To make it work for cluster bootstrapping, we will need a function to fit the selection model, which takes in a dataset with one row per cluster and returns a vector of parameter estimates. The function also has to have an index argument which is a vector of row indexes used to create the bootstrap sample. Here is a skeleton for such a function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(
    dat,   # dataset with one row per cluster
    index, # vector of indexes used to create the bootstrap sample
    ...    # any further arguments
) { 
  
  # take subset of data
  boot_dat &amp;lt;- dat[index,]
  
  # fit selection model
  
  # compile parameter estimates into a vector
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;clustering-and-unclustering&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Clustering and unclustering&lt;/h3&gt;
&lt;p&gt;The Lehmann dataset has one row per effect size, sometimes with multiple rows per study, so we need to modify the data to have one row per study. There are at least two ways to accomplish this. One option is to create a dataset consisting only of study-level IDs, then merge it back on to the full data to get the effect-size level data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make a dataset of study IDs
cluster_IDs &amp;lt;- data.frame(study = unique(lehmann_dat$study))

glimpse(cluster_IDs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 41
## Columns: 1
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Ble…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Merge with full data
full_dat &amp;lt;- merge(cluster_IDs, lehmann_dat, by = &amp;quot;study&amp;quot;)

full_dat %&amp;gt;% select(study, yi, vi) %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 81
## Columns: 3
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Big…
## $ yi    &amp;lt;dbl&amp;gt; 0.05716727, 0.55411916, 0.31467980, -0.73259462, 0.07921700, -0.…
## $ vi    &amp;lt;dbl&amp;gt; 0.10267348, 0.06030579, 0.29520322, 0.53354343, 0.02692608, 0.05…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another option is to use the &lt;a href=&#34;https://dplyr.tidyverse.org/reference/nest_by.html&#34;&gt;&lt;code&gt;dplyr::nest_by()&lt;/code&gt;&lt;/a&gt; function to nest the data by cluster &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. Then, we can use &lt;a href=&#34;https://tidyr.tidyverse.org/reference/unnest.html&#34;&gt;&lt;code&gt;tidyr::unnest()&lt;/code&gt;&lt;/a&gt; to recover the effect size level data &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. Like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Nest the data for each study
lehmann_nested &amp;lt;- nest_by(lehmann_dat, study, .key = &amp;quot;data&amp;quot;)

glimpse(lehmann_nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 41
## Columns: 2
## Rowwise: study
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Ble…
## $ data  &amp;lt;list&amp;lt;tibble[,49]&amp;gt;&amp;gt; [&amp;lt;tbl_df[1 x 49]&amp;gt;], [&amp;lt;tbl_df[1 x 49]&amp;gt;], [&amp;lt;tbl_df[2…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Recover the full dataset
full_dat &amp;lt;-
  lehmann_nested %&amp;gt;%
  unnest(data)

full_dat %&amp;gt;% select(study, yi, vi) %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 81
## Columns: 3
## Groups: study [41]
## $ study &amp;lt;chr&amp;gt; &amp;quot;Banas, 2014 &amp;quot;, &amp;quot;Berthold, 2013 &amp;quot;, &amp;quot;Bigelow et al., 2013 &amp;quot;, &amp;quot;Big…
## $ yi    &amp;lt;dbl&amp;gt; 0.05716727, 0.55411916, 0.31467980, -0.73259462, 0.07921700, -0.…
## $ vi    &amp;lt;dbl&amp;gt; 0.10267348, 0.06030579, 0.29520322, 0.53354343, 0.02692608, 0.05…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will follow the latter strategy for the remainder of our example.&lt;/p&gt;
&lt;p&gt;With this nest-and-unnest approach, we can fill in a little bit more of our function skeleton:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(
    dat,   # dataset with one row per cluster
    index, # vector of indexes used to create the bootstrap sample
    ...    # any further arguments
) { 
  
  # take subset of data
  boot_dat_cluster &amp;lt;- dat[index, ]
  
  # expand to one row per effect size
  boot_dat &amp;lt;- tidyr::unnest(boot_dat_cluster, data)
  
  # fit selection model
  
  # compile parameter estimates into a vector
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;selection-model-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Selection model function&lt;/h3&gt;
&lt;p&gt;Next, we need to complete the function by writing code to fit the selection model. This is a little bit involved because of the way the &lt;code&gt;metafor&lt;/code&gt; package implements the Vevea-Hedges selection model. We first need to fit a regular random effects model using &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/rma.uni.html&#34;&gt;&lt;code&gt;metafor::rma.uni()&lt;/code&gt;&lt;/a&gt;, then pass the result to the &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/selmodel.html&#34;&gt;&lt;code&gt;metafor::selmodel()&lt;/code&gt;&lt;/a&gt; function to fit a selection model, and then pull out the parameter estimates as a vector. To make the code clearer, we will move this step out into its own function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_sel_model &amp;lt;- function(dat, steps = .025) {
  
  # initial random effects model
  RE_mod &amp;lt;- metafor::rma.uni(
      yi = yi, vi = vi, data = dat, method = &amp;quot;ML&amp;quot;
  )
  
  # fit selection model
  res &amp;lt;- metafor::selmodel(
    RE_mod, type = &amp;quot;stepfun&amp;quot;, steps = steps,
    skiphes = TRUE, # turn off SE calculation
    skiphet = TRUE # turn off heterogeneity test
  )
  
  # compile parameter estimates into a vector
  c(beta = res$beta[,1], tau = sqrt(res$tau2), delta = res$delta[-1])
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the use of &lt;code&gt;skiphes&lt;/code&gt; and &lt;code&gt;skiphet&lt;/code&gt; arguments in the &lt;code&gt;selmodel()&lt;/code&gt; call, which skip the calculation of standard errors and skip the calculation of the test for heterogeneity. We don’t need the standard errors here because we’re going to use bootstrapping instead, and we’re not interested in the heterogeneity test. Turning off these calculations saves computational time.&lt;/p&gt;
&lt;p&gt;A further complication with fitting a selection model is that the parameter estimates are obtained by maximum likelihood, using an iterative optimization algorithm that sometimes fails to converge. To handle non-convergence, we will pass our function through &lt;a href=&#34;https://purrr.tidyverse.org/reference/possibly.html&#34;&gt;&lt;code&gt;purrr::possibly()&lt;/code&gt;&lt;/a&gt; so that errors are suppressed, rather than causing everything to grind to a halt &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. We set the &lt;code&gt;otherwise&lt;/code&gt; argument so that non-convergent results are returned as &lt;code&gt;NA&lt;/code&gt; values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_sel_model &amp;lt;- purrr::possibly(run_sel_model, otherwise = rep(NA_real_, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-first-bootstrap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A first bootstrap&lt;/h3&gt;
&lt;p&gt;Here is the completed fitting function called &lt;code&gt;fit_selmodel()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(dat, 
                         index = 1:nrow(dat), 
                         steps = 0.025) {
  
  # take subset of data
  boot_dat_cluster &amp;lt;- dat[index, ]
  
  # expand to one row per effect size
  boot_dat &amp;lt;- tidyr::unnest(boot_dat_cluster, data)
  
  # fit selection model, return vector
  run_sel_model(boot_dat, steps = steps)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we take a subset of the data based on the index argument. This generates a bootstrap sample from the original data based on re-sampled clusters. We then use &lt;a href=&#34;https://tidyr.tidyverse.org/reference/unnest.html&#34;&gt;&lt;code&gt;tidyr::unnest()&lt;/code&gt;&lt;/a&gt; to get the effect size level data for those re-sampled clusters. We then re-fit the model using our &lt;code&gt;run_sel_model()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Now let’s apply our function to the Lehmann dataset. We will first need to create a nested version of the dataset, with one row per study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lehmann_nested &amp;lt;- nest_by(lehmann_dat, study, .key = &amp;quot;data&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can fit the selection model using &lt;code&gt;fit_sel_model()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel(lehmann_nested)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## beta.intrcpt          tau        delta 
##    0.1327996    0.2848302    0.5484540&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results reproduce what we saw earlier when we estimated the three parameter selection model.&lt;/p&gt;
&lt;p&gt;Now we can bootstrap using the &lt;a href=&#34;https://cran.r-project.org/web/packages/boot/boot.pdf&#34;&gt;&lt;code&gt;boot::boot()&lt;/code&gt;&lt;/a&gt; function. The inputs to &lt;code&gt;boot()&lt;/code&gt; are the nested dataset, the function to fit the selection model, and then any additional arguments passed to &lt;code&gt;fit_selmodel()&lt;/code&gt;—here we include an argument for &lt;code&gt;steps&lt;/code&gt;—and finally, the number of bootstrap replications:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate bootstrap
set.seed(20230321)

tic()

boots &amp;lt;- boot(
  data = lehmann_nested,            # nested dataset
  statistic = fit_selmodel,         # function for fitting selection model
  steps = .025,                     # further arguments to the fitting function
  R = 1999                          # number of bootstraps
)

time_seq &amp;lt;- toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 265.2 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code takes a while to run, but we can speed it up with parallel processing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parallel-processing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Parallel processing&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;boot&lt;/code&gt; package has some handy parallel processing features, but they can be a bit finicky to use here because of how R manages environments across multiple processes. With the above code, we can’t simply turn on parallel processing because the worker processes won’t know where to find the &lt;code&gt;run_sel_model()&lt;/code&gt; function that gets called inside &lt;code&gt;fit_selmodel()&lt;/code&gt;. To fix this, we include the &lt;code&gt;run_sel_model()&lt;/code&gt; function &lt;em&gt;inside&lt;/em&gt; our fitting function, as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_selmodel &amp;lt;- function(dat, 
                         index = 1:nrow(dat), 
                         steps = 0.025) {
  
  # take subset of data
  boot_dat_cluster &amp;lt;- dat[index, ]
  
  # expand to one row per effect size
  boot_dat &amp;lt;- tidyr::unnest(boot_dat_cluster, data)
  
  # build run_selmodel
  run_sel_model &amp;lt;- function(dat, steps = .025) {
  
    # initial random effects model
    RE_mod &amp;lt;- metafor::rma.uni(
      yi = yi, vi = vi, data = dat, method = &amp;quot;ML&amp;quot;
    )
    
    # fit selection model
    res &amp;lt;- metafor::selmodel(
      RE_mod, type = &amp;quot;stepfun&amp;quot;, steps = steps,
      skiphes = TRUE, # turn off SE calculation
      skiphet = TRUE # turn off heterogeneity test
    )
    
    # compile parameter estimates into a vector
    c(beta = res$beta[,1], tau = sqrt(res$tau2), delta = res$delta[-1])
    
  }
  
  p &amp;lt;- 2L + length(steps)  # calculate total number of model parameters
  
  # error handling for run_sel_model
  run_sel_model &amp;lt;- purrr::possibly(run_sel_model, otherwise = rep(NA_real_, p))
  
  # fit selection model, return vector of parameter estimates
  run_sel_model(boot_dat, steps = steps)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can call &lt;code&gt;boot()&lt;/code&gt; with options for parallel processing. The machine we used to compile this post has 12 cores. We will use half of the available cores for parallel processing. The configuration of parallel processing will depend on your operating system (different options are available for Mac), so you may need to adapt this code a bit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ncpus &amp;lt;- parallel::detectCores() / 2

# Generate bootstrap
set.seed(20230321)

tic()

boots &amp;lt;- boot(
  data = lehmann_nested,
  statistic = fit_selmodel, steps = .025,
  R = 1999,
  parallel = &amp;quot;snow&amp;quot;, ncpus = ncpus # parallel processing options
)

time_par &amp;lt;- toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 63.08 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Parallel processing is really helpful here. We get 2000 bootstraps in 63 seconds, 4.2 times faster than sequential processing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-errors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Standard Errors&lt;/h3&gt;
&lt;p&gt;The standard deviations of the bootstrapped parameter estimates can be interpreted as standard errors for the parameter estimates that take into account the dependence structure of the effect size estimates. Here is a table comparing the cluster-bootstrapped standard errors to the model-based standard errors generated by &lt;code&gt;selmodel()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est &amp;lt;- boots$t0 # original parameter estimates

# calculate bootstrap SEs
boot_SE &amp;lt;- apply(boots$t, 2, sd, na.rm = TRUE)  

# calculate model-based SEs
model_SE &amp;lt;- with(RE_sel, c(se, se.tau2 / (2 * sqrt(tau2)), se.delta[-1]))

# make a table
res &amp;lt;- tibble(
  Parameter = names(est),
  Est = est,
  `SE(bootstrap)` = boot_SE,
  `SE(model)` = model_SE,
  `SE(bootstrap) / SE(model)` = boot_SE / model_SE
)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-condensed&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Parameter
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Est
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SE(bootstrap)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SE(model)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SE(bootstrap) / SE(model)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
beta.intrcpt
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.133
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.113
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.066
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.732
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tau
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.285
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.148
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.046
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.233
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
delta
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.548
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.780
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.127
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The standard errors based on cluster bootstrapping are all substantially larger than the model-based standard errors, which don’t account for dependence.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;confidence-intervals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Confidence Intervals&lt;/h3&gt;
&lt;p&gt;For reporting results from this sort of analysis, it is useful to provide confidence intervals along with the model parameter estimates and standard errors. These can be calculated using the &lt;a href=&#34;https://cran.r-project.org/web/packages/boot/boot.pdf&#34;&gt;&lt;code&gt;boot::boot_ci()&lt;/code&gt;&lt;/a&gt; function. This function provides several different types of confidence intervals; for illustration, we will stick with simple percentile confidence intervals, which are calculated by taking percentiles of the bootstrap distribution of each parameter estimate. To use the function, we’ll specify the type of confidence interval and the index of the parameter we want. An index of 1 is for the overall average effect size:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot.ci(boots, type = &amp;quot;perc&amp;quot;, index = 1) # For overall average ES&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1995 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boots, type = &amp;quot;perc&amp;quot;, index = 1)
## 
## Intervals : 
## Level     Percentile     
## 95%   (-0.0038,  0.4171 )  
## Calculations and Intervals on Original Scale&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the confidence interval for between-study heterogeneity:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot.ci(boots, type = &amp;quot;perc&amp;quot;, index = 2) # For heterogeneity&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1995 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boots, type = &amp;quot;perc&amp;quot;, index = 2)
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.001,  0.489 )  
## Calculations and Intervals on Original Scale&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And for the selection weight:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot.ci(boots, type = &amp;quot;perc&amp;quot;, index = 3) # For selection weight&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1995 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boots, type = &amp;quot;perc&amp;quot;, index = 3)
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.0574,  2.7536 )  
## Calculations and Intervals on Original Scale&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Percentile confidence intervals can be asymmetric, and here the confidence interval for the selection weight parameter is notably asymmetric. The end-points of the confidence interval range from 0.057 (which represents very strong selective reporting, with only 6% of non-significant results reported) to 2.754 (which represents very strong selection &lt;em&gt;against&lt;/em&gt; affirmative results).&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; So, overall we can’t really draw any strong conclusions about the strength of selective reporting.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this post, we’ve demonstrated how to code a cluster-level bootstrap for a three parameter version of the Vevea-Hedges selection model. We think this cluster-bootstrapping technique is interesting and promising because it can be applied with a very broad swath of models and methods to investigate selective reporting. For instance, the code we’ve demonstrated could be modified by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using a meta-regression model instead of just a summary meta-analysis;&lt;/li&gt;
&lt;li&gt;using a different form of selection function such as the beta-weight model proposed by Citkowicz and Vevea &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Citkowicz2017parsimonious&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; or a more elaborate step function with multiple steps; or&lt;/li&gt;
&lt;li&gt;using a step function model applied across subsets of effect sizes, as in &lt;span class=&#34;citation&#34;&gt;Coburn &amp;amp; Vevea (&lt;a href=&#34;#ref-Coburn2015publication&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;a href=&#34;https://wviechtb.github.io/metafor/&#34;&gt;metafor&lt;/a&gt; package implements an expansive set of selection models with the &lt;a href=&#34;https://wviechtb.github.io/metafor/reference/selmodel.html&#34;&gt;&lt;code&gt;selmodel&lt;/code&gt;&lt;/a&gt; function, so one could really just swap specifications in and out. In principle, the cluster-level bootstrap could also be used in combination with other forms of selective reporting analysis such as PET-PEESE &lt;span class=&#34;citation&#34;&gt;(although with such regression adjustments, cluster-robust variance estimation is also an option, see &lt;a href=&#34;#ref-rodgers2020evaluating&#34; role=&#34;doc-biblioref&#34;&gt;Rodgers &amp;amp; Pustejovsky, 2020&lt;/a&gt;)&lt;/span&gt; or Copas-style sensitivity analyses &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Copas2001sensitivity&#34; role=&#34;doc-biblioref&#34;&gt;Copas &amp;amp; Shi, 2001&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We are currently studying the performance of bootstrapping a three parameter selection model in some big Monte Carlo simulations. Based on some very preliminary results, it looks like the cluster bootstrapped selection model provides confidence intervals with reasonable coverage levels. We have more to do before we share these results, so again we want to emphasize that what we have demonstrated in this post is &lt;em&gt;experimental&lt;/em&gt; and &lt;em&gt;exploratory&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Further questions we need to investigate are how things work if we include covariates in the selection model, whether there are better variations of the bootstrap than what we have demonstrated here &lt;span class=&#34;citation&#34;&gt;(e.g., the fractionally weighted bootstrapping, &lt;a href=&#34;#ref-xu2020applications&#34; role=&#34;doc-biblioref&#34;&gt;Xu et al., 2020&lt;/a&gt;)&lt;/span&gt;, and the limits of this method in terms of the number of studies needed for adequate performance. If things pan out, we also plan to turn the workflow we’ve demonstrated here into some more user-friendly functions, perhaps as part of the &lt;a href=&#34;https://meghapsimatrix.github.io/wildmeta/index.html&#34;&gt;wildmeta&lt;/a&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-vanaert2016conducting&#34; class=&#34;csl-entry&#34;&gt;
Aert, R. C. M. van, Wicherts, J. M., &amp;amp; Assen, M. A. L. M. van. (2016). Conducting meta-analyses based on &lt;em&gt;p&lt;/em&gt; values: Reservations and recommendations for applying &lt;em&gt;p&lt;/em&gt; -uniform and &lt;em&gt;p&lt;/em&gt; -curve. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(5), 713–729. &lt;a href=&#34;https://doi.org/10.1177/1745691616650874&#34;&gt;https://doi.org/10.1177/1745691616650874&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-VanAssen2015meta&#34; class=&#34;csl-entry&#34;&gt;
Assen, M. A. L. M. van, Van Aert, R. C. M., &amp;amp; Wicherts, J. M. (2015). &lt;span class=&#34;nocase&#34;&gt;Meta-analysis using effect size distributions of only statistically significant studies&lt;/span&gt;. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;20&lt;/em&gt;(3), 293–309. https://doi.org/&lt;a href=&#34;http://dx.doi.org/10.1037/met0000025&#34;&gt;http://dx.doi.org/10.1037/met0000025&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Becker2000multivariate&#34; class=&#34;csl-entry&#34;&gt;
Becker, B. J. (2000). &lt;span class=&#34;nocase&#34;&gt;Multivariate Meta-analysis&lt;/span&gt;. In S. D. Brown &amp;amp; H. E. A. Tinsley (Eds.), &lt;em&gt;Handbook of applied multivariate statistics and mathematical modeling&lt;/em&gt; (pp. 499–525). Academic Press. &lt;a href=&#34;https://doi.org/10.1016/B978-012691360-6/50018-5&#34;&gt;https://doi.org/10.1016/B978-012691360-6/50018-5&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-begg1994operating&#34; class=&#34;csl-entry&#34;&gt;
Begg, C. B., &amp;amp; Mazumdar, M. (1994). Operating characteristics of a rank correlation test for publication bias. &lt;em&gt;Biometrics&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(4), 1088. &lt;a href=&#34;https://doi.org/10.2307/2533446&#34;&gt;https://doi.org/10.2307/2533446&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-boos2003introduction&#34; class=&#34;csl-entry&#34;&gt;
Boos, D. D. (2003). Introduction to the bootstrap world. &lt;em&gt;Statistical Science&lt;/em&gt;, &lt;em&gt;18&lt;/em&gt;(2), 168–174.
&lt;/div&gt;
&lt;div id=&#34;ref-cameron2008bootstrap&#34; class=&#34;csl-entry&#34;&gt;
Cameron, A. C., Gelbach, J. B., &amp;amp; Miller, D. L. (2008). Bootstrap-based improvements for inference with clustered errors. &lt;em&gt;The Review of Economics and Statistics&lt;/em&gt;, &lt;em&gt;90&lt;/em&gt;(3), 414–427.
&lt;/div&gt;
&lt;div id=&#34;ref-boot&#34; class=&#34;csl-entry&#34;&gt;
Canty, A., &amp;amp; Ripley, B. D. (2021). &lt;em&gt;Boot: Bootstrap r (s-plus) functions&lt;/em&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-Citkowicz2017parsimonious&#34; class=&#34;csl-entry&#34;&gt;
Citkowicz, M., &amp;amp; Vevea, J. L. (2017). &lt;span class=&#34;nocase&#34;&gt;A parsimonious weight function for modeling publication bias&lt;/span&gt;. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;22&lt;/em&gt;(1), 28–41. &lt;a href=&#34;https://doi.org/10.1037/met0000119&#34;&gt;https://doi.org/10.1037/met0000119&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Coburn2015publication&#34; class=&#34;csl-entry&#34;&gt;
Coburn, K. M., &amp;amp; Vevea, J. L. (2015). &lt;span class=&#34;nocase&#34;&gt;Publication bias as a function of study characteristics&lt;/span&gt;. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;20&lt;/em&gt;(3), 310–330. &lt;a href=&#34;https://doi.org/10.1037/met0000046&#34;&gt;https://doi.org/10.1037/met0000046&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Copas2001sensitivity&#34; class=&#34;csl-entry&#34;&gt;
Copas, J., &amp;amp; Shi, J. Q. (2001). &lt;span class=&#34;nocase&#34;&gt;A sensitivity analysis for publication bias in systematic reviews.&lt;/span&gt; &lt;em&gt;Statistical Methods in Medical Research&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;, 251–265.
&lt;/div&gt;
&lt;div id=&#34;ref-duval2000nonparametric&#34; class=&#34;csl-entry&#34;&gt;
Duval, S., &amp;amp; Tweedie, R. (2000). A nonparametric &#34;trim and fill&#34; method of accounting for publication bias in meta-analysis. &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt;, &lt;em&gt;95&lt;/em&gt;(449), 89–98. &lt;a href=&#34;https://doi.org/10.2307/2669529&#34;&gt;https://doi.org/10.2307/2669529&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-egger1997bias&#34; class=&#34;csl-entry&#34;&gt;
Egger, M., Smith, G. D., Schneider, M., &amp;amp; Minder, C. (1997). Bias in meta-analysis detected by a simple, graphical test. &lt;em&gt;BMJ&lt;/em&gt;, &lt;em&gt;315&lt;/em&gt;(7109), 629–634.
&lt;/div&gt;
&lt;div id=&#34;ref-hedges1992modeling&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V. (1992). Modeling publication selection effects in meta-analysis. &lt;em&gt;Statistical Science&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;(2), 246–255.
&lt;/div&gt;
&lt;div id=&#34;ref-Hedges2010robust&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V., Tipton, E., &amp;amp; Johnson, M. C. (2010). &lt;span class=&#34;nocase&#34;&gt;Robust variance estimation in meta-regression with dependent effect size estimates&lt;/span&gt;. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(1), 39–65. &lt;a href=&#34;https://doi.org/10.1002/jrsm.5&#34;&gt;https://doi.org/10.1002/jrsm.5&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Hedges1996estimating&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V., &amp;amp; Vevea, J. L. (1996). &lt;span class=&#34;nocase&#34;&gt;Estimating effect size under publication bias: Small sample properties and robustness of a random effects selection model&lt;/span&gt;. &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt;, &lt;em&gt;21&lt;/em&gt;(4), 299. &lt;a href=&#34;https://doi.org/10.2307/1165338&#34;&gt;https://doi.org/10.2307/1165338&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hedges2005selection&#34; class=&#34;csl-entry&#34;&gt;
Hedges, L. V., &amp;amp; Vevea, J. L. (2005). Selection method approaches. In &lt;em&gt;Publication bias in meta-analysis: Prevention, assessment, and adjustments&lt;/em&gt; (pp. 145–174). John Wiley &amp;amp; Sons.
&lt;/div&gt;
&lt;div id=&#34;ref-ioannidis2007exploratory&#34; class=&#34;csl-entry&#34;&gt;
Ioannidis, J. P. A., &amp;amp; Trikalinos, T. A. (2007). An exploratory test for an excess of significant findings. &lt;em&gt;Clinical Trials&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(3), 245–253. &lt;a href=&#34;https://doi.org/10.1177/1740774507079441&#34;&gt;https://doi.org/10.1177/1740774507079441&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-lehmann2018metaanalysis&#34; class=&#34;csl-entry&#34;&gt;
Lehmann, G. K., Elliot, A. J., &amp;amp; Calin-Jageman, R. J. (2018). Meta-analysis of the effect of red on perceived attractiveness. &lt;em&gt;Evolutionary Psychology&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(4), 147470491880241. &lt;a href=&#34;https://doi.org/10.1177/1474704918802412&#34;&gt;https://doi.org/10.1177/1474704918802412&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mathur2020sensitivity&#34; class=&#34;csl-entry&#34;&gt;
Mathur, M. B., &amp;amp; VanderWeele, T. J. (2020). Sensitivity analysis for publication bias in meta‐analyses. &lt;em&gt;Journal of the Royal Statistical Society: Series C (Applied Statistics)&lt;/em&gt;, &lt;em&gt;69&lt;/em&gt;(5), 1091–1119. &lt;a href=&#34;https://doi.org/10.1111/rssc.12440&#34;&gt;https://doi.org/10.1111/rssc.12440&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcshane2016adjusting&#34; class=&#34;csl-entry&#34;&gt;
McShane, B. B., Böckenholt, U., &amp;amp; Hansen, K. T. (2016). Adjusting for publication bias in meta-analysis an evaluation of selection methods and some cautionary notes. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt;(5), 730–749. &lt;a href=&#34;http://pps.sagepub.com/content/11/5/730.short&#34;&gt;http://pps.sagepub.com/content/11/5/730.short&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rodgers2020evaluating&#34; class=&#34;csl-entry&#34;&gt;
Rodgers, M. A., &amp;amp; Pustejovsky, J. E. (2020). Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes. &lt;em&gt;Psychological Methods&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1037/met0000300&#34;&gt;https://doi.org/10.1037/met0000300&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rothstein2006publication&#34; class=&#34;csl-entry&#34;&gt;
Rothstein, H. R., Sutton, A. J., &amp;amp; Borenstein, M. (2006). &lt;em&gt;Publication bias in meta-analysis: Prevention, assessment and adjustments&lt;/em&gt;. John Wiley &amp;amp; Sons.
&lt;/div&gt;
&lt;div id=&#34;ref-simonsohn2014pcurve&#34; class=&#34;csl-entry&#34;&gt;
Simonsohn, U., Nelson, L. D., &amp;amp; Simmons, J. P. (2014). P-curve and effect size: Correcting for publication bias using only significant results. &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(6), 666–681. &lt;a href=&#34;https://doi.org/10.1177/1745691614553988&#34;&gt;https://doi.org/10.1177/1745691614553988&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stanley2008metaregression&#34; class=&#34;csl-entry&#34;&gt;
Stanley, T. D. (2008). Meta-regression methods for detecting and estimating empirical effects in the presence of publication selection*. &lt;em&gt;Oxford Bulletin of Economics and Statistics&lt;/em&gt;, &lt;em&gt;70&lt;/em&gt;(1), 103–127. &lt;a href=&#34;https://doi.org/10.1111/j.1468-0084.2007.00487.x&#34;&gt;https://doi.org/10.1111/j.1468-0084.2007.00487.x&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stanley2014metaregression&#34; class=&#34;csl-entry&#34;&gt;
Stanley, T. D., &amp;amp; Doucouliagos, H. (2014). Meta-regression approximations to reduce publication selection bias. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;5&lt;/em&gt;(1), 60–78.
&lt;/div&gt;
&lt;div id=&#34;ref-sterne2001funnel&#34; class=&#34;csl-entry&#34;&gt;
Sterne, J. A. C., &amp;amp; Egger, M. (2001). Funnel plots for detecting bias in meta-analysis: Guidelines on choice of axis. &lt;em&gt;Journal of Clinical Epidemiology&lt;/em&gt;, &lt;em&gt;54&lt;/em&gt;(10), 1046–1055.
&lt;/div&gt;
&lt;div id=&#34;ref-Sterne2011recommendations&#34; class=&#34;csl-entry&#34;&gt;
Sterne, J. A. C., Sutton, A. J., Ioannidis, J. P. A., Terrin, N., Jones, D. R., Lau, J., Carpenter, J., Rücker, G., Harbord, R. M., Schmid, C. H., Tetzlaff, J., Deeks, J. J., Peters, J. L., Macaskill, P., Schwarzer, G., Duval, S., Altman, D. G., Moher, D., &amp;amp; Higgins, J. P. T. (2011). &lt;span class=&#34;nocase&#34;&gt;Recommendations for examining and interpreting funnel plot asymmetry in meta-analyses of randomised controlled trials.&lt;/span&gt; &lt;em&gt;BMJ&lt;/em&gt;, &lt;em&gt;343&lt;/em&gt;, d4002. &lt;a href=&#34;https://doi.org/10.1136/bmj.d4002&#34;&gt;https://doi.org/10.1136/bmj.d4002&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-sutton2009publication&#34; class=&#34;csl-entry&#34;&gt;
Sutton, A. (2009). Publication bias. In &lt;em&gt;The handbook of research synthesis and meta-analysis&lt;/em&gt; (pp. 435–445). Russell Sage Foundation.
&lt;/div&gt;
&lt;div id=&#34;ref-VandenNoortgate2013threelevel&#34; class=&#34;csl-entry&#34;&gt;
Van den Noortgate, W., López-López, J. A., Marín-Martínez, F., &amp;amp; Sánchez-Meca, J. (2013). &lt;span class=&#34;nocase&#34;&gt;Three-level meta-analysis of dependent effect sizes&lt;/span&gt;. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;45&lt;/em&gt;(2), 576–594. &lt;a href=&#34;https://doi.org/10.3758/s13428-012-0261-6&#34;&gt;https://doi.org/10.3758/s13428-012-0261-6&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vevea1995general&#34; class=&#34;csl-entry&#34;&gt;
Vevea, J. L., &amp;amp; Hedges, L. V. (1995). A general linear model for estimating effect size in the presence of publication bias. &lt;em&gt;Psychometrika&lt;/em&gt;, &lt;em&gt;60&lt;/em&gt;(3), 419–435. &lt;a href=&#34;https://doi.org/10.1007/BF02294384&#34;&gt;https://doi.org/10.1007/BF02294384&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vevea2005publication&#34; class=&#34;csl-entry&#34;&gt;
Vevea, J. L., &amp;amp; Woods, C. M. (2005). Publication bias in research synthesis: Sensitivity analysis using a priori weight functions. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(4), 428–443. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.10.4.428&#34;&gt;https://doi.org/10.1037/1082-989X.10.4.428&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Viechtbauer2010conducting&#34; class=&#34;csl-entry&#34;&gt;
Viechtbauer, W. (2010). &lt;span class=&#34;nocase&#34;&gt;Conducting meta-analyses in R with the metafor package&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;36&lt;/em&gt;(3), 1–48.
&lt;/div&gt;
&lt;div id=&#34;ref-metadat&#34; class=&#34;csl-entry&#34;&gt;
White, T., Noble, D., Senior, A., Hamilton, W. K., &amp;amp; Viechtbauer, W. (2022). &lt;em&gt;Metadat: Meta-analysis datasets&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=metadat&#34;&gt;https://CRAN.R-project.org/package=metadat&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the &lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-xu2020applications&#34; class=&#34;csl-entry&#34;&gt;
Xu, L., Gotwalt, C., Hong, Y., King, C. B., &amp;amp; Meeker, W. Q. (2020). Applications of the fractional-random-weight bootstrap. &lt;em&gt;The American Statistician&lt;/em&gt;, &lt;em&gt;74&lt;/em&gt;(4), 345–358. &lt;a href=&#34;https://doi.org/10.1080/00031305.2020.1731599&#34;&gt;https://doi.org/10.1080/00031305.2020.1731599&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Technically, these parameters &lt;span class=&#34;math inline&#34;&gt;\(\lambda_1,\lambda_2,\lambda_3\)&lt;/span&gt; are not absolute probabilities but instead &lt;em&gt;relative&lt;/em&gt; risks of being reported, compared to a reference range of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values. In the above example, they would be defined relative to the probability of being reported for an effect size estimate with &lt;span class=&#34;math inline&#34;&gt;\(p \leq .01\)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Compare this to the model-based confidence interval of &lt;span class=&#34;math inline&#34;&gt;\([0.059, 1.037]\)&lt;/span&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Comparison of competing approaches to analyzing cross-classified data: Random effects models, ordinary least squares, or fixed effects with cluster robust standard errors</title>
      <link>http://localhost:4321/publication/competing-approaches-for-cross-classified-data/</link>
      <pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/competing-approaches-for-cross-classified-data/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Between-case standardized mean differences: Flexible methods for single-case designs</title>
      <link>http://localhost:4321/publication/three-level-bc-smd/</link>
      <pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/three-level-bc-smd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cohen&#39;s $d_z$ makes me dizzy when considering measurement error</title>
      <link>http://localhost:4321/dizzy-for-d-z/</link>
      <pubDate>Fri, 17 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/dizzy-for-d-z/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\cor{{\text{cor}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Meta-analyses in education, psychology, and related fields rely heavily of Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, or the standardized mean difference effect size, for quantitatively describing the magnitude and direction of intervention effects. In these fields, Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is so pervasive that its use is nearly automatic, and analysts rarely question its utility or consider alternatives (response ratios, anyone? POMP?). Despite this state of affairs, working with Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is theoretically challenging because the standardized mean difference metric does not have a singular definition. Rather, its definition depends on the choice of the standardizing variance used in the denominator.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this post, I’m going to mull over how measurement error and design decisions influence the metric definition of Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; in basic within-group experimental designs. The distorting effects of measurement error has long been a source of concern within psychometric meta-analysis, a perspective associated with the work of &lt;a href=&#34;https://methods.sagepub.com/book/methods-of-meta-analysis-3e&#34;&gt;Frank Schmidt and Jack Hunter&lt;/a&gt;, and measurement-error corrections are well developed and often applied in meta-analyses of correlations. Straight-forward measurement-error corrections have also been described for Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; from between-group designs (see recent work by &lt;a href=&#34;https://psyarxiv.com/9mpbn/&#34;&gt;Brenton Wiernik and Jeff Dahlke&lt;/a&gt;). However, I have literally never seen a meta-analytic application that applied these corrections and I have thus far been unable to locate work on such corrections specifically for effect sizes in within-group designs.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; So, time to muck about…&lt;/p&gt;
&lt;div id=&#34;effect-size-definitions-in-within-group-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Effect size definitions in within-group designs&lt;/h2&gt;
&lt;p&gt;In basic between-group designs, the only variances in the model are the within-group variances, so the choice of standardizing variance is limited to a) the singular population variance, assuming it is homogeneous across groups, b) the variance of one group, or c) the average of the variances in each group. In most applications, homogeneity is assumed (often without much reflection), version (a) of Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is estimated, and the meta-analyst can go along their merry way. For sake of succinctness, I’ll call this effect size &lt;span class=&#34;math inline&#34;&gt;\(d_{b}\)&lt;/span&gt;, where the &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; indicates the usual version for basic between-group designs.&lt;/p&gt;
&lt;p&gt;For within-group or repeated measures designs, the set of choices is more involved and includes a) standardizing by the across-participant variance in one condition (or both conditions, assuming homogeneity) or b) standardizing by the variance of the difference scores. The former approach is sometimes called &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, the latter is called &lt;span class=&#34;math inline&#34;&gt;\(d_z\)&lt;/span&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt; metric uses the same standardizing variance as the &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; from a basic between-group design, and so results from both types of designs are, in principle, on the same scale.&lt;/p&gt;
&lt;p&gt;In the context of meta-analysis, the comparability of &lt;span class=&#34;math inline&#34;&gt;\(d_b\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt; is useful when working with a set of studies that include both types of designs. On the other hand, in meta-analyses that consist solely of within-group or repeated measures designs, comparability with &lt;span class=&#34;math inline&#34;&gt;\(d_b\)&lt;/span&gt; may be less of a priority and one could consider using &lt;span class=&#34;math inline&#34;&gt;\(d_z\)&lt;/span&gt; for synthesis. Purely on a pragmatic level, using &lt;span class=&#34;math inline&#34;&gt;\(d_z\)&lt;/span&gt; might be attractive because the only pieces of information needed to calculate it are the total sample size and the &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; statistic (or &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value) from the comparison between conditions. In contrast, calculating &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt; also requires the between-participant standard deviations from one or both groups, which primary studies might not always report.&lt;/p&gt;
&lt;p&gt;Going in to this exercise, I had the notion that measurement error would affect &lt;span class=&#34;math inline&#34;&gt;\(d_z\)&lt;/span&gt; to a greater degree than &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt; because &lt;span class=&#34;math inline&#34;&gt;\(d_z\)&lt;/span&gt; involves difference scores and difference scores get hit by measurement error twice. Does this intuition hold up? Let me try to formalize things a bit.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-within-group-design-with-measurement-error&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A within-group design with measurement error&lt;/h2&gt;
&lt;p&gt;Suppose we have a within-group design involving two conditions, where participants are assessed on &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; trials under each condition. Let &lt;span class=&#34;math inline&#34;&gt;\(Y_{ijk}\)&lt;/span&gt; denote the outcome from trial &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; for participant &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under condition &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,N\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;. A basic model for this set-up is
&lt;span class=&#34;math display&#34;&gt;\[
Y_{ijk} = \mu_i + u_{ij} + e_{ijk}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(u_{1j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{2j}\)&lt;/span&gt; are participant-specific errors in the true scores under each condition and the &lt;span class=&#34;math inline&#34;&gt;\(e_{ijk}\)&lt;/span&gt;’s are measurement errors. For simplicity, I will assume that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the true-score variance is equal across conditions, with &lt;span class=&#34;math inline&#34;&gt;\(\Var(u_{ij}) = \sigma^2\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,2\)&lt;/span&gt;,&lt;/li&gt;
&lt;li&gt;the true scores are correlated across conditions, &lt;span class=&#34;math inline&#34;&gt;\(\cor(u_{1j}, u_{2j}) = \rho\)&lt;/span&gt;, and&lt;/li&gt;
&lt;li&gt;measurement errors are uncorrelated and have homogeneous variance across conditions, with &lt;span class=&#34;math inline&#34;&gt;\(\Var(e_{ijk}) = \psi^2\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(\phi = \sigma^2 / (\sigma^2 + \psi^2)\)&lt;/span&gt; denote the reliability (intra-class correlation) of a single observed score. Note that we can write &lt;span class=&#34;math inline&#34;&gt;\(\psi^2\)&lt;/span&gt; in terms of the reliability and true-score variance as &lt;span class=&#34;math inline&#34;&gt;\(\psi^2 = \sigma^2 \times \frac{1 - \phi}{\phi}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Under this model, there are several different standardized mean difference metrics that we could consider. Since measurement reliability might vary from study to study, it would make sense to define the metric in terms of true score variances alone, as
&lt;span class=&#34;math display&#34;&gt;\[
\delta_{av} = \frac{\mu_2 - \mu_1}{\sigma}
\]&lt;/span&gt;
or in terms of the variance of the difference in true scores, as
&lt;span class=&#34;math display&#34;&gt;\[
\delta_z = \frac{\mu_2 - \mu_1}{\sigma \sqrt{2(1 - \rho)}}.
\]&lt;/span&gt;
However, we don’t directly observe the true scores, and we can’t estimate their variance unless we have information about score reliabilities. Thus, meta-analysts will usually need to calculate effect sizes in terms of &lt;em&gt;observed&lt;/em&gt; scores that include measurement error.&lt;/p&gt;
&lt;p&gt;Suppose that the analysis is conducted by taking the average of the &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; trials for each participant under each condition, &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_{ij} = \frac{1}{K} \sum_{k=1}^K Y_{ijk}\)&lt;/span&gt;, and conducting the analysis using these mean scores. The variance of the mean scores is
&lt;span class=&#34;math display&#34;&gt;\[
\Var(\bar{Y}_{ij}) = \sigma^2 \left(1 + \frac{1 - \phi}{\phi K}\right),
\]&lt;/span&gt;
so we can define the observed-score standardized mean difference using raw score standardization as
&lt;span class=&#34;math display&#34;&gt;\[
\tilde\delta_{av} = \frac{\mu_2 - \mu_1}{\sigma \sqrt{1 + \frac{1 - \phi}{\phi K}}} = \frac{1}{\sqrt{1 + \frac{1 - \phi}{\phi K}}} \times \delta_{av}.
\]&lt;/span&gt;
From this expression, we can see that measurement error attenuates the true-score effect size because the multiplier term is always going to be less than one.&lt;/p&gt;
&lt;p&gt;Similarly, the variance of the observed difference scores is
&lt;span class=&#34;math display&#34;&gt;\[
\Var(\bar{Y}_{2j} - \bar{Y}_{1j}) =2 \sigma^2 \left(1 - \rho + \frac{1 - \phi}{\phi K}\right),
\]&lt;/span&gt;
so we can define the observed-score standardized mean difference using change score standardization as
&lt;span class=&#34;math display&#34;&gt;\[
\tilde\delta_z = \frac{\mu_2 - \mu_1}{\sigma \sqrt{2 \left(1 - \rho + \frac{1 - \phi}{\phi K}\right)}} = \sqrt{\frac{1 - \rho}{1 - \rho + \frac{1 - \phi}{\phi K}}} \times \delta_z.
\]&lt;/span&gt;
Again, we can see that measurement error attenuates the true-score effect size because the multiplier term is always going to be less than one. However, unlike with &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt;, the attenuation factor here depends on &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; in addition to &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;. This additional term in the correction factor is one indication that &lt;span class=&#34;math inline&#34;&gt;\(d_z\)&lt;/span&gt; might be less desirable for meta-analysis. Correcting &lt;span class=&#34;math inline&#34;&gt;\(d_z\)&lt;/span&gt; for the distortion from measurement error would require estimates of both the true-score correlation and the reliability of the scores, whereas correcting &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt; would require only the latter.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;meta-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Meta-analysis&lt;/h2&gt;
&lt;p&gt;The relationships between the true-score effect sizes and the analogous observed score effect sizes starts to be a problem when we consider a meta-analysis of multiple primary studies. Primary studies will often use different instruments and procedures for measuring outcomes (necessitating the use of some standardized effect size), and those differences in instruments and procedures might come along with differences in score reliability as well as variation in the number of trials collected per condition (and plenty of other things, such as sample size, participant characteristics, etc.). Procedural heterogeneity like this creates two potential challenges for meta-analysis: bias in average effect sizes and extra heterogeneity in the distribution of effect sizes. Both could make findings from a meta-analysis more difficult to interpret, although I will argue that extra heterogeneity is more concerning than bias.&lt;/p&gt;
&lt;p&gt;To illustrate, let’s now imagine that the parameters of the within-group study design, &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; are random variables, drawn from the distribution of parameters across a population of hypothetical studies.&lt;/p&gt;
&lt;div id=&#34;a-model-for-delta_av&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A model for &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Let’s first consider &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt; and assume that it follows a random effects model, with
&lt;span class=&#34;math display&#34;&gt;\[
\delta_{av} \sim N\left(\mu, \tau^2\right).
\]&lt;/span&gt;
Let’s also assume that the remaining parameters &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; are independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;. These parameters determine the attenuation factor &lt;span class=&#34;math inline&#34;&gt;\(A_{av} = \left(1 + \frac{1 - \phi}{\phi K}\right)^{-1/2}\)&lt;/span&gt;, which relates the observed-score effect size parameter to the true score effect size parameter.&lt;/p&gt;
&lt;p&gt;The bias of &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; is therefore
&lt;span class=&#34;math display&#34;&gt;\[
\E\left(\tilde\delta_{av}\right) = \E\left(A_{av}\delta_{av}\right) = \E(A_{av}) \times \mu.
\]&lt;/span&gt;
Thus, under my very simplistic assumptions, a meta-analysis of observed score Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d_{av}\)&lt;/span&gt; estimates will be biased (downward) for the overall average effect in the true-score distribution.&lt;/p&gt;
&lt;p&gt;You might find that the downward bias in &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; is undesirable. On the other hand, bias might not be as a big a problem as it first seems. If all of the observed-score effect sizes are biased to a degree that is unrelated to the true effects, then bias just stretches or compresses the scale of measurement, but doesn’t necessarily lead to interpretive problems. Imagine you have a ruler that is half an inch too short, and you’re trying to compare the heights of different objects. As long as you use the same ruler, then you will still be able to determine which objects are bigger and which are smaller, and by how much, even if the measurements are off in an absolute sense.&lt;/p&gt;
&lt;p&gt;Apart from bias, however, variability in &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; will also induce &lt;em&gt;additional heterogeneity&lt;/em&gt; in the distribution of observed score effect sizes. This is a clear problem because it creates additional uncertainty, making it harder to draw inferences about the distribution of effects, predict new effect sizes, or identify substantively interesting moderators. To measure this additional heterogeneity and keep its consequences separate from the consequences for bias, I will look at the coefficient of variation in &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt;. Under the assumption that &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; is independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\sqrt{\Var(\tilde\delta_{av})}}{\E(\tilde\delta_{av})} = \frac{\sqrt{(\mu^2 + 2 \tau^2) \Var(A_{av}) + \tau^2 \left[\E(A_{av})\right]^2}}{\E\left(A_{av} \right) \times \mu } = \sqrt{\left[\left(1 + \frac{2 \tau^2}{\mu^2}\right) \frac{\Var(A_{av})}{\left[\E\left(A_{av} \right)\right]^2} + \frac{\tau^2}{\mu^2}\right]}.
\]&lt;/span&gt;
Thus, the coefficient of variation for &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; is amplified by a factor that depends on the squared coefficient of variation of &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt;. Under the same model,
&lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z = A_z \times \delta_{av}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(A_z = \left(1 - \rho + \frac{1 - \phi}{\phi K}\right)^{-1/2}\)&lt;/span&gt;, and so &lt;span class=&#34;math inline&#34;&gt;\(\E(\tilde\delta_z) = \E(A_z) \times \mu\)&lt;/span&gt; and
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\sqrt{\Var(\tilde\delta_z)}}{\E(\tilde\delta_z)} = \sqrt{\left[\left(1 + \frac{2 \tau^2}{\mu^2}\right) \frac{\Var(A_z)}{\left[\E\left(A_z \right)\right]^2} + \frac{\tau^2}{\mu^2}\right]}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To see what’s going on here, let’s consider some specific distributions for these measurement factors. First, let’s assume:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\rho \sim B(14, 6)\)&lt;/span&gt;, so that &lt;span class=&#34;math inline&#34;&gt;\(\E(\rho) = .7\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\Var(\rho) = 0.1^2\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\phi \sim B(3, 5)\)&lt;/span&gt;, so that &lt;span class=&#34;math inline&#34;&gt;\(\E(\rho) = .0.375\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\Var(\rho) = 0.161^2\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(K \sim 1 + Pois(9)\)&lt;/span&gt;, so &lt;span class=&#34;math inline&#34;&gt;\(\E(K) = 10\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\Var(K) = 3^2\)&lt;/span&gt;; and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; are mutually independent and independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below I simulate 50000 samples from these distributions and calculate &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(A_z\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;R &amp;lt;- 50000
rho &amp;lt;- rbeta(R, 14, 6)
phi &amp;lt;- rbeta(R, 3, 5)
K &amp;lt;- 1 + rpois(R, 9)
A_av &amp;lt;- 1 / sqrt(1 + (1 - phi) / (phi * K))
A_z &amp;lt;- 1 / sqrt(2 * (1 - rho + (1 - phi) / (phi * K)))

library(ggplot2)
library(patchwork)

density_plot &amp;lt;- function(x, lab, col, limits) {
  ggplot(data.frame(x), aes(x)) + 
    xlim(limits) +
    geom_density(alpha = 0.4, fill = col) + 
    scale_y_continuous(labels = NULL) +
    theme_minimal() + 
    labs(x = lab, y = NULL)
}

p_A_av &amp;lt;- density_plot(A_av, expression(A[av]),&amp;quot;blue&amp;quot;, c(0.2,1))
p_A_z &amp;lt;- density_plot(A_z, expression(A[z]), &amp;quot;purple&amp;quot;, c(0, 3))
p_A_av + p_A_z&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/dizzy-for-d-z_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The distribution of &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; is mostly concentrated around the mean of &lt;span class=&#34;math inline&#34;&gt;\(E(A_{av}) = 0.898\)&lt;/span&gt;, with a coefficient of variation of &lt;span class=&#34;math inline&#34;&gt;\(CV(A_{av}) = 0.085\)&lt;/span&gt;. In contrast, the distribution of &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; has a mean very close to one, &lt;span class=&#34;math inline&#34;&gt;\(E(A_z) = 1.005\)&lt;/span&gt; but a coefficient of variation of &lt;span class=&#34;math inline&#34;&gt;\(CV(A_z) = 0.209\)&lt;/span&gt;, about 2.5 times larger. Thus, variation in measurement procedure induces more extra heterogeneity into the distribution of &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; than into &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now, one potential objection to this hypothetical scenario is that researchers do not choose the number of trials at random, without consideration for the other parameters of the study design. A more realistic assumption might be that researchers choose &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; to ensure they achieve at least some threshold level of reliability for the observed scores. The reliability of the observed scores is &lt;span class=&#34;math inline&#34;&gt;\(A_{av}^2\)&lt;/span&gt;, so ensuring some threshold of reliability is equivalent to ensuring the square root of the threshold for &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt;. Let’s suppose that researchers always ensure &lt;span class=&#34;math inline&#34;&gt;\(A_{av} \geq 0.8\)&lt;/span&gt; so that reliability is always at least &lt;span class=&#34;math inline&#34;&gt;\(0.64\)&lt;/span&gt;. This leads to the following distributions for &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(A_z\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A_av_trunc &amp;lt;- A_av[A_av &amp;gt;= 0.8]
A_z_trunc &amp;lt;- A_z[A_av &amp;gt;= 0.8]
p_A_av_trunc &amp;lt;- density_plot(A_av_trunc, expression(A[av]),&amp;quot;blue&amp;quot;, c(0.2, 1))
p_A_z_trunc &amp;lt;- density_plot(A_z_trunc, expression(A[z]), &amp;quot;purple&amp;quot;, c(0, 3))
p_A_av_trunc + p_A_z_trunc&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/dizzy-for-d-z_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;960&#34; /&gt;
The distribution of &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; loses its left tail, so that its mean is &lt;span class=&#34;math inline&#34;&gt;\(E(A_{av}|A_{av} \geq 0.8) = 0.917\)&lt;/span&gt; and its coefficient of variation is reduced to &lt;span class=&#34;math inline&#34;&gt;\(CV(A_{av} | A_{av} \geq 0.8) = 0.05\)&lt;/span&gt;. The distribution of &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt; now has a mean of &lt;span class=&#34;math inline&#34;&gt;\(E(A_z | A_{av} \geq 0.8) = 1.044\)&lt;/span&gt; and a coefficient of variation of &lt;span class=&#34;math inline&#34;&gt;\(CV(A_z | A_{av} \geq 0.8) = 0.174\)&lt;/span&gt;, about 3.5 times larger than the squared coefficient of variation of &lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Under both of these scenarios, the observed-score &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; is substantially more sensitive to procedural heterogeneity than is &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt;. Based on this model and hypothetical example, it seems clear &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; should be preferred over &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; as a metric for meta-analysis. However, these relationships are predicated on a certain model for the study-specific parameters. One might object to this model because there’s a sense that we have assumed that &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt; is the right answer. After all, the underlying effect size model is specified in terms of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;, and the design parameters—including &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; in particular—are treated as noise, uncorrelated with &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;.
What happens to the observed-score metrics &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; if we instead start with a model specified in terms of &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-model-for-delta_z&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A model for &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Let’s now see how this works if we treat &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt; as the correct metric and assume that the design parameters are independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt;. Assume that
&lt;span class=&#34;math display&#34;&gt;\[
\delta_z \sim N(\alpha, \omega^2)
\]&lt;/span&gt;
and that the remaining parameters &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; are independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;. Then the observed-score standardized mean difference using change score standardization can be written as &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z = B_z \times \delta_z\)&lt;/span&gt;, where
&lt;span class=&#34;math display&#34;&gt;\[
B_z = \sqrt{\frac{1 - \rho}{1 - \rho + \frac{1 - \phi}{\phi K}}}
\]&lt;/span&gt;
and the observed-score standardized mean difference using raw score standardization can be written as &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av} = B_{av} \times \delta_z\)&lt;/span&gt;, where
&lt;span class=&#34;math display&#34;&gt;\[
B_{av} = \frac{\sqrt{2}(1 - \rho)}{\sqrt{1 - \rho + \frac{1 - \phi}{\phi K}}}.
\]&lt;/span&gt;
The plots below show the distribution of &lt;span class=&#34;math inline&#34;&gt;\(B_z\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B_{av}\)&lt;/span&gt; under the same scenarios considered above. First, the scenario where observed-score reliability is not controlled:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B_z &amp;lt;- sqrt((1 - rho) / (1 - rho + (1 - phi) / (phi * K)))
B_av &amp;lt;- sqrt(2) * (1 - rho) / sqrt(1 - rho + (1 - phi) / (phi * K))

p_B_av &amp;lt;- density_plot(B_av, expression(B[av]),&amp;quot;green&amp;quot;, c(0,1.5))
p_B_z &amp;lt;- density_plot(B_z, expression(B[z]), &amp;quot;yellow&amp;quot;, c(0, 1))
p_B_av + p_B_z&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/dizzy-for-d-z_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;
Second, the scenario where observed-score reliability is at least 0.64:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B_z_trunc &amp;lt;- B_z[A_av &amp;gt;= 0.8]
B_av_trunc &amp;lt;- B_av[A_av &amp;gt;= 0.8]

p_B_av_trunc &amp;lt;- density_plot(B_av, expression(B[av]),&amp;quot;green&amp;quot;, c(0,1.5))
p_B_z_trunc &amp;lt;- density_plot(B_z, expression(B[z]), &amp;quot;yellow&amp;quot;, c(0, 1))
p_B_av_trunc + p_B_z_trunc&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/dizzy-for-d-z_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;960&#34; /&gt;
The table below reports the coefficients of variation for each of the multiplicative factors I have considered.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
dat &amp;lt;- tibble(A_av, A_z, B_av, B_z)

random_rel &amp;lt;- 
  dat |&amp;gt;
  summarise(
    across(everything(), ~ sd(.) / mean(.)),
    reliability = &amp;quot;random&amp;quot;
  )

controlled_rel &amp;lt;-
  dat |&amp;gt;
  filter(A_av &amp;gt;= 0.8) |&amp;gt;
  summarise(
    across(everything(), ~ sd(.) / mean(.)),
    reliability = &amp;quot;at least 0.64&amp;quot;
  )

CVs &amp;lt;- 
  bind_rows(random_rel, controlled_rel) |&amp;gt;
  mutate(
    A_ratio = A_z / A_av,
    B_ratio = B_z / B_av
  ) |&amp;gt;
  select(reliability, A_av, A_z, A_ratio, B_av, B_z, B_ratio)

knitr::kable(
  CVs, 
  digits = c(0,3,3,1,3,3,2),
  caption = &amp;quot;Coefficients of variation&amp;quot;,
  col.names = c(&amp;quot;Reliability&amp;quot;,&amp;quot;$A_{av}$&amp;quot;,&amp;quot;$A_z$&amp;quot;,&amp;quot;$A_z /A_{av}$&amp;quot;, &amp;quot;$B_{av}$&amp;quot;,&amp;quot;$B_z$&amp;quot;, &amp;quot;$B_{z} / B_{av}$&amp;quot;),
  escape = TRUE
)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-6&#34;&gt;Table 1: &lt;/span&gt;Coefficients of variation&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;8%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;8%&#34; /&gt;
&lt;col width=&#34;22%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Reliability&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_{av}\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_z\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_z /A_{av}\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(B_{av}\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(B_z\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(B_{z} / B_{av}\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;random&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.085&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.209&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.286&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.182&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;at least 0.64&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.050&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.174&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.258&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.138&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.53&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The tables are now more or less turned. Under both reliability scenarios, &lt;span class=&#34;math inline&#34;&gt;\(B_z\)&lt;/span&gt; has a lower coefficient of variation than &lt;span class=&#34;math inline&#34;&gt;\(B_{av}\)&lt;/span&gt;, indicating that &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; is less affected by procedural heterogeneity than is &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt;. However, &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; is still affected in absolute terms, considering that the coefficient of variation for &lt;span class=&#34;math inline&#34;&gt;\(B_z\)&lt;/span&gt; is about 79% of the coefficient of variation for &lt;span class=&#34;math inline&#34;&gt;\(A_z\)&lt;/span&gt;. Of course, &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; is quite strongly affected under this model, with a coefficient of variation of 0.258.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;consequences-for-heterogeneity&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Consequences for heterogeneity&lt;/h3&gt;
&lt;p&gt;To make these results a bit more concrete, it’s useful to consider think in terms of heterogeneity of the observed score effect sizes. The figure below plots the CVs of observed-score effect size parameters as a function of the CVs of the true effect size distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyr)
library(stringr)

CV_obs &amp;lt;- 
  CVs |&amp;gt;
  select(-A_ratio, -B_ratio) |&amp;gt;
  pivot_longer(-reliability, names_to = &amp;quot;metric&amp;quot;, values_to = &amp;quot;het&amp;quot;) |&amp;gt;
  expand_grid(tau_mu = seq(0,1,0.02)) |&amp;gt;
  mutate(
    reliability = recode(reliability, &amp;#39;at least 0.64&amp;#39; = &amp;quot;Reliability of at least 0.64&amp;quot;, &amp;#39;random&amp;#39; = &amp;quot;Random reliability&amp;quot;),
    metric = paste0(str_replace(metric, &amp;quot;\\_&amp;quot;,&amp;quot;\\[&amp;quot;),&amp;quot;]&amp;quot;),
    CV = sqrt((1 + 2 * tau_mu^2) * het^2 + tau_mu^2)
  )

CV_ex &amp;lt;- CV_obs |&amp;gt;
  filter(tau_mu == 0.5, reliability == &amp;quot;Reliability of at least 0.64&amp;quot;) |&amp;gt;
  select(metric, CV) |&amp;gt;
  mutate(
    CV = round(CV, 3),
    metric = str_replace(str_sub(metric, 1, -2), &amp;quot;\\[&amp;quot;, &amp;quot;_&amp;quot;)
  ) |&amp;gt;
  pivot_wider(names_from = metric, values_from = CV)

CV_obs_labs &amp;lt;-
  CV_obs %&amp;gt;%
  filter(tau_mu == 0)

ggplot(CV_obs, aes(tau_mu, CV, color = metric)) + 
  facet_wrap(vars(reliability)) +
  scale_x_continuous(expand = expansion(c(0.1,0),0), breaks = seq(0.2, 1, 0.2)) + 
  scale_y_continuous(expand = expansion(0,0), breaks = seq(0, 1, 0.2)) + 
  geom_vline(xintercept = 0) + 
  geom_hline(yintercept = 0) + 
  geom_abline(slope = 1, linetype = &amp;quot;dashed&amp;quot;) + 
  geom_text(
    data = CV_obs_labs, 
    aes(x = tau_mu, y = CV, color = metric, label = metric),
    nudge_x = -0.05,
    parse = TRUE
  ) + 
  geom_line() + 
  theme_minimal() + 
  labs(x = expression(tau / mu), y = &amp;quot;Coefficient of variation for observed score ES&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/dizzy-for-d-z_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
Consider, for instance, a scenario where observed-score reliability is always at least 0.64 and &lt;span class=&#34;math inline&#34;&gt;\(\tau / \mu = 0.5\)&lt;/span&gt;, which would be the case if effect sizes are normally distributed and about 97% of effect sizes are positive. Under the effect size model based on &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;, the observed-score &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; is hardly affected by measurement heterogeneity at all, with a CV of 0.504 but the CV of the observed-score &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; is 0.543. Under the effect size model based on &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;, the observed-score &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; is strongly affected by measurement heterogeneity, with a CV of 0.592; in comparison, the CV of the observed-score &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; of 0.528. Under both models, these increases in CV are effectively constant for larger values of &lt;span class=&#34;math inline&#34;&gt;\(\tau / \mu\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;so-whats-your-point&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;So what’s your point?&lt;/h2&gt;
&lt;p&gt;Unfortunately, this particular trip down a rabbit hole doesn’t seem to yield many clear take-aways. For the scenario that I looked at here, the preferred choice of effect size metric is apparently driven by what assumptions we find more plausible. If we think the more plausible model is the one in which &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; is less strongly affected by measurement variation and therefore preferred. Further, the attenuation in &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_{av}\)&lt;/span&gt; depends only on &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, which might mean that a correction for attenuation is more feasible. However, if we think the more plausible model is the one in which &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; is less strongly affected by measurement variation and therefore preferred.&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; In the latter model, one caveat is that the measurement error attenuation in &lt;span class=&#34;math inline&#34;&gt;\(\tilde\delta_z\)&lt;/span&gt; is still a complicated mess, depending on both the true score correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; and the reliability &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. This would make it pretty hard to implement some sort of correction for attenuation.&lt;/p&gt;
&lt;p&gt;So, how could one decide which meta-analytic model is more plausible in a given application? On a conceptual level, I would argue that the model for &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt; would tend to be more plausible in meta-analyses where there is more operational variation in the interventions examined. I would venture that syntheses that include many different versions of an intervention would tend to have a wider range of correlations between true scores (i.e., more heterogeneous correlations between potential outcomes), even holding the outcome measurement procedures constant. This doesn’t necessarily justify the assumption that &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is independent of &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt;, but it does make it seem rather implausible that &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt; would be independent of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;On a more practical level, it seems like there are a few empirical things that a meta-analyst could do to inform a choice between a model for &lt;span class=&#34;math inline&#34;&gt;\(\delta_{av}\)&lt;/span&gt; and one for &lt;span class=&#34;math inline&#34;&gt;\(\delta_z\)&lt;/span&gt;. Pragmatically, one could calculate both effect size metrics and just see which one exhibits more heterogeneity. All else equal, it seems reasonable to prefer the metric that has less heterogeneity. One could also try to gather data on the correlation between observed scores, on the reliability of the observed scores, and on the number of trials used in each study. With this information, one could construct measurement-related predictors and use them in a meta-regression to explain variation in the observed effect size estimates. Alternately, one could use the formulas given above to implement attenuation corrections for the effect sizes and see if this leads to reduced heterogeneity. How well would any of these approaches actually work? Answering that question would take some further, more careful and systematic investigation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Perhaps because use of Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is so under-scrutinized in practice, methodologists have spent many an afternoon blogging about this problem. For general discussions about issues with how to define Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, see excellent posts from &lt;a href=&#34;https://janhove.github.io/reporting/2015/02/05/standardised-vs-unstandardised-es&#34;&gt;Jan Vanhove&lt;/a&gt; (with &lt;a href=&#34;https://janhove.github.io/design/2015/03/16/standardised-es-revisited&#34;&gt;a sequel&lt;/a&gt;), &lt;a href=&#34;http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/&#34;&gt;Jake Westfall&lt;/a&gt;, &lt;a href=&#34;http://datacolada.org/33&#34;&gt;Uri Simonsohn&lt;/a&gt;, and &lt;a href=&#34;https://transparentstatistics.org/2018/07/05/meanings-effect-size/&#34;&gt;Pierre Dragicevic&lt;/a&gt;; a more formal discussion by &lt;a href=&#34;https://www.floppybunny.org/robin/web/virtualclassroom/stats/basics/articles/effect_size/effect_size_baguley_2009.pdf&#34;&gt;Thom Baguley&lt;/a&gt;; and some very interesting work on alternative conceptualizations by &lt;a href=&#34;https://doi.org/10.1002/jrsm.1130&#34;&gt;Tony Ades and colleagues&lt;/a&gt;.
I can promise, dear reader, that the present blog post will not be nearly as cogent as these contributions—this is more about getting my own thoughts straight than making any recommendations—and so &lt;em&gt;caveat lector&lt;/em&gt; applies.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I would &lt;em&gt;love&lt;/em&gt; to be corrected on both of these points. Please drop a comment or email me with suggested reading.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;When the standardizing variance is calculated using measurements from only one condition (i.e., the pre-test in a repeated measures design), this version of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; corresponds to &lt;code&gt;measure = &#34;SMCR&#34;&lt;/code&gt;, the “standardized mean change using raw score standardization” in &lt;code&gt;metafor::escalc&lt;/code&gt;.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;This version of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; corresponds to &lt;code&gt;measure = &#34;SMCC&#34;&lt;/code&gt;, the “standardized mean change using change score standardization” in &lt;code&gt;metafor::escalc&lt;/code&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;And of course, these two models are not the only alternatives—one could look at intermediate scenarios where &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; are more or less strongly correlated with the true score effect sizes.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>POMADE</title>
      <link>http://localhost:4321/software/pomade/</link>
      <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/pomade/</guid>
      <description>&lt;p&gt;An R package for computing power levels, minimum detectable effect sizes, and minimum required sample sizes for the test of the overall average effect size in meta-analysis of dependent effect sizes. The package also includes functions for creating plots of power analysis results.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Single case design research in Special Education: Next generation standards and considerations</title>
      <link>http://localhost:4321/publication/single-case-next-generation-standards/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/single-case-next-generation-standards/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Corrigendum to Pustejovsky and Tipton (2018), redux</title>
      <link>http://localhost:4321/pusto-tipton-2018-theorem-2-redux/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/pusto-tipton-2018-theorem-2-redux/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;
&lt;strong&gt;UPDATE, March 8, 2023: The correction to our paper has now been published at &lt;em&gt;Journal of Business and Economic Statistics&lt;/em&gt;. It is available at&lt;/strong&gt; &lt;a href=&#34;https://doi.org/10.1080/07350015.2023.2174123&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1080/07350015.2023.2174123&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In my &lt;a href=&#34;http://localhost:4321/publication/rve-in-fixed-effects-models/&#34;&gt;2018 paper with Beth Tipton&lt;/a&gt;, published in the &lt;em&gt;Journal of Business and Economic Statistics&lt;/em&gt;, we considered how to do cluster-robust variance estimation in fixed effects models estimated by weighted (or unweighted) least squares. As explained in &lt;a href=&#34;http://localhost:4321/pusto-tipton-2018-theorem-2/&#34;&gt;my previous post&lt;/a&gt;, we were recently alerted that Theorem 2 in the paper is incorrect as stated. It turns out, the conditions in the original version of the theorem are too general. A more limited version of the Theorem does actually hold, but only for models estimated using ordinary (unweighted) least squares, under a working model that assumes independent, homoskedastic errors. In this post, I’ll give the revised theorem, following the notation and setup of &lt;a href=&#34;http://localhost:4321/pusto-tipton-2018-theorem-2/&#34;&gt;the previous post&lt;/a&gt; (so better read that first, or what follows won’t make much sense!).&lt;/p&gt;
&lt;div id=&#34;theorem-2-revised&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Theorem 2, revised&lt;/h3&gt;
&lt;p&gt;Consider the model
&lt;span class=&#34;math display&#34; id=&#34;eq:regression&#34;&gt;\[
\bm{y}_i = \bm{R}_i \bs\beta + \bm{S}_i \bs\gamma + \bm{T}_i \bs\mu + \bs\epsilon_i, \tag{1}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\bm{y}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times 1\)&lt;/span&gt; vector of responses for cluster &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bm{R}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times r\)&lt;/span&gt; matrix of focal predictors, &lt;span class=&#34;math inline&#34;&gt;\(\bm{S}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times s\)&lt;/span&gt; matrix of additional covariates that vary across multiple clusters, and &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times t\)&lt;/span&gt; matrix encoding cluster-specific fixed effects, all for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,m\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{U}_i = \left[ \bm{R}_i \ \bm{S}_i \right]\)&lt;/span&gt; be the set of predictors that vary across clusters and &lt;span class=&#34;math inline&#34;&gt;\(\bm{X}_i = \left[ \bm{R}_i \ \bm{S}_i \ \bm{T}_i \right]\)&lt;/span&gt; be the full set of predictors. Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{U}}_i = \left(\bm{I} - \bm{T}_i \bm{M}_{\bm{T}}\bm{T}_i&amp;#39;\right) \bm{U}_i\)&lt;/span&gt; be an absorbed version of the focal predictors and the covariates. The cluster-robust variance estimator for the coefficients of &lt;span class=&#34;math inline&#34;&gt;\(\bm{U}_i\)&lt;/span&gt; is
&lt;span class=&#34;math display&#34; id=&#34;eq:CRVE&#34;&gt;\[
\bm{V}^{CR2} = \bm{M}_{\bm{\ddot{U}}} \left(\sum_{i=1}^m \bm{\ddot{U}}_i&amp;#39; \bm{W}_i \bm{A}_i \bm{e}_i \bm{e}_i&amp;#39; \bm{A}_i \bm{W}_i \bm{\ddot{U}}_i \right) \bm{M}_{\bm{\ddot{U}}},
\tag{2}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_1,...,\bm{A}_m\)&lt;/span&gt; are the CR2 adjustment matrices.&lt;/p&gt;
&lt;p&gt;If we assume a working model in which &lt;span class=&#34;math inline&#34;&gt;\(\bs\Psi_i = \sigma^2 \bm{I}_i\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,m\)&lt;/span&gt; and estimate the model by ordinary least squares, then the CR2 adjustment matrices have a fairly simple form:
&lt;span class=&#34;math display&#34; id=&#34;eq:A-matrix&#34;&gt;\[
\bm{A}_i = \left(\bm{I}_i - \bm{X}_i \bm{M_X} \bm{X}_i&amp;#39;\right)^{+1/2},
\tag{3}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(B^{+1/2}\)&lt;/span&gt; is the symmetric square root of the Moore-Penrose inverse of &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}\)&lt;/span&gt;. However, this form is computationally expensive because it involves the full set of predictors, &lt;span class=&#34;math inline&#34;&gt;\(\bm{X}_i\)&lt;/span&gt;, including the cluster-specific fixed effects &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_i\)&lt;/span&gt;. If the model is estimated after absorbing the cluster-specific fixed effects, then it would be convenient to use the adjustment matrices based on the absorbed predictors only,
&lt;span class=&#34;math display&#34; id=&#34;eq:A-tilde&#34;&gt;\[
\bm{\tilde{A}}_i = \left(\bm{I}_i - \bm{\ddot{U}}_i \bm{M_\ddot{U}} \bm{\ddot{U}}_i&amp;#39;\right)^{+1/2}.
\tag{4}
\]&lt;/span&gt;
The original version of Theorem 2 asserted that &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i = \bm{\tilde{A}}_i\)&lt;/span&gt;, which is not actually the case. However, for ordinary least squares with the independent, homoskedastic working model, we can show that &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i \bm{\ddot{U}}_i = \bm{\tilde{A}}_i \bm{\ddot{U}}_i\)&lt;/span&gt;. Thus, it doesn’t matter whether we use &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_i\)&lt;/span&gt; to calculate the cluster-robust variance estimator. We’ll get the same result either way, but &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_i\)&lt;/span&gt; is bit easier to compute.&lt;/p&gt;
&lt;p&gt;Here’s a formal statement of Theorem 2:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{L}_i = \left(\bm{\ddot{U}}&amp;#39;\bm{\ddot{U}} - \bm{\ddot{U}}_i&amp;#39;\bm{\ddot{U}}_i\right)\)&lt;/span&gt; and assume that &lt;span class=&#34;math inline&#34;&gt;\(\bm{L}_1,...,\bm{L}_m\)&lt;/span&gt; have full rank &lt;span class=&#34;math inline&#34;&gt;\(r + s\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(\bm{W}_i = \bm{I}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bs\Phi_i = \bm{I}_i\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,m\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i \bm{\ddot{U}}_i = \bm{\tilde{A}}_i \bm{\ddot{U}}_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\bm{A}}_i\)&lt;/span&gt; are as defined in &lt;a href=&#34;#eq:A-matrix&#34;&gt;(3)&lt;/a&gt; and &lt;a href=&#34;#eq:A-tilde&#34;&gt;(4)&lt;/a&gt;, respectively.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;proof&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Proof&lt;/h3&gt;
&lt;p&gt;We can prove this revised Theorem 2 by showing how &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i\)&lt;/span&gt; can be constructed in terms of &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_i\)&lt;/span&gt;. First, because &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_i&amp;#39;\bm{T}_k = \bm{0}\)&lt;/span&gt; for any &lt;span class=&#34;math inline&#34;&gt;\(i \neq k\)&lt;/span&gt;, it follows that &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_i \bm{M_T} \bm{T}_i&amp;#39;\)&lt;/span&gt; is idempotent, i.e.,
&lt;span class=&#34;math display&#34;&gt;\[
\bm{T}_i \bm{M_T} \bm{T}_i&amp;#39; \bm{T}_i \bm{M_T} \bm{T}_i&amp;#39; = \bm{T}_i \bm{M_T} \bm{T}_i&amp;#39;.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Next, denote the thin QR decomposition of &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{U}}_i\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(\bm{Q}_i \bm{R}_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\bm{Q}_i\)&lt;/span&gt; is semi-orthogonal &lt;span class=&#34;math inline&#34;&gt;\((\bm{Q}_i&amp;#39;\bm{Q}_i = \bm{I})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bm{R}_i\)&lt;/span&gt; has the same rank as &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{U}}_i\)&lt;/span&gt;. Next, let &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{B}}_i = \bm{I}_i - \bm{\ddot{U}}_i \bm{M_\ddot{U}} \bm{\ddot{U}}_i&amp;#39;\)&lt;/span&gt; and observe that this can be written as
&lt;span class=&#34;math display&#34;&gt;\[
\tilde{\bm{B}}_i = \bm{I}_i - \bm{Q}_i \bm{Q}_i&amp;#39; + \bm{Q}_i \left(\bm{I} - \bm{R}_i \bm{M}_{\bm{\ddot{U}}} \bm{R}_i&amp;#39;\right)\bm{Q}_i&amp;#39;.
\]&lt;/span&gt;
It can then be seen that
&lt;span class=&#34;math display&#34;&gt;\[
\bm{\tilde{A}}_i = \tilde{\bm{B}}_i^{+1/2} = \bm{I}_i - \bm{Q}_i \bm{Q}_i&amp;#39; + \bm{Q}_i \left(\bm{I} - \bm{R}_i \bm{M}_{\bm{\ddot{U}}} \bm{R}_i&amp;#39;\right)^{+1/2} \bm{Q}_i&amp;#39;.
\]&lt;/span&gt;
It follows that &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_i \bm{T}_i = \bm{T}_i\)&lt;/span&gt; because &lt;span class=&#34;math inline&#34;&gt;\(\bm{Q}_i&amp;#39;\bm{T}_i = \bm{0}\)&lt;/span&gt;. Further, &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{B}}_i \bm{T}_i = \bm{T}_i\)&lt;/span&gt; as well.&lt;/p&gt;
&lt;p&gt;Now, let &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}_i = \left(\bm{I}_i - \bm{X}_i \bm{M_X} \bm{X}_i&amp;#39;\right)\)&lt;/span&gt; and observe that this can be written as
&lt;span class=&#34;math display&#34;&gt;\[
\bm{B}_i = \bm{I}_i - \bm{\ddot{U}}_i \bm{M_{\ddot{U}}}\bm{\ddot{U}}_i&amp;#39; - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39; = \bm{\tilde{B}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;
\]&lt;/span&gt;
because &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{U}}_i&amp;#39;\bm{T}_i = \bm{0}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We then construct the full adjustment matrix &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i\)&lt;/span&gt; as
&lt;span class=&#34;math display&#34; id=&#34;eq:A-constructed&#34;&gt;\[
\bm{A}_i = \tilde{\bm{A}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;.
\tag{5}
\]&lt;/span&gt;
Showing that &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}_i \bm{A}_i \bm{B}_i \bm{A}_i = \bm{B}_i\)&lt;/span&gt; will suffice to verify that &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i\)&lt;/span&gt; is the symmetric square root of the Moore-Penrose inverse of &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}_i\)&lt;/span&gt;. Because &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_i \bm{M_T} \bm{T}_i&amp;#39;\)&lt;/span&gt; is idempotent, &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{B}}_i \bm{T}_i = \bm{T}_i\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_i \bm{T}_i = \bm{T}_i\)&lt;/span&gt;, we have
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\bm{B}_i \bm{A}_i \bm{B}_i \bm{A}_i &amp;amp;= \left(\tilde{\bm{B}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right) \left(\tilde{\bm{A}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right)\left(\tilde{\bm{B}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right) \left(\tilde{\bm{A}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right) \\
&amp;amp;= \left(\tilde{\bm{B}}_i\tilde{\bm{A}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right)\left(\tilde{\bm{B}}_i\tilde{\bm{A}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right) \\
&amp;amp;= \left(\tilde{\bm{B}}_i\tilde{\bm{A}}_i\tilde{\bm{B}}_i\tilde{\bm{A}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right) \\
&amp;amp;= \left(\tilde{\bm{B}}_i - \bm{T}_i \bm{M_T}\bm{T}_i&amp;#39;\right) \\
&amp;amp;= \bm{B}_i.
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;From the representation of &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i\)&lt;/span&gt; in &lt;a href=&#34;#eq:A-constructed&#34;&gt;(5)&lt;/a&gt;, it is clear that &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_i \bm{\ddot{U}}_i = \bm{\tilde{A}}_i \bm{\ddot{U}}_i - \bm{T}_i \bm{M_T} \bm{T}_i&amp;#39; \bm{\ddot{U}}_i = \bm{\tilde{A}}_i \bm{\ddot{U}}_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Power approximations for overall average effects in meta-analysis of dependent effect sizes</title>
      <link>http://localhost:4321/publication/power-approximations-for-dependent-effects/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/power-approximations-for-dependent-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating narrative performance in children with developmental language disorder: A systematic review and meta-analysis</title>
      <link>http://localhost:4321/publication/investigating-narrative-performance/</link>
      <pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/investigating-narrative-performance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Corrigendum to Pustejovsky and Tipton (2018)</title>
      <link>http://localhost:4321/pusto-tipton-2018-theorem-2/</link>
      <pubDate>Wed, 28 Sep 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/pusto-tipton-2018-theorem-2/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt;
In my &lt;a href=&#34;http://localhost:4321/publication/rve-in-fixed-effects-models/&#34;&gt;2018 paper with Beth Tipton&lt;/a&gt;, published in the &lt;em&gt;Journal of Business and Economic Statistics&lt;/em&gt;, we considered how to do cluster-robust variance estimation in fixed effects models estimated by weighted (or unweighted) least squares. A careful reader, &lt;a href=&#34;https://eeecon.uibk.ac.at/~pfaffermayr/&#34;&gt;Dr. Michael Pfaffermayr&lt;/a&gt;, recently alerted us to a problem with Theorem 2 in the paper, which concerns a computational short cut for a certain cluster-robust variance estimator in models with cluster-specific fixed effects. The theorem is incorrect as stated, and we are currently working on issuing a correction for the published version of the paper. In the interim, this post details the problem with Theorem 2. I’ll first review the CR2 variance estimator, then describe the assertion of the theorem, and then provide a numerical counter-example demonstrating that the assertion is not correct as stated.&lt;/p&gt;
&lt;div id=&#34;a-fixed-effects-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A fixed effects model&lt;/h3&gt;
&lt;p&gt;For data that can be grouped into &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; clusters of observations, we considered the model
&lt;span class=&#34;math display&#34; id=&#34;eq:regression&#34;&gt;\[
\bm{y}_i = \bm{R}_i \bs\beta + \bm{S}_i \bs\gamma + \bm{T}_i \bs\mu + \bs\epsilon_i, \tag{1}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\bm{y}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times 1\)&lt;/span&gt; vector of responses for cluster &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bm{R}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times r\)&lt;/span&gt; matrix of focal predictors, &lt;span class=&#34;math inline&#34;&gt;\(\bm{S}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times s\)&lt;/span&gt; matrix of additional covariates that vary across multiple clusters, and &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_i\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times t\)&lt;/span&gt; matrix encoding cluster-specific fixed effects, all for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,m\)&lt;/span&gt;. The cluster-specific fixed effects satisfy &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_h \bm{T}_i&amp;#39; = \bm{0}\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(h \neq i\)&lt;/span&gt;. Interest centers on inference for the coefficients on the focal predictors &lt;span class=&#34;math inline&#34;&gt;\(\bs\beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We considered estimation of Model &lt;a href=&#34;#eq:regression&#34;&gt;(1)&lt;/a&gt; by weighted least squares (WLS), possibly under a working model for the distribution of &lt;span class=&#34;math inline&#34;&gt;\(\bs\epsilon_i\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{W}_1,...,\bm{W}_m\)&lt;/span&gt; be a set of symmetric weight matrices used for WLS estimation. Sometimes, these weight matrices may be diagonal, consisting of sampling weights for each observation. Other times, the weight matrices may involve off-diagonal terms as well. Consider a working model &lt;span class=&#34;math inline&#34;&gt;\(\Var\left(\bs\epsilon_i | \bm{R}_i, \bm{S}_i, \bm{T}_i\right) = \sigma^2 \bs\Phi_i\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\bs\Phi_i\)&lt;/span&gt; is a symmetric &lt;span class=&#34;math inline&#34;&gt;\(n_i \times n_i\)&lt;/span&gt; matrix that may be a function of a low-dimensional, estimable parameter. Based on this working model, the weight matrices might be taken as &lt;span class=&#34;math inline&#34;&gt;\(\bm{W}_i = \bs{\hat\Phi}_i^{-1}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\bs{\hat\Phi}_i\)&lt;/span&gt; is an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\bs\Phi_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-cr2-variance-estimator&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The CR2 variance estimator&lt;/h3&gt;
&lt;p&gt;In the paper, we provide a generalization of the bias-reduced linearization estimator introduced by &lt;span class=&#34;citation&#34;&gt;McCaffrey et al. (&lt;a href=&#34;#ref-McCaffrey2001generalizations&#34; role=&#34;doc-biblioref&#34;&gt;2001&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Bell &amp;amp; McCaffrey (&lt;a href=&#34;#ref-Bell2002bias&#34; role=&#34;doc-biblioref&#34;&gt;2002&lt;/a&gt;)&lt;/span&gt; that can be applied to Model &lt;a href=&#34;#eq:regression&#34;&gt;(1)&lt;/a&gt;. The variance estimator is effectively a generalization of the HC2 correction for heteroskedasticity-robust standard errors, but that works for models with within-cluster dependence and cluster-specific fixed effects, and so we refer to it the “CR2” estimator.&lt;/p&gt;
&lt;p&gt;In order to define the CR2 variance estimator and explain the issue with Theorem 2, I’ll need to lay down a bit more notation. Let &lt;span class=&#34;math inline&#34;&gt;\(N = \sum_{i=1}^m n_i\)&lt;/span&gt; be the total sample size. Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{U}_i = \left[ \bm{R}_i \ \bm{S}_i \right]\)&lt;/span&gt; be the set of predictors that vary across clusters and &lt;span class=&#34;math inline&#34;&gt;\(\bm{X}_i = \left[ \bm{R}_i \ \bm{S}_i \ \bm{T}_i \right]\)&lt;/span&gt; be the full set of predictors. Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{R}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bm{S}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bm{U}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\bm{X}\)&lt;/span&gt; denote the stacked versions of the cluster-specific matrices (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\bm{R} = \left[\bm{R}_1&amp;#39; \ \bm{R}_2&amp;#39; \ \cdots \ \bm{R}_m&amp;#39;\right]&amp;#39;\)&lt;/span&gt;, etc.). Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{W} = \bigoplus_{i=1}^m \bm{W}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bs\Phi = \bigoplus_{i=1}^m \bs\Phi_i\)&lt;/span&gt;. For a generic matrix &lt;span class=&#34;math inline&#34;&gt;\(\bm{Z}\)&lt;/span&gt;, let &lt;span class=&#34;math inline&#34;&gt;\(\bm{M}_{Z} = \left(\bm{Z}&amp;#39;\bm{W}\bm{Z}\right)^{-1}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bm{H}_{\bm{Z}} = \bm{Z} \bm{M}_{\bm{Z}}\bm{Z}&amp;#39;\bm{W}\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{C}_i\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(n_i \times N\)&lt;/span&gt; matrix that selects the rows of cluster &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from the full set of observations, such that &lt;span class=&#34;math inline&#34;&gt;\(\bm{X}_i = \bm{C}_i \bm{X}\)&lt;/span&gt;. These operators provide an easy way to define absorbed versions of the predictors. Specifically, let &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{S}} = \left(\bm{I} - \bm{H}_{\bm{T}}\right) \bm{S}\)&lt;/span&gt; be the covariates after absorbing (i.e., partialling out) the cluster-specific effects, let &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{U}} = \left(\bm{I} - \bm{H}_{\bm{T}}\right) \bm{U}\)&lt;/span&gt; be an absorbed version of the focal predictors and the covariates, and let &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{R}} = \left(\bm{I} - \bm{H}_{\bm{\ddot{S}}}\right)\left(\bm{I} - \bm{H}_{\bm{T}}\right) \bm{R}\)&lt;/span&gt; be the focal predictors after absorbing the covariates and the cluster-specific fixed effects.&lt;/p&gt;
&lt;p&gt;With this notation established, the CR2 variance estimator has the form
&lt;span class=&#34;math display&#34;&gt;\[
\bm{V}^{CR2} = \bm{M}_{\bm{\ddot{R}}} \left(\sum_{i=1}^m \bm{\ddot{R}}_i&amp;#39; \bm{W}_i \bm{A}_i \bm{e}_i \bm{e}_i&amp;#39; \bm{A}_i \bm{W}_i \bm{\ddot{R}}_i \right) \bm{M}_{\bm{\ddot{R}}},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{R}}_i = \bm{C}_i \bm{\ddot{R}}\)&lt;/span&gt; is the cluster-specific matrix of absorbed focal predictors, &lt;span class=&#34;math inline&#34;&gt;\(\bm{e}_i\)&lt;/span&gt; is the vector of weighted least squares residuals from cluster &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_1,...,\bm{A}_m\)&lt;/span&gt; are a set of adjustment matrices that correct the bias of the residual cross-products.
The adjustment matrices are calculated as follows. Let &lt;span class=&#34;math inline&#34;&gt;\(\bm{D}_i\)&lt;/span&gt; be the upper-right Cholesky factorization of &lt;span class=&#34;math inline&#34;&gt;\(\bm{\Phi}_i\)&lt;/span&gt; and define the matrices
&lt;span class=&#34;math display&#34; id=&#34;eq:B-matrix&#34;&gt;\[
\bm{B}_i = \bm{D}_i \bm{C}_i \left(\bm{I} - \bm{H}_{\bm{X}}\right) \bs\Phi \left(\bm{I} - \bm{H}_{\bm{X}}\right)&amp;#39;\bm{C}_i&amp;#39; \bm{D}_i&amp;#39;
\tag{2}
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,m\)&lt;/span&gt;. The adjustment matrices are then calculated as
&lt;span class=&#34;math display&#34; id=&#34;eq:A-matrix&#34;&gt;\[
\bm{A}_i = \bm{D}_i&amp;#39; \bm{B}_i^{+1/2} \bm{D}_i,
\tag{3}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}_i^{+1/2}\)&lt;/span&gt; is the symmetric square root of the Moore-Penrose inverse of &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}_i\)&lt;/span&gt;.
Theorem 1 in the paper shows that, if the working model &lt;span class=&#34;math inline&#34;&gt;\(\bs\Phi\)&lt;/span&gt; is correctly specified and some conditions on the rank of &lt;span class=&#34;math inline&#34;&gt;\(\bm{U}\)&lt;/span&gt; are satisfied, then the CR2 estimator is exactly unbiased for the sampling variance of the weighted least squares estimator of &lt;span class=&#34;math inline&#34;&gt;\(\bs\beta\)&lt;/span&gt;. Across multiple simulation studies, it’s been observed that the CR2 estimator also works well and outperforms alternative sandwich estimators even when the working model is not correctly specified.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;theorem-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Theorem 2&lt;/h3&gt;
&lt;p&gt;The adjustment matrices given in &lt;a href=&#34;#eq:A-matrix&#34;&gt;(3)&lt;/a&gt; can be expensive to compute directly because the &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}_i\)&lt;/span&gt; matrices involve computing a “residualized” version of the &lt;span class=&#34;math inline&#34;&gt;\(N \times N\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\bs\Phi\)&lt;/span&gt; involving the full set of predictors &lt;span class=&#34;math inline&#34;&gt;\(\bm{X}\)&lt;/span&gt;—including the cluster-specific fixed effects &lt;span class=&#34;math inline&#34;&gt;\(\bm{T}_1,...,\bm{T}_m\)&lt;/span&gt;. Theorem 2 considered whether one can take a computational short cut by omitting the cluster-specific fixed effects from the calculation of the &lt;span class=&#34;math inline&#34;&gt;\(\bm{B}_i\)&lt;/span&gt; matrices. Specifically, define the modified matrices
&lt;span class=&#34;math display&#34; id=&#34;eq:B-modified&#34;&gt;\[
\bm{\tilde{B}}_i = \bm{D}_i \bm{C}_i \left(\bm{I} - \bm{H}_{\bm{\ddot{U}}}\right) \bs\Phi \left(\bm{I} - \bm{H}_{\bm{\ddot{U}}}\right)&amp;#39;\bm{C}_i&amp;#39; \bm{D}_i&amp;#39;
\tag{4}
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34; id=&#34;eq:A-modified&#34;&gt;\[
\bm{\tilde{A}}_i = \bm{D}_i&amp;#39; \bm{\tilde{B}}_i^{+1/2} \bm{D}_i,
\tag{5}.
\]&lt;/span&gt;
Theorem 2 claims that if the weight matrices are inverse of the working model, such that &lt;span class=&#34;math inline&#34;&gt;\(\bm{W}_i = \bs\Phi_i^{-1}\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,m\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{B}}_i^{+1/2} = \bm{B}_i^{+1/2}\)&lt;/span&gt; and hence &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_i = \bm{A}_i\)&lt;/span&gt;. The implication is that the cluster-specific fixed effects can be ignored when calculating the adjustment matrices. However, the claimed equivalence does not actually hold.&lt;/p&gt;
&lt;p&gt;Here is a simple numerical example that contradicts the assertion of Theorem 2. I first create a predictor matrix consisting of 4 clusters, a single focal predictor, and cluster-specific fixed effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(20220926)
m &amp;lt;- 4                                             # number of clusters
ni &amp;lt;- 2 + rpois(m, 3.5)                            # cluster sizes
N &amp;lt;- sum(ni)                                       # total sample size
id &amp;lt;- factor(rep(LETTERS[1:m], ni))                # cluster ID
R &amp;lt;- rnorm(N)                                      # focal predictor
dat &amp;lt;- data.frame(R, id)                           # create raw data frame
X &amp;lt;- model.matrix(~ R + id + 0, data = dat)        # full predictor matrix
Ui &amp;lt;- tapply(R, id, \(x) x - mean(x))              # absorbed version of R
U &amp;lt;- unsplit(Ui, id)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Consider a model estimated by ordinary least squares, where the assumed working model is homoskedastic and independent errors, so &lt;span class=&#34;math inline&#34;&gt;\(\bs\Phi_i = \bm{I}_i\)&lt;/span&gt;, an &lt;span class=&#34;math inline&#34;&gt;\(n_i \times n_i\)&lt;/span&gt; identity matrix (with no parameters to estimate). In this case, the adjustment matrices simplify considerably, to
&lt;span class=&#34;math display&#34;&gt;\[
\bm{A}_i = \left(\bm{I}_i - \bm{X}_i \bm{M}_{X} \bm{X}_i&amp;#39; \right)^{+1/2} \qquad \text{and} \qquad \bm{\tilde{A}}_i = \left(\bm{I}_i - \bm{\ddot{U}}_i \bm{M}_{\ddot{U}} \bm{\ddot{U}}_i&amp;#39; \right)^{+1/2}.
\]&lt;/span&gt;
I calculate these directly as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_power &amp;lt;- function(x, p) {
  eig &amp;lt;- eigen(x, symmetric = TRUE)
  val_p &amp;lt;- with(eig, ifelse(values &amp;gt; 10^-12, values^p, 0))
  with(eig, vectors %*% (val_p * t(vectors)))
}

MX &amp;lt;- solve(crossprod(X))
B &amp;lt;- 
  by(X, id, as.matrix) |&amp;gt;
  lapply(\(x) diag(nrow(x)) - x %*% MX %*% t(x))
A &amp;lt;- lapply(B, matrix_power, p = -1/2)
  
MU &amp;lt;- 1 / crossprod(U)
Btilde &amp;lt;- lapply(Ui, \(x) diag(length(x)) - x %*% MU %*% t(x))
Atilde &amp;lt;- lapply(Btilde, matrix_power, p = -1/2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the adjustment matrices based on the full predictor matrix &lt;span class=&#34;math inline&#34;&gt;\(\bm{X}\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(A, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $A
##        [,1]   [,2]   [,3]   [,4]   [,5]
## [1,]  0.853 -0.198 -0.207 -0.191 -0.257
## [2,] -0.198  0.800 -0.200 -0.200 -0.202
## [3,] -0.207 -0.200  0.801 -0.201 -0.192
## [4,] -0.191 -0.200 -0.201  0.802 -0.210
## [5,] -0.257 -0.202 -0.192 -0.210  0.860
## 
## $B
##        [,1]   [,2]   [,3]
## [1,]  0.668 -0.338 -0.330
## [2,] -0.338  0.683 -0.345
## [3,] -0.330 -0.345  0.675
## 
## $C
##        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]
## [1,]  0.873 -0.206 -0.163 -0.105 -0.233 -0.166
## [2,] -0.206  0.873 -0.171 -0.229 -0.100 -0.167
## [3,] -0.163 -0.171  0.834 -0.160 -0.173 -0.167
## [4,] -0.105 -0.229 -0.160  0.931 -0.271 -0.166
## [5,] -0.233 -0.100 -0.173 -0.271  0.946 -0.168
## [6,] -0.166 -0.167 -0.167 -0.166 -0.168  0.833
## 
## $D
##        [,1]   [,2]   [,3]
## [1,]  0.797 -0.342 -0.455
## [2,] -0.342  0.667 -0.325
## [3,] -0.455 -0.325  0.780&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare the above with the adjustment matrices based on the absorbed predictors only:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(Atilde, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $A
##          [,1]      [,2]     [,3]      [,4]     [,5]
## [1,]  1.05313  0.001860 -0.00742  0.008995 -0.05657
## [2,]  0.00186  1.000065 -0.00026  0.000315 -0.00198
## [3,] -0.00742 -0.000260  1.00104 -0.001257  0.00790
## [4,]  0.00900  0.000315 -0.00126  1.001523 -0.00958
## [5,] -0.05657 -0.001980  0.00790 -0.009576  1.06022
## 
## $B
##          [,1]     [,2]     [,3]
## [1,]  1.00139 -0.00478  0.00339
## [2,] -0.00478  1.01642 -0.01163
## [3,]  0.00339 -0.01163  1.00824
## 
## $C
##           [,1]      [,2]      [,3]      [,4]     [,5]      [,6]
## [1,]  1.039180 -0.039378  4.00e-03  0.061921 -0.06632  5.94e-04
## [2,] -0.039378  1.039577 -4.02e-03 -0.062234  0.06665 -5.97e-04
## [3,]  0.003999 -0.004019  1.00e+00  0.006320 -0.00677  6.07e-05
## [4,]  0.061921 -0.062234  6.32e-03  1.097861 -0.10481  9.39e-04
## [5,] -0.066317  0.066651 -6.77e-03 -0.104808  1.11225 -1.01e-03
## [6,]  0.000594 -0.000597  6.07e-05  0.000939 -0.00101  1.00e+00
## 
## $D
##          [,1]     [,2]    [,3]
## [1,]  1.13078 -0.00914 -0.1216
## [2,] -0.00914  1.00064  0.0085
## [3,] -0.12165  0.00850  1.1131&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The matrices differ:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(A, Atilde)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Component \&amp;quot;A\&amp;quot;: Mean relative difference: 0.6073885&amp;quot;
## [2] &amp;quot;Component \&amp;quot;B\&amp;quot;: Mean relative difference: 0.7403564&amp;quot;
## [3] &amp;quot;Component \&amp;quot;C\&amp;quot;: Mean relative difference: 0.5671847&amp;quot;
## [4] &amp;quot;Component \&amp;quot;D\&amp;quot;: Mean relative difference: 0.6682793&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus, Theorem 2 is incorrect as stated. (I have yet to identify the mis-step in the proof as given in the supplementary materials of the paper.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further thoughts&lt;/h3&gt;
&lt;p&gt;For this particular model specification, it is interesting to note that &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_i = \bm{A}_i + \bm{T}_i \bm{M}_{\bm{T}} \bm{T}_i&amp;#39;\)&lt;/span&gt;. Because &lt;span class=&#34;math inline&#34;&gt;\(\bm{\ddot{U}}_i&amp;#39; \bm{T}_i = \bm{0}\)&lt;/span&gt;, it follows that
&lt;span class=&#34;math display&#34;&gt;\[
\bm{\ddot{U}}_i&amp;#39; \bm{\tilde{A}}_i = \bm{\ddot{U}}_i&amp;#39; \left(\bm{A}_i + \bm{T}_i \bm{M}_{\bm{T}} \bm{T}_i&amp;#39; \right) = \bm{\ddot{U}}_i&amp;#39; \bm{A}_i.
\]&lt;/span&gt;
This holds in the numerical example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;UiAtilde &amp;lt;- mapply(\(u, a) t(u) %*% a, u = Ui, a = Atilde, SIMPLIFY = FALSE)
UiA &amp;lt;- mapply(\(u, a) t(u) %*% a, u = Ui, a = A, SIMPLIFY = FALSE)
all.equal(UiAtilde, UiA)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus, although the exact statement of Theorem 2 is incorrect, the substantive implication actually still holds. For this particular example, computing the CR2 variance estimator using the short-cut adjustment matrices &lt;span class=&#34;math inline&#34;&gt;\(\bm{\tilde{A}}_1,...,\bm{\tilde{A}}_m\)&lt;/span&gt; is equivalent to computing the CR2 variance estimator using the full model adjustment matrices &lt;span class=&#34;math inline&#34;&gt;\(\bm{A}_1,...,\bm{A}_m\)&lt;/span&gt;. However, I have not yet been able to work out the general conditions under which this equivalence holds. It may require stricter conditions than those assumed in Theorem 2.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-Bell2002bias&#34; class=&#34;csl-entry&#34;&gt;
Bell, R. M., &amp;amp; McCaffrey, D. F. (2002). &lt;span class=&#34;nocase&#34;&gt;Bias reduction in standard errors for linear regression with multi-stage samples&lt;/span&gt;. &lt;em&gt;Survey Methodology&lt;/em&gt;, &lt;em&gt;28&lt;/em&gt;(2), 169–181.
&lt;/div&gt;
&lt;div id=&#34;ref-McCaffrey2001generalizations&#34; class=&#34;csl-entry&#34;&gt;
McCaffrey, D. F., Bell, R. M., &amp;amp; Botts, C. H. (2001). &lt;span class=&#34;nocase&#34;&gt;Generalizations of biased reduced linearization&lt;/span&gt;. &lt;em&gt;Proceedings of the Annual Meeting of the American Statistical Association&lt;/em&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A matter of emphasis: Comparison of working models for meta-analysis of dependent effect sizes</title>
      <link>http://localhost:4321/talk/srsm-2022-matter-of-emphasis/</link>
      <pubDate>Wed, 20 Jul 2022 14:50:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/srsm-2022-matter-of-emphasis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The state of single case synthesis: Premises, tools, and possibilities</title>
      <link>http://localhost:4321/talk/sscc-2022-state-of-scd-synthesis/</link>
      <pubDate>Thu, 19 May 2022 13:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sscc-2022-state-of-scd-synthesis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-level meta-analysis of single-case experimental designs using robust variance estimation</title>
      <link>http://localhost:4321/publication/sced-mlma-rve/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/sced-mlma-rve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Augmentative and Alternative Communication intervention targets for school-aged participants with ASD and ID: A single-case systematic review and meta-analysis</title>
      <link>http://localhost:4321/publication/aac-communication-outcomes/</link>
      <pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/aac-communication-outcomes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Considering instructional contexts in AAC interventions for people with ASD and/or IDD experiencing complex communication needs: A single-case design meta-analysis</title>
      <link>http://localhost:4321/publication/aac-instructional-contexts/</link>
      <pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/aac-instructional-contexts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Participant characteristics predicting communication outcomes in AAC implementation for individuals with ASD and IDD: Meta-analysis</title>
      <link>http://localhost:4321/publication/aac-participant-characteristics/</link>
      <pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/aac-participant-characteristics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meta-Analysis with robust variance estimation: Expanding the range of working models</title>
      <link>http://localhost:4321/publication/rve-meta-analysis-expanding-the-range/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/rve-meta-analysis-expanding-the-range/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Selective reporting in meta-analysis of dependent effect size estimates</title>
      <link>http://localhost:4321/talk/stanford-qsu-2022-selective-reporting/</link>
      <pubDate>Tue, 08 Feb 2022 18:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/stanford-qsu-2022-selective-reporting/</guid>
      <description>&lt;p&gt;Publication bias and other forms of selective outcome reporting are important threats to the validity of findings from research syntheses—even undermining their special status for informing evidence-based practice and policy guidance. An array of methods have been proposed for detecting selective outcome reporting, but nearly all of the available statistical tests are premised on the assumption that each study contributes a single effect size, which is statistically independent of the other effect sizes in the analysis. In practice, however, it is very common for meta-analyses to include studies that contribute multiple, statistically dependent effect sizes (e.g., effect sizes for multiple, related outcome measures, effect sizes at different follow-up times, or effect sizes from multiple replications based on a common protocol). In this talk, I will review these issues and describe the range of methods that synthesists currently use to examine selective reporting issues under effect size dependence. I then describe a new test for diagnosing selective reporting by comparing the observed number of statistically significant effect sizes to the number expected based on the power of included studies to detect the estimated average effect. This test generalizes the Test of Excess Significance (TES; Ioannidis &amp;amp; Trikalinos, 2007) and is closely related to the score test under a simple version of the Vevea and Hedges (1995) selection model. It uses cluster-robust sandwich estimation methods to handle dependence of effect sizes nested within studies. I report some simulation evidence on the power of this new test relative to existing alternatives and discuss further directions for investigating selective reporting issues in meta-analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cluster wild bootstrapping to handle dependent effect sizes in meta-analysis with a small number of studies</title>
      <link>http://localhost:4321/publication/cluster-wild-bootstrap-for-meta-analysis/</link>
      <pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/cluster-wild-bootstrap-for-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Easy, cluster-robust standard errors with the clubSandwich package</title>
      <link>http://localhost:4321/talk/oslorug-2022-clubsandwich/</link>
      <pubDate>Thu, 03 Feb 2022 10:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/oslorug-2022-clubsandwich/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Examining the effects of social stories on challenging behavior and prosocial skills in young children: A systematic review and meta-analysis</title>
      <link>http://localhost:4321/publication/effects-of-social-stories-on-challenging-behavior-and-prosocial-skills/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/effects-of-social-stories-on-challenging-behavior-and-prosocial-skills/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meta-analysis with robust variance estimation and multiply imputed covariates</title>
      <link>http://localhost:4321/rve-meta-analysis-with-mi/</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/rve-meta-analysis-with-mi/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.1.5     v dplyr   1.0.5
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tibble&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyr&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metadat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;metadat&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;metafor&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: Matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;Matrix&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:tidyr&amp;#39;:
## 
##     expand, pack, unpack&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Loading the &amp;#39;metafor&amp;#39; package (version 3.0-2). For an
## introduction to the package please type: help(metafor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;metafor&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:metadat&amp;#39;:
## 
##     dat.hackshaw1998, dat.ishak2007, dat.konstantopoulos2011,
##     dat.lim2014, dat.maire2019, dat.moura2021, dat.raudenbush1985,
##     dat.riley2003&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mice)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;mice&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;mice&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     cbind, rbind&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mitools)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;mitools&amp;#39; was built under R version 4.0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create missingness

set.seed(20211222)

dat_miss &amp;lt;- 
  dat.assink2016 %&amp;gt;%
  group_by(study) %&amp;gt;%
  mutate(
    pubstatus = if_else(rbinom(1L, 1L, 0.15) == 1L, NA_integer_, unique(pubstatus)),
    pubstatus = factor(pubstatus, levels = 0:1, labels = c(&amp;quot;unpublished&amp;quot;,&amp;quot;published&amp;quot;)),
    deltype = if_else(rbinom(n(), 1L, prob = plogis(-2.5 - 0.1 * year)) == 1L, NA_character_, deltype),
    deltype = factor(deltype)
  )

# Impute missing values 20 times

predMatrix &amp;lt;- make.predictorMatrix(dat_miss)
predMatrix[,c(&amp;quot;study&amp;quot;,&amp;quot;esid&amp;quot;,&amp;quot;id&amp;quot;)] &amp;lt;- 0 # don&amp;#39;t use study or esid or id for imputing

impMethod &amp;lt;- make.method(dat_miss)
impMethod&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     study      esid        id        yi        vi pubstatus      year   deltype 
##        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;        &amp;quot;&amp;quot;  &amp;quot;logreg&amp;quot;        &amp;quot;&amp;quot; &amp;quot;polyreg&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp &amp;lt;- mice(dat_miss, m = 20, print = FALSE,
            predictorMatrix = predMatrix, 
            method=impMethod, seed = 20211222)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Number of logged events: 70&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit SCE+ model
fits &amp;lt;- with(imp, rma.mv(
  yi = yi, 
  V = impute_covariance_matrix(vi = vi, cluster = study, r = 0.6, subgroup = deltype),
  mods = ~ pubstatus + deltype + year,
  random = list(~ deltype | study, ~ deltype | id),
  struct = c(&amp;quot;DIAG&amp;quot;,&amp;quot;DIAG&amp;quot;)
))

# Get coefficients
coefs &amp;lt;- map(fits$analyses, coef)

# Get CR2 variance-covariance matrices
vcovs &amp;lt;- map(fits$analyses, vcovCR, type = &amp;quot;CR2&amp;quot;)

# Get denominator df from complete-data F-tests
q &amp;lt;- 2
dfs &amp;lt;- 
  map_dfr(fits$analyses, Wald_test, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(3:4), test = &amp;quot;HTZ&amp;quot;) %&amp;gt;%
  mutate(
    eta = df_denom + (q - 1)
  )
eta &amp;lt;- mean(dfs$eta)

# Combine imputed results
res &amp;lt;- MIcombine(results = coefs, variances = vcovs)
res$coefficients&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            intrcpt pubstatuspublished       deltypeovert      deltypecovert 
##         0.89897557        -0.55770641        -0.38101335        -0.46723794 
##               year 
##        -0.02576823&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res$variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                         intrcpt pubstatuspublished deltypeovert deltypecovert
## intrcpt             0.074539988       -0.083961053 -0.058577507  0.0010493986
## pubstatuspublished -0.083961053        0.103264126  0.067143252 -0.0032322609
## deltypeovert       -0.058577507        0.067143252  0.106429071 -0.0108120033
## deltypecovert       0.001049399       -0.003232261 -0.010812003  0.0321118999
## year                0.002758525       -0.004318211 -0.003867039  0.0002642098
##                             year
## intrcpt             0.0027585250
## pubstatuspublished -0.0043182112
## deltypeovert       -0.0038670392
## deltypecovert       0.0002642098
## year                0.0004815795&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Calculate manual HTZ test using averaged eta 
Cmat &amp;lt;- constrain_zero(3:4, coefs = res$coefficients)
Q &amp;lt;- t(Cmat %*% res$coefficients) %*% solve(Cmat %*% res$variance %*% t(Cmat)) %*% (Cmat %*% res$coefficients)
Fstat &amp;lt;- (eta - q + 1) / (eta * q) * as.numeric(Q)
p_val &amp;lt;- pf(Fstat, df1 = q, df2 = eta - q + 1, lower.tail = FALSE)
data.frame(Fstat = Fstat, df_num = q, df_denom = eta - q + 1, p_val = p_val)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Fstat df_num df_denom     p_val
## 1 3.003453      2 1.663534 0.2804675&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Variance component estimates in meta-analysis with mis-specified sampling correlation</title>
      <link>http://localhost:4321/variance-components-with-misspecified-correlation/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/variance-components-with-misspecified-correlation/</guid>
      <description>


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In a recent paper with Beth Tipton, we proposed &lt;a href=&#34;http://localhost:4321/publication/rve-meta-analysis-expanding-the-range/&#34;&gt;new working models&lt;/a&gt; for meta-analyses involving dependent effect sizes. The central idea of our approach is to use a working model that captures the main features of the effect size data, such as by allowing for both between- and within-study heterogeneity in the true effect sizes (rather than only between-study heterogeneity). Doing so will lead to more precise estimates of overall average effects or, in models that include predictor variables, more precise estimates of meta-regression coefficients. Further, one can combine this working model with robust variance estimation methods to provide protection against the possibility that some of the model’s assumptions could be mis-specified.&lt;/p&gt;
&lt;p&gt;In order to estimate these new working models, the analyst must first make some assumption about the degree of correlation between effect size estimates that come from the same sample. In typical applications, it can be difficult to obtain good empirical information about the correlation between effect size estimates, and so it is common to impose some simplifying assumptions and use rough guesses about the degree of correlation. There’s a sense that this might not matter much—particularly because robust variance estimation should protect the inferences if the assumptions about the correlation are wrong. However, I’m still curious about the extent to which these assumptions about the correlation structure matter for anything.&lt;/p&gt;
&lt;p&gt;There’s a few reasons to wonder about how much the correlation matters. One is that the analyst might actually care about the variance component estimates from the working model, if they’re substantively interested in the extent of heterogeneity or if they’re trying to make predictions about the distribution of effect sizes that could be expected in a new study. Compared to earlier working models, the variance component estimates of the models that we proposed in the paper seem to be relatively more sensitive to the assumed correlation. Second, one alternative analytic strategy that’s been proposed (and applied) for meta-analysis of dependent effect sizes is to use a multi-level meta-analysis (MLMA) model. The MLMA is a special case of the correlated-and-hierarchical effects model that we described in the paper, the main difference being that MLMA &lt;em&gt;ignores&lt;/em&gt; any correlations between effect size estimates (at the level of the sampling errors), or equivalently, assumes that the correlations are all zero. Thus, MLMA is one specific way that this correlation assumption might be mis-specified. There’s some simulation evidence that inferences based on MLMA may be robust (even without using robust variance estimation), but it’s not clear how general this robustness property might be.&lt;/p&gt;
&lt;p&gt;In this post, I’m going to look at the implications of using a mis-specified assumption about the sampling correlation for the variance components in the correlated-and-hierarchical effects working model. As in &lt;a href=&#34;http://localhost:4321/weighting-in-multivariate-meta-analysis/&#34;&gt;my previous post on weights in multivariate meta-analysis&lt;/a&gt;, I’m going to mostly limit consideration to the simple (but important!) case of an intercept-only model, without any further predictors of effect size, to see what can be learned about how the variance components can go wrong.&lt;/p&gt;
&lt;div id=&#34;the-correlated-and-hierarchical-effects-che-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The correlated-and-hierarchical effects (CHE) model&lt;/h1&gt;
&lt;p&gt;Consider a meta-analytic dataset with effect size estimates &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,k_j\)&lt;/span&gt; indexes effect size estimates within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes studies, for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;. Say that effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; has sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{ij}\)&lt;/span&gt;, and there is some sampling correlation between effect sizes &lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, denoted &lt;span class=&#34;math inline&#34;&gt;\(\phi_{hij}\)&lt;/span&gt;.
The correlated-and-hierarchical effects (or CHE) model describes the distribution of effect sizes using random effects to capture between-study heterogeneity (as in the basic random effects model) and within-study heterogeneity in true effect sizes. In hierarchical notation, the model is
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
T_{ij} &amp;amp;= \theta_j + \nu_{ij} + e_{ij} \\
\theta_j &amp;amp;= \mu + \eta_j
\end{align}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\Var(e_{ij}) = \sigma^2_{ij}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\Var(\nu_{ij}) = \omega^2\)&lt;/span&gt; is the within-study variance, and &lt;span class=&#34;math inline&#34;&gt;\(\Var(\eta_j) = \tau^2\)&lt;/span&gt; is the between-study variance.
To simplify things, let us also assume that the effect size estimates from a given study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; all have equal sampling variance, so &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{1j} = \sigma^2_{2j} = \cdots = \sigma^2_{k_jj} = \sigma^2_j\)&lt;/span&gt;, and that there is a common correlation between any pair of effect size estimates from the same study, so &lt;span class=&#34;math inline&#34;&gt;\(\Cov(e_{hj}, e_{ij}) = \phi \sigma^2_j\)&lt;/span&gt; for some correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Typically, the analyst would estimate this working model using restricted maximum likelihood (REML) estimation to obtain estimates of the variance components &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;, after specifying a value of &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. With an adequately large sample of studies, the REML estimators should be close-to-unbiased and accurate. But what if the assumed correlation is wrong? Let’s suppose that the analyst estimates (via REML) the CHE working model but uses the assumption that there is a common correlation between effect size estimates of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, which is not necessarily equal to the true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. What are the consequences for estimating &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mis-specified-reml&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mis-specified REML&lt;/h1&gt;
&lt;p&gt;To figure out what’s going on here, we need to know something about how REML estimators behave under mis-specified models. For starters, I’ll work with a more general case than the CHE model described above. Suppose that we have a vector of multi-variate normal outcomes &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, explained by a set of covariates &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt;, and with true variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi_j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_j \ \sim \ N\left( \mathbf{X}_j \beta, \boldsymbol\Phi_j \right)
\]&lt;/span&gt;
However, suppose that we posit a variance structure &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega_j(\boldsymbol\theta)\)&lt;/span&gt;, which is a function of a &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;-dimensional variance component parameter &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt;, and where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi_j\)&lt;/span&gt; is not necessarily conformable to &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega_j(\boldsymbol\theta)\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; denote the full vector of outcomes and the full (stacked) predictor matrix for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Omega\)&lt;/span&gt; denote the corresponding block-diagonal variance-covariance matrices.&lt;/p&gt;
&lt;p&gt;We estimate &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt; by REML, which maximizes the log likelihood
&lt;span class=&#34;math display&#34;&gt;\[
2 l_R(\boldsymbol\theta) = c -\log \left|\boldsymbol\Omega_j(\boldsymbol\theta)\right| - \log \left|\mathbf{X}&amp;#39; \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X}\right| - \mathbf{T}&amp;#39;\mathbf{Q}(\boldsymbol\theta)\mathbf{T},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Q}(\boldsymbol\theta) = \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) - \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X} \left(\mathbf{X}&amp;#39; \boldsymbol\Omega^{-1}_j(\boldsymbol\theta) \mathbf{X}\right)^{-1} \mathbf{X}&amp;#39;\boldsymbol\Omega^{-1}_j(\boldsymbol\theta)\)&lt;/span&gt;. Equivalently, the REML estimators solve the score equations
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial l_R(\boldsymbol\theta)}{\partial \theta_q} = 0, \qquad \text{for} \qquad q = 1,...,v.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Under mis-specification, the REML estimators converge (as &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; increases) to the values that minimize the Kullback-Liebler divergence between the posited model and the true data-generating process. For the restricted likelihood, the Kullback-Liebler divergence is given by
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathcal{KL}(\theta, \theta_0) &amp;amp;= \E\left[l_R(\boldsymbol\Phi) - l_R(\boldsymbol\theta)\right] \\
&amp;amp;= c + \log \left| \boldsymbol\Omega(\boldsymbol\theta) \right| + \log \left| \mathbf{X}&amp;#39;\boldsymbol\Omega^{-1}(\boldsymbol\theta) \mathbf{X} \right| + \text{tr}\left(\mathbf{Q}(\boldsymbol\theta) \boldsymbol\Phi\right),
\end{aligned}
\]&lt;/span&gt;
where the expectation in the first line is taken with respect to the true data-generating process and where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; (in the second line) is a constant that does not depend on &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;back-to-che&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Back to CHE&lt;/h1&gt;
&lt;p&gt;Let me now jump back to the special case of the CHE model for a meta-analysis with no predictors. Let &lt;span class=&#34;math inline&#34;&gt;\(\tau_*^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega_*^2\)&lt;/span&gt; denote the variance components in the true data-generating process. Let &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; denote the asymptotic limits of the REML estimators under the mis-specified model. In this model, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j = \mathbf{1}_j\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\boldsymbol\Phi_j &amp;amp;= \left(\tau_*^2 + \phi \sigma_j^2\right) \mathbf{1}_j \mathbf{1}_j&amp;#39; + \left(\omega_*^2 + (1 - \phi) \sigma_j^2\right) \mathbf{I}_j \\
\boldsymbol\Omega_j &amp;amp;= \left(\tilde\tau^2 + \rho \sigma_j^2\right) \mathbf{1}_j \mathbf{1}_j&amp;#39; + \left(\tilde\omega^2 + (1 - \rho) \sigma_j^2\right) \mathbf{I}_j \\
\boldsymbol\Omega_j^{-1} &amp;amp;= \frac{1}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\left[\mathbf{I}_j - \frac{\tilde\tau^2 + \rho \sigma_j^2}{k_j \tilde\tau^2 + k_j \rho \sigma_j^2 + \tilde\omega^2 + (1 - \rho)\sigma_j^2} \mathbf{1}_j \mathbf{1}_j&amp;#39; \right].
\end{aligned}
\]&lt;/span&gt;
Let &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{\tilde{w}_j = \frac{k_j}{k_j \tilde\tau^2 + k_j \rho \sigma_j^2 + \tilde\omega^2 + (1 - \rho)\sigma_j^2}}\)&lt;/span&gt; denote the weight assigned to study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under the mis-specified model, with the total weight denoted as &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{\tilde{W} = \sum_{j=1}^J \tilde{w}_j}\)&lt;/span&gt;. Similarly, let &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{w^*_j = \frac{k_j}{k_j \tau_*^2 + k_j \phi \sigma_j^2 + \omega_*^2 + (1 - \phi)\sigma_j^2}}\)&lt;/span&gt; denote the weight that &lt;em&gt;should&lt;/em&gt; be assigned to study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under the true model. Then we have that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{tr}\left(\mathbf{Q} \boldsymbol\Phi\right) &amp;amp;= \text{tr}\left(\boldsymbol\Omega^{-1} \boldsymbol\Phi\right) - \text{tr}\left[\left(\mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \mathbf{1}\right)^{-1} \mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \boldsymbol\Phi \boldsymbol\Omega^{-1} \mathbf{1}\right] \\
&amp;amp;= \sum_{j=1}^J \text{tr}\left(\boldsymbol\Omega^{-1}_j \boldsymbol\Phi_j\right) - \frac{1}{\tilde{W}}\sum_{j=1}^J \mathbf{1}_j&amp;#39;\boldsymbol\Omega^{-1}_j \boldsymbol\Phi_j \boldsymbol\Omega_j^{-1} \mathbf{1}_j \\
&amp;amp;= \sum_{j=1}^J \frac{k_j}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\left[\tau_*^2 + \omega_*^2 + \sigma_j^2 - \left(\tilde\tau^2 + \rho \sigma_j^2\right) \frac{\tilde{w}_j}{w^*_j}\right] - \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j} \\
&amp;amp;= \sum_{j=1}^J (k_j - 1) \left(\frac{\omega_*^2 + (1 - \phi)\sigma_j^2}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\right) + \sum_{j=1}^J \frac{\tilde{w}_j}{w_j^*} - \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j},
\end{aligned}
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\log \left| \boldsymbol\Omega \right| = \sum_{j=1}^J\log \left| \boldsymbol\Omega_j \right| = \sum_{j=1}^J\left[ \left(k_j - 1\right) \log\left(\tilde\omega^2 + (1 - \rho)\sigma_j^2\right) - \log \left(\frac{\tilde{w}_j}{k_j}\right)\right]
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\log \left|\mathbf{1}&amp;#39;\boldsymbol\Omega^{-1} \mathbf{1}\right| = \log \left(\tilde{W}\right),
\]&lt;/span&gt;
It follows that the REML estimators converge to the values &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; that minimize
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathcal{KL}\left(\tilde\tau^2, \tilde\omega^2, \rho, \tau_*^2, \omega_*^2, \phi\right) &amp;amp;= \sum_{j=1}^J (k_j - 1) \left(\frac{\omega_*^2 + (1 - \phi)\sigma_j^2}{\tilde\omega^2 + (1 - \rho)\sigma_j^2}\right) + \sum_{j=1}^J \frac{\tilde{w}_j}{w_j^*} - \frac{1}{\tilde{W}}\sum_{j=1}^J \frac{\tilde{w}_j^2}{w^*_j} \\
&amp;amp; \qquad \qquad + \sum_{j=1}^J\left(k_j - 1\right) \log\left(\tilde\omega^2 + (1 - \rho)\sigma_j^2\right) - \sum_{j=1}^J \log \left(\frac{\tilde{w}_j}{k_j}\right) + \log(\tilde{W})
\end{aligned}
\]&lt;/span&gt;
This is a complicated non-linear objective function, but it can be minimized numerically using standard techniques.&lt;/p&gt;
&lt;p&gt;Here are some heatmaps of the function for &lt;span class=&#34;math inline&#34;&gt;\(\tau = 0.2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\omega = 0.1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi = 0.4\)&lt;/span&gt;, and some simulated values for &lt;span class=&#34;math inline&#34;&gt;\(k_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j^2\)&lt;/span&gt;, for three different assumed correlations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
set.seed(20211124)

CHE_KL &amp;lt;- function(to, tau, omega, phi, rho, k_j, sigmasq_j) {
  
  trs_j &amp;lt;- to[1]^2 + rho * sigmasq_j
  ors_j &amp;lt;- to[2]^2 + (1 - rho) * sigmasq_j
  w_j &amp;lt;- k_j / (k_j * trs_j + ors_j)
  W &amp;lt;- sum(w_j)
  
  tausq_ps_j &amp;lt;- tau^2 + phi * sigmasq_j
  omegasq_ps_j &amp;lt;- omega^2 + (1 - phi) * sigmasq_j
  wj_star &amp;lt;- k_j / (k_j * tausq_ps_j + omegasq_ps_j)
  
  A1 &amp;lt;- sum((k_j - 1) * omegasq_ps_j / ors_j)
  A2 &amp;lt;- sum(w_j / wj_star)
  A3 &amp;lt;- sum(w_j^2 / wj_star) / W
  B &amp;lt;- sum((k_j - 1) * log(ors_j) - log(w_j / k_j))
  C &amp;lt;- log(W)
  
  A1 + A2 - A3 + B + C
  
}

tau &amp;lt;- 0.2
omega &amp;lt;- 0.1
phi &amp;lt;- 0.4
J &amp;lt;- 20
k_j &amp;lt;- 1 + rpois(J, 5)
sigmasq_j &amp;lt;- 4 / pmax(rgamma(J, 3, scale = 30), 20)


KL_dat &amp;lt;- 
  cross_df(list(t = seq(0,0.4,0.01),
                o = seq(0,0.2,0.005),
                rho = c(0, 0.4, 0.8))) %&amp;gt;%
  mutate(
    to = map2(.x = t, .y = o, ~ c(.x, .y)),
    KL = map2_dbl(.x = to, .y = rho, .f = CHE_KL, 
                  tau = tau, omega = omega,
                  phi = phi, k_j = k_j, sigmasq_j = sigmasq_j),
    rho = paste(&amp;quot;rho ==&amp;quot;, rho)
  ) %&amp;gt;%
  group_by(rho)

KL_min &amp;lt;- 
  KL_dat %&amp;gt;%
  filter(KL == min(KL))

KL_dat %&amp;gt;%
  mutate(KL = -pmin(0.25, (KL - min(KL)) / (max(KL) - min(KL)))) %&amp;gt;%
ggplot() + 
  facet_wrap(~ rho, scales = &amp;quot;free&amp;quot;, labeller = &amp;quot;label_parsed&amp;quot;) + 
  geom_contour_filled(aes(x = t, y = o, z = KL), bins = 30) + 
  geom_point(x = tau, y = omega, color = &amp;quot;white&amp;quot;, size = 2) + 
  geom_point(data = KL_min, aes(x = t, y = o), color = &amp;quot;red&amp;quot;, size = 2) + 
  theme_minimal() + 
  labs(x = expression(tau), y = expression(omega)) + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Variance-component-estimation-in-misspecified-CHE_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The white points correspond to the true parameter values, while the red points correspond with the values that minimized the K-L divergence. In the middle plot, where &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.4\)&lt;/span&gt; corresponds to the true sampling correlation, the function is minimized at the true values of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;. In the left-hand plot, assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.0\)&lt;/span&gt; leads to an upwardly biased value of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and a downwardly biased value of &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;. In the right-hand plot, assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.8\)&lt;/span&gt; leads to a smaller value of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and a larger value of &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;completely-balanced-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Completely balanced designs&lt;/h2&gt;
&lt;p&gt;Things simplify considerably in the special case that the sample of studies is completely balanced, such that &lt;span class=&#34;math inline&#34;&gt;\(k_1 = k_2 = \cdots = k_J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2 = \sigma_2^2 = \cdots = \sigma_J^2\)&lt;/span&gt;. In such a design, the log-likelihood depends on &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; only through the quantities &lt;span class=&#34;math inline&#34;&gt;\(a = \tau^2 + \rho \sigma^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b = \omega^2 + (1 - \rho) \sigma^2\)&lt;/span&gt;. It follows that
&lt;span class=&#34;math display&#34;&gt;\[
l_R\left(\tau^2, \omega^2, \phi\right) = l_R\left(\tilde\tau^2, \tilde\omega^2, \rho\right)
\]&lt;/span&gt;
so long as
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tau^2 + \phi \sigma^2 &amp;amp;= \tilde\tau^2 + \rho \sigma^2 \\
\omega^2 + (1 - \phi)\sigma^2 &amp;amp;= \tilde\omega^2 + (1 - \rho) \sigma^2.
\end{aligned}
\]&lt;/span&gt;
If we assume that &lt;span class=&#34;math inline&#34;&gt;\((\rho - \phi)\sigma^2 &amp;lt; \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\((\phi - \rho)\sigma^2 &amp;lt; \omega^2\)&lt;/span&gt;, then we can set
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tilde\tau^2 &amp;amp;= \tau^2 - \left(\rho - \phi\right) \sigma^2 \\
\tilde\omega^2 &amp;amp;= \omega^2 + \left(\rho - \phi\right) \sigma^2
\end{aligned}
\]&lt;/span&gt;
and achieve the exact same likelihood.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Because the Kullback-Liebler divergence is minimized at the log likelihood of the true parameter values, setting &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; equal to the above quantities will also minimize the K-L divergence.&lt;/p&gt;
&lt;p&gt;The relationships here are fairly intuitive, I think. When &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is an over-estimate of the true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, then the between-study variance will be under-estimated and the within-study variance will be over-estimated, each to an extent that depends on a) the difference between &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; and b) the size of the (average) sampling variance. When &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is an under-estimate of the true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, then the between-study variance will be over-estimated and the within-study variance will be under-estimated, each to an extent that depends on the same components. It’s also rather intriguing to see that the total variance (the sum of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;) is totally invariant to &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; and will be preserved no matter what assumption we make regarding the sample correlation.&lt;/p&gt;
&lt;p&gt;In practice, of course, it’s pretty unlikely to have a meta-analytic dataset that is completely balanced. Still, the formulas for this completely balanced case might nonetheless be useful as heuristics for the direction of the biases in the parameter estimates—perhaps even as rough guides for the magnitude of bias that could be expected.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finding-tildetau2-and-tildeomega2-in-imbalanced-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Finding &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; in imbalanced designs&lt;/h2&gt;
&lt;p&gt;In imbalanced designs, we can find &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega^2\)&lt;/span&gt; by direct minimization of &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{KL}\)&lt;/span&gt;, given design information &lt;span class=&#34;math inline&#34;&gt;\(k_1,...,k_J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2,...,\sigma_J^2\)&lt;/span&gt;; true parameter values &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;; and assumed correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. The plot below depicts how &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega\)&lt;/span&gt;, and the total SD &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{\tilde\tau^2 + \tilde\omega^2}\)&lt;/span&gt; change as a function of the assumed correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, for various levels of true correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, when the design is imbalanced. As previously, I use &lt;span class=&#34;math inline&#34;&gt;\(\tau = 0.2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega = 0.1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_tau_omega &amp;lt;- function(tau, omega, phi, rho, k_j, sigmasq_j) {

  res &amp;lt;- optim(par = c(tau + 0.001, omega + 0.001), fn = CHE_KL, 
                tau = tau, omega = omega, phi = phi, rho = rho,
                k_j = k_j, sigmasq_j = sigmasq_j,
                lower = c(0,0), method = &amp;quot;L-BFGS-B&amp;quot;)

  data.frame(tau_tilde = res$par[1], omega_tilde = res$par[2])
}

sigmasq_bar &amp;lt;- mean(sigmasq_j)

opt_params &amp;lt;- 
  cross_df(list(tau = tau,
                omega = omega,
                phi = seq(0.2,0.8,0.2),
                rho = seq(0,0.95,0.05))) %&amp;gt;%
  mutate(
    res = pmap(., .f = find_tau_omega, k_j = k_j, sigmasq_j = sigmasq_j),
  ) %&amp;gt;%
  unnest(res) %&amp;gt;%
  mutate(
    total_tilde = sqrt(tau_tilde^2 + omega_tilde^2),
    tau_pred = sqrt(pmax(0,tau^2 + (phi - rho) * sigmasq_bar)),
    omega_pred = sqrt(pmax(0, omega^2 - (phi - rho) * sigmasq_bar)),
    total_pred = sqrt(tau_pred^2+ omega_pred^2),
    phi_lab = paste(&amp;quot;phi ==&amp;quot;, phi)
  )

opt_params %&amp;gt;% 
  pivot_longer(c(ends_with(&amp;quot;_tilde&amp;quot;), ends_with(&amp;quot;_pred&amp;quot;)),
               names_to = &amp;quot;q&amp;quot;, values_to = &amp;quot;p&amp;quot;) %&amp;gt;%
  separate(q, into = c(&amp;quot;param&amp;quot;,&amp;quot;type&amp;quot;)) %&amp;gt;%
  mutate(
    type = recode(type, tilde = &amp;quot;exact&amp;quot;, pred = &amp;quot;balanced&amp;quot;),
    type = factor(type, levels = c(&amp;quot;exact&amp;quot;,&amp;quot;balanced&amp;quot;)),
    param = factor(param, levels = c(&amp;quot;tau&amp;quot;,&amp;quot;omega&amp;quot;,&amp;quot;total&amp;quot;),
                   labels = c(&amp;quot;tau&amp;quot;,&amp;quot;omega&amp;quot;,&amp;quot;sqrt(tau^2 + omega^2)&amp;quot;))
  ) %&amp;gt;%
  ggplot(aes(rho, p, color = type, linetype = type)) + 
  geom_hline(yintercept = 0) + 
  geom_line() + 
  scale_color_brewer(type = &amp;quot;qual&amp;quot;, palette = 2) + 
  facet_grid(param ~ phi_lab, labeller = &amp;quot;label_parsed&amp;quot;) + 
  theme_minimal() + 
  labs(x = expression(rho), y = &amp;quot;Parameter&amp;quot;, color = &amp;quot;&amp;quot;, linetype = &amp;quot;&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Variance-component-estimation-in-misspecified-CHE_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The top row of the figure shows &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau\)&lt;/span&gt;, the middle row shows &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega\)&lt;/span&gt;, and the bottom row shows the total SD, for varying levels of assumed correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. The solid green lines represent the values that actually minimize the KL divergence. The dashed orange lines correspond to the minimizing values assuming complete balance (and using the average value of the &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j^2\)&lt;/span&gt;’s to evaluate the bias). The “balanced” approximations are fairly close—close enough to use as heuristics, at least—although they’re not perfect. In particular, the balanced approximation becomes discrepant from the real minimizing values when &lt;span class=&#34;math inline&#34;&gt;\(\tilde\tau\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\tilde\omega\)&lt;/span&gt; gets closer to zero. It’s also notable that the total variance is nearly constant (except when one or the other variance component is zero) and the balanced approximation is quite close to the real minimizing values.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;implications&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Implications&lt;/h1&gt;
&lt;p&gt;This post was mostly just to satisfy my own curiosity about how variance components behave in the MLMA and, more broadly, under mis-specified correlated-and-hierarchical effects meta-analysis models. I don’t think the bias formulas have much practical utility because, if you’re concerned about bias due to mis-specified sampling correlations, the first thing to do is try and develop better assumptions about the sampling correlation structure. Still, I think this analysis might be helpful for purposes of gauging how far off from the true your variance component estimates might be. In further work along these lines, it might be useful to examine the consequences of the biased variance component estimates for the efficiency of overall average effect size estimates based on mis-specified CHE models and the accuracy of model-based standard errors and confidence intervals under mis-specification. It would also be important to verify that these approximations provide accurate predictions for the bias of variance component estimates in realistic meta-analytic data (especially with a small or moderate number of studies).&lt;/p&gt;
&lt;p&gt;Another implication of this investigation is that &lt;em&gt;imbalance&lt;/em&gt; in the data structure seems to matter. When all studies have an equal number of effect sizes and are equally precise, then everything is simpler and more robust to mistaken assumptions about sampling correlation. Variance component estimation matters more for meta-analytic data in which some studies are more precise or contribute more effect size estimates than others. Therefore, further investigations—including simulation studies—of methods for handling dependent effect sizes really need to examine conditions with imbalanced data in order to draw defensible, generalizable conclusions about the robustness or utility of particular methods.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Consequently, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is not identifiable (in the statistical sense) in the completely balanced design.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Implications of mean-variance relationships for standardized mean differences</title>
      <link>http://localhost:4321/mean-variance-relationships-and-smds/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/mean-variance-relationships-and-smds/</guid>
      <description>


&lt;p&gt;I spend more time than I probably should discussing meta-analysis problems on the &lt;a href=&#34;https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis&#34;&gt;R-SIG-meta-analysis listserv&lt;/a&gt;. The questions that folks pose there are often quite interesting—especially when they’re motivated by issues that they’re wrestling with while trying to complete meta-analysis projects in their diverse fields. For those interested in meta-analytic methodology, I think perusing the mailing list is a good way to get a bit of ground sense about problems that come up in practice and places where there is a need for new methodological work, or at least further methodological guidance.&lt;/p&gt;
&lt;p&gt;Recently, a &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003318.html&#34;&gt;question came up&lt;/a&gt; on the listserv about whether it was reasonable to use the standardized mean difference metric for synthesizing studies where the outcomes are measured as proportions. Luke Martinez wrote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I’m doing a meta-analysis where the papers report only “mean” and “sd” of some form of proportion and/or “mean” and “sd” of corresponding raw frequencies. (For context, the papers ask students to read, find, and correct the wrong words in a text.) … My question is given that all these studies only report “mean” and “sd”, can I simply use a SMD effect size?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think this is an interesting question because, while the &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003320.html&#34;&gt;SMD could work perfectly fine&lt;/a&gt; as an effect size metric for proportions, there are also other alternatives that could be considered, such as odds ratios or response ratios or raw differences in proportions. Further, there are some situations where the SMD has disadvantages for synthesizing contrasts between proportions. Thus, it’s a situation where one has to make a choice about the effect size metric, and where the most common metric (the SMD) might not be the right answer. As &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003331.html&#34;&gt;I wrote in reply&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I would suggest that you could also consider other effect measures besides the SMD. For example, the response ratio is also a scale-free metric that could work with the proportion outcomes that you’ve described, and would also be appropriate for raw frequency counts as long as the total number possible is the same for the groups being compared within a given study.&lt;/p&gt;
&lt;p&gt;Whether the response ratio would be more appropriate than the SMD is hard to gauge. One would need to know more about how the proportions were assessed and how the assessment procedures varied from study to study. For instance, did some studies use passages with many possible errors to be corrected while other studies used passages with just a few errors? Did the difficulty of the passages differ from study to study? Were there very low or very high mean proportions in any studies? Does there seem to be a relationship between the means and the variances of the proportions of a given group?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In a &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003361.html&#34;&gt;follow-up&lt;/a&gt;, I elaborated on some potential problems with using the SMD:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Variation in the number of possible errors (and perhaps also in the length of the time provided for the test?) suggests that the measures from different studies may have varying degrees of reliability. Varying reliability introduces heterogeneity in the SMD (because the denominator is inflated or shrunk by the degree of reliability).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A relationship between the M and SD of the proportions for a given group suggests that the distribution of the individual-level outcomes might also exhibit mean-variance relationships. (I say “suggests” rather than implies because there’s an ecological inference here, i.e., assuming something about individual-level variation on the basis of group-level variation.) If this supposition is reasonable, then that introduces a further potential source of heterogeneity in the SMDs (study-to-study variation in the M for the reference group influences the SD of the reference group, thereby inflating or shrinking the SMDs).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;And I suggested a possible work-flow for examining the choice of effect size metric:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here’s how I might proceed if I were conducting
this analysis:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Calculate &lt;em&gt;both&lt;/em&gt; SMDs and log-transformed response ratios for the full set of studies.&lt;/li&gt;
&lt;li&gt;Examine the distribution of effect size estimates for each metric (using histograms or funnel plots). If one of the distributions is skewed or has extreme outliers, take that as an indication that the metric might not be appropriate.&lt;/li&gt;
&lt;li&gt;Fit meta-analytic models to summarize the distribution of effect sizes in each metric, using a model that appropriately describes the dependence structure of the estimates. Calculate I-squared statistics, give preference to the metric with lower I-squared.&lt;/li&gt;
&lt;li&gt;If (2) and (3) don’t lead to a clearly preferable metric, then choose between SMD and RR based on whichever will make the synthesis results easier to explain to people.&lt;/li&gt;
&lt;li&gt;(Optional/extra credit) Whichever metric you choose, repeat your main analyses using the other metric and stuff all those results in supplementary materials, to satisfy any inveterate statistical curmudgeons who might review/read your synthesis.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;(When I referred to “inveterate statistical curmudgeons”, I mostly had myself in mind.)&lt;/p&gt;
&lt;p&gt;In this post, I want to provide a bit more detail regarding why I think mean-variance relationships in raw data can signal that the standardized mean differences might be less useful as an effect size metric compared to alternatives. The concern is actually broader than meta-analyses of outcomes measured as proportions, so I’ll start with a different case and then return to a situation similar to the one described in the original question.&lt;/p&gt;
&lt;div id=&#34;mean-variance-relationships-can-induce-heterogeneity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mean-variance relationships can induce heterogeneity&lt;/h2&gt;
&lt;p&gt;The standardized mean difference parameter for a given study can be defined as:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sigma_{Ai}},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt; are the (population) mean outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; of study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{Ai}\)&lt;/span&gt; is the (population) standard deviation in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; of study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;
The ideal case for using the SMD metric is when the outcomes in different studies are linearly equatable, so that the outcome scale in one study can be directly translated into the outcome scale of another study. However, if outcomes exhibit mean-variance relationships, linearly equatability seems rather implausible, and we might expect that SMDs will display heterogeneity across studies as a result.&lt;/p&gt;
&lt;p&gt;Let me lay out an example of a situation where the outcomes exhibit mean-variance relationships and where, as a consequence, the SMD metric becomes heterogeneous. Suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, each involving a two-group comparison, with groups of equal size. In study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; follow a poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;, so that the variance of the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is also &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,k\)&lt;/span&gt;. The outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; follow a poisson distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt;, so the variance is also &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt;. Now, suppose that there is a fixed, proportional relationship between &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;,
so that &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi} = \lambda \mu_{Ai}\)&lt;/span&gt; for some &lt;span class=&#34;math inline&#34;&gt;\(\lambda &amp;gt; 0\)&lt;/span&gt;. In other words, the treatment contrast is &lt;em&gt;constant&lt;/em&gt; on the scale of the response ratio.
However, the means in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; vary from study to study. To make things concrete, let’s assume that the means in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; follow a gamma distribution with shape parameter &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and rate parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\mu_{Ai} \sim \Gamma(\alpha, \beta).
\]&lt;/span&gt;
What does this model imply about the distribution of standardized mean differences across this set of studies?&lt;/p&gt;
&lt;p&gt;Under this model, the SMD parameter for study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sqrt{\mu_{Ai}}} = (\lambda - 1) \times \sqrt{\mu_{Ai}}.
\]&lt;/span&gt;
The first term in the above expression is a constant that only
depend on the size of the response ratio, but the second term is random because we have assumed that the group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means vary from study to study. It will therefore create heterogeneity in the SMD parameters—the greater the variance of the &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;’s, the greater the heterogeneity in &lt;span class=&#34;math inline&#34;&gt;\(\delta_i\)&lt;/span&gt;. Specifically, under the above assumptions, the effect size parameters follow a &lt;a href=&#34;https://en.wikipedia.org/wiki/Nakagami_distribution&#34;&gt;Nakagami distribution&lt;/a&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i \sim \text{Nakagami}\left(m = \alpha, \Omega = \frac{(\lambda - 1)^2 \alpha}{\beta}\right)
\]&lt;/span&gt;
Thus, even though we have a model where there is an underlying fixed relationship between &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Bi}\)&lt;/span&gt;, using the SMD metric for synthesis will lead to a situation with heterogeneous effects (even if all of the studies had large sample sizes and so effect sizes in individual studies are precisely estimated).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-with-proportions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An example with proportions&lt;/h2&gt;
&lt;p&gt;This sort of behavior is not restricted to the poisson-gamma model I sketched above. The key features of that example are a) the assumption that the outcomes have a strong mean-variance relationship and b) the assumption that the &lt;span class=&#34;math inline&#34;&gt;\(\mu_{Ai}\)&lt;/span&gt;’s are heterogeneous across studies. If both of these hold, then the resulting SMDs will also be heterogeneous. I’ll now describe a similar model, but where the outcomes within each study are proportions.&lt;/p&gt;
&lt;p&gt;As before, suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, each involving a two-group comparison, with groups of equal size. In study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; follow a binomial distribution with mean proportion &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; trials, so that the variance of the outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\left(1 - \pi_{Ai}\right) T_i\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,k\)&lt;/span&gt;. The outcomes in group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; also follow a binomial distribution, this one with mean proportion &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Bi}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; trials, so the variance is &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Bi}\left(1 - \pi_{Bi}\right) T_i\)&lt;/span&gt;. Next, to induce variation in the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means, let’s assume that the mean proportions follow a beta distribution:
&lt;span class=&#34;math display&#34;&gt;\[
\pi_{Ai} \sim \text{Beta}(\alpha, \beta).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Finally, suppose that &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Bi} = \lambda_i \pi_{Ai}\)&lt;/span&gt; for some &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i &amp;gt; 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Under these assumptions, the SMD parameter for study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_i = \frac{\pi_{Bi}T_i - \pi_{Ai} T_i}{\sqrt{\pi_{Ai} (1 - \pi_{Ai}) T_i}} = (\lambda_i - 1) \times \sqrt{T_i} \times \sqrt{\frac{\pi_{Ai}}{1 - \pi_{Ai}}}.
\]&lt;/span&gt;
From the above expression, it can be seen that there are three potential sources of variation in &lt;span class=&#34;math inline&#34;&gt;\(\delta_i\)&lt;/span&gt;: variation in the study-specific response ratio &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt;, variation in the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; proportions &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt;, and variation in the number of trials &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;. The total heterogeneity in &lt;span class=&#34;math inline&#34;&gt;\(\delta_i\)&lt;/span&gt; will depend on all three, as well as on the co-variation between &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To make this concrete, let me simulate some meta-analytic data that follows the above model. To do so, I’ll need to make some additional distributional assumptions&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;that &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt; is log-normally distributed such that &lt;span class=&#34;math inline&#34;&gt;\(\ln \lambda_i \sim N(\ln \Lambda, \tau^2)\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;that the number of trials is uniformly distributed on the integers between &lt;span class=&#34;math inline&#34;&gt;\(t_{min}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t_{max}\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;that &lt;span class=&#34;math inline&#34;&gt;\(N_i\)&lt;/span&gt;, the number of observations per group in study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, is uniformly distributed on the integers between &lt;span class=&#34;math inline&#34;&gt;\(n_{min}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_{max}\)&lt;/span&gt;; and&lt;/li&gt;
&lt;li&gt;that &lt;span class=&#34;math inline&#34;&gt;\(\pi_{Ai}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\lambda_i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(N_i\)&lt;/span&gt; are mutually independent.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here’s a function that generates study-specific parameter values and sample proportions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_binom_summary &amp;lt;- function(pi_i, T_i, n_i) {
  y &amp;lt;- rbinom(n_i, size = T_i, prob = pi_i) / T_i
  data.frame(M = mean(y), SD = sd(y))
}

sim_props &amp;lt;- function(
  k, # number of studies
  alpha, beta, # parameters of pi_Ai distribution,
  Lambda, tau, # parameters of lambda_i distribution
  t_min, t_max, # parameters of T_i distribution
  n_min, n_max # parameters of the sample size distribution
) {
  
  # simulate parameters
  pi_Ai &amp;lt;- rbeta(k, shape1 = alpha, shape2 = beta)
  lambda_i &amp;lt;- exp(rnorm(k, mean = log(Lambda), sd = tau))
  pi_Bi &amp;lt;- lambda_i * pi_Ai
  T_i &amp;lt;- sample(t_min:t_max, size = k, replace = TRUE)
  delta_i &amp;lt;- (pi_Bi - pi_Ai) * T_i / sqrt(pi_Ai * (1 - pi_Ai) * T_i)
  n_i &amp;lt;- sample(n_min:n_max, size = k, replace = TRUE)
  
  # simulate data
  stats_A &amp;lt;- purrr::pmap_dfr(list(pi_i = pi_Ai, T_i = T_i, n_i = n_i),
                             sim_binom_summary) 
                             
  stats_B &amp;lt;- purrr::pmap_dfr(list(pi_i = pi_Bi, T_i = T_i, n_i = n_i),
                             sim_binom_summary)
  
  # compile
  res &amp;lt;- data.frame(
    pi_Ai = pi_Ai, pi_Bi = pi_Bi, 
    lambda_i = lambda_i, T_i = T_i, 
    delta_i = delta_i, n_i = n_i,
    mA = stats_A$M, sdA = stats_A$SD,
    mB = stats_B$M, sdB = stats_B$SD
  )

  # effect size calculations
  res &amp;lt;- metafor::escalc(
    data = res, measure = &amp;quot;ROM&amp;quot;, var.names = c(&amp;quot;lRR&amp;quot;, &amp;quot;V_lRR&amp;quot;),
    m1i = mB, m2i = mA, 
    sd1i = sdB, sd2i = sdA,
    n1i = n_i, n2i = n_i
  )
  res &amp;lt;- metafor::escalc(
    data = res, measure = &amp;quot;SMD&amp;quot;, var.names = c(&amp;quot;d&amp;quot;, &amp;quot;V_d&amp;quot;),
    m1i = mB, m2i = mA, 
    sd1i = sdB, sd2i = sdA,
    n1i = n_i, n2i = n_i
  )
  
  res
}

set.seed(20211024)
dat &amp;lt;- sim_props(k = 60, alpha = 12, beta = 4, 
                 Lambda = 0.7, tau = .05,
                 t_min = 5, t_max = 18,
                 n_min = 10, n_max = 40)

head(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##       pi_Ai     pi_Bi  lambda_i T_i    delta_i n_i        mA       sdA 
## 1 0.7584480 0.5836965 0.7695933  11 -1.3540950  24 0.7500000 0.1080650 
## 2 0.7359047 0.4950740 0.6727420  16 -2.1851474  24 0.7786458 0.1222235 
## 3 0.7132014 0.4773027 0.6692398  12 -1.8068471  10 0.7333333 0.1097134 
## 4 0.6223653 0.4627406 0.7435193   9 -0.9877857  30 0.6666667 0.1399386 
## 5 0.5916619 0.4205407 0.7107787   6 -0.8527716  28 0.5833333 0.2103299 
## 6 0.7266748 0.5014601 0.6900751   9 -1.5160305  35 0.7619048 0.1209466 
##          mB       sdB     lRR  V_lRR       d    V_d 
## 1 0.6174242 0.1285066 -0.1945 0.0027 -1.0983 0.0959 
## 2 0.5260417 0.1275776 -0.3922 0.0035 -1.9888 0.1245 
## 3 0.3583333 0.1622089 -0.7161 0.0227 -2.5934 0.3681 
## 4 0.4555556 0.1943213 -0.3808 0.0075 -1.2306 0.0793 
## 5 0.4583333 0.2060055 -0.2412 0.0119 -0.5921 0.0746 
## 6 0.4920635 0.1793349 -0.4372 0.0045 -1.7447 0.0789&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the specified parameter values, there is only a small amount of true heterogeneity in the log of the response ratios (the blue density). Of course, there is further heterogeneity in the log response ratio estimates (the green density) due to sampling error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
ggplot(dat) + 
  geom_density(aes(log(lambda_i), ..scaled..), fill = &amp;quot;blue&amp;quot;, alpha = 0.5) + 
  geom_density(aes(lRR, ..scaled..), fill = &amp;quot;green&amp;quot;, alpha = 0.2) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;576&#34; /&gt;
A random effects meta-analysis confirms that there is only a modest degree of true heterogeneity in the log response ratios:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
rma(yi = lRR, vi = V_lRR, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.0028 (SE = 0.0013)
## tau (square root of estimated tau^2 value):      0.0529
## I^2 (total heterogeneity / total variability):   42.01%
## H^2 (total variability / sampling variability):  1.72
## 
## Test for Heterogeneity:
## Q(df = 59) = 100.6304, p-val = 0.0006
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub      
##  -0.3498  0.0111  -31.5751  &amp;lt;.0001  -0.3715  -0.3281  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Contrast this with what we get from using the standardized mean difference metric. The distributions of true effect sizes (blue) and of effect size estimates (light purple) have large spread as well as strong left skew:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
ggplot(dat) + 
  geom_density(aes(delta_i, ..scaled..), fill = &amp;quot;blue&amp;quot;, alpha = 0.2) + 
  geom_density(aes(d, ..scaled..), fill = &amp;quot;purple&amp;quot;, alpha = 0.5) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;
A random effects meta-analysis of the standardized mean differences shows a greater degree of true heterogeneity, both in terms of the estimated &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and in &lt;span class=&#34;math inline&#34;&gt;\(I^2\)&lt;/span&gt;, or the proportion of total variance in the effect size estimates that is attributable to true heterogeneity:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma(yi = d, vi = V_d, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.2838 (SE = 0.0743)
## tau (square root of estimated tau^2 value):      0.5327
## I^2 (total heterogeneity / total variability):   72.61%
## H^2 (total variability / sampling variability):  3.65
## 
## Test for Heterogeneity:
## Q(df = 59) = 203.0513, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se      zval    pval    ci.lb    ci.ub      
##  -1.5967  0.0824  -19.3771  &amp;lt;.0001  -1.7582  -1.4352  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;diagnostics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Diagnostics&lt;/h2&gt;
&lt;p&gt;The code above more-or-less implements the workflow I suggested for deciding between the standardized mean difference or response ratio metric (for proportions, we could also add further comparisons with log odds ratios and with raw differences in proportions). But is there further diagnostic information in the data that could provide a better sense of what is going on? I think there are a few things that might be helpful to consider.&lt;/p&gt;
&lt;p&gt;First, the issues I’m concerned with here will arise when there are mean-variance relationships in the outcomes. To get at that, we can simply plot the means and SDs of each group. In the code below, I re-structure the data so that there is one row per group per study. I then plot the SD versus the mean of each group:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(tidyr)

long_summary_stats &amp;lt;- 
  dat %&amp;gt;%
  select(n_i, T_i, mA, sdA, mB, sdB) %&amp;gt;%
  pivot_longer(cols = c(mA, sdA, mB, sdB), 
               names_to = c(&amp;quot;.value&amp;quot;,&amp;quot;group&amp;quot;),
               names_pattern = &amp;quot;(m|sd)(A|B)&amp;quot;)

ggplot(long_summary_stats,
       aes(m, sd, color = group)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  expand_limits(y = 0) + 
  theme_minimal() + 
  theme(legend.position = c(0.1, 0.9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;
The plot above does suggest a mean-variance relationship, though it’s a bit messy. We can do better by using the scaled SD, after adjusting for the degree of spread that we would expect given &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;long_summary_stats %&amp;gt;%
  mutate(
    sd_scaled = sd * sqrt(T_i)
  ) %&amp;gt;%
  ggplot(aes(m, sd_scaled, color = group)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  geom_function(fun = function(x) sqrt(x * (1 - x)),
                color = &amp;quot;black&amp;quot;) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  expand_limits(y = 0) + 
  theme_minimal() + 
  theme(legend.position = c(0.1, 0.9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;
From the above, it does appear that there could be a relationship between the scaled SD and the mean. The black curve indicates the theoretical mean-variance relationship that would be expected under the binomial distribution, and indeed the empirical relationship appears to be quite similar. This suggests that mean-variance relationships might be at play (a correct supposition, since of course we know the true data-generating process here).&lt;/p&gt;
&lt;p&gt;Second, since the outcomes in each group are all proportions, we can simply plot the mean in group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; versus the mean in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat, aes(mA, mB)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;, formula = y ~ x) + 
  coord_cartesian(xlim = c(0,1), ylim = c(0,1), expand = FALSE) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;
This plot shows that there is a strong linear relationship between the two means, with a best-fit line that might go through the origin. This suggests that the response ratio might be an appropriate metric (although the difference in proportions might also be appropriate here, since a line with unit slope would probably fit quite well).&lt;/p&gt;
&lt;p&gt;Third (and most speculatively/hand-wavily), I think exploratory moderator analysis can be useful here, but interpreted in a non-typical way. Under the model I’ve sketched, we would expect that the standardized mean difference estimates should be systematically associated with the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means, as well as with the number of trials used to assess outcomes. The scatter-plots below show that this is indeed the case (the right-hand plot shows &lt;span class=&#34;math inline&#34;&gt;\(d_i\)&lt;/span&gt; versus &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{T_i}\)&lt;/span&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(patchwork)
mA_d_plot &amp;lt;- 
  ggplot(dat, aes(mA, d)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  theme_minimal()

Ti_d_plot &amp;lt;- 
  ggplot(dat, aes(sqrt(T_i), d)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  theme_minimal()

mA_d_plot + Ti_d_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This impression is also born out by a meta-regression that includes the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means and &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{T_i}\)&lt;/span&gt; as moderators:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma(d ~ mA + sqrt(T_i), vi = V_d, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0238 (SE = 0.0238)
## tau (square root of estimated tau^2 value):             0.1544
## I^2 (residual heterogeneity / unaccounted variability): 18.12%
## H^2 (unaccounted variability / sampling variability):   1.22
## R^2 (amount of heterogeneity accounted for):            91.60%
## 
## Test for Residual Heterogeneity:
## QE(df = 57) = 68.9706, p-val = 0.1330
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 110.9125, p-val &amp;lt; .0001
## 
## Model Results:
## 
##            estimate      se     zval    pval    ci.lb    ci.ub      
## intrcpt      2.5225  0.3964   6.3632  &amp;lt;.0001   1.7455   3.2995  *** 
## mA          -2.8326  0.4336  -6.5321  &amp;lt;.0001  -3.6825  -1.9827  *** 
## sqrt(T_i)   -0.6109  0.0756  -8.0855  &amp;lt;.0001  -0.7590  -0.4628  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the same plots as above, but using the log of the response ratio as the effect size metric:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mA_lRR_plot &amp;lt;- 
  ggplot(dat, aes(mA, lRR)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + 
  theme_minimal()

Ti_lRR_plot &amp;lt;- 
  ggplot(dat, aes(sqrt(T_i), lRR)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = &amp;quot;green&amp;quot;) + 
  geom_smooth(method = &amp;quot;lm&amp;quot;) + 
  theme_minimal()

mA_lRR_plot + Ti_lRR_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Mean-variance-relationships-and-SMDs_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the left-hand plot, there does not appear to be any relationship between the effect size estimates and the group-&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; means. In the right-hand plot, there does seem to be a mild relationship between the effect size estimates and &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{T_i}\)&lt;/span&gt;, which is a bit surprising, although the strength of the relationship is much weaker than what we saw with the standardized mean differences. Meta-regression analysis supports these interpretations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma(lRR ~  mA + sqrt(T_i), vi = V_lRR, data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 60; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0019 (SE = 0.0011)
## tau (square root of estimated tau^2 value):             0.0439
## I^2 (residual heterogeneity / unaccounted variability): 32.87%
## H^2 (unaccounted variability / sampling variability):   1.49
## R^2 (amount of heterogeneity accounted for):            31.30%
## 
## Test for Residual Heterogeneity:
## QE(df = 57) = 84.4977, p-val = 0.0105
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 10.6344, p-val = 0.0049
## 
## Model Results:
## 
##            estimate      se     zval    pval    ci.lb    ci.ub     
## intrcpt     -0.2362  0.0950  -2.4864  0.0129  -0.4224  -0.0500   * 
## mA           0.1061  0.0948   1.1196  0.2629  -0.0796   0.2918     
## sqrt(T_i)   -0.0553  0.0179  -3.0852  0.0020  -0.0904  -0.0202  ** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, you might think that a meta-analyst should get excited about the standardized mean difference results, since they’ve uncovered two systematic predictors of effect size magnitude. However, both of these factors are purely operational, arbitrary features of the (simulated) study designs, rather than theoretically or substantively interesting features of the studies. Considered in this light, the finding that they each moderate the magnitude of the standardized mean differences is, more than anything else, &lt;em&gt;annoying&lt;/em&gt;. If we wanted to examine other more theoretically interesting moderators, we’d have to do so in a way that accounts for these methodological predictors. At minimum, that would mean including them all in a meta-regression (leading to a model with 3+ predictors). Further, we would have to worry about whether the functional form of the regression is reasonable. Simply adding the theoretical moderator to the model amounts to assuming that it predicts effect size magnitude in a linear, additive fashion, but what if that’s not the right model? Since we know the true data-generating process here, we can see that the linear, additive model &lt;em&gt;would not&lt;/em&gt; be correct. But in practice, when we don’t know the true process, this would be much murkier.&lt;/p&gt;
&lt;p&gt;The general principle that I’m suggesting here is that effect sizes should ideally be on a metric that is &lt;em&gt;independent&lt;/em&gt; of arbitrary methodological factors because this should &lt;em&gt;reduce&lt;/em&gt; overall heterogeneity and &lt;em&gt;simplify&lt;/em&gt; the model, making it easier to detect real relations of interest. If one has a choice between several different effect size metrics, then a metric that shows clear associations with methodological factors should be discounted in favor of metrics that do not show such associations or show them only weakly. How to fully operationalize this sort of decision (as one would need to when writing a protocol for a meta-analysis, for example), I’m not yet sure about. It seems like a useful avenue for further methodological work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Yes, there are other ways to define the SMD. Yes, usually we use the standard deviation pooled across both groups. I’m going to use the standard deviation in group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; alone because it simplifies some of the mathy bits. Please feel free to work through the case with a pooled SD for yourself.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;One of the vexing things about simulations is that you often end up needing to specify a bunch of assumptions about auxiliary quantities, beyond those of the model you’re actually interested in investigating.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Inverting partitioned matrices</title>
      <link>http://localhost:4321/inverting-partitioned-matrices/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inverting-partitioned-matrices/</guid>
      <description>


&lt;p&gt;There’s lots of linear algebra out there that’s quite useful for statistics, but that I never learned in school or never had cause to study in depth. In the same spirit as my &lt;a href=&#34;http://localhost:4321/Woodbury-identity/&#34;&gt;previous post on the Woodbury identity&lt;/a&gt;, I thought I would share my notes on another helpful bit of math about matrices. At some point in high school or college, you might have learned how to invert a small matrix by hand. You might recall the formula for the inverse of a two-by-two matrix:
&lt;span class=&#34;math display&#34;&gt;\[
\left[\begin{array}{cc} a &amp;amp; b \\ c &amp;amp; d\end{array}\right]^{-1} = \frac{1}{ad - bc}\left[\begin{array}{rr} d &amp;amp; -b \\ -c &amp;amp; a\end{array}\right].
\]&lt;/span&gt;
It turns out that there’s a straight-forward generalization of this formula to matrices of arbitrary size, but that are &lt;em&gt;partitioned&lt;/em&gt; into four pieces. The following is based on the presentation from some old notes by Dr. Thomas Minka, &lt;a href=&#34;https://tminka.github.io/papers/matrix/&#34;&gt;Old and New Matrix Algebra Useful for Statistics&lt;/a&gt;. The statement there is quite detailed and general. My version will be for a more specific, simple case, which I’ve found to be common and handy, and that can be presented in a fairly simple form.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{P}\)&lt;/span&gt; be a matrix of arbitrary size that is composed of four sub-matrices:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{P} = \left[\begin{array}{cc} \mathbf{A} &amp;amp; \mathbf{B} \\ \mathbf{C} &amp;amp; \mathbf{D}\end{array}\right],
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{A}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{D}\)&lt;/span&gt; are &lt;span class=&#34;math inline&#34;&gt;\(a \times a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d \times d\)&lt;/span&gt; matrices, both of which are invertible, and where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{B}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{C}\)&lt;/span&gt; are of conformable dimension.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X} = \left(\mathbf{D} - \mathbf{C}\mathbf{A}^{-1} \mathbf{B}\right)^{-1}\)&lt;/span&gt;, a &lt;span class=&#34;math inline&#34;&gt;\(d \times d\)&lt;/span&gt; matrix. Then
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{P}^{-1} = \left[\begin{array}{cc} \mathbf{A}^{-1} + \mathbf{A}^{-1} \mathbf{B} \mathbf{X} \mathbf{C} \mathbf{A}^{-1} &amp;amp; - \mathbf{A}^{-1} \mathbf{B} \mathbf{X} \\ - \mathbf{X} \mathbf{C} \mathbf{A}^{-1} &amp;amp; \mathbf{X}\end{array}\right].
\]&lt;/span&gt;
This representation is particularly helpful if &lt;span class=&#34;math inline&#34;&gt;\(d &amp;lt; a\)&lt;/span&gt;, because in this case &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; is of lower dimension and so simpler (in a sense) than &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{A}^{-1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Another equivalency is more helpful when &lt;span class=&#34;math inline&#34;&gt;\(d &amp;gt; a\)&lt;/span&gt;. Here, take &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{W} = \left(\mathbf{A} - \mathbf{B}\mathbf{D}^{-1} \mathbf{C}\right)^{-1}\)&lt;/span&gt;, an &lt;span class=&#34;math inline&#34;&gt;\(a \times a\)&lt;/span&gt; matrix (and so of lower dimension than &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{D}\)&lt;/span&gt;). Then
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{P}^{-1} = \left[\begin{array}{cc} \mathbf{W} &amp;amp; - \mathbf{W} \mathbf{B} \mathbf{D}^{-1} \\ - \mathbf{D}^{-1} \mathbf{C} \mathbf{W} &amp;amp; \mathbf{D}^{-1} + \mathbf{D}^{-1} \mathbf{C} \mathbf{W} \mathbf{B} \mathbf{D}^{-1}\end{array}\right].
\]&lt;/span&gt;
Of course, this is just two ways of writing the same thing. You can see this by applying &lt;a href=&#34;http://localhost:4321/Woodbury-identity/&#34;&gt;everyone’s favorite matrix identity&lt;/a&gt; to find that &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{W} = \mathbf{A}^{-1} + \mathbf{A}^{-1} \mathbf{B} \mathbf{X} \mathbf{C} \mathbf{A}^{-1}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X} = \mathbf{D}^{-1} + \mathbf{D}^{-1} \mathbf{C} \mathbf{W} \mathbf{B} \mathbf{D}^{-1}\)&lt;/span&gt;. It is an interesting little algebraic exercise to show that &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{W} \mathbf{B} \mathbf{D}^{-1} = \mathbf{A}^{-1} \mathbf{B} \mathbf{X}\)&lt;/span&gt; and that &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{D}^{-1} \mathbf{C} \mathbf{W} = \mathbf{X} \mathbf{C} \mathbf{A}^{-1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;These representations of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{P}^{-1}\)&lt;/span&gt; are useful for a variety of statistical problems. To give just one example, they lead to a very direct proof of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem&#34;&gt;Frisch-Waugh-Lovell theorem&lt;/a&gt;, including under more general conditions than are usually stated.&lt;/p&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://tminka.github.io/papers/matrix/&#34;&gt;Minka’s notes&lt;/a&gt; on partitioned matrices treat a more general case, in which &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{A}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{D}\)&lt;/span&gt; need not be square matrices, nor must they be invertible.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Standardized mean differences in single-group, repeated measures designs</title>
      <link>http://localhost:4321/smds-in-single-group/</link>
      <pubDate>Wed, 06 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/smds-in-single-group/</guid>
      <description>
&lt;script src=&#34;http://localhost:4321/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I received a question from a colleague about computing variances and covariances for standardized mean difference effect sizes from a design involving a single group, measured repeatedly over time. Deriving these quantities is a little exercise in normal distribution theory, which I find kind of relaxing sometimes (hey, we all have our coping mechanisms!).&lt;/p&gt;
&lt;div id=&#34;the-set-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The set-up&lt;/h1&gt;
&lt;p&gt;Consider a study in which a single group of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; participants was measured at each of &lt;span class=&#34;math inline&#34;&gt;\(T + 1\)&lt;/span&gt; time-points, indexed as &lt;span class=&#34;math inline&#34;&gt;\(t = 0,...,T\)&lt;/span&gt;. At the first time-point, there has not yet been any exposure to an intervention. At the second and subsequent time-points, there is some degree of exposure, and so we are interested in describing change between time point &lt;span class=&#34;math inline&#34;&gt;\(t &amp;gt; 0\)&lt;/span&gt; and time-point 0. For each time-point, we have a sample mean &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_t\)&lt;/span&gt; and a sample standard deviation &lt;span class=&#34;math inline&#34;&gt;\(s_{t}\)&lt;/span&gt;. For now, assume that there is complete response. Let &lt;span class=&#34;math inline&#34;&gt;\(\mu_t\)&lt;/span&gt; denote the population mean and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_t\)&lt;/span&gt; denote the population standard deviation, both at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\rho_{st}\)&lt;/span&gt; denote the correlation between outcomes measured at time &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; and time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(s,t = 0,..,T\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\rho_{tt} = 1\)&lt;/span&gt;. We might also have sample correlations for each time point, denoted &lt;span class=&#34;math inline&#34;&gt;\(r_{st}\)&lt;/span&gt;. We calculate a standardized mean difference for each time-point &lt;span class=&#34;math inline&#34;&gt;\(t &amp;gt; 0\)&lt;/span&gt; by taking
&lt;span class=&#34;math display&#34;&gt;\[
d_t = \frac{\bar{y}_t - \bar{y}_0}{s_P},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(s_p\)&lt;/span&gt; is the sample standard deviation pooled across all time-points:
&lt;span class=&#34;math display&#34;&gt;\[
s_P^2 = \frac{1}{T+1}\sum_{t=0}^T s_t^2.
\]&lt;/span&gt;
The question is then, what is &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(d_t)\)&lt;/span&gt; and what is &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(d_s, d_t)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(s,t = 1,...,T\)&lt;/span&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The results&lt;/h1&gt;
&lt;p&gt;Define the &lt;em&gt;unstandardized&lt;/em&gt; mean difference between time-point &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; and time-point 0 as &lt;span class=&#34;math inline&#34;&gt;\(D_t = \bar{y}_t - \bar{y}_0\)&lt;/span&gt;. Then, from the algebra of variances and covariances, we have
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(D_t) = \frac{1}{n}\left(\sigma_0^2 + \sigma_t^2 - 2 \rho_{t0} \sigma_0 \sigma_t\right)
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(D_s, D_t) = \frac{1}{n}\left[\sigma_0^2 + \rho_{st} \sigma_s \sigma_t - \sigma_0 \left(\rho_{s0} \sigma_s + \rho_{t0} \sigma_t\right) \right].\]&lt;/span&gt;
From a &lt;a href=&#34;http://localhost:4321/distribution-of-sample-variances/&#34;&gt;previous post&lt;/a&gt; about the distribution of sample variances, we have that
&lt;span class=&#34;math display&#34;&gt;\[
\text{Cov}(s_s^2, s_t^2) = \frac{2 \left(\rho_{st} \sigma_s \sigma_t\right)^2}{n - 1}.
\]&lt;/span&gt;
Consequently,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{Var}(s_P^2) &amp;amp;= \frac{1}{(T + 1)^2} \sum_{s=0}^T \sum_{t=0}^T \text{Cov}(s_s^2, s_t^2) \\
&amp;amp;= \frac{2}{(n-1)(T + 1)^2} \sum_{s=0}^T \sum_{t=0}^T \left(\rho_{st} \sigma_s \sigma_t\right)^2.
\end{aligned}
\]&lt;/span&gt;
Let &lt;span class=&#34;math inline&#34;&gt;\(\sigma_P^2 = \frac{1}{T+1}\sum_{t=0}^T \sigma_t^2\)&lt;/span&gt; denote the average population variance across all &lt;span class=&#34;math inline&#34;&gt;\(T + 1\)&lt;/span&gt; time-points, and let &lt;span class=&#34;math inline&#34;&gt;\(\delta_t\)&lt;/span&gt; denote the standardized mean difference parameter at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Then, following the &lt;a href=&#34;http://localhost:4321/multivariate-delta-method/&#34;&gt;multivariate delta method&lt;/a&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(d_t) \approx \frac{\text{Var}(D_t)}{\sigma_P^2} + \frac{\delta_t^2}{2 \nu} \qquad \text{and} \qquad \text{Cov}(d_s, d_t) \approx \frac{\text{Cov}(D_s, D_t)}{\sigma_P^2} + \frac{\delta_s \delta_t}{2 \nu},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{\nu = \frac{2 \sigma_P^4}{\text{Var}(s_P^2)}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Without imposing further assumptions, and assuming that we have access to the sample correlations between time-points, a feasible estimator of the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d_t\)&lt;/span&gt; is
&lt;span class=&#34;math display&#34;&gt;\[
V_t = \frac{s_0^2 + s_t^2 - 2 r_{t0} s_0 s_t}{n s_P^2} + \frac{d_t^2}{2 \hat\nu},
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
\hat\nu = \frac{(n-1) s_p^4}{\frac{1}{(T + 1)^2}\sum_{s=0}^T \sum_{t=0}^T r_{st}^2 s_s^2 s_t^2}.
\]&lt;/span&gt;
Similarly, a feasible estimator for the covariance between &lt;span class=&#34;math inline&#34;&gt;\(d_s\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d_t\)&lt;/span&gt; is
&lt;span class=&#34;math display&#34;&gt;\[
C_{st} = \frac{s_0^2 + r_{st} s_s s_t - s_0 \left(r_{s0} s_s + r_{t0} s_t\right)}{n s_P^2} + \frac{d_s d_t}{2 \hat\nu}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In some cases, it might be reasonable to use further assumptions about distributional structure in order to simplify these approximations. In particular, suppose we assume that the population variances are constant across time-points, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_0 = \sigma_1 = \cdots = \sigma_T\)&lt;/span&gt;. In this case, the variances and covariances no longer depend on the scale of the outcome, and we have
&lt;span class=&#34;math display&#34;&gt;\[
\hat\nu = \frac{(n - 1)(T + 1)}{T R + 1}, \qquad \text{where} \qquad R = \frac{2}{T (T + 1)}\sum_{s=0}^{T-1} \sum_{t=s+1}^T r_{st}^2
\]&lt;/span&gt;
(here, &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is the average of the squared correlations between pairs of distinct time-points). Since &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; will always be less than 1, &lt;span class=&#34;math inline&#34;&gt;\(\hat\nu\)&lt;/span&gt; will always be larger than &lt;span class=&#34;math inline&#34;&gt;\(n - 1\)&lt;/span&gt;. If sample correlations aren’t reported or available, it would seem fairly reasonable to use &lt;span class=&#34;math inline&#34;&gt;\(\hat\nu = n - 1\)&lt;/span&gt;, or to make a rough assumption about the average squared correlation &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;. With the approximate degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\hat\nu\)&lt;/span&gt;, the variances and covariances are then given by
&lt;span class=&#34;math display&#34;&gt;\[
V_t = \frac{2(1 - r_{t0})}{n} + \frac{d_t^2}{2 \hat\nu} \qquad \text{and} \qquad C_{st} = \frac{1 + r_{st} - r_{s0} - r_{t0}}{n} + \frac{d_s d_t}{2 \hat\nu}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extension&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Extension&lt;/h1&gt;
&lt;p&gt;In some contexts, one might encounter a design that uses &lt;em&gt;over-lapping&lt;/em&gt; but &lt;em&gt;not identical&lt;/em&gt; samples at each time-point. For instance, in a rotating panel survey, each participant is measured repeatedly for some small number of time-points &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; T + 1\)&lt;/span&gt; (say &lt;span class=&#34;math inline&#34;&gt;\(p = 2\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(p = 3\)&lt;/span&gt;), and new participants are added to the sample with each new time-point. The simple repeated measures set-up that I described in this post is an imperfect approximation for such designs. In dealing with such a design, suppose that one knew the total number of observations at each time-point, denoted &lt;span class=&#34;math inline&#34;&gt;\(n_t\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(t = 0,...,T\)&lt;/span&gt;, as well as the number of observations that were common across any pair of time-points, denoted as &lt;span class=&#34;math inline&#34;&gt;\(n_{st}\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(s,t = 0,...,T\)&lt;/span&gt;. Further suppose that the drop-outs and additions are ignorable (missing completely at random), so that any subset of participants defined by a pattern of response or non-response is still representative of the full population. I leave it as an exercise for the reader (a relaxing and fun one!) to derive &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(d_t)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(d_s, d_t)\)&lt;/span&gt; under such a model.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Four things every quantitative social scientist should know about meta-analysis</title>
      <link>http://localhost:4321/talk/edpsych-colloquium-2021-four-things/</link>
      <pubDate>Mon, 27 Sep 2021 10:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/edpsych-colloquium-2021-four-things/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Design &amp; Analysis of Quasi-Experiments for Causal Inference</title>
      <link>http://localhost:4321/teaching/quasi-experimental/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/teaching/quasi-experimental/</guid>
      <description>&lt;p&gt;In many fields, randomized experiments are often considered the gold standard approach for learning about the causal effects of an intervention, program, or policy. However, randomized experiments are not always feasible or ethical. Furthermore, the increasing availability of large-scale observational datasets presents opportunities to investigate causal effects outside of the realm of designed experiments. This course surveys contemporary research design strategies for investigating questions about causal effects, focusing on the theory and application of quasi-experimental methods that can, under some conditions, provide strong warrants for drawing causal inferences. The focus of the course is on causal description of point-in-time interventions (“Is this intervention effective?”) rather than causal explanation (“Why is this intervention effective?”).&lt;/p&gt;
&lt;p&gt;The course begins with an introduction to the potential outcomes framework for expressing causal quantities, followed by an examination of (idealized) simple and block randomized experiments as prototypes for learning about causal effects. The remainder of the course covers theory and data-analysis strategies for drawing causal inferences from four quasi-experimental designs: instrumental variables approaches, regression discontinuity designs, non-equivalent control group designs (using techniques such as matching and propensity score weighting), and comparative interrupted time series designs. For each design, we will consider (i) the core strategy for identifying a causal effect, (ii) corresponding statistical approaches for estimating the effect, and (iii) strategies and design elements for strengthening the design. Further, advanced topics will be covered based on student interest.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-963-001-Quasi-Experiments-2021-Fall-syllabus.pdf&#34;&gt;2021 (Fall) syllabus&lt;/a&gt; and 
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-963-001-Quasi-Experiments-2021-Fall-reading-list.pdf&#34;&gt;reading list&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-963-001-Quasi-Experiments-2023-Fall-syllabus.pdf&#34;&gt;2023 (Fall) syllabus&lt;/a&gt; and 
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-963-001-Quasi-Experiments-2023-Fall-reading-list.pdf&#34;&gt;reading list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Synthesis of dependent effect sizes: Robust variance estimation with clubSandwich</title>
      <link>http://localhost:4321/talk/oslorug-2021-rve-with-metafor-and-clubsandwich/</link>
      <pubDate>Thu, 02 Sep 2021 10:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/oslorug-2021-rve-with-metafor-and-clubsandwich/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Statistical frontiers for selective reporting and publication bias</title>
      <link>http://localhost:4321/talk/sips-2021-statistical-frontiers-for-selective-reporting/</link>
      <pubDate>Wed, 23 Jun 2021 12:30:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sips-2021-statistical-frontiers-for-selective-reporting/</guid>
      <description>&lt;p&gt;This workshop will cover methods to investigate selective reporting in meta-analysis of statistically dependent effect sizes, which are a common feature of systematic reviews in psychology. The workshop is organized into two sections. In the first section, we will describe situations where dependent effect sizes occur and review methods for summarizing findings in the presence of dependent effects. We will then describe methods for creating and interpreting funnel plots, including tests of asymmetry, with dependent effect sizes. In the second section, we will present new statistical sensitivity analyses for publication bias, which perform well in small meta-analyses, those with non-normal or dependent effect sizes, and those with heterogeneity. The sensitivity analyses enable statements such as &amp;ldquo;For publication bias to shift the observed point estimate to the null, &amp;lsquo;significant&amp;rsquo; results would need to be at least 10-fold more likely to be published than negative or &amp;rsquo;non-significant&amp;rsquo; results&amp;rdquo; or &amp;ldquo;no amount of publication bias could explain away the average effect.&amp;rdquo; In both sections, we will demonstrate methods using R code and examples from real meta-analyses.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Finding the distribution of significant effect sizes</title>
      <link>http://localhost:4321/number-of-significant-effects/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/number-of-significant-effects/</guid>
      <description>
&lt;script src=&#34;http://localhost:4321/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In basic meta-analysis, where each study contributes just a single effect size estimate, there has been a lot of work devoted to developing models for selective reporting. Most of these models formulate the selection process as a function of the statistical significance of the effect size estimate; some also allow for the possibility that the precision of the study’s effect influences the probability of selection (i.e., bigger studies are more likely to be reported, regardless of statistical significance).&lt;/p&gt;
&lt;p&gt;A problem that I’ve been mulling recently is how to think about selective reporting in meta-analyses that include some studies with &lt;em&gt;multiple&lt;/em&gt; effect size estimates. This setting is quite a bit more complicated than basic meta-analysis because there are several different ways that selective reporting could happen. It could be that each effect size estimate is selected (or censored) individually, on the basis of its statistical significance. However, it seems just as plausible that the pattern of statistical significance across the full set of results could influence whether &lt;em&gt;any&lt;/em&gt; of the results get selected.&lt;/p&gt;
&lt;p&gt;In pondering this stuff, I’m trying to find ways to simplify the space of possibilities or formulate stylized (or “toy”) problems that are more tractable. Here is one such problem. I’ll write it as a question such as you might find in a problem set from a course on statistical distribution theory.&lt;/p&gt;
&lt;div id=&#34;the-general-problem&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The general problem&lt;/h1&gt;
&lt;p&gt;Consider a study that assesses some effect size across &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; different outcomes. Let &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; denote the effect size estimate for outcome &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, let &lt;span class=&#34;math inline&#34;&gt;\(V_i\)&lt;/span&gt; denote the sampling variance of the effect size estimate for outcome &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt; denote the true effect size parameter for corresponding to outcome &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. Assume that
&lt;span class=&#34;math display&#34;&gt;\[T_i \sim N(\theta_i, V_i),\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(V_i\)&lt;/span&gt; is known. Define &lt;span class=&#34;math inline&#34;&gt;\(A_i\)&lt;/span&gt; as an indicator that is equal to one if &lt;span class=&#34;math inline&#34;&gt;\(T_i\)&lt;/span&gt; is statistically significant at level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; based on a one-sided test, and otherwise equal to zero. (Equivalently, let &lt;span class=&#34;math inline&#34;&gt;\(A_i\)&lt;/span&gt; be equal to one if the effect is statistically significant at level &lt;span class=&#34;math inline&#34;&gt;\(2 \alpha\)&lt;/span&gt; and in the theoretically expected direction.) Formally,
&lt;span class=&#34;math display&#34;&gt;\[A_i = I\left(\frac{T_i}{\sqrt{V_i}} &amp;gt; q_\alpha \right)\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(q_\alpha = \Phi^{-1}(1 - \alpha)\)&lt;/span&gt; is the critical value from a standard normal distribution (e.g., &lt;span class=&#34;math inline&#34;&gt;\(q_{.05} = 1.645\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(q_{.025} = 1.96\)&lt;/span&gt;). Let &lt;span class=&#34;math inline&#34;&gt;\(N_A = \sum_{i=1}^m A_i\)&lt;/span&gt; denote the total number of statistically significant effect sizes in the study. Our general interest is in the distribution of &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;compound-symmetry&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compound symmetry&lt;/h2&gt;
&lt;p&gt;In general, the distribution of &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt; will depend on the joint distribution of &lt;span class=&#34;math inline&#34;&gt;\((T_1,...,T_m)\)&lt;/span&gt;, so we will need to make some further assumptions regarding that joint distribution in order to make progress here. One simplifying assumption that seems worth considering is that the effect size estimates follow a compound symmetric distribution. Specifically, assume that all of the effect size estimates have equal sampling variance, &lt;span class=&#34;math inline&#34;&gt;\(V_1 = V_2 = \cdots = V_m = V\)&lt;/span&gt;, and that there is a constant correlation between every pair of effect size estimates:
&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(T_h, T_i) = \rho V\]&lt;/span&gt;
for some correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. Further, assume that the true effect sizes vary based on a compound symmetric distribution where
&lt;span class=&#34;math display&#34;&gt;\[
\theta_i \sim N(\mu, \omega^2).
\]&lt;/span&gt;
All of this implies that the joint distribution of the effect size estimates is compound symmetric:
&lt;span class=&#34;math display&#34;&gt;\[
\left(\begin{array}{c} T_1 \\ T_2 \\ \vdots \\ T_m \end{array}\right) \sim N\left[ \mu \mathbf{1}_m, \ \left(\omega^2 + \rho V\right)\mathbf{J}_m + (1 - \rho) V \mathbf{I}_m \right],
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{1}_m\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(m \times 1\)&lt;/span&gt; vector of 1’s, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{J}_m\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(m \times m\)&lt;/span&gt; matrix of 1’s, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{I}_m\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(m \times m\)&lt;/span&gt; identity matrix.&lt;/p&gt;
&lt;p&gt;Given the above assumptions, What is the distribution of &lt;span class=&#34;math inline&#34;&gt;\(N_A\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;Please write to me if you’d like to discuss the theory or implications of this problem.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating the Transition to College Mathematics Course in Texas high schools: Examining heterogeneity across schools and student characteristics</title>
      <link>http://localhost:4321/publication/transition-to-college-mathematics-year-3/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/transition-to-college-mathematics-year-3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A systematic review and meta‐analysis of effects of psychosocial interventions on spiritual well‐being in adults with cancer</title>
      <link>http://localhost:4321/publication/psychosocial-interventions-for-spiritual-well-being/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/psychosocial-interventions-for-spiritual-well-being/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Synthesis of dependent effect sizes: Versatile models through metafor and clubSandwich</title>
      <link>http://localhost:4321/talk/esmarconf2021-rve-with-metafor-and-clubsandwich/</link>
      <pubDate>Thu, 21 Jan 2021 09:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/esmarconf2021-rve-with-metafor-and-clubsandwich/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meta-analysis</title>
      <link>http://localhost:4321/teaching/meta-analysis/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/teaching/meta-analysis/</guid>
      <description>&lt;p&gt;Meta-analysis is the set of statistical methods and practices for synthesizing evidence collected from multiple sources, such as multiple studies on the same topic. Often conducted as part of a systematic literature review, meta-analyses play an increasingly prominent role in education research, psychology, and many other areas of social and behavior science. This course introduces the stages of the research synthesis process and the statistical methods used for conducting quantitative syntheses of social-scientific research. The focus of the course is on practical application and interpretation of meta-analytic methods, enriched with discussion of underlying statistical theory. Major topics include scope of research syntheses, systematic search and screening procedures, effect size calculations, summary meta-analysis, meta-regression, dependent effect sizes, selective reporting and publication bias analysis. Computational exercises use the R statistical computing environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-711-011-Meta-analysis-2021-Spring-syllabus.pdf&#34;&gt;2021 (Spring) syllabus&lt;/a&gt; and 
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-711-011-Meta-analysis-2021-Spring-reading-list.pdf&#34;&gt;reading list&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-711-003-Meta-analysis-2024-Spring-syllabus.pdf&#34;&gt;2024 (Spring) syllabus&lt;/a&gt; and 
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDPSYCH-711-003-Meta-analysis-2024-Spring-reading-list.pdf&#34;&gt;reading list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Systematic review and meta-analysis of stay-play-talk interventions for improving social behaviors of young children</title>
      <link>http://localhost:4321/publication/stay-play-talk-meta-analysis/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/stay-play-talk-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evaluating the Transition to College Mathematics Course in Texas high schools: Findings from the second year of implementation</title>
      <link>http://localhost:4321/publication/transition-to-college-mathematics-year-2/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/transition-to-college-mathematics-year-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Woodbury identity</title>
      <link>http://localhost:4321/woodbury-identity/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/woodbury-identity/</guid>
      <description>


&lt;p&gt;As in many parts of life, statistics is full of little bits of knowledge that are useful if you happen to know them, but which hardly anybody ever bothers to mention. You would think, if something is so useful, perhaps your professors would spend a fair bit of time explaining it to you. But maybe the stuff seems trivial, obvious, or simple to them, so they don’t bother.&lt;/p&gt;
&lt;p&gt;One example of this is Excel keyboard shortcuts. In a previous life, I was an Excel jockey so I learned all the keyboard shortcuts, such as how to move the cursor to the last cell in a continuous block of entries (&lt;code&gt;ctrl&lt;/code&gt; + an arrow key). Whenever I do this while sharing a screen in a meeting, someone is invariably astounded and wants to know what dark sorcery I’m conjuring. It’s a simple trick, but a useful one—especially if you’re working with a really large dataset with thousands of rows. But it’s also something that there’s no reason to expect anyone to figure out on their own, and that no stats or quant methods professor is going to spend class time demonstrating.&lt;/p&gt;
&lt;p&gt;Let me explain another, slightly more involved example, involving one of my favorite pieces of matrix algebra. There’s a thing called the Woodbury identity, also known as the Sherman-Morrison-Woodbury identity, that is a little life hack for inverting certain types of matrices. It has a &lt;a href=&#34;https://en.wikipedia.org/wiki/Woodbury_matrix_identity&#34;&gt;Wikipedia page&lt;/a&gt;, which I have visited many times. It is a very handy bit of math, if you happen to be a statistics student working with hierarchical models (such as meta-analytic models). I’ll give a statement of the identity, then explain a bit about the connection to hierarchical models.&lt;/p&gt;
&lt;div id=&#34;the-woodbury-identity&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Woodbury identity&lt;/h1&gt;
&lt;p&gt;Say that you’ve got four matrices, an &lt;span class=&#34;math inline&#34;&gt;\(n \times n\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{A}\)&lt;/span&gt;, a &lt;span class=&#34;math inline&#34;&gt;\(k \times k\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{C}\)&lt;/span&gt;, an &lt;span class=&#34;math inline&#34;&gt;\(n \times k\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{U}\)&lt;/span&gt;, and a &lt;span class=&#34;math inline&#34;&gt;\(k \times n\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}\)&lt;/span&gt;. Assume that &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{A}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{C}\)&lt;/span&gt; are invertible. The Woodbury identity tells you how to get the inverse of a certain combination of these matrices:
&lt;span class=&#34;math display&#34;&gt;\[
\left(\mathbf{A} + \mathbf{U} \mathbf{C} \mathbf{V}\right)^{-1} = \mathbf{A}^{-1} - \mathbf{A}^{-1} \mathbf{U} \left(\mathbf{C}^{-1} + \mathbf{V} \mathbf{A}^{-1} \mathbf{U} \right)^{-1} \mathbf{V} \mathbf{A}^{-1}.
\]&lt;/span&gt;
Admit it, you’re impressed. “Dude! Mind. Blown.” you’re probably saying to yourself right now.&lt;/p&gt;
&lt;p&gt;Or perhaps you’re still a touch skeptical that this formula is worth knowing. Let me explain the connection to hierarchical models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hierarchical models&lt;/h1&gt;
&lt;p&gt;Hierarchical linear models are a mainstay of statistical analysis in many, many areas of application, including education research, where we often deal with data collected on individuals (students, teachers) nested within larger aggregate units (like schools). In meta-analysis, these models come up if we’re dealing with samples that have more than one relevant outcome, so that we have multiple effect size estimates nested within a given sample or study.&lt;/p&gt;
&lt;p&gt;Suppose we have a hierarchical structure with &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; clusters, where cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; has &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; individual observations. A quite general way of expressing a hierarchical model for such a data structure is
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{Y}_j = \mathbf{X}_j \boldsymbol\beta + \mathbf{Z}_j \boldsymbol\eta_j + \boldsymbol\epsilon_j,
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, where, for cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times 1\)&lt;/span&gt; vector of outcomes,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times p\)&lt;/span&gt; design matrix for the fixed effects,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(p \times 1\)&lt;/span&gt; vector of fixed effect coefficients,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Z}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times q\)&lt;/span&gt; design matrix for the random effects,&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\eta_j\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(q \times 1\)&lt;/span&gt; vector of random effects, and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\epsilon_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times 1\)&lt;/span&gt; vector of level-1 errors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this model, we assume that the random effects have mean zero and unknown variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt;, often assumed to be an unstructured, symmetric and invertible matrix; we assume that the level-1 errors are also mean zero with variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j\)&lt;/span&gt;; and we assume that &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\eta_j\)&lt;/span&gt; is independent of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\epsilon_j\)&lt;/span&gt;. In many instances, we might assume that the entries of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{e}_j\)&lt;/span&gt; are all independent, so &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j\)&lt;/span&gt; will be a multiple of an identity matrix, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j = \sigma^2 \mathbf{I}_j\)&lt;/span&gt;. In other instances (such as models for longitudinal data), &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma\)&lt;/span&gt; might be a patterned matrix that includes off-diagonal terms, such as an auto-regressive structure.&lt;/p&gt;
&lt;p&gt;What is the marginal variance of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_j | \mathbf{X}_j\)&lt;/span&gt; in this model? In other words, if we combine the variance due to the random effects and the variance of the level-1 errors, what do we get? We get
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(\mathbf{Y}_j | \mathbf{X}_j \right) = \mathbf{V}_j = \mathbf{Z}_j \mathbf{T} \mathbf{Z}_j&amp;#39; + \boldsymbol\Sigma_j,
\]&lt;/span&gt;
a matrix that, if you reverse the terms, looks like
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{V}_j = \boldsymbol\Sigma_j + \mathbf{Z}_j \mathbf{T} \mathbf{Z}_j&amp;#39;
\]&lt;/span&gt;
a simple form of the combination of matrices in the left-hand side of the Woodbury identity. Thus, the identity tells us how we can invert this matrix.&lt;/p&gt;
&lt;p&gt;But why would we care about inverting this variance-covariance matrix, you might ask? One good reason is that the fixed effect coefficients in the hierarchical model are estimated by weighted least squares, where the weight matrices are the inverse of an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;. Thus, to understand how the weights in a hierarchical model work, it’s quite useful to be able to invert &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;. Another good (related) reason is that the sampling variance of the fixed effect estimates is approximately
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\boldsymbol{\hat\beta}) \approx \left(\sum_{j=1}^J \mathbf{X}_j&amp;#39;\mathbf{V}_j^{-1} \mathbf{X}_j \right)^{-1}
\]&lt;/span&gt;
(it would be exact if we knew the parameters of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt; with certainty). So if we want to understand the precision of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\hat\beta}\)&lt;/span&gt; or the power of a hypothesis test involving &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\hat\beta}\)&lt;/span&gt;, then we we won’t be able to get very far without inverting &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Directly applying the identity, we get
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{V}_j^{-1} = \boldsymbol\Sigma_j^{-1} - \boldsymbol\Sigma_j^{-1} \mathbf{Z}_j \left(\mathbf{T}^{-1} + \mathbf{Z}_j&amp;#39;\boldsymbol\Sigma_j^{-1}\mathbf{Z}_j \right)^{-1} \mathbf{Z}_j&amp;#39; \boldsymbol\Sigma_j^{-1}
\]&lt;/span&gt;
This expression looks like a bit of a mess, I’ll admit, but it can be useful. Things simplify quite a bit of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j^{-1}\)&lt;/span&gt; has a form that is easy to invert (like a multiple of an identity matrix) and if the dimension of the random effects &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; is small. Under these conditions, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j^{-1}\)&lt;/span&gt; is easy to work with, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}^{-1}\)&lt;/span&gt; is manageable because it has small dimensions, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Z}_j&amp;#39;\boldsymbol\Sigma_j^{-1}\mathbf{Z}_j\)&lt;/span&gt; becomes manageable because it also has small dimensions (&lt;span class=&#34;math inline&#34;&gt;\(q \times q\)&lt;/span&gt;, in both cases).&lt;/p&gt;
&lt;div id=&#34;random-intercepts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Random intercepts&lt;/h2&gt;
&lt;p&gt;As an example, consider a very simple model that includes only random intercepts, so &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Z}_j = \mathbf{1}_j\)&lt;/span&gt;, an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times 1\)&lt;/span&gt; vector with every entry equal to 1, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt; is simply &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, the variance of the random intercepts. For simplicity, let’s also assume that the level-1 errors are independent, so &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j = \sigma^2 \mathbf{I}_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j^{-1} = \sigma^{-2} \mathbf{I}_j\)&lt;/span&gt;. Applying the Woodbury identity,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mathbf{V}_j^{-1} &amp;amp;= \boldsymbol\Sigma_j^{-1} - \boldsymbol\Sigma_j^{-1} \mathbf{1}_j \left(\mathbf{T}^{-1} + \mathbf{1}_j&amp;#39;\boldsymbol\Sigma_j^{-1}\mathbf{1}_j \right)^{-1} \mathbf{1}_j&amp;#39; \boldsymbol\Sigma_j^{-1} \\
&amp;amp;= \sigma^{-2} \mathbf{I}_j - \sigma^{-4} \mathbf{1}_j \left(\tau^{-2} + \sigma^{-2} \mathbf{1}_j&amp;#39;\mathbf{1}_j \right)^{-1} \mathbf{1}_j&amp;#39; \\
&amp;amp;= \sigma^{-2} \mathbf{I}_j - \sigma^{-4} \left(\tau^{-2} + \sigma^{-2} n_j \right)^{-1} \mathbf{1}_j \mathbf{1}_j&amp;#39; \\
&amp;amp;= \sigma^{-2} \left(\mathbf{I}_j - \frac{\tau^2} {\sigma^2 + n_j \tau^2} \mathbf{1}_j \mathbf{1}_j&amp;#39;\right).
\end{aligned}
\]&lt;/span&gt;
Try checking this for yourself by carrying through the matrix algebra for &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j \mathbf{V}_j^{-1}\)&lt;/span&gt;, which should come out equal to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{I}_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now suppose that the design matrix is also quite simple, consisting of just an intercept term &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j = \mathbf{1}_j\)&lt;/span&gt;, so that &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta = \beta\)&lt;/span&gt; is simply a population mean. How precise is the estimate of the population mean from this hierarchical model? Well, the sampling variance of the estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta\)&lt;/span&gt; is approximately
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{Var}(\hat\beta) &amp;amp;\approx \left(\sum_{j=1}^J \mathbf{1}_j&amp;#39;\mathbf{V}_j^{-1} \mathbf{1}_j \right)^{-1} \\
&amp;amp;= \left(\sigma^{-2}\sum_{j=1}^J \mathbf{1}_j&amp;#39; \left(\mathbf{I}_j - \frac{\tau^2} {\sigma^2 + n_j \tau^2} \mathbf{1}_j \mathbf{1}_j&amp;#39;\right) \mathbf{1}_j \right)^{-1} \\
&amp;amp;= \left(\sigma^{-2} \sum_{j=1}^J n_j \left(1 - \frac{n_j \tau^2} {\sigma^2 + n_j \tau^2} \right)  \right)^{-1} \\ 
&amp;amp;= \left( \sigma^{-2} \sum_{j=1}^J \frac{n_j \sigma^2} {\sigma^2 + n_j \tau^2} \right)^{-1} \\ 
&amp;amp;= \left(\sum_{j=1}^J \frac{n_j} {\sigma^2 + n_j \tau^2} \right)^{-1} \\
&amp;amp;= \left(\sigma^2 + \tau^2\right) \left(\sum_{j=1}^J \frac{n_j} {1 + (n_j - 1) \rho} \right)^{-1},
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\rho = \tau^2 / (\tau^2 + \sigma^2)\)&lt;/span&gt; is the intra-class correlation. Squint at this expression for a bit and you can see how the ICC influences the varince. If &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is near zero, then the sampling variance will be close to &lt;span class=&#34;math inline&#34;&gt;\(\left(\sigma^2 + \tau^2\right) / N\)&lt;/span&gt;, which is what you would get if you treated every observation as independent. If &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is near 1, then the sampling variance ends up being nearly &lt;span class=&#34;math inline&#34;&gt;\(\left(\sigma^2 + \tau^2\right) / J\)&lt;/span&gt;, which is what you would get if you treated every cluster as a single observation. For intermediate ICCs, the sample size from cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (in the numerator of the fraction inside the summation) gets cut down to size accordingly.&lt;/p&gt;
&lt;p&gt;The estimator of the population mean is a weighted average of the outcomes. Specifically,
&lt;span class=&#34;math display&#34;&gt;\[
\hat\beta = \left(\sum_{j=1}^J \mathbf{1}_j&amp;#39;\mathbf{\hat{V}}_j^{-1} \mathbf{1}_j \right)^{-1} \sum_{j=1}^J \mathbf{1}_j&amp;#39;\mathbf{\hat{V}}_j^{-1} \mathbf{Y}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\hat{V}}_j\)&lt;/span&gt; is an estimator of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt;. If you carry through the matrix algebra, you’ll find that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\hat\beta &amp;amp;= \left(\sum_{j=1}^J \frac{n_j} {\sigma^2 + n_j \tau^2} \right)^{-1} \sum_{j=1}^J \frac{\mathbf{1}_j&amp;#39;\mathbf{Y}_j}{\sigma^2 + n_j \tau^2} \\
&amp;amp;= \frac{1}{W} \sum_{j=1}^J \sum_{i=1}^{n_j} w_j y_{ij},
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(w_j = \frac{1}{1 + (n_j - 1) \rho}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{W = \sum_{j=1}^J n_j w_j}\)&lt;/span&gt;. From this, we can see that the weight of a given observation depends on the ICC and the size of the cluster. If the ICC is low, then weights will all be close to 1. For higher ICCs, observations in smaller clusters get proportionately &lt;em&gt;more&lt;/em&gt; weight than observations in larger clusters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-meta-analysis-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A meta-analysis example&lt;/h2&gt;
&lt;p&gt;In a &lt;a href=&#34;http://localhost:4321/weighting-in-multivariate-meta-analysis/&#34;&gt;previous post&lt;/a&gt; on multi-variate meta-analysis, I examined how weighting works in some multi-variate meta-analysis models, where you have multiple effect size estimates nested within a study. Letting &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; denote effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;. The first model I considered in the previous post was
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \mu + \eta_j + \nu_{ij} + e_{ij},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\nu_{ij}) = \omega^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(e_{ij}) = V_j\)&lt;/span&gt;, treated as known, and &lt;span class=&#34;math inline&#34;&gt;\(\text{cor}(e_{hj}, e_{ij}) = \rho\)&lt;/span&gt; for some specified value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; This model makes the simplifying assumptions that the effect sizes within a given study all have the same sampling variance, &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;, and that there is a single correlation between pairs of outcomes from the same study, that is constant across all pairs of outcomes and across all studies.&lt;/p&gt;
&lt;p&gt;You can write this model in matrix form as
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_j = \mu \mathbf{1}_j + \eta_j \mathbf{1}_j + \boldsymbol\nu_j + \mathbf{e}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\boldsymbol\nu_j) = \omega^2 \mathbf{I}_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{e}_j) = V_j \left[\rho \mathbf{1}_j \mathbf{1}_j&amp;#39; + (1 - \rho) \mathbf{I}_j\right]\)&lt;/span&gt;. It follows that
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\mathbf{T}_j) = (\tau^2 + V_j\rho) \mathbf{1}_j \mathbf{1}_j&amp;#39; + [\omega^2 + V_j (1 - \rho)] \mathbf{I}_j.
\]&lt;/span&gt;
The Woodbury identity comes in handy here again, if we want to examine the weights implied by this model or the sampling variance of the overall average effect size estimator.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; I’ll leave it as an exercise to find an expression for the weight assigned to effect size &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; under this model.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; You could also try finding an expression for the variance of the overall average effect size estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu\)&lt;/span&gt;, based on inverse-variance weighting, when the model is correctly specified.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-meta-analysis-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Another meta-analysis example&lt;/h2&gt;
&lt;p&gt;In the &lt;a href=&#34;http://localhost:4321/weighting-in-multivariate-meta-analysis/&#34;&gt;previous post&lt;/a&gt;, I also covered weighting in a bit more general model, where the sampling variances and correlations are no longer quite so constrained. As before, we have
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_j = \mu \mathbf{1}_j + \eta_j \mathbf{1}_j + \boldsymbol\nu_j + \mathbf{e}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\boldsymbol\nu_j) = \omega^2 \mathbf{I}_j\)&lt;/span&gt;. But now let &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{e}_j) = \boldsymbol\Sigma_j\)&lt;/span&gt; for some arbitrary, symmetric, invertible matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma_j\)&lt;/span&gt;. The marginal variance of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_j\)&lt;/span&gt; is therefore
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\mathbf{T}_j) = \tau^2\mathbf{1}_j \mathbf{1}_j&amp;#39; + \omega^2 \mathbf{I}_j + \boldsymbol\Sigma_j.
\]&lt;/span&gt;
Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_j = \left(\omega^2 \mathbf{I}_j + \boldsymbol\Sigma_j\right)^{-1}\)&lt;/span&gt;. Try applying the Woodbury identity to invert &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{T}_j)\)&lt;/span&gt; in terms of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_j\)&lt;/span&gt;. Then see if you can derive the weight assigned to effect &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; under this model. See the previous post for the solution.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;This model is what we call the “correlated-and-hierarchical effects model” in my paper (with Beth Tipton) on &lt;a href=&#34;http://localhost:4321/publication/rve-meta-analysis-expanding-the-range/&#34;&gt;extending working models for robust variance estimation&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Or squint hard at the formula for the variance of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_j\)&lt;/span&gt;, and you’ll see that it has the same form as the random intercepts model in the previous example. Just replace the &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; in that model with &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 + V_j \rho\)&lt;/span&gt; and replace the &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; in that model with &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 + V_j (1 - \rho)\)&lt;/span&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;See the &lt;a href=&#34;http://localhost:4321/weighting-in-multivariate-meta-analysis/&#34;&gt;previous post&lt;/a&gt; for the answer.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;In the previous post, I expressed the weights in terms of &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt;, the sum of the entries in row &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; of the &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_j\)&lt;/span&gt; matrix. In vector form, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{s}_j = \left(s_{1j} \ s_{2j} \ \cdots \ s_{n_j j}\right)&amp;#39; = \mathbf{S}_j \mathbf{1}_j\)&lt;/span&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An ANCOVA puzzler</title>
      <link>http://localhost:4321/ancova-puzzler/</link>
      <pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/ancova-puzzler/</guid>
      <description>


&lt;p&gt;Doing effect size calculations for meta-analysis is a good way to lose your faith in humanity—or at least your faith in researchers’ abilities to do anything like sensible statistical inference. Try it, and you’re surely encounter head-scratchingly weird ways that authors have reported even simple analyses, like basic group comparisons. When you encounter this sort of thing, you have two paths: you can despair, curse, and/or throw things, or you can view the studies as curious little puzzles—brain-teasers, if you will—to keep you awake and prevent you from losing track of those notes you took during your stats courses, back when. Here’s one of those curious little puzzles, which I recently encountered in helping a colleague with a meta-analysis project.&lt;/p&gt;
&lt;p&gt;A researcher conducts a randomized experiment, assigning participants to each of &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; groups. Each participant is assessed on a variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at pre-test and at post-test (we can assume there’s no attrition). In their study write-up, the researcher reports sample sizes for each group, means and standard deviations for each group at pre-test and at post-test, and &lt;em&gt;adjusted&lt;/em&gt; means at post-test, where the adjustment is done using a basic analysis of covariance, controlling for pre-test scores only. The data layout looks like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Group&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Adjusted post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Group A&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(n_A\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_{A}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{A0}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{A}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{A1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}_A\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Group B&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(n_B\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_{B}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{B0}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{B}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{B1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}_B\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note that the write-up does &lt;em&gt;not&lt;/em&gt; provide an estimate of the correlation between the pre-test and the post-test, nor does it report a standard deviation or standard error for the mean change-score between pre-test and post-test within each group. All we have are the summary statistics, plus the adjusted post-test scores. We can assume that the adjustment was done according to the basic ANCOVA model, assuming a common slope across groups as well as homoskedasticity and so on. The model is then
&lt;span class=&#34;math display&#34;&gt;\[
y_{ig} = \alpha_g + \beta x_{ig} + e_{ig},
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(g = 1,...,G\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(e_{ig}\)&lt;/span&gt; is an independent error term that is assumed to have constant variance across groups.&lt;/p&gt;
&lt;div id=&#34;for-realz&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;For realz?&lt;/h3&gt;
&lt;p&gt;Here’s an example with real data, drawn from Table 2 of &lt;a href=&#34;https://doi.org/10.1080/10573560500455703&#34;&gt;Murawski (2006)&lt;/a&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Group&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Pre-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Post-test &lt;span class=&#34;math inline&#34;&gt;\(SD\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Adjusted post-test &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Group A&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;37.48&lt;/td&gt;
&lt;td&gt;4.64&lt;/td&gt;
&lt;td&gt;37.96&lt;/td&gt;
&lt;td&gt;4.35&lt;/td&gt;
&lt;td&gt;37.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Group B&lt;/td&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;36.85&lt;/td&gt;
&lt;td&gt;5.18&lt;/td&gt;
&lt;td&gt;36.46&lt;/td&gt;
&lt;td&gt;3.86&lt;/td&gt;
&lt;td&gt;36.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Group C&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;37.88&lt;/td&gt;
&lt;td&gt;3.88&lt;/td&gt;
&lt;td&gt;37.38&lt;/td&gt;
&lt;td&gt;4.76&lt;/td&gt;
&lt;td&gt;36.98&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;That study reported this information for each of several outcomes, with separate analyses for each of two sub-groups (LD and NLD). The text also reports that they used a two-level hierarchical linear model for the ANCOVA adjustment. For simplicity, let’s just ignore the hierarchical linear model aspect and assume that it’s a straight, one-level ANCOVA.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-puzzler&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The puzzler&lt;/h3&gt;
&lt;p&gt;Calculate an estimate of the standardized mean difference between group &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; and group &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;, along with the sampling variance of the SMD estimate, that adjusts for pre-test differences between groups. Candidates for numerator of the SMD include the adjusted mean difference, &lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}_B - \tilde{y}_A\)&lt;/span&gt; or the difference-in-differences, &lt;span class=&#34;math inline&#34;&gt;\(\left(\bar{y}_B - \bar{x}_B\right) - \left(\bar{y}_A - \bar{x}_A\right)\)&lt;/span&gt;. In either case, the tricky bit is finding the sampling variance of this quantity, which involves the pre-post correlation. For the denominator of the SMD, you use the post-test SD, either pooled across just groups &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; or pooled across all &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; groups, assuming a common population variance.&lt;/p&gt;
&lt;p&gt;Have an idea for how to solve this? Post it in the comments or email it to me. Need the solution because you have a study like this in your meta-analysis? Contact me and I’ll share it with you directly. I’m being coy because I’m teaching meta-analysis next semester, and I feel like this would make a good extra credit problem…&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Centering categorical predictors in meta-regression</title>
      <link>http://localhost:4321/centering-categorical-predictors/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/centering-categorical-predictors/</guid>
      <description>


&lt;p&gt;Meta-analyses of dependent effect size estimates involve a hierarchical data structure, where you’ve got multiple independent samples (or experiments or studies, you might call them) and one or more effect size estimates are drawn from each sample.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(fastDummies)
library(clubSandwich)
library(metafor)

tmp &amp;lt;- tempfile(fileext = &amp;quot;.rds&amp;quot;)
download.file(&amp;quot;https://jepusto.com/data/Tanner-Smith-Lipsey-2015-subset.rds&amp;quot;, tmp)

TSL15 &amp;lt;- 
  readRDS(file = tmp) %&amp;gt;%
  # exclude observations missing control variables
  filter(!is.na(percoll), !is.na(attrition_all), !is.na(permale))

# Shorten dv category labels
levels(TSL15$dv_cat) &amp;lt;- c(&amp;quot;freq&amp;quot;,&amp;quot;heavy&amp;quot;,&amp;quot;quantity&amp;quot;,&amp;quot;peak&amp;quot;,&amp;quot;BAC&amp;quot;,&amp;quot;combined&amp;quot;)

# Center control variables

TSL15_cent &amp;lt;- 
  TSL15 %&amp;gt;%
  mutate(
    postwks_c = pmin(postwks, 26) - 12,
    postwks_long = as.numeric(postwks &amp;gt; 26),
    percoll_c = percoll - 1,
    permale_c = permale - 0.5,
    attrition_c = attrition_all - median(attrition_all),
    study_dv = paste(studyid, dv_cat, sep = &amp;quot;-&amp;quot;),
    study_ctype = paste(studyid, Ctype, sep = &amp;quot;-&amp;quot;)
  ) %&amp;gt;%
  # make dummies
  dummy_cols(&amp;quot;dv_cat&amp;quot;) %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  # group center, group means
  mutate(across(starts_with(&amp;quot;dv_cat_&amp;quot;), list(gc = ~ .x - mean(.x), gm = ~ mean(.x)))) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(
    # center group means
    across(matches(&amp;quot;dv_cat_.+_gm&amp;quot;), ~ .x - mean(.x)),
    # add grand means to group-centered
    across(matches(&amp;quot;dv_cat_.+_gc&amp;quot;), ~ .x + mean(.x), .names = &amp;quot;{.col}g&amp;quot;)
  )

# constant sampling correlation assumption
rho &amp;lt;- 0.6

# constant sampling correlation working model
V_mat &amp;lt;- impute_covariance_matrix(TSL15_cent$V, 
                                  cluster = TSL15_cent$studyid, 
                                  r = rho, 
                                  smooth_vi = TRUE)

# fit random effects working model in metafor
dv_multilevel &amp;lt;- rma.mv(yi = es,
                        mods = ~ 0 + dv_cat,
                        V = V_mat, 
                        random = ~ 1 | studyid / esid,
                        data = TSL15_cent, sparse = TRUE)
dv_multilevel

dv_A &amp;lt;- update(dv_multilevel, 
               mods = ~ dv_cat_freq_gc + dv_cat_heavy_gc + dv_cat_quantity_gc + dv_cat_peak_gc + dv_cat_BAC_gc + 
                 dv_cat_freq_gm + dv_cat_heavy_gm + dv_cat_quantity_gm + dv_cat_peak_gm + dv_cat_BAC_gm)
dv_A
Wald_test(dv_A, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE))
Wald_test(dv_A, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE, with_zero = TRUE), tidy = TRUE)

dv_B &amp;lt;- update(dv_multilevel, 
               mods = ~ dv_cat_freq_gc + dv_cat_heavy_gc + dv_cat_quantity_gc + dv_cat_peak_gc + dv_cat_BAC_gc)
dv_B
Wald_test(dv_B, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE))
Wald_test(dv_B, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(&amp;quot;dv_cat_.+_gc&amp;quot;, reg_ex = TRUE, with_zero = TRUE), tidy = TRUE)


dv_C &amp;lt;- update(dv_multilevel, 
               mods = ~ 0 + dv_cat + 
                 dv_cat_freq_gm + dv_cat_heavy_gm + dv_cat_quantity_gm + dv_cat_peak_gm + dv_cat_BAC_gm)

dv_C
Wald_test(dv_C, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_equal(1:6))
Wald_test(dv_C, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(1:6), tidy = TRUE)

dv_D &amp;lt;- rma.mv(yi = es,
               mods = ~ 0 + factor(studyid) + dv_cat,
               V = V_mat, 
               random = ~ 1 | esid,
               data = TSL15_cent, sparse = TRUE)
Wald_test(dv_D, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_zero(&amp;quot;dv_cat&amp;quot;, reg_ex = TRUE))
Wald_test(dv_D, vcov = &amp;quot;CR2&amp;quot;, constraints = constrain_pairwise(&amp;quot;dv_cat&amp;quot;, reg_ex = TRUE, with_zero = TRUE), tidy = TRUE)

coef(dv_A)[2:6]
coef(dv_B)[2:6]
coef(dv_C)[1:5] - coef(dv_C)[6]
coef(dv_D)[118:122]
coef(dv_C)[2:6] - coef(dv_C)[1]&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>From Longhorn to Badger</title>
      <link>http://localhost:4321/from-longhorn-to-badger/</link>
      <pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/from-longhorn-to-badger/</guid>
      <description>


&lt;p&gt;It’s taken me a while to finally get around to updating my website with some personal news. I’ve moved from UT Austin to the &lt;a href=&#34;https://www.wisc.edu/&#34;&gt;UW Madison&lt;/a&gt; &lt;a href=&#34;https://education.wisc.edu/&#34;&gt;School of Education&lt;/a&gt;, where I am now an associate professor in the &lt;a href=&#34;https://edpsych.education.wisc.edu/&#34;&gt;Educational Psychology Department&lt;/a&gt;’s &lt;a href=&#34;https://edpsych.education.wisc.edu/academics/quantitative-methods/&#34;&gt;Quantitative Methods program&lt;/a&gt;. We left Austin at the very end of July, arriving in Madison on August 1st. Our moving truck took a bit longer to arrive, but we’re now more or less installed in our new (or rather old–1950’s era) home. I grew up in Wisconsin (in the Milwaukee area), so this move brings us much closer to my family, who have already come to visit. We’ve also already been enjoying the fantastic bike paths and facilities that Madison has to offer.&lt;/p&gt;
&lt;p&gt;On a professional level, I’m very much looking forward to the opportunities that the School of Education and Educational Psychology Department present, especially to opportunities for collaboration with new colleagues and students. I’m planning to offer a course on research synthesis and meta-analysis this coming Spring semester—something I’ve never had the opportunity to teach in a semester-long format, actually—and I’m looking forward to offering my own pedagogical perspective on material that I think about constantly in a research context. Gene Glass, who is credited as the originator of the term meta-analysis and who conducted some of the first meta-analyses within the social sciences, &lt;a href=&#34;https://en.wikipedia.org/wiki/Gene_V._Glass#Background&#34;&gt;received his Ph.D. in Educational Psychology from UW Madison in 1965&lt;/a&gt;, so perhaps I’ll be able to channel a bit of his spirit in my course.&lt;/p&gt;
&lt;p&gt;Even as I’m excited to get started at Madison, I will also very much miss my colleagues at UT Austin, who were so supportive during my pre-tenure phase. Because of COVID, I didn’t really get to say a proper farewell before we skipped town. I am continuing to advise several doctoral students in the Quantitative Methods program though, so we will likely get to connect in video meetings, at least.&lt;/p&gt;
&lt;p&gt;Moving during the COVID pandemic has presented some challenges (logistical, emotional, and family-related) for me, though I know many others have had to deal with far worse. As we all weather this together, please feel free to leave a comment or drop me a line if you’d like to talk about stats, meta-analysis, R programming, or what-not.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes</title>
      <link>http://localhost:4321/publication/selective-reporting-with-dependent-effects/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/selective-reporting-with-dependent-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What do meta-analysts mean by &#39;multivariate&#39; meta-analysis?</title>
      <link>http://localhost:4321/what-does-multivariate-mean/</link>
      <pubDate>Sat, 27 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/what-does-multivariate-mean/</guid>
      <description>


&lt;p&gt;If you’ve ever had class with me or attended one of my presentations, you’ve probably heard me grouse about how statisticians are mostly awful about naming things.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; A lot of the terminology in our field is pretty bad and ineloquent. As a leading example, look no further than Rubin and Little’s classification of missing data mechanisms as missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR). Clear as mud, and the last one sounds like something you’d see on a handmade sign with a picture of someone’s pet puppy who wandered off last week.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://petkey.blob.core.windows.net/resource/images/940000/949000/949340_500W.jpg&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;As another example, consider that introductory statistics students always struggle to distinguish between no less than &lt;strong&gt;&lt;em&gt;three&lt;/em&gt;&lt;/strong&gt; different concepts that are all called “variance”: population variance, sample variance, and sampling variance.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Unless the instructor also took diction training from the Royal Shakespeare Company, it’s no wonder that a fair number of students are left confused.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Hamlet-z-transform.jpg&#34; /&gt;
In this post, I will try to clarify (at least a little bit) another mess of terminology that crops up a lot in my work on meta-analysis: what do we mean when we say a model or method is “multivariate”? In the context of meta-analysis methods, I think there are at least three distinct senses in which this term is used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As an umbrella term for models/methods where there is more than one effect size estimate per study,&lt;/li&gt;
&lt;li&gt;As a description for a class of methods within that broad umbrella, where certain aspects of the model are treated as known, or&lt;/li&gt;
&lt;li&gt;As a description for a class of models for multivariate effect size estimates, where each effect size estimate from a study falls into one of a set of distinct categories.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let me explain what I mean by each of these.&lt;/p&gt;
&lt;div id=&#34;multivariate-handwaving&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multivariate handwaving&lt;/h2&gt;
&lt;p&gt;In the context of meta-analysis, the broadest meaning of “multivariate” is any method used for modeling data that includes more than one effect size estimate in some or all of the included studies. Formally, the term would apply to any model appropriate for a set of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; includes &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; effect size estimates, and where the effect size estimates would be denoted &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;As it is used here, “multivariate” is really an umbrella term that could encompass a wide variety of methods and models, including multi-level meta-analysis or meta-regression models, multivariate methods in the narrower senses I will describe subsequently, and even robust variance estimation methods. It would also encompass techniques for handling this sort of data structure that aren’t strictly models, such as aggregating effect size estimates to the level of the study or using Harris Cooper’s “shifting unit-of-analysis” method &lt;span class=&#34;citation&#34;&gt;(Cooper, &lt;a href=&#34;#ref-Cooper1998synthesizing&#34; role=&#34;doc-biblioref&#34;&gt;1998&lt;/a&gt;)&lt;/span&gt;.
This usage of “multivariate” involves a bit too much hand-waving for my taste (although I’ve been guilty of using the term this way in the past). I think a better, clearer term for this broad class of methods would be to call them methods for &lt;strong&gt;&lt;em&gt;meta-analysis of dependent effect sizes&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multivariate-sampling-errors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multivariate sampling errors&lt;/h2&gt;
&lt;p&gt;Another sense in which “multivariate” is used pertains to a certain class of models for dependent effect sizes. In particular, “multivariate meta-analysis” sometimes means a model where the sampling variances and covariances of the effect size estimates are treated as fully known. Say that each effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; has a corresponding true effect size parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta_{ij}\)&lt;/span&gt;, so that the sampling error is &lt;span class=&#34;math inline&#34;&gt;\(e_{ij} = T_{ij} - \theta_{ij}\)&lt;/span&gt;, or
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \theta_{ij} + e_{ij}.
\]&lt;/span&gt;
Typically, meta-analysis techniques treat the sampling errors as having known variances, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(e_{ij}) = \sigma_{ij}^2\)&lt;/span&gt; for known &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{ij}^2\)&lt;/span&gt;.
Here, a multivariate meta-analysis would go a step further and make assumptions that &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{hj}, e_{ij}) = \rho_{hij}\sigma_{hj} \sigma_{ij}\)&lt;/span&gt; for &lt;em&gt;known&lt;/em&gt; correlations &lt;span class=&#34;math inline&#34;&gt;\(\rho_{hij}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(h,i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j=1,...,k\)&lt;/span&gt;.
Typically, the sampling variances and covariances would play into how the model is estimated and how one conducts inference and gets standard errors on things, etc.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Becker (&lt;a href=&#34;#ref-Becker2000multivariate&#34; role=&#34;doc-biblioref&#34;&gt;2000&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Gleser &amp;amp; Olkin (&lt;a href=&#34;#ref-Gleser2009stochastically&#34; role=&#34;doc-biblioref&#34;&gt;2009&lt;/a&gt;)&lt;/span&gt; describe a whole slew of different situations where meta-analysts will encounter multiple effect size estimates within a given study, and both provide formulas for the covariances between those effect sizes.
In some situations, these covariances can be calculated just based on primary study sample sizes or other information readily available from study reports.
In other situations (such as when one calculates &lt;a href=&#34;http://localhost:4321/correlations-between-smds/&#34;&gt;standardized mean differences for each of several outcomes on a common set of participants&lt;/a&gt;), the information needed to calculate covariances might not be available, which is where methods like robust variance estimation come in.
With this meaning of the term, multivariate meta-analysis methods are those that both directly model the dependent effects structure and that treat the sampling covariances as known. They are therefore distinct from methods, such as robust variance estimation, that do not rely on knowing the exact variance-covariance structure of the sampling errors.
In my own work, I find it helpful to be able to draw this distinction, so I rather like this usage of “multivariate.” This will surely irritate some statisticians, though, who prefer the third, stricter meaning of the term.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;strictly-multivariate-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Strictly multivariate models&lt;/h2&gt;
&lt;p&gt;A third meaning of multivariate is to denote a class of models for multivariate data, meaning data where each unit is measured on several dimensions or characteristics. In the meta-analysis context, multivariate effect sizes are ones where, for each included study or sample, we have effect sizes describing outcomes (e.g., treatment effects) on one or more dimensions.
For example, say that we have a bunch of studies examining some sort of educational intervention, and each study reports effect sizes describing the intervention’s impact on a) reading performance, b) social studies achievement, and/or c) language arts achievement. What differentiates this sort of multivariate data from the first, “umbrella” sense of the term is that with strictly multivariate data, no study has more than one effect size within a given dimension. In contrast, meta-analysis of dependent effect sizes deal with data structures that are not necessarily so tidy and organized, such that we might not be able to classify each effect size into one of a finite and exhaustive set of categories.&lt;/p&gt;
&lt;p&gt;When working with strictly multivariate data like this, a multivariate meta-analysis (or meta-regression) model would entail estimating average effects (or regression coefficients) &lt;em&gt;for each dimension&lt;/em&gt; rather than aggregating across dimensions. This class of models was discussed extensively in an excellent article by &lt;span class=&#34;citation&#34;&gt;Jackson et al. (&lt;a href=&#34;#ref-Jackson2011multivariate&#34; role=&#34;doc-biblioref&#34;&gt;2011&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; With my example of educational intervention studies, we would estimate average impacts on reading performance, social studies achievement, and language arts achievement. Estimating an overall aggregate effect on academic achievement would make little sense here, because we’d be mixing apples, oranges, and kiwis.&lt;/p&gt;
&lt;p&gt;Formally, this sort of data structure and model can be described as follows. As previously, say that we have a set of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; has &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; effect sizes, &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, and correspoding sampling variances &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{ij}^2\)&lt;/span&gt;, both for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...k\)&lt;/span&gt;. Effect size &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; can be classified into one of &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; dimensions. Let &lt;span class=&#34;math inline&#34;&gt;\(d^c_{ij}\)&lt;/span&gt; be an indicator for whether effect &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; falls into dimension &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(c = 1,...,C\)&lt;/span&gt;. With a strictly multivariate structure, there is never more than one effect per category, so &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^{n_j} d^c_{ij} \leq 1\)&lt;/span&gt; for each &lt;span class=&#34;math inline&#34;&gt;\(c = 1,...,C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;. A typical multivariate random effects model would then be
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \sum_{c=1}^C \left(\mu_c + v_{cj}\right) d^c_{ij} + e_{ij},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mu_c\)&lt;/span&gt; is the average effect size for category &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(v_{cj}\)&lt;/span&gt; is a random effect for category &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(e_{ij}\)&lt;/span&gt; is the sampling error term. The classic assumption about the random effects is that they are dependent within study, so
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(v_{cj}) = \tau^2_c \qquad \text{and} \qquad \text{Cov}(v_{bj}, v_{cj}) = \tau_{bc}
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(b,c = 1,...,C\)&lt;/span&gt;. Typically, these sorts of models would also rely on assumptions about the correlations between the sampling errors, just as with the second meaning of multivariate. Thus, to complete the model, we would have &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{hj}, e_{ij}) = \rho_{hij}\sigma_{hj}\sigma_{ij}\)&lt;/span&gt; for known &lt;span class=&#34;math inline&#34;&gt;\(\rho_{hij}\)&lt;/span&gt;. In practice, we might want to impose some common structure to the correlations across studies, such as using &lt;span class=&#34;math inline&#34;&gt;\(\rho_{hij}\)&lt;/span&gt;’s that depend on the dimensions being correlated but are common across studies. Formally, we would have
&lt;span class=&#34;math display&#34;&gt;\[
\rho_{hij} = \sum_{b=1}^C \sum_{c=1}^C d^b_{ij} \ d^c_{ij} \ \rho_{bc}.
\]&lt;/span&gt;
Of course, even getting this level of detail about correlations between effect sizes might often be pretty challenging.&lt;/p&gt;
&lt;p&gt;In a strictly multivariate meta-regression model, we would also allow the coefficients for each predictor to be specific to each category, so that
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \sum_{c=1}^C \left(\mathbf{x}_{ij}\boldsymbol\beta_c + v_{cj}\right) d^c_{ij} + e_{ij},
\]&lt;/span&gt;
In my example of educational intervention impact studies, say that are interested in whether the effects differ between quasi-experimental studies and true randomized control trials, and whether the effects differ based on the proportion of the sample that was economically disadvantaged. The strictly multivariate model would always involve interacting these predictors with the outcome category. In R’s equation notation, the meta-regression specification would be&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ES ~ 0 + Cat + Cat:RCT + Cat:disadvantaged_pct&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In contrast, in a generic meta-regression for dependent effect sizes, we might not include all of the interactions, and instead assume that the associations of the predictors were constant across outcome dimensions, as in&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ES ~ 0 + outcome_cat + RCT + college_pct&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the strict sense of the term, the model without interactions is no longer really a multivariate meta-regression.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;remarks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Remarks&lt;/h2&gt;
&lt;p&gt;An interesting property of strict multivariate meta-analysis models is that they involve partial pooling—or “borrowing of strength”—across dimensions &lt;span class=&#34;citation&#34;&gt;(Riley et al., &lt;a href=&#34;#ref-riley_evaluation_2007&#34; role=&#34;doc-biblioref&#34;&gt;2007&lt;/a&gt;, &lt;a href=&#34;#ref-riley_multivariate_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;. Even though the model has separate coefficients for each dimension, the estimates for a given dimension are influenced by the available effect sizes for &lt;em&gt;all&lt;/em&gt; dimensions. For instance, in the meta-analysis of educational intervention studies, the average impact on reading performance outcomes is based in part on the effect size estimates for the social studies and language arts performance. This happens because the model treats all of the dimensions as &lt;em&gt;correlated&lt;/em&gt;—through the correlated sampling errors and, potentially, through the correlated random effects structure. &lt;span class=&#34;citation&#34;&gt;Copas et al. (&lt;a href=&#34;#ref-copas_role_2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; examine how this works and propose a diagnostic plot to understand how it happens in application. &lt;span class=&#34;citation&#34;&gt;Kirkham et al. (&lt;a href=&#34;#ref-kirkham_multivariate_2012&#34; role=&#34;doc-biblioref&#34;&gt;2012&lt;/a&gt;)&lt;/span&gt; also show that the borrowing of strength phenomenon can partially mitigate bias from selective outcome reporting. These concepts could be quite relevant even beyond the “strict” multivariate meta-analysis context in which they have been explored. It strikes me that it would be useful to investigate them in the more general context of meta-analysis with dependent effect sizes—that is, multivariate meta-analysis in the first, broadest sense.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Becker2000multivariate&#34;&gt;
&lt;p&gt;Becker, B. J. (2000). Multivariate meta-analysis. In S. D. Brown &amp;amp; H. E. A. Tinsley (Eds.), &lt;em&gt;Handbook of applied multivariate statistics and mathematical modeling&lt;/em&gt; (pp. 499–525). Academic Press. &lt;a href=&#34;https://doi.org/10.1016/B978-012691360-6/50018-5&#34;&gt;https://doi.org/10.1016/B978-012691360-6/50018-5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Cooper1998synthesizing&#34;&gt;
&lt;p&gt;Cooper, H. M. (1998). &lt;em&gt;Synthesizing Research: A Guide for Literature Reviews&lt;/em&gt; (3rd ed.). Sage Publications, Inc.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-copas_role_2018&#34;&gt;
&lt;p&gt;Copas, J. B., Jackson, D., White, I. R., &amp;amp; Riley, R. D. (2018). The role of secondary outcomes in multivariate meta-analysis. &lt;em&gt;Journal of the Royal Statistical Society: Series C (Applied Statistics)&lt;/em&gt;, &lt;em&gt;67&lt;/em&gt;(5), 1177–1205. &lt;a href=&#34;https://doi.org/10.1111/rssc.12274&#34;&gt;https://doi.org/10.1111/rssc.12274&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Gleser2009stochastically&#34;&gt;
&lt;p&gt;Gleser, L. J., &amp;amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp;amp; J. C. Valentine (Eds.), &lt;em&gt;The handbook of research synthesis and meta-analysis&lt;/em&gt; (2nd ed., pp. 357–376). Russell Sage Foundation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Jackson2011multivariate&#34;&gt;
&lt;p&gt;Jackson, D., Riley, R. D., &amp;amp; White, I. R. (2011). Multivariate meta-analysis: Potential and promise. &lt;em&gt;Statistics in Medicine&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1002/sim.4172&#34;&gt;https://doi.org/10.1002/sim.4172&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kirkham_multivariate_2012&#34;&gt;
&lt;p&gt;Kirkham, J. J., Riley, R. D., &amp;amp; Williamson, P. R. (2012). A multivariate meta-analysis approach for reducing the impact of outcome reporting bias in systematic reviews. &lt;em&gt;Statistics in Medicine&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(20), 2179–2195. &lt;a href=&#34;https://doi.org/10.1002/sim.5356&#34;&gt;https://doi.org/10.1002/sim.5356&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-riley_evaluation_2007&#34;&gt;
&lt;p&gt;Riley, R. D., Abrams, K. R., Lambert, P. C., Sutton, A. J., &amp;amp; Thompson, J. R. (2007). An evaluation of bivariate random-effects meta-analysis for the joint synthesis of two correlated outcomes. &lt;em&gt;Statistics in Medicine&lt;/em&gt;, &lt;em&gt;26&lt;/em&gt;(1), 78–97. &lt;a href=&#34;https://doi.org/10.1002/sim.2524&#34;&gt;https://doi.org/10.1002/sim.2524&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-riley_multivariate_2017&#34;&gt;
&lt;p&gt;Riley, R. D., Jackson, D., Salanti, G., Burke, D. L., Price, M., Kirkham, J., &amp;amp; White, I. R. (2017). Multivariate and network meta-analysis of multiple outcomes and multiple treatments: Rationale, concepts, and examples. &lt;em&gt;BMJ&lt;/em&gt;, j3932. &lt;a href=&#34;https://doi.org/10.1136/bmj.j3932&#34;&gt;https://doi.org/10.1136/bmj.j3932&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;“Mostly” rather than “uniformly” due to exceptions like Brad Efron (a.k.a. Mr. Bootstrap) and Rob Tibshirani (a.k.a. Mr. Lasso).&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;And then consider the square roots of these quantities, respectively: population standard deviation, sample standard deviation, and &lt;strong&gt;&lt;em&gt;standard error&lt;/em&gt;&lt;/strong&gt;. WTF?&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Read this article! It’s essential. And it comes with pages and pages of commentary by other statisticans.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Weighting in multivariate meta-analysis</title>
      <link>http://localhost:4321/weighting-in-multivariate-meta-analysis/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/weighting-in-multivariate-meta-analysis/</guid>
      <description>


&lt;p&gt;One common question about multivariate/multi-level meta-analysis is how such models assign weight to individual effect size estimates. When a version of the question came up recently on the &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2020-June/002149.html&#34;&gt;R-sig-meta-analysis listserv&lt;/a&gt;, Dr. Wolfgang Viechtbauer offered a &lt;a href=&#34;http://www.metafor-project.org/doku.php/tips:weights_in_rma.mv_models&#34;&gt;whole blog post&lt;/a&gt; in reply, demonstrating how weights work in simpler fixed effect and random effects meta-analysis and then how things get more complicated in multivariate models. I started thumb-typing my own reply as well, but then decided it would be better to write up a post so that I could use a bit of math notation (and to give my thumbs a break). So, in this post I’ll try to add some further intuition on how weights work in certain multivariate meta-analysis models. Most of the discussion will apply to models that include multiple level of random effects, but no predictors. I’ll also comment briefly on meta-regression models with only study-level predictor variables, and finally give some pointers to work on more complicated models.&lt;/p&gt;
&lt;div id=&#34;a-little-background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A little background&lt;/h2&gt;
&lt;p&gt;It’s helpful to start by looking briefly at the basic fixed effect and random effects models, assuming that we’ve got a set of studies that each contribute a single effect size estimate so everything’s independent. Letting &lt;span class=&#34;math inline&#34;&gt;\(T_j\)&lt;/span&gt; be the effect size from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, with sampling variance &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;, both for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;, the basic random effects model is:
&lt;span class=&#34;math display&#34;&gt;\[
T_j = \mu + \eta_j + e_j
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall average effect size, &lt;span class=&#34;math inline&#34;&gt;\(v_j\)&lt;/span&gt; is a random effect with variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e_j\)&lt;/span&gt; is a sampling error with known variance &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;. The first step in estimating this model is to estimate &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;. There’s lots of methods for doing so, but let’s not worry about those details—just pick one and call the estimate &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt;. Then, to estimate &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, we take a weighted average of the effect size estimates:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\mu = \frac{1}{W} \sum_{j=1}^k w_j T_j, \qquad \text{where} \quad W = \sum_{j=1}^k w_j.
\]&lt;/span&gt;
The weights used in the weighted average are chosen to make the overall estimate as precise as possible (i.e., having the smallest possible sampling variance or standard error). Mathematically, the best possible weights are &lt;strong&gt;&lt;em&gt;inverse variance&lt;/em&gt;&lt;/strong&gt; weights, that is, setting the weight for each effect size estimate proportional to the inverse of how much variance there is in each estimate. With inverse variance weights, larger studies with more precise effect size estimates will tend to get more weight and smaller, noisier studies will tend to get less weight.&lt;/p&gt;
&lt;p&gt;In the basic random effects model, the weights for each study are proportional to
&lt;span class=&#34;math display&#34;&gt;\[
w_j = \frac{1}{\hat\tau^2 + V_j},
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;. The denominator term here includes both the (estimated) between-study heterogeneity and the sampling variance because both terms contribute to how noisy the effect size estimate is. In the fixed effect model, we ignore between-study heterogeneity so the weights are inversely proportional to the sampling variances, with &lt;span class=&#34;math inline&#34;&gt;\(w_j = 1 / V_j\)&lt;/span&gt;. In the random effects model, larger between-study heterogeneity will make the weights closer to equal, while smaller between-study heterogeneity will lead to weights that tend to emphasize larger studies with more precise estimates. In the remainder, I’ll show that there are some similar dynamics at work in a more complicated, multivariate meta-analysis model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-multivariate-meta-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A multivariate meta-analysis&lt;/h2&gt;
&lt;p&gt;Now let’s consider the case where some or all studies in our synthesis contribute more than one effect size estimate. Say that we have effect sizes &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt; indexes effect size estimates within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes studies, for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;. Say that effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; has sampling variance &lt;span class=&#34;math inline&#34;&gt;\(V_{ij}\)&lt;/span&gt;, and there is some sampling correlation between effect sizes &lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; within study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, denoted &lt;span class=&#34;math inline&#34;&gt;\(r_{hij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There are many models that a meta-analyst might consider for this data structure. A fairly common one would be a model that includes random effects not only for between-study heterogeneity (as in the basic random effects model) but also random effects capturing within-study heterogeneity in true effect sizes. Let me write this model heirarchically, as
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
T_{ij} &amp;amp;= \theta_j + \nu_{ij} + e_{ij} \\
\theta_j &amp;amp;= \mu + \eta_j
\end{align}
\]&lt;/span&gt;
In the first line of the model, &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; denotes the average effect size parameter for study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\nu_{ij}\)&lt;/span&gt; captures within-study heterogeneity in the true effect size parameters and &lt;span class=&#34;math inline&#34;&gt;\(e_{ij}\)&lt;/span&gt; is a sampling error. Above, I’ve assumed that we know the structure of the sampling errors, so &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(e_{ij}) = V_{ij}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{hj}, e_{ij}) = r_{hij} \sqrt{V_{hj} V_{ij}}\)&lt;/span&gt;. Let’s also denote the within-study variance as &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;, so &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\nu_{ij}) = \omega^2\)&lt;/span&gt;.
In the second line of the model, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is still the overall average effect size across all studies and effect sizes within studies and &lt;span class=&#34;math inline&#34;&gt;\(\eta_j\)&lt;/span&gt; is a between-study error, with &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\eta_j) = \tau^2\)&lt;/span&gt;, capturing the degree of heterogeneity in the &lt;em&gt;average&lt;/em&gt; effect sizes (the &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;’s) across studies.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One thing to note about this model is that it treats all of the effect sizes as coming from a population with a common mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. Some statisticians might object to calling it a multivariate model because we’re not distinguishing averages for different dimensions (or variates) of the effect sizes. To this I say: whatev’s, donkey! I’m calling it multivariate because you have to use the &lt;code&gt;rma.mv()&lt;/code&gt; function from the &lt;code&gt;metafor&lt;/code&gt; package to estimate it. I will acknowledge, though, that there will often be reason to use more complicated models, for example by replacing the overall average &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; with some meta-regression &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_{ij} \boldsymbol\beta\)&lt;/span&gt;. That’s a discussion for another day. For now, we’re only going to consider the model with an overall average effect size parameter &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. The question is, &lt;strong&gt;&lt;em&gt;how do the individual effect size estimates &lt;span class=&#34;math inline&#34;&gt;\(T_{ij}\)&lt;/span&gt; contribute to the estimate of this overall average effect?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;equally-precise-effect-size-estimates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Equally precise effect size estimates&lt;/h2&gt;
&lt;p&gt;To make some headway, it is helpful to first consider an even more specific model where, within a given study, all effect size estimates are equally precise and equally correlated. In particular, let’s assume that for each study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, the sampling variances are all equal, with &lt;span class=&#34;math inline&#34;&gt;\(V_{ij} = V_j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n_j\)&lt;/span&gt;, and the correlations between the sampling errors are also all equal, with &lt;span class=&#34;math inline&#34;&gt;\(r_{hij} = r_j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(h,i = 1,...,n_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;These assumptions might not be all that far-fetched. Within a given study, if the effect size estimates are for different measures of a common construct, it’s not unlikely that they would all be based on similar sample sizes (+/- a bit of item non-response). It might be a bit less likely if the effect size estimates are for treatment effects from different follow-up times (since drop-out/non-response tends to increase over time) or different treatment groups compared to a common control group—but still perhaps not entirely unreasonable. Further, it’s rather &lt;em&gt;uncommon&lt;/em&gt; to have good information about the correlations between effect size estimates from a given study (because primary studies don’t often report all of the information needed to calculate these correlations). In practice, meta-analysts might need to simply &lt;a href=&#34;http://localhost:4321/imputing-covariance-matrices-for-multi-variate-meta-analysis/&#34;&gt;make a rough guess about the correlations&lt;/a&gt; and then use robust variance estimation and/or sensitivity analysis to check themselves. And if we’re just ball-parking, then we’ll probably assume a single correlation for all of the studies.&lt;/p&gt;
&lt;p&gt;The handy thing about this particular scenario is that, because all of the effect size estimates within a study are equally precise and equally correlated, the most efficient way to estimate an average effect for a given study is to &lt;strong&gt;&lt;em&gt;just take the simple average&lt;/em&gt;&lt;/strong&gt; (and, intuitively, this seems like the only sensible thing to do). To be precise, consider how we would estimate &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; for a given study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;. The most precise possible estimate is simply
&lt;span class=&#34;math display&#34;&gt;\[
\hat\theta_j = \frac{1}{n_j} \sum_{i=1}^{n_j} T_{ij}.
\]&lt;/span&gt;
And we could do the same for each of the other studies, &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;.
It turns out that the estimate of the overall average effect size is a weighted average of these study-specific average effect sizes:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\mu = \frac{1}{W} \sum_{j=1}^k w_j \hat\theta_j,
\]&lt;/span&gt;
for some weights &lt;span class=&#34;math inline&#34;&gt;\(w_1,...,w_k\)&lt;/span&gt;. But what are these weights? Just like in the basic random effects model, they are inverse-variance weights. It’s just that the variance is a little bit more complicated.&lt;/p&gt;
&lt;p&gt;Consider how precise each of the study-specific estimates are, relative to the true effects in their respective studies. Conditional on the true effect &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\hat\theta_j | \theta_j) = \frac{1}{n_j}\left(\omega^2 + (n_j - 1) r_j V_j + V_j\right).
\]&lt;/span&gt;
Without conditioning on &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;, the variance of the &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta_j\)&lt;/span&gt; estimates also includes a term for variation in the true study-specific average effect sizes, becoming
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\hat\theta_j) = \tau^2 + \frac{1}{n_j}\left(\omega^2 + (n_j - 1) r_j V_j + V_j\right).
\]&lt;/span&gt;
The weights used in estimating &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; are the inverse of this quantity:
&lt;span class=&#34;math display&#34;&gt;\[
w_j = \frac{1}{\tau^2 + \frac{1}{n_j}\left(\omega^2 + (n_j - 1) r_j V_j + V_j\right)}.
\]&lt;/span&gt;
Within a study, each individual effect size gets an &lt;span class=&#34;math inline&#34;&gt;\(n_j^{th}\)&lt;/span&gt; of this study-level weight. We can therefore write the overall average as
&lt;span class=&#34;math display&#34;&gt;\[
\hat\mu = \frac{1}{W} \sum_{j=1}^k \sum_{i=1}^{n_j} w_{ij} T_{ij},
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
w_{ij} = \frac{1}{n_j \tau^2 + \omega^2 + (n_j - 1) r_j V_j + V_j}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;There are several things worth noting about this expression for the weights. First, suppose that there is little between-study or within-study heterogeneity, so &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; are both close to zero. Then the weights are driven by the number of effect sizes within the study (&lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt;), the sampling variance of those effect sizes (&lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt;) and their correlation &lt;span class=&#34;math inline&#34;&gt;\(r_j\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(r_j\)&lt;/span&gt; is near one, then averaging together a bunch of highly correlated estimates doesn’t improve precision much, relative to just using one of the effect sizes. The study-specific average effect estimate will therefore have variance close to &lt;span class=&#34;math inline&#34;&gt;\(V_j\)&lt;/span&gt; (i.e., the variance of a single effect size estimate). If &lt;span class=&#34;math inline&#34;&gt;\(r_j\)&lt;/span&gt; is below one, then averaging yields a more precise estimate than any of the individual effect sizes, and averaging together more effect sizes will yield a more precise estimate at the study level. If the assumed correlations are reasonably accurate, the weights used in the multi-variate meta-analysis will appropriately take into account the number of effect sizes within each study and the precision of those effect sizes.&lt;/p&gt;
&lt;p&gt;Second, now suppose that there is no between-study heterogeneity (&lt;span class=&#34;math inline&#34;&gt;\(\tau^2 = 0\)&lt;/span&gt;) but there is positive within-study heterogeneity. Larger degrees of within-study heterogeneity will tend to equalize the weights &lt;em&gt;at the effect size level&lt;/em&gt;, regardless of how effect size estimates are nested within studies. When there is within-study heterogeneity, averaging together a bunch of estimates will yield a more precise estimate of study-specific average effects. Therefore, when &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; is larger, studies with more effect sizes will tend to get a relatively larger share of the weight.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Third and finally, between-study heterogeneity will tend to equalize the weights at the study level, so that the overall average is pulled closer to a simple average of the study-specific average effects. This works very much like in basic random effects meta-analysis, where increased heterogeneity will lead to weights that are closer to equal and an average effect size estimate that is closer to a simple average.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-computational-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A computational example&lt;/h2&gt;
&lt;p&gt;I think it’s useful to verify algebraic results like the ones I’ve given above by checking that you can reproduce them with real data. I’ll use the &lt;code&gt;corrdat&lt;/code&gt; dataset from the &lt;code&gt;robumeta&lt;/code&gt; package for illustration. The dataset has one duplicated row in it (I have no idea why!), which I’ll remove before analyzing further.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

data(corrdat, package = &amp;quot;robumeta&amp;quot;)

corrdat &amp;lt;- 
  corrdat %&amp;gt;%
  distinct(studyid, esid, .keep_all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This dataset included a total of 171 effect size estimates from 39 unique studies. For each study, between 1 and 18 eligible effect size estimates were reported. Here is a histogram depicting the number of studies by the number of reported effect size estimates:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is the plot of the variances of each effect size versus the study IDs:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For most of the studies, the effect sizes have very similar sampling variances. One exception is study 9, where two of the effect sizes have variances of under 0.20 and the other two effect sizes have variances in excess of 0.35. Another exception is study 30, which has one effect size with much larger variance than the others.&lt;/p&gt;
&lt;p&gt;Just for sake of illustration, I’m going to &lt;em&gt;enforce&lt;/em&gt; my assumption that effect sizes have equal variances within each study by recomputing the sampling variances as the &lt;em&gt;average&lt;/em&gt; sampling variance within each study. I will then impute a sampling variance-covariance matrix for the effect sizes, assuming a correlation of 0.7 for effects from the same study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)

corrdat &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(V_bar = mean(var)) %&amp;gt;%
  ungroup()

V_mat &amp;lt;- impute_covariance_matrix(vi = corrdat$V_bar, 
                                  cluster = corrdat$studyid,
                                  r = 0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this variance-covariance matrix, I can then estimate the multivariate meta-analysis model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)

MVMA_fit &amp;lt;- rma.mv(yi = effectsize, V = V_mat, 
                   random = ~ 1 | studyid / esid,
                   data = corrdat)

summary(MVMA_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 171; method: REML)
## 
##   logLik  Deviance       AIC       BIC      AICc   
## -94.7852  189.5703  195.5703  204.9777  195.7149   
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed        factor 
## sigma^2.1  0.0466  0.2159     39     no       studyid 
## sigma^2.2  0.1098  0.3314    171     no  studyid/esid 
## 
## Test for Heterogeneity:
## Q(df = 170) = 1141.4235, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub      
##   0.2263  0.0589  3.8413  0.0001  0.1108  0.3417  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this model, between-study heterogeneity is estimated as &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.216\)&lt;/span&gt; and within-study heterogeneity is estimated as &lt;span class=&#34;math inline&#34;&gt;\(\hat\omega = 0.331\)&lt;/span&gt;, both of which are quite high. The overall average effect size estimate is 0.226, with a standard error of 0.059.&lt;/p&gt;
&lt;p&gt;I’ll first get the weights used in &lt;code&gt;rma.mv&lt;/code&gt; to compute the overall average. The weights are represented as an &lt;span class=&#34;math inline&#34;&gt;\(N \times N\)&lt;/span&gt; matrix. Taking the row or column sums, then rescaling by the total, gives the weight assigned to each effect size estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;W_mat &amp;lt;- weights(MVMA_fit, type = &amp;quot;matrix&amp;quot;)
corrdat$w_ij_metafor &amp;lt;- colSums(W_mat) / sum(W_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To verify that the formulas above are correct, I’ll use them to directly compute weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r &amp;lt;- 0.7
tau_sq &amp;lt;- MVMA_fit$sigma2[1]
omega_sq &amp;lt;- MVMA_fit$sigma2[2]

corrdat_weights &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(
    n_j = n(),
    w_ij = 1 / (n_j * tau_sq + omega_sq + (n_j - 1) * r * V_bar + V_bar)
  ) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(
    w_ij = w_ij / sum(w_ij)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The weights I computed are perfectly correlated with the weights used &lt;code&gt;rma.mv&lt;/code&gt;, as can be seen in the plot below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(corrdat_weights, aes(w_ij, w_ij_metafor)) + 
  geom_point() + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we remove the within-study random effect term from the model, the weights will be equivalent to setting &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; to zero, but with a different estimate of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVMA_no_omega &amp;lt;- rma.mv(yi = effectsize, V = V_mat, 
                        random = ~ 1 | studyid,
                        data = corrdat)
MVMA_no_omega&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 171; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2    0.0951  0.3084     39     no  studyid 
## 
## Test for Heterogeneity:
## Q(df = 170) = 1141.4235, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub      
##   0.2235  0.0619  3.6122  0.0003  0.1022  0.3448  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Re-fitting the model with &lt;code&gt;rma.mv()&lt;/code&gt; gives an between-study heterogeneity estimate of &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau = 0.308\)&lt;/span&gt; and an overall average effect size estimate of &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu = 0\)&lt;/span&gt;. Using this estimate, I’ll compute the weights based on the formula and then use those weights to determine the overall average effect size estimate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tau_sq &amp;lt;- MVMA_no_omega$sigma2

corrdat_weights &amp;lt;- 
  corrdat_weights %&amp;gt;%
  mutate(
    w_ij_no_omega = 1 / (n_j * tau_sq + (n_j - 1) * r * V_bar + V_bar),
    w_ij_no_omega = w_ij_no_omega / sum(w_ij_no_omega)
  )

with(corrdat_weights, weighted.mean(effectsize, w = w_ij_no_omega))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2235231&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This matches the output of &lt;code&gt;rma.mv()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is a plot showing the weights of individual effect sizes for each study. In blue are the weights under the assumption that &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 = 0\)&lt;/span&gt;. In green are the weights allowing for &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 &amp;gt; 0\)&lt;/span&gt;. It’s notable here that introducing the within-study heterogeneity term leads to pretty big changes in the weights for some studies. In particular, studies that have only a single effect size estimate (e.g., studys 7, 8, 22, 25, 28) lose &lt;em&gt;a lot&lt;/em&gt; of weight when &lt;span class=&#34;math inline&#34;&gt;\(\omega^2 &amp;gt; 0\)&lt;/span&gt;. That’s partially because &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; tends to pull weight towards studies with more effect sizes, and partially because of the change in the estimate of &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;, which tends to equalize the weight assigned to each study.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Below is a plot illustrating the changes in study-level weights (i.e., aggregating the weight assigned to each study). The bar color corresponds to the number of effect size estimates in each study; light grey studies have just one effect size, while studies with more effect sizes are more intensly purple. The notable drops in weight for studies with a single effect size estimate (light grey) are visible here too. Studies with more effect sizes (e.g., studies 2, 15, 30, with dark purple bars) gain weight when we allow &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; to be greater than zero.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in
## ggplot2 3.3.4.
## ℹ Please use &amp;quot;none&amp;quot; instead.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Weighting-in-multivariate-meta-analysis_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-without-compound-symmetry&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Now without compound symmetry&lt;/h2&gt;
&lt;p&gt;If we remove the restrictions that effect sizes from the same study have the same sampling variance and are equi-correlated, then the weights get a little bit more complicated. However, the general intuitions carry through. Let’s now consider the model with arbitrary sampling variance &lt;span class=&#34;math inline&#34;&gt;\(V_{ij}\)&lt;/span&gt; and sampling correlations within studies &lt;span class=&#34;math inline&#34;&gt;\(r_{hij}\)&lt;/span&gt;. The most efficient estimate of the study-specific average effect is now a &lt;em&gt;weighted&lt;/em&gt; average, with weights that depend on both the variances and covariances of the effect size estimates within each study. Let
&lt;span class=&#34;math display&#34;&gt;\[
\boldsymbol{\hat\Sigma}_j = \hat\omega^2 \mathbf{I}_j + \mathbf{V}_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{I}_j\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(n_j \times n_j\)&lt;/span&gt; identity matrix and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_j\)&lt;/span&gt; is the sampling variance-covariance matrix of the effect size estimates, with entry &lt;span class=&#34;math inline&#34;&gt;\((h,i)\)&lt;/span&gt; equal to &lt;span class=&#34;math inline&#34;&gt;\(\left[\mathbf{V}_j\right]_{h,i} = r_{hij} \sqrt{V_{hj} V_{ij}}\)&lt;/span&gt;. The estimate of the study-specific average effect size for study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is still a weighted average:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\theta_j = \frac{\sum_{i=1}^{n_j} s_{ij} T_{ij}}{\sum_{i=1}^{n_j} s_{ij}},
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
s_{ij} = \displaystyle{\sum_{h=1}^{n_j} \left[\boldsymbol{\hat\Sigma}^{-1}\right]_{hi}},
\]&lt;/span&gt;
and &lt;span class=&#34;math inline&#34;&gt;\(\left[\boldsymbol{\hat\Sigma}^{-1}\right]_{hi}\)&lt;/span&gt; denotes entry &lt;span class=&#34;math inline&#34;&gt;\((h,i)\)&lt;/span&gt; in the inverse of the matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{\hat\Sigma}\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(V^C_j\)&lt;/span&gt; denote the variance of the study-specific average effect size estimate, conditional on the true &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
V^C_j = \text{Var}(\hat\theta_j | \theta_j) = \left(\sum_{i=1}^{n_j} s_{ij} \right)^{-1}
\]&lt;/span&gt;
The unconditional variance of &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta_j\)&lt;/span&gt; is then
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\hat\theta_j) = \tau^2 + V^C_j.
\]&lt;/span&gt;
Because the overall average effect size estimate is (still) the inverse-variance weighted average, the weight assigned at the study level is equal to
&lt;span class=&#34;math display&#34;&gt;\[
w_j = \frac{1}{\hat\tau^2 + V^C_j}
\]&lt;/span&gt;
and the weight assigned to individual effect sizes is
&lt;span class=&#34;math display&#34;&gt;\[
w_{ij} = \frac{s_{ij} V^C_j}{\hat\tau^2 + V^C_j}.
\]&lt;/span&gt;
How do &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; affect these more general weights? The intuitions that I described earlier still mostly hold. Increasing &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; will tend to equalize the weights at the effect size level (i.e., equalize the &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt; across &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;), pulling weight towards studies with more effect size estimates. Increasing &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; will tend to equalize the weights at the study-level.&lt;/p&gt;
&lt;p&gt;One wrinkle with the more general form of the weights is that the effect-size level weights can sometimes be &lt;em&gt;negative&lt;/em&gt; (i.e., negative &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt;). This will tend to happen when the sampling variances within a study are discrepant, such as when one &lt;span class=&#34;math inline&#34;&gt;\(V_{ij}\)&lt;/span&gt; is much smaller than the others in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, when the (assumed or estimated) sampling correlation is high, and when &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt; is zero or small. This is something that warrants further investigation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-meta-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What about meta-regression?&lt;/h2&gt;
&lt;p&gt;Some of the foregoing analysis also applies to models that include predictors. In particular, the formulas I’ve given for the weights will still hold for meta-regression models &lt;strong&gt;&lt;em&gt;that include only study-level predictors&lt;/em&gt;&lt;/strong&gt;. In other words, they work for models of the following form:
&lt;span class=&#34;math display&#34;&gt;\[
T_{ij} = \mathbf{x}_j \boldsymbol\beta + \eta_j + \nu_{ij} + e_{ij},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_j\)&lt;/span&gt; is a row-vector of one or more predictors for study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (including a constant intercept). Introducing these predictors will alter the variance component estimates &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat\omega^2\)&lt;/span&gt;, but the form of the weights will remain the same as above, and the intuitions still hold. This is because, for purposes of estimating &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt;, the model is essentially the same as a meta-regression at the study level, using the study-specific average effect size estimates as input:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\theta_j = \mathbf{x}_j \boldsymbol\beta + \eta_j + \tilde{e}_j
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\tilde{e}_j) = \text{Var}(\hat\theta_j | \theta_j)\)&lt;/span&gt;.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here is an illustration with the &lt;code&gt;corrdat&lt;/code&gt; meta-analysis. In these data, the variable &lt;code&gt;college&lt;/code&gt; indicates whether the effect size comes from a college-age sample; it varies only at the study level. The variable &lt;code&gt;males&lt;/code&gt;, &lt;code&gt;binge&lt;/code&gt;, and &lt;code&gt;followup&lt;/code&gt; have some within-study variation, which I’ll by taking the average of each of these predictors at the study level:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrdat &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(
    males_M = mean(males),
    binge_M = mean(binge),
    followup_M = mean(followup)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s fit a meta-regression model using all of the study-level predictors:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVMR_fit &amp;lt;- rma.mv(yi = effectsize, V = V_mat,
                   mods = ~ college + males_M + binge_M + followup_M,  
                   random = ~ 1 | studyid / esid,
                   data = corrdat)

summary(MVMR_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 171; method: REML)
## 
##   logLik  Deviance       AIC       BIC      AICc   
## -86.6244  173.2488  187.2488  209.0327  187.9577   
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed        factor 
## sigma^2.1  0.0297  0.1723     39     no       studyid 
## sigma^2.2  0.1068  0.3268    171     no  studyid/esid 
## 
## Test for Residual Heterogeneity:
## QE(df = 166) = 1083.6655, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:5):
## QM(df = 4) = 13.0787, p-val = 0.0109
## 
## Model Results:
## 
##             estimate      se     zval    pval    ci.lb    ci.ub    
## intrcpt      -0.0361  0.3678  -0.0982  0.9218  -0.7571   0.6849    
## college       0.2660  0.1384   1.9215  0.0547  -0.0053   0.5373  . 
## males_M       0.0023  0.0048   0.4753  0.6346  -0.0072   0.0118    
## binge_M       0.3441  0.1570   2.1927  0.0283   0.0365   0.6518  * 
## followup_M   -0.0023  0.0011  -2.0379  0.0416  -0.0044  -0.0001  * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you might expect, between-study heterogeneity is reduced a bit by the inclusion of these predictors.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We can check my claim of computational equivalence by fitting the meta-regression model at the study level. Here I’ll aggregate everything up to the study level and compute the study-level weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tau_sq_reg &amp;lt;- MVMR_fit$sigma2[1]
omega_sq_reg &amp;lt;- MVMR_fit$sigma2[2]

corrdat_studylevel &amp;lt;- 
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(n_j = n()) %&amp;gt;%
  summarize_at(vars(effectsize, n_j, V_bar, college, binge_M, followup_M, males_M), mean
  ) %&amp;gt;%
  mutate(
    V_cond = (omega_sq_reg + (n_j - 1) * r * V_bar + V_bar) / n_j,
    w_j = 1 / (tau_sq_reg + V_cond)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can fit a study-level meta-regression model. I use the &lt;code&gt;weights&lt;/code&gt; argument to ensure that the meta-regression is estimated using the &lt;span class=&#34;math inline&#34;&gt;\(w_j\)&lt;/span&gt; weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MR_study_fit &amp;lt;- rma(yi = effectsize, vi = V_cond, 
                    mods = ~ college + males_M + binge_M + followup_M, 
                    weights = w_j, data = corrdat_studylevel)
summary(MR_study_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 39; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc   
## -13.0651   26.1303   38.1303   47.2884   41.2414   
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0297 (SE = 0.0264)
## tau (square root of estimated tau^2 value):             0.1723
## I^2 (residual heterogeneity / unaccounted variability): 26.89%
## H^2 (unaccounted variability / sampling variability):   1.37
## R^2 (amount of heterogeneity accounted for):            37.90%
## 
## Test for Residual Heterogeneity:
## QE(df = 34) = 46.5050, p-val = 0.0748
## 
## Test of Moderators (coefficients 2:5):
## QM(df = 4) = 13.0787, p-val = 0.0109
## 
## Model Results:
## 
##             estimate      se     zval    pval    ci.lb    ci.ub    
## intrcpt      -0.0361  0.3678  -0.0982  0.9218  -0.7571   0.6849    
## college       0.2660  0.1384   1.9215  0.0547  -0.0053   0.5373  . 
## males_M       0.0023  0.0048   0.4753  0.6346  -0.0072   0.0118    
## binge_M       0.3441  0.1570   2.1927  0.0283   0.0365   0.6518  * 
## followup_M   -0.0023  0.0011  -2.0379  0.0416  -0.0044  -0.0001  * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The meta-regression coefficient estimates are essentially identical to those from the multi-variate meta-regression, although the between-study heterogeneity estimate differs slightly because it is based on maximizing the single-level model, conditional on an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\omega^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;and-beyond&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;And beyond!&lt;/h1&gt;
&lt;p&gt;In true multi-variate models, the meta-regression specification would typically include indicators for each dimension of the model. More generally, we might have a model that includes predictors varying within study, encoding characteristics of the outcome measures, sub-groups, or treatment conditions corresponding to each effect size estimate. The weights in these model get substantially more complicated, not in the least because the weights &lt;em&gt;are specific to the predictors&lt;/em&gt;. For instance, in a model with four within-study predictors, a different set of weights is used in estimating the coefficients corresponding to each predictor. As Dr. &lt;a href=&#34;https://twitter.com/Richard_D_Riley&#34;&gt;Richard Riley&lt;/a&gt; noted on Twitter, relevant work on more complicated models includes &lt;a href=&#34;https://doi.org/10.1177/0962280215611702&#34;&gt;this great paper by Dan Jackson and colleagues&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.1177/0962280216688033&#34;&gt;this paper by Riley and colleagues&lt;/a&gt;. The latter paper demonstrates how multivariate models entail partial “borrowing of strength” across dimensions of the effect sizes, which is very helpful for building intuition about how these models work. I would encourage you to check out both papers if you are grappling with understanding how weights work in complex meta-regression models.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Note that this model also encompasses the multi-level meta-analysis described by &lt;a href=&#34;https://doi.org/10.1002/jrsm.35&#34;&gt;Konstantopoulos (2011)&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.3758/s13428-012-0261-6&#34;&gt;Van den Noortgate, et al. (2013)&lt;/a&gt; as a special case, with &lt;span class=&#34;math inline&#34;&gt;\(r_{hij} = 0\)&lt;/span&gt; for all &lt;span class=&#34;math inline&#34;&gt;\(h,i=1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,k\)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Perhaps that makes sense, if you’ve carefully selected the set of effect sizes for inclusion in your meta-analysis. However, it seems to me that it could sometimes lead to perverse results. Say that all studies but one include just a single effect size estimate, each using the absolute gold standard approach to assessing the outcome, but that one study took a “kitchen sink” approach and assessed the outcome a bunch of different ways, including the gold standard plus a bunch of junky scales. Inclusion of the junky scales will lead to within-study heterogeneity, which in turn will &lt;em&gt;pull the overall average effect size towards this study—the one with all the junk!&lt;/em&gt; That seems less than ideal, and the sort of situation where it would be better to select from the study with multiple outcomes the single effect size estimate based on the outcome assessment that most closely aligns with the other studies.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Things get even simpler if the model does not include within-study random effects, as I discussed in &lt;a href=&#34;http://localhost:4321/sometimes-aggregating-effect-sizes-is-fine/&#34;&gt;a previous post&lt;/a&gt;.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;However, this need not be the case—it’s possible that introducing between-study predictors could &lt;em&gt;increase&lt;/em&gt; the estimate of between-study heterogeneity. Yes, that’s totally counter-intuitive. Multi-level models can be weird.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An update on code folding with blogdown &#43; Academic theme</title>
      <link>http://localhost:4321/code-folding-update/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/code-folding-update/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;UPDATED November 21, 2020&lt;/strong&gt;. &lt;em&gt;Thanks to Allen O’Brien for pointing out a bug in the codefolding code, which led to the last code chunk defaulting to hidden rather than open. Allen sent along a simple fix to the &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/static/js/codefolding.js&#34;&gt;&lt;code&gt;codefolding.js&lt;/code&gt;&lt;/a&gt; file.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;About a year ago I added a code-folding feature to my site, following an approach developed by &lt;a href=&#34;https://statnmap.com/2017-11-13-enable-code-folding-in-bookdown-and-blogdown/&#34;&gt;Sébastien Rochette&lt;/a&gt;. I recently updated my site to work with the latest version of the &lt;a href=&#34;https://sourcethemes.com/academic/&#34;&gt;Academic theme&lt;/a&gt; for Hugo, and it turns out that this broke &lt;a href=&#34;http://localhost:4321/code-folding-with-blogdown-academic/&#34;&gt;my code-folding implementation&lt;/a&gt;. It took a bit of putzing and some help from a freelance web developer to fix it, but it’s now working again, and I’m again doing my happy robot dance:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/mIZ9rPeMKefm0/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this post, I’ll provide instructions on how to reproduce the approach with the current version of the Academic theme, which is &lt;a href=&#34;https://sourcethemes.com/academic/updates/v4.8.0/&#34;&gt;4.8 (March 2020)&lt;/a&gt;. Credit where credit is due:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sébastien Rochette worked out &lt;a href=&#34;https://statnmap.com/2017-11-13-enable-code-folding-in-bookdown-and-blogdown/&#34;&gt;the earlier implementation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Web developer &lt;a href=&#34;https://upwork.com/freelancers/~01328c0a21498eac2a&#34;&gt;Max B.&lt;/a&gt; worked out the kinks to get it working with the latest version of Academic. We connected through Upwork. Hire him there if you have web dev work!&lt;/li&gt;
&lt;li&gt;As I’ve said before, I couldn’t write javascript to save my life, and my only contribution here is to write down the instructions.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;code-folding-with-the-academic-theme&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Code folding with the Academic theme&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;You’ll first need to add the codefolding javascript assets. Create a folder called &lt;code&gt;js&lt;/code&gt; under the &lt;code&gt;/static&lt;/code&gt; directory of your site. Add the file &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/static/js/codefolding.js&#34;&gt;&lt;code&gt;codefolding.js&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a folder called &lt;code&gt;css&lt;/code&gt; under the &lt;code&gt;/static&lt;/code&gt; directory of your site. Add the file &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/static/css/codefolding.css&#34;&gt;&lt;code&gt;codefolding.css&lt;/code&gt;&lt;/a&gt;. This is the css for the buttons that will appear on your posts.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the file &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/partials/article_footer_js.html&#34;&gt;&lt;code&gt;article_footer_js.html&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;/layouts/partials&lt;/code&gt; directory of your site.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the file &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/partials/header_maincodefolding.html&#34;&gt;&lt;code&gt;header_maincodefolding.html&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;/layouts/partials&lt;/code&gt; directory of your site.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you do not already have a file &lt;code&gt;head_custom.html&lt;/code&gt; in the &lt;code&gt;/layouts/partials&lt;/code&gt; directory, create it. Add the following lines of code to the file:&lt;/p&gt;
&lt;pre class=&#34;js&#34;&gt;&lt;code&gt;{{ if not site.Params.disable_codefolding }}
  &amp;lt;script src=&amp;quot;https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;{{ &amp;quot;css/codefolding.css&amp;quot; | relURL }}&amp;quot; /&amp;gt;
{{ end }}&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you do not already have a file &lt;code&gt;site_footer.html&lt;/code&gt; in the &lt;code&gt;/layouts/partials&lt;/code&gt; directory, copy it over from &lt;code&gt;/themes/hugo-academic/layouts/partials&lt;/code&gt;. Add the following lines of code to it, somewhere towards the bottom (see &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/partials/site_footer.html&#34;&gt;my version&lt;/a&gt; for example):&lt;/p&gt;
&lt;pre class=&#34;js&#34;&gt;&lt;code&gt;&amp;lt;!-- Init code folding --&amp;gt;
{{ partial &amp;quot;article_footer_js.html&amp;quot; . }}&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you do not already have the file &lt;code&gt;page_header.html&lt;/code&gt; in the &lt;code&gt;/layouts/partials&lt;/code&gt; directory, copy it over from &lt;code&gt;/themes/hugo-academic/layouts/partials&lt;/code&gt;. Add the following line of code at appropriate points so that your posts will include the “Show/hide code” button:&lt;/p&gt;
&lt;pre class=&#34;js&#34;&gt;&lt;code&gt; {{ partial &amp;quot;header_maincodefolding&amp;quot; . }}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that you’ll likely need to add it twice due do conditionals in &lt;code&gt;page_header.html&lt;/code&gt;. For example, &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/partials/page_header.html&#34;&gt;my version of the file&lt;/a&gt; includes the partial at lines 62 and 91.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modify your &lt;code&gt;params.toml&lt;/code&gt; file (in the directory &lt;code&gt;/config/_default&lt;/code&gt;) to include the following lines:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;############################
## Code folding
############################

# Set to true to disable code folding
disable_codefolding = false
# Set to &amp;quot;hide&amp;quot; or &amp;quot;show&amp;quot; all codes by default
codefolding_show = &amp;quot;show&amp;quot;
# Set to true to exclude the &amp;quot;Show/hide all&amp;quot; button
codefolding_nobutton = false&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-codefolding-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the codefolding parameters&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;params.toml&lt;/code&gt; file now has three parameters that control code folding:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;disable_codefolding&lt;/code&gt; controls whether to load the code folding scripts on your site. Set it to &lt;code&gt;true&lt;/code&gt; to disable code folding globally.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;codefolding_show&lt;/code&gt; controls whether code blocks will be shown or hidden by default. If your previous posts have lots of code in them, set the default to &lt;code&gt;show&lt;/code&gt; to minimize changes in the appearance of your site.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;codefolding_nobutton&lt;/code&gt; controls whether the “Show/hide code” button will appear at the top of posts that include code blocks. Set it to &lt;code&gt;true&lt;/code&gt; to disable the button but keep the other code folding functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above parameters are defaults for your entire site. To over-ride the defaults, you can also set the parameters in the YAML header of any post:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set &lt;code&gt;disable_codefolding: true&lt;/code&gt; to turn off code folding for the post.&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;codefolding_show: hide&lt;/code&gt; to hide the code blocks in the post (as in &lt;a href=&#34;http://localhost:4321/package-downloads/&#34;&gt;this post&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;codefolding_nobutton: true&lt;/code&gt; to turn off the “Show/hide code” button at the top of the post (as in the present post).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I hope these instructions work for you. If not, questions, corrections, and clarifications are welcome. Happy blogging, y’all!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>lmeInfo</title>
      <link>http://localhost:4321/software/lmeinfo/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/lmeinfo/</guid>
      <description>&lt;p&gt;lmeInfo provides analytic derivatives and information matrices for fitted linear mixed effects models and generalized least squares models estimated using &lt;code&gt;nlme::lme()&lt;/code&gt; and &lt;code&gt;nlme::gls()&lt;/code&gt;, respectively. The package includes functions for estimating the sampling variance-covariance of variance component parameters using the inverse Fisher information. The variance components include the parameters of the random effects structure (for lme models), the variance structure, and the correlation structure. The expected and average forms of the Fisher information matrix are used in the calculations, and models estimated by full maximum likelihood or restricted maximum likelihood are supported. The package also includes a function for estimating standardized mean difference effect sizes (
&lt;a href=&#34;http://localhost:4321/publication/design-comparable-effect-sizes/&#34;&gt;Pustejovsky et al., 2014&lt;/a&gt;) based on fitted lme or gls models.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R package 
&lt;a href=&#34;https://cran.r-project.org/package=lmeInfo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/lmeInfo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R source code on Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>simhelpers</title>
      <link>http://localhost:4321/software/simhelpers/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/simhelpers/</guid>
      <description>&lt;p&gt;Monte Carlo simulations are computer experiments designed to study the performance of statistical methods under known data-generating conditions. The goal of simhelpers is to assist in running such simulation studies. The main tools in the package consist of functions to calculate measures of estimator performance, such as bias, root mean squared error, rejection rates. The functions also calculate the associated Monte Carlo standard errors (MCSE) of the performance measures. The functions use the tidyeval principles, so that they play well with dplyr and fit easily into a &lt;code&gt;%&amp;gt;%&lt;/code&gt;-centric workflow.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://CRAN.R-project.org/package=simhelpers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/meghapsimatrix/simhelpers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Source code and installation instructions on Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The impact of response-guided designs on count outcomes in single-case experimental design baselines</title>
      <link>http://localhost:4321/publication/response-guided-designs-in-sced-baselines/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/response-guided-designs-in-sced-baselines/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Psychosocial interventions for cancer survivors: A meta-analysis of effects on positive affect</title>
      <link>http://localhost:4321/publication/psychosocial-interventions-for-positive-affect/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/psychosocial-interventions-for-positive-affect/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulating correlated standardized mean differences for meta-analysis</title>
      <link>http://localhost:4321/simulating-correlated-smds/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/simulating-correlated-smds/</guid>
      <description>


&lt;p&gt;As I’ve discussed in &lt;a href=&#34;http://localhost:4321/Sometimes-aggregating-effect-sizes-is-fine&#34;&gt;previous posts&lt;/a&gt;, meta-analyses in psychology, education, and other areas often include studies that contribute multiple, statistically dependent effect size estimates.
I’m interested in methods for meta-analyzing and meta-regressing effect sizes from data structures like this, and studying this sort of thing often entails conducting Monte Carlo simulations.
Monte Carlo simulations involve generating artificial data—in this case, a set of studies, each of which has one or more dependent effect size estimates—that follows a certain distributional model, applying different analytic methods to the artificial data, and then repeating the process a bunch of times.
Because we know the true parameters that govern the data-generating process, we can evaluate the performance of the analytic methods in terms of bias, accuracy, hypothesis test calibration and power, confidence interval coverage, and the like.&lt;/p&gt;
&lt;p&gt;In this post, I’ll discuss two alternative methods to simulate meta-analytic datasets that include studies with multiple, dependent effect size estimates: simulating individual participant-level data or simulating summary statistics. I’ll focus on the case of the standardized mean difference (SMD) because it is so common in meta-analyses of intervention studies. For simplicity, I’ll assume that the effect sizes all come from simple, two-group comparisons (without any covariate adjustment or anything like that) and that the individual observations are multi-variate normally distributed within each group. Our goal will be to simulate a set of &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is based on measuring &lt;span class=&#34;math inline&#34;&gt;\(J_k\)&lt;/span&gt; outcomes on a sample of &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt; participants, all for &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;.
Let &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\delta_k = (\delta_{1k} \cdots \delta_{J_k k})&amp;#39;\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of true standardized mean differences for study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
I’ll assume that we know these true effect size parameters for all &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, so that I can avoid committing to any particular form of random effects model.&lt;/p&gt;
&lt;div id=&#34;simulating-individual-participant-level-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulating individual participant-level data&lt;/h1&gt;
&lt;p&gt;The most direct way to simulate this sort of effect size data is to generate outcome data for every artificial participant in every artificial study. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_{ik}^T\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of outcomes for treatment group participant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Y}_{ik}^C\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector outcomes for control group participant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(i=1,...,N_k / 2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;. Assuming multi-variate normality of the outcomes, we can generate these outcome vectors as
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{Y}_{ik}^T \sim N\left(\boldsymbol\delta_k, \boldsymbol\Psi_k\right) \qquad \text{and}\qquad \mathbf{Y}_{ik}^C \sim N\left(\mathbf{0}, \boldsymbol\Psi_k\right),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Psi_k\)&lt;/span&gt; is the population correlation matrix of the outcomes in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
Note that I am setting the mean outcomes of the control group participants to zero and also specifying that the outcomes all have unit variance within each group.
After simulating data based on these distributions, the effect size estimates for each outcome can be calculated directly, following standard formulas.&lt;/p&gt;
&lt;p&gt;Here’s what this approach looks like in code.
It is helpful to simplify things by focusing on simulating just a single study with multiple, correlated effect sizes.
Focusing first on just the input parameters, a function might look like the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_SMDs_raw &amp;lt;- function(delta, J, N, Psi) {
  # stuff
  return(ES_data)  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above function skeleton, &lt;code&gt;delta&lt;/code&gt; would be the true effect size parameter &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\delta_k\)&lt;/span&gt;, &lt;code&gt;J&lt;/code&gt; would be the number of effect sizes to generate &lt;span class=&#34;math inline&#34;&gt;\((J_k)\)&lt;/span&gt;, &lt;code&gt;N&lt;/code&gt; is the total number of participants &lt;span class=&#34;math inline&#34;&gt;\((N_k)\)&lt;/span&gt;, and &lt;code&gt;Psi&lt;/code&gt; is a matrix of correlations between the outcomes &lt;span class=&#34;math inline&#34;&gt;\((\Psi_k)\)&lt;/span&gt;.
From these parameters, we’ll generate raw data, calculate effect size estimates and standard errors, and return the results in a little dataset.&lt;/p&gt;
&lt;p&gt;To make the function a little bit easier to use, I’m going overload the &lt;code&gt;Psi&lt;/code&gt; argument so that it can be a single number, indicating a common correlation between the outcomes. Thus, instead of having to feed in a &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; matrix, you can specify a single correlation &lt;span class=&#34;math inline&#34;&gt;\(r_k\)&lt;/span&gt;, and the function will assume that all of the outcomes are equicorrelated. In code, the logic is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!is.matrix(Psi)) Psi &amp;lt;- Psi + diag(1 - Psi, nrow = J)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the function with the innards:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_SMDs_raw &amp;lt;- function(delta, J, N, Psi) {

  require(mvtnorm) # for simulating multi-variate normal data
  
  # create Psi matrix assuming equicorrelation
  if (!is.matrix(Psi)) Psi &amp;lt;- Psi + diag(1 - Psi, nrow = J)
  
  # generate control group summary statistics
  Y_C &amp;lt;- rmvnorm(n = N / 2, mean = rep(0, J), sigma = Psi)
  ybar_C &amp;lt;- colMeans(Y_C)
  sd_C &amp;lt;- apply(Y_C, 2, sd)
  
  # generate treatment group summary statistics
  delta &amp;lt;- rep(delta, length.out = J)
  Y_T &amp;lt;- rmvnorm(n = N / 2, mean = delta, sigma = Psi)
  ybar_T &amp;lt;- colMeans(Y_T)
  sd_T &amp;lt;- apply(Y_T, 2, sd)

  # calculate Cohen&amp;#39;s d
  sd_pool &amp;lt;- sqrt((sd_C^2 + sd_T^2) / 2)
  ES &amp;lt;- (ybar_T - ybar_C) / sd_pool
  
  # calculate SE of d
  SE &amp;lt;- sqrt(4 / N + ES^2 / (2 * (N - 2)))

  data.frame(ES = ES, SE = SE, N = N)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In action:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;delta &amp;lt;- rnorm(4, mean = 0.2, sd = 0.1)
r_SMDs_raw(delta = delta, J = 4, N = 40, Psi = 0.6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: mvtnorm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            ES        SE  N
## 1 -0.19106514 0.3169863 40
## 2  0.18427227 0.3169334 40
## 3  0.25646209 0.3175932 40
## 4  0.00210429 0.3162279 40&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or if you’d rather specify the full &lt;span class=&#34;math inline&#34;&gt;\(\Psi_k\)&lt;/span&gt; matrix yourself:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Psi_k &amp;lt;- 0.6 + diag(0.4, nrow = 4)
Psi_k&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4]
## [1,]  1.0  0.6  0.6  0.6
## [2,]  0.6  1.0  0.6  0.6
## [3,]  0.6  0.6  1.0  0.6
## [4,]  0.6  0.6  0.6  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_SMDs_raw(delta = delta, J = 4, N = 40, Psi = Psi_k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           ES        SE  N
## 1 -0.1597097 0.3167580 40
## 2 -0.1717717 0.3168410 40
## 3 -0.4369032 0.3201744 40
## 4  0.0657410 0.3163177 40&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercises&lt;/h2&gt;
&lt;p&gt;The function above is serviceable but quite basic. I can think of several additional features that one might like to have for use in research simulations, but I’m feeling both cheeky and lazy at the moment, so I’ll leave them for you, dear reader. Here are some suggested exercises:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Add an argument to the function, &lt;code&gt;Hedges_g = TRUE&lt;/code&gt;, which controls where the simulated effect size is Hedges’ &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; or Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. If it is Hedges’ g, make sure that the standard error is corrected too.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add an argument to the function, &lt;code&gt;p_val = TRUE&lt;/code&gt;, which allows the user to control whether or not to return &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values from the test of mean differences for each outcome. Note that the p-values should be for a test of the &lt;em&gt;raw&lt;/em&gt; mean differences between groups, rather than a test of the effect size &lt;span class=&#34;math inline&#34;&gt;\(\delta_{jk} = 0\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add an argument to the function, &lt;code&gt;corr_mat = FALSE&lt;/code&gt;, which controls whether the function returns just the simulated effect sizes and SEs or both the simulated effect sizes and the full sampling variance-covariance matrix of the effect sizes. See &lt;a href=&#34;http://localhost:4321/correlations-between-SMDs&#34;&gt;here&lt;/a&gt; for the relevant formulas.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simulating-summary-statistics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulating summary statistics&lt;/h1&gt;
&lt;p&gt;Another approach to simulating SMDs is to sample from the distribution of the &lt;em&gt;summary statistics&lt;/em&gt; used in calculating the effect size. This approach should simplify the code, at the cost of having to use a bit of distribution theory. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\bar{y}}_{Tk}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\bar{y}}_{Ck}\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vectors of sample means for the treatment and control groups, respectively. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_k\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; sample covariance matrix of the outcomes, pooled across the treatment and control groups. Again assuming multi-variate normality, and following the same notation as above:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{\bar{y}}_{Ck} \sim N\left(\mathbf{0}, \frac{2}{N_k} \boldsymbol\Psi_k\right), \qquad \mathbf{\bar{y}}_{Tk} \sim N\left(\boldsymbol\delta_k, \frac{2}{N_k} \boldsymbol\Psi_k\right),
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
\left(\mathbf{\bar{y}}_{Tk} - \mathbf{\bar{y}}_{Ck}\right) \sim N\left(\boldsymbol\delta_k, \frac{4}{N_k} \boldsymbol\Psi_k\right).
\]&lt;/span&gt;
This shows how we could directly simulate the numerator of the standardized mean difference.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;http://localhost:4321/distribution-of-sample-variances&#34;&gt;further bit of distribution theory&lt;/a&gt; says that the pooled sample covariance matrix follows a multiple of a &lt;a href=&#34;https://en.wikipedia.org/wiki/Wishart_distribution&#34;&gt;Wishart distribution&lt;/a&gt; with &lt;span class=&#34;math inline&#34;&gt;\(N_k - 2\)&lt;/span&gt; degrees of freedom and scale matrix &lt;span class=&#34;math inline&#34;&gt;\(\Psi_k\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
(N_k - 2) \mathbf{S}_k \sim Wishart\left(N_k - 2, \Psi_k \right).
\]&lt;/span&gt;
Thus, to simulate the denominators of the SMD estimates, we can simulate a single Wishart matrix, pull out the diagonal entries, divide by &lt;span class=&#34;math inline&#34;&gt;\(N_k - 2\)&lt;/span&gt;, and take the square root. In all, we draw a single &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; observation from a multi-variate normal distribution and a single &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; observation from a Wishart distribution. In contrast, the raw data approach requires simulating &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt; observations from a multi-variate normal distribution, then calculating &lt;span class=&#34;math inline&#34;&gt;\(4 J_k\)&lt;/span&gt; summary statistics (M and SD for each group on each outcome).&lt;/p&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercises&lt;/h2&gt;
&lt;p&gt;Once again, I’ll leave it to you, dear reader, to do the fun programming bits:&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create a modified version of the function &lt;code&gt;r_SMDs_raw&lt;/code&gt; that simulates summary statistics instead of raw data (Call it &lt;code&gt;r_SMDs_stats&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;microbenchmark&lt;/code&gt; package (or your preferred benchmarking tool) to compare the computational efficiency of both versions of the function.&lt;/li&gt;
&lt;li&gt;Check your work! Verify that both versions of the function generate the same distributions if the same parameters are used as input.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;which-approach-is-better&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Which approach is better?&lt;/h1&gt;
&lt;p&gt;Like many things in research, there’s no clearly superior method here. The advantage of the summary statistics approach is computational efficiency. It should generally be faster than the raw data approach, and if you need to generate 10,000 meta-analysis each with 80 studies in them, the computational savings might add up. On the other hand, computational efficiency isn’t everything.&lt;/p&gt;
&lt;p&gt;I see two potential advantages of the raw data approach. First is interpretability: simulating raw data is likely easier to understand. It feels tangible and familiar, harkening back to those bygone days we spent learning ANOVA, whereas the summary statistics approach requires a bit of distribution theory to follow (bookmark this blog post!). Second is extensibility: it is relatively straightforward to extend the approach to use other distributional models for the raw dat (perhaps you want to look at outcomes that follow a &lt;a href=&#34;https://en.wikipedia.org/wiki/Multivariate_t-distribution&#34;&gt;multi-variate &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; distribution&lt;/a&gt;?) or more complicated estimators of the SMD (difference-in-differences? covariate-adjusted? cluster-randomized trial?). To use the summary statistics approach in more complicated scenarios, you’d have to work out the sampling distributions for yourself, or locate the right reference.&lt;/p&gt;
&lt;p&gt;Of course, there’s also no need to choose between these two approaches. As I’m trying to hint at in Exercise 6, it’s actually useful to write both. Then, you can use the (potentially slower) raw data version to verify that the summary statistics version is correct.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulating-full-meta-analyses&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulating full meta-analyses&lt;/h1&gt;
&lt;p&gt;So far we’ve got a data-generating function that simulates a single study’s worth of effect size estimates. To study meta-analytic methods, we’ll need to build out the function to simulate multiple studies. To do so, I think it’s useful to use the technique of &lt;a href=&#34;https://r4ds.had.co.nz/iteration.html&#34;&gt;mapping&lt;/a&gt;, as implemented in the &lt;code&gt;purrr&lt;/code&gt; package’s &lt;code&gt;map_*&lt;/code&gt; functions. The idea here is to first generate a “menu” of study-specific parameters for each of &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, then apply the &lt;code&gt;r_SMDs&lt;/code&gt; function to each parameter set.&lt;/p&gt;
&lt;p&gt;Let’s consider how to do this for a simple random effects model, where the true effect size parameter is constant within each study (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\delta_k = (\delta_k \cdots \delta_k)&amp;#39;\)&lt;/span&gt;), and in a model without covariates. We’ll need to generate a true effect for each study, along with a sample size, an outcome dimension, and a correlation between outcomes. For the true effects, I’ll assume that
&lt;span class=&#34;math display&#34;&gt;\[
\delta_k \sim N(\mu, \tau^2),
\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
J_k \sim 2 + Poisson(3),
\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
N_k \sim 20 + 2 \times Poisson(10),
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
r_k \sim Beta\left(\rho \nu, (1 - \rho)\nu\right),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\rho = \text{E}(r_k)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\nu &amp;gt; 0\)&lt;/span&gt; controls the variability of &lt;span class=&#34;math inline&#34;&gt;\(r_k\)&lt;/span&gt; across studies, with smaller &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; corresponding to more variable correlations.
Specifically, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(r_k) = \rho (1 - \rho) / (1 + \nu)\)&lt;/span&gt;.
These distributions are just made up, without any particular justification.&lt;/p&gt;
&lt;p&gt;Here’s what these distributional models look like in R code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;K &amp;lt;- 6
mu &amp;lt;- 0.2
tau &amp;lt;- 0.05
J_mean &amp;lt;- 5
N_mean &amp;lt;- 45
rho &amp;lt;- 0.6
nu &amp;lt;- 39

study_data &amp;lt;- 
  data.frame(
    delta = rnorm(K, mean = mu, sd = tau),
    J = 2 + rpois(K, J_mean - 2),
    N = 20 + 2 * rpois(K, (N_mean - 20) / 2),
    Psi = rbeta(K, rho * nu, (1 - rho) * nu)
  )

study_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       delta J  N       Psi
## 1 0.1749657 6 56 0.6670410
## 2 0.1371771 4 52 0.7952095
## 3 0.1430044 2 46 0.5551301
## 4 0.1953675 6 46 0.5339670
## 5 0.1653242 4 42 0.5623903
## 6 0.1419457 7 40 0.6615825&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have the “menu” of study-level characteristics, it’s just a matter of mapping the parameters to the data-generating function. One way to do this is with &lt;code&gt;pmap_df&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
meta_data &amp;lt;- pmap_df(study_data, r_SMDs_raw, .id = &amp;quot;study&amp;quot;)
meta_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    study           ES        SE  N
## 1      1  0.427048814 0.2704019 56
## 2      1  0.206502285 0.2679989 56
## 3      1  0.270244756 0.2685234 56
## 4      1  0.423149362 0.2703451 56
## 5      1  0.525878094 0.2720096 56
## 6      1  0.746186579 0.2767383 56
## 7      2 -0.005809721 0.2773507 52
## 8      2 -0.082222645 0.2774719 52
## 9      2  0.114670949 0.2775871 52
## 10     2 -0.001432641 0.2773501 52
## 11     3 -0.031231291 0.2949027 46
## 12     3  0.302264458 0.2966391 46
## 13     4  0.085338908 0.2950242 46
## 14     4 -0.062511255 0.2949592 46
## 15     4 -0.040178730 0.2949150 46
## 16     4 -0.082519741 0.2950151 46
## 17     4  0.207953122 0.2957160 46
## 18     4 -0.005713721 0.2948845 46
## 19     5  0.293666394 0.3103483 42
## 20     5  0.258312309 0.3099551 42
## 21     5  0.362126706 0.3112512 42
## 22     5  0.177656049 0.3092452 42
## 23     6 -0.115158991 0.3165035 40
## 24     6  0.094349350 0.3164129 40
## 25     6 -0.052996601 0.3162862 40
## 26     6 -0.042766762 0.3162658 40
## 27     6 -0.314584445 0.3182800 40
## 28     6  0.078519103 0.3163560 40
## 29     6 -0.103034241 0.3164486 40&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(meta_data$study)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 1 2 3 4 5 6 
## 6 4 2 6 4 7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Putting it all together into a function, we have&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_meta &amp;lt;- function(K, mu, tau, J_mean, N_mean, rho, nu) {
  require(purrr)
  
  study_data &amp;lt;- 
    data.frame(
      delta = rnorm(K, mean = mu, sd = tau),
      J = 2 + rpois(K, J_mean - 2),
      N = 20 + 2 * rpois(K, (N_mean - 20) / 2),
      Psi = rbeta(K, rho * nu, (1 - rho) * nu)
    )
  
  pmap_df(study_data, r_SMDs_raw, .id = &amp;quot;study&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercises&lt;/h2&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Modify &lt;code&gt;r_meta&lt;/code&gt; so that it uses &lt;code&gt;r_SMDs_stats&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add options to &lt;code&gt;r_meta&lt;/code&gt; for &lt;code&gt;Hedges_g&lt;/code&gt;, &lt;code&gt;p_val = TRUE&lt;/code&gt;, and &lt;code&gt;corr_mat = FALSE&lt;/code&gt; and ensure that these get passed along to the &lt;code&gt;r_SMDs&lt;/code&gt; function.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One way to check that the &lt;code&gt;r_meta&lt;/code&gt; function is working properly is to generate a very large meta-analytic dataset, then to verify that the generated distributions align with expectations. Here’s a very large meta-analytic dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_data &amp;lt;- 
  r_meta(100000, mu = 0.2, tau = 0.05, 
         J_mean = 5, N_mean = 40, 
         rho = 0.6, nu = 39)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare the distribution of the simulated dataset against what you would expect to get based on the input parameters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modify the &lt;code&gt;r_meta&lt;/code&gt; function so that &lt;span class=&#34;math inline&#34;&gt;\(J_k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt; are correlated, according to
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
J_k &amp;amp;\sim 2 + Poisson(\mu_J - 2) \\
N_k &amp;amp;\sim 20 + 2 \times Poisson\left(\frac{1}{2}(\mu_N - 20) + \alpha (J_k - \mu_J) \right)
\end{align}
\]&lt;/span&gt;
for user-specified values of &lt;span class=&#34;math inline&#34;&gt;\(\mu_J\)&lt;/span&gt; (the average number of outcomes per study), &lt;span class=&#34;math inline&#34;&gt;\(\mu_N\)&lt;/span&gt; (the average total sample size per study), and &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, which controls the degree of dependence between &lt;span class=&#34;math inline&#34;&gt;\(J_k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_k\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;a-challenge&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A challenge&lt;/h2&gt;
&lt;p&gt;The meta-analytic model that we’re using here is quite simple—simplistic, even—and for some simulation studies, something more complex might be needed. For example, we might need to generate data from a model that includes within-study random effects, as in:
&lt;span class=&#34;math display&#34;&gt;\[
\delta_{jk} = \mu + u_k + v_{jk}, \quad \text{where}\quad u_k \sim N(0, \tau^2), \quad v_{jk} \sim N(0, \omega^2).
\]&lt;/span&gt;
Even more complex would be to simulate from a multi-level meta-regression model
&lt;span class=&#34;math display&#34;&gt;\[
\delta_{jk} = \mathbf{x}_{jk} \boldsymbol\beta + u_k + v_{jk}, \quad \text{where}\quad u_k \sim N(0, \tau^2), \quad v_{jk} \sim N(0, \omega^2),
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_{jk}\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(1 \times p\)&lt;/span&gt; row-vector of covariates describing outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(p \times 1\)&lt;/span&gt; vector of meta-regression coefficients. In past work, I’ve done this by writing a data-generating function that takes a fixed design matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X} = \left(\mathbf{x}_{11}&amp;#39; \cdots \mathbf{x}_{J_K K}&amp;#39;\right)&amp;#39;\)&lt;/span&gt; as an input argument, along with &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt;. The design matrix would also include an identifier for each unique study. There are surely better (simpler, easier to follow) ways to implement the multi-level meta-regression model. I’ll once again leave it to you to work out an approach.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An examination of measurement procedures and characteristics of baseline outcome data in single-case research</title>
      <link>http://localhost:4321/publication/measurement-procedures-and-baseline-outcomes/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/measurement-procedures-and-baseline-outcomes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A generalized excess significance test for selective outcome reporting with dependent effect sizes</title>
      <link>http://localhost:4321/talk/srsm-2019-generalized-excess-significance-test/</link>
      <pubDate>Mon, 22 Jul 2019 13:30:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/srsm-2019-generalized-excess-significance-test/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sometimes, aggregating effect sizes is fine</title>
      <link>http://localhost:4321/sometimes-aggregating-effect-sizes-is-fine/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/sometimes-aggregating-effect-sizes-is-fine/</guid>
      <description>


&lt;p&gt;In meta-analyses of psychology, education, and other social science research, it is very common that some of the included studies report more than one relevant effect size.
For example, in a meta-analysis of intervention effects on reading outcomes, some studies may have used multiple measures of reading outcomes (each of which meets inclusion criteria), or may have measured outcomes at multiple follow-up times; some studies might have also investigated more than one version of an intervention, and it might be of interest to include effect sizes comparing each version to the no-intervention control condition;
and it’s even possible that some studies may have &lt;em&gt;all&lt;/em&gt; of these features, potentially contributing &lt;em&gt;lots&lt;/em&gt; of effect size estimates.&lt;/p&gt;
&lt;p&gt;These situations create a technical challenge for conducting a meta-analysis.
Because effect size estimates from the same study are correlated, it’s not usually reasonable to use methods that are premised on each effect size estimate being independent (i.e., univariate methods).
Instead, the analyst needs to apply methods that take into account the dependencies among estimates coming from the same study.
It used to be common to use ad hoc approaches for handling dependence, such as averaging the estimates together or selecting one estimate per study and then using univariate methods &lt;span class=&#34;citation&#34;&gt;(cf. Becker, &lt;a href=&#34;#ref-Becker2000multivariate&#34; role=&#34;doc-biblioref&#34;&gt;2000&lt;/a&gt;)&lt;/span&gt;.
More sophisticated, multivariate meta-analysis (MVMA) models that directly account for correlations among the effect size estimates had been developed &lt;span class=&#34;citation&#34;&gt;(Kalaian &amp;amp; Raudenbush, &lt;a href=&#34;#ref-Kalaian1996multivariate&#34; role=&#34;doc-biblioref&#34;&gt;1996&lt;/a&gt;)&lt;/span&gt; but were challenging to implement and so rarely used (at least, that’s my impression).
More recently, techniques such as multi-level meta-analysis &lt;span class=&#34;citation&#34;&gt;(MLMA; Van den Noortgate et al., &lt;a href=&#34;#ref-VandenNoortgate2013threelevel&#34; role=&#34;doc-biblioref&#34;&gt;2013&lt;/a&gt;, &lt;a href=&#34;#ref-VandenNoortgate2015metaanalysis&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; and robust variance estimation &lt;span class=&#34;citation&#34;&gt;(RVE; Hedges et al., &lt;a href=&#34;#ref-Hedges2010robust&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;)&lt;/span&gt; have emerged, which account for dependencies while using all available effect size estimates and still being feasible to implement.
These new techniques of MLMA and RVE are starting to be more widely adopted in practice, and it is not implausible that they will become the standard approach in psychological and educational meta-analysis within a few years.&lt;/p&gt;
&lt;p&gt;Given the extent of interest in MLMA and RVE, one might wonder: are the older ad hoc approaches &lt;em&gt;ever&lt;/em&gt; reasonable or appropriate?
I think that some are, under certain circumstances.
In this post I’ll highlight one such circumstance, where aggregating effect size estimates is not only reasonable but leads to &lt;em&gt;exactly the same results&lt;/em&gt; as a multivariate model. This occurs when two conditions are met:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We are not interested in within-study heterogeneity of effects and&lt;/li&gt;
&lt;li&gt;Any predictors included in the model vary between studies but not within a given study (i.e., effect sizes from the same study all have the same values of the predictors).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In short, if all we care about is understanding between-study variation in effect sizes, then it is fine to aggregate them up to the study level.&lt;/p&gt;
&lt;div id=&#34;a-model-thats-okay-to-average&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A model that’s okay to average&lt;/h1&gt;
&lt;p&gt;To make this argument precise, let me lay out a model where it applies.
For full generality, I’ll consider a meta-regression model for a collection of &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; studies, where study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; contributes &lt;span class=&#34;math inline&#34;&gt;\(J_k \geq 1\)&lt;/span&gt; effect size estimates.
Let &lt;span class=&#34;math inline&#34;&gt;\(T_{jk}\)&lt;/span&gt; denote effect size estimate &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, with sampling variance &lt;span class=&#34;math inline&#34;&gt;\(S_{jk}^2\)&lt;/span&gt;.
Effect size estimates from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; maybe be correlated at the sampling level, with correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho_{ijk}\)&lt;/span&gt; between effect size estimates &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
I will assume that the correlations are known, although in practice one might need to just take a guess about the degree of correlation, such as by assuming &lt;span class=&#34;math inline&#34;&gt;\(\rho_{ijk} = 0.7\)&lt;/span&gt; for all pairs of estimates from each included study.
Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_k\)&lt;/span&gt; be a row vector of predictor variables for study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.
Note that the predictors do not have a subscript &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; because I’m assuming here that they are constant within a study.&lt;/p&gt;
&lt;p&gt;A multivariate meta-regression model for these data might be:
&lt;span class=&#34;math display&#34;&gt;\[
T_{jk} = \mathbf{x}_k \boldsymbol\beta + u_k + e_{jk},
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(u_k\)&lt;/span&gt; is a between-study random effect with variance &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e_{jk}\)&lt;/span&gt; is the sampling error for effect size &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, assumed to have known variance &lt;span class=&#34;math inline&#34;&gt;\(S_{jk}^2\)&lt;/span&gt;.
Errors from the same study are correlated, so &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(e_{ik}, e_{jk}) = \rho_{ijk} S_{ik} S_{jk}\)&lt;/span&gt;.
This is a commonly considered model for dependent effect size estimates.
In the paper that introduced RVE, &lt;span class=&#34;citation&#34;&gt;Hedges et al. (&lt;a href=&#34;#ref-Hedges2010robust&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;)&lt;/span&gt; termed it the “correlated effects” model (implemented in &lt;code&gt;robumeta&lt;/code&gt; as &lt;code&gt;model = &#34;CORR&#34;&lt;/code&gt;, which is the default).
Note that it also satisfies the conditions I outlined above: no within-study random effects, predictors that vary only between study.
We can fit it using the &lt;code&gt;rma.mv()&lt;/code&gt; function in the &lt;code&gt;metafor&lt;/code&gt; package, as I will demonstrate below.&lt;/p&gt;
&lt;p&gt;An alternative to this multivariate model would be to first average the effects within each study, then fit a univariate random effects model.
Just how we do the averaging will matter: we’ll need to use inverse-variance weighting.
Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of effect size estimates from study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_k\)&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; sampling covariance matrix for &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{1}_k\)&lt;/span&gt; be a &lt;span class=&#34;math inline&#34;&gt;\(J_k \times 1\)&lt;/span&gt; vector of 1s. The inverse-variance weighted average of the effects from study k can then be written as
&lt;span class=&#34;math display&#34;&gt;\[
\bar{T}_k = V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{T}_k, 
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(V_k = 1 / (\mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{1}_k)\)&lt;/span&gt;. The quantity &lt;span class=&#34;math inline&#34;&gt;\(V_k\)&lt;/span&gt; is also the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(\bar{T}_k\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A conventional, univariate random effects model for the averaged effect sizes is
&lt;span class=&#34;math display&#34;&gt;\[
\bar{T}_k = \mathbf{x}_k \boldsymbol\beta + u_k + \bar{e}_k, 
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(u_k) = \tau^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\bar{e}_k) = V_k\)&lt;/span&gt;.
This model can be fit using &lt;code&gt;rma.uni&lt;/code&gt; from &lt;code&gt;metafor&lt;/code&gt;.
In fact, doing so will yield the same estimates of model parameters as fitting the multivariate model—for all intents and purposes, they are equivalent models.
There are at several different ways to see that this equivalence holds.
I’ll offer three, from most practical to most theoretical.
(If you’d rather just take my word that this claim is true, feel free to skip down to the &lt;a href=&#34;#so-what&#34;&gt;last section&lt;/a&gt;, where I comment on implications.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;computational-equivalence&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Computational equivalence&lt;/h1&gt;
&lt;p&gt;One good way to check the equivalence of the univariate and multivariate models is to apply both to a dataset. I’ll use the data from a stylized example described in &lt;span class=&#34;citation&#34;&gt;Tanner-Smith &amp;amp; Tipton (&lt;a href=&#34;#ref-TannerSmith2013robust&#34; role=&#34;doc-biblioref&#34;&gt;2013&lt;/a&gt;)&lt;/span&gt;, looking at the effects of alcohol abuse interventions on alcohol consumption among adolescents and young adults. (The data are simulated for teaching purposes, so don’t infer anything about real life from the results below!) The data are included in the &lt;code&gt;robumeta&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

data(corrdat, package = &amp;quot;robumeta&amp;quot;)

# sort by study
corrdat &amp;lt;- arrange(corrdat, studyid, esid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data consist of 172 effect sizes from 39 studies. Some studies report effects at multiple follow-up times and/or for multiple programs compared to a common control condition, leading to dependent effect size estimates.The data also include variables encoding a variety of sample and study characteristics, such as whether the study was conducted with a college student sample and the gender composition of the sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(corrdat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   esid studyid effectsize        var binge followup males college
## 1 4006       1  0.2086383 0.03246468     1 51.42857    67       0
## 2 4016       1  0.2244635 0.03244931     1 51.42857    67       0
## 3 4026       1  0.3151743 0.03278697     1 51.42857    67       0
## 4 3513       2  0.2220929 0.01972874     0 17.14286    81       1
## 5 3514       2 -0.1922628 0.02031393     0 17.14286    86       1
## 6 3556       2  0.3273109 0.01987042     0 17.14286    81       1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose that we are interested in estimating the differences in average effects by type of sample (college versus adolescent), controlling for the proportion of males in the study. For some reason, there is within-study variation in the percentage of males, so I’ll take the study-level average for this covariate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrdat &amp;lt;-
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  mutate(males = mean(males))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then fit this model using a multi-variate meta-regression in metafor.&lt;/p&gt;
&lt;p&gt;In order to estimate the model, we’ll first need to create a variance-covariance matrix for the effect size estimates in each study, which can be accomplished using &lt;code&gt;impute_covariance_matrix&lt;/code&gt; from &lt;code&gt;clubSandwich&lt;/code&gt; (&lt;a href=&#34;http://localhost:4321/imputing-covariance-matrices-for-multi-variate-meta-analysis/&#34;&gt;further details here&lt;/a&gt;). I’ll assume a correlation of 0.6 between pairs of effect sizes within a given study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)
library(metafor)

V_list &amp;lt;- impute_covariance_matrix(vi = corrdat$var, cluster = corrdat$studyid, r = 0.6)

MV_fit &amp;lt;- rma.mv(effectsize ~ college + males, V = V_list, 
                 random = ~ 1 | studyid,
                 data = corrdat, method = &amp;quot;REML&amp;quot;)
MV_fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 172; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2    0.0590  0.2429     39     no  studyid 
## 
## Test for Residual Heterogeneity:
## QE(df = 169) = 815.2448, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 9.9016, p-val = 0.0071
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb    ci.ub 
## intrcpt    0.6466  0.2693   2.4007  0.0164   0.1187   1.1744   * 
## college    0.3703  0.1317   2.8123  0.0049   0.1122   0.6283  ** 
## males     -0.0076  0.0038  -1.9832  0.0473  -0.0152  -0.0001   * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternately, we could aggregate the effects up to the study level and then fit a univariate meta-regression using the same moderators. Here is a function to calculate the aggregated effect size estimates and variances:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;agg_effects &amp;lt;- function(yi, vi, r = 0.6) {
  corr_mat &amp;lt;- r + diag(1 - r, nrow = length(vi))
  sd_mat &amp;lt;- tcrossprod(sqrt(vi))
  V_inv_mat &amp;lt;- chol2inv(chol(sd_mat * corr_mat))
  V &amp;lt;- 1 / sum(V_inv_mat)
  data.frame(es = V * sum(yi * V_inv_mat), var = V)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the data-munging:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrdat_agg &amp;lt;-
  corrdat %&amp;gt;%
  group_by(studyid) %&amp;gt;%
  summarise(
    es = list(agg_effects(yi = effectsize, vi = var, r = 0.6)),
    males = mean(males),
    college = mean(college)
  ) %&amp;gt;%
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `cols` is now required.
## Please use `cols = c(es)`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(corrdat_agg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   studyid      es    var males college
##     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1       1  0.249  0.0239  67         0
## 2       2 -0.0210 0.0129  81         1
## 3       3  0.726  0.0819  76.2       0
## 4       4  0.370  0.0431  80         1
## 5       5 -0.0911 0.0281  79         0
## 6       6 -0.416  0.0111  74         0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here’s the meta-regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uni_fit &amp;lt;- rma.uni(es ~ college + males, vi = var, 
                   data = corrdat_agg, method = &amp;quot;REML&amp;quot;)
uni_fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Mixed-Effects Model (k = 39; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0590 (SE = 0.0242)
## tau (square root of estimated tau^2 value):             0.2429
## I^2 (residual heterogeneity / unaccounted variability): 61.42%
## H^2 (unaccounted variability / sampling variability):   2.59
## R^2 (amount of heterogeneity accounted for):            19.12%
## 
## Test for Residual Heterogeneity:
## QE(df = 36) = 96.7794, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 9.9016, p-val = 0.0071
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb    ci.ub 
## intrcpt    0.6466  0.2693   2.4007  0.0164   0.1187   1.1744   * 
## college    0.3703  0.1317   2.8123  0.0049   0.1122   0.6283  ** 
## males     -0.0076  0.0038  -1.9832  0.0473  -0.0152  -0.0001   * 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The heterogeneity estimates are nearly equal (the difference is due to using numerical optimization):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MV_fit$sigma2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0589972&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uni_fit$tau2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.05899673&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the meta-regression coefficient estimates are identical to six decimal places:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(MV_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      intrcpt      college        males 
##  0.646561371  0.370274721 -0.007633517&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(uni_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      intrcpt      college        males 
##  0.646561352  0.370274307 -0.007633519&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(coef(MV_fit), coef(uni_fit))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Mean relative difference: 4.243578e-07&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this example we arrive at the same results using either multivariate meta-analysis or univariate meta-analysis of aggregated effect size estimates.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; The main limitation of this illustration is generality—how can we be sure that these results aren’t just a quirk of this particular dataset? Would we get the same results for &lt;em&gt;any&lt;/em&gt; dataset?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;from-multivariate-to-univariate-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;From multivariate to univariate model&lt;/h1&gt;
&lt;p&gt;Here’s another, somewhat more general perspective on the relationship between the models: the univariate model can be &lt;em&gt;derived&lt;/em&gt; directly from the multivariate one. Start with the multivariate model in matrix form:
&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{T}_k = \mathbf{x}_k \boldsymbol\beta \mathbf{1}_k + u_k \mathbf{1}_k + \mathbf{e}_k,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{e}_k\)&lt;/span&gt; is the vector of sampling errors for study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\mathbf{e}_k) = \mathbf{S}_k\)&lt;/span&gt;. Pre-multiply both sides by &lt;span class=&#34;math inline&#34;&gt;\(V_k \mathbf{1}_k’ \mathbf{S}_k^{-1}\)&lt;/span&gt; to get
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{T}_k &amp;amp;= V_k \left(\mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{1}_k\right) \mathbf{x}_k \boldsymbol\beta + u_k V_k \left(\mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{1}_k\right) + V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{e}_k \\
\bar{T}_k &amp;amp;= \mathbf{x}_k \boldsymbol\beta + u_k + \bar{e}_k,
\end{aligned}
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\bar{e}_k) = V_k \mathbf{1}_k’ \mathbf{S}_k^{-1} \mathbf{S}_k \mathbf{S}_k^{-1} \mathbf{1}_k V_k = V_k\)&lt;/span&gt;, just as in the univariate model.&lt;/p&gt;
&lt;p&gt;This demonstrates that the parameters of the two models are the same quantities—that is, both models are estimating the same thing. But that would also hold if we used &lt;em&gt;any&lt;/em&gt; weighted average of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt;—it needn’t be inverse-variance. The only thing that would be different is &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\bar{e}_k)\)&lt;/span&gt;. To fully establish the equivalence of the two models, I’ll examine the likelihoods of each model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;equivalence-of-likelihoods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Equivalence of likelihoods&lt;/h1&gt;
&lt;p&gt;Multivariate meta-analysis models are typically estimated by full maximum likelihood (FML) or restricted maximum likelihood methods. FML and RML are also commonly used for univariate meta-analysis. With these methods, estimates are obtained as the parameter values that maximize the log likelihood of the model, given the data (or the restricted likelihood for RML). Therefore, we can establish the exact equivalence of parameter estimates by showing that the log likelihood of the univariate and multivariate models differ by a constant value (so that the location of the maxima are identical).&lt;/p&gt;
&lt;div id=&#34;full-likelihood&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full likelihood&lt;/h2&gt;
&lt;p&gt;For the univariate model, the log-likelihood contribution of study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
l^{U}_k\left(\boldsymbol\beta, \tau^2\right) = -\frac{1}{2} \log\left(\tau^2 + V_k\right) - \frac{1}{2} \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k}.
\]&lt;/span&gt;
For the multivariate model, the log-likelihood contribution of study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is:
&lt;span class=&#34;math display&#34;&gt;\[
l^{MV}_k\left(\boldsymbol\beta, \tau^2\right) = -\frac{1}{2} A -\frac{1}{2} B
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
A = \log\left|\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right| 
\]&lt;/span&gt;
and
&lt;span class=&#34;math display&#34;&gt;\[
B = \left(\mathbf{T}_k - \mathbf{x}_k \boldsymbol\beta \mathbf{1}_k\right)&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \left(\mathbf{T}_k - \mathbf{x}_k \boldsymbol\beta \mathbf{1}_k\right).
\]&lt;/span&gt;
The term &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; can be rearranged as
&lt;span class=&#34;math display&#34;&gt;\[
A = \log\left|\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1} + \mathbf{I}_k\right) \mathbf{S}_k\right|
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{I}_k\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(J_k \times J_k\)&lt;/span&gt; identity matrix. One of the properties of determinants is that the determinant of a product of two matrices is equal to the product of the determinants. Another is that, for two vectors &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{v}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\left|\mathbf{I} + \mathbf{u}\mathbf{v}&amp;#39;\right| = 1 + \mathbf{v}&amp;#39;\mathbf{u}\)&lt;/span&gt;. Applying both of these properties, it follows that
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
A &amp;amp;= \log\left|\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1} + \mathbf{I}_k\right) \mathbf{S}_k\right| \\
&amp;amp;= \log \left( \left|\mathbf{I}_k + \tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\right| \left|\mathbf{S}_k\right|\right) \\
&amp;amp;= \log \left(1 + \frac{\tau^2}{V_k}\right) + \log \left|\mathbf{S}_k\right| \\
&amp;amp;= \log(\tau^2 + V_k) - \log(V_k) + \log \left|\mathbf{S}_k\right|.
\end{aligned}
\]&lt;/span&gt;
The &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; term takes a little more work.
From &lt;a href=&#34;https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula&#34;&gt;the Sherman-Morrison identity&lt;/a&gt;, we have that:
&lt;span class=&#34;math display&#34; id=&#34;eq:Sherman&#34;&gt;\[
\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} = \mathbf{S}_k^{-1} - \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1},
\tag{1}
\]&lt;/span&gt;
by which it follows that
&lt;span class=&#34;math display&#34; id=&#34;eq:inversevariance&#34;&gt;\[
\mathbf{1}_k&amp;#39;\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1}\mathbf{1}_k = \frac{1}{\tau^2 + V_k}.
\tag{2}
\]&lt;/span&gt;
Now, rearrange the &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; term to get
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B &amp;amp;= \left[\mathbf{T}_k - \bar{T}_k \mathbf{1}_k + \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \mathbf{1}_k\right]&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \left[\mathbf{T}_k - \bar{T}_k \mathbf{1}_k + \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \mathbf{1}_k\right] \\
&amp;amp;= B_1 + 2 B_2 + B_3
\end{aligned}
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B_1 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) \\
B_2 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \\
B_3 &amp;amp;= \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \mathbf{1}_k&amp;#39; \left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1} \mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)
\end{aligned}
\]&lt;/span&gt;
Applying &lt;a href=&#34;#eq:Sherman&#34;&gt;(1)&lt;/a&gt; to &lt;span class=&#34;math inline&#34;&gt;\(B_1\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B_1 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left[\mathbf{S}_k^{-1} - \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\right] \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) \\ 
&amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) - \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) \\
&amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right).
\end{aligned}
\]&lt;/span&gt;
The second term drops out because &lt;span class=&#34;math inline&#34;&gt;\(\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1} \mathbf{1}_k = \bar{T}_k / V_k - \bar{T}_k / V_k = 0\)&lt;/span&gt;. Along similar lines,
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
B_2 &amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \left[\mathbf{S}_k^{-1} - \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\right] \mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \\ 
&amp;amp;= \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) - \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1} \mathbf{1}_k \left(\frac{1}{\tau^2} + \frac{1}{V_k}\right)^{-1} \mathbf{1}_k&amp;#39;\mathbf{S}_k^{-1}\mathbf{1}_k \left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right) \\
&amp;amp;= 0.
\end{aligned}
\]&lt;/span&gt;
Finally, the third term simplifies using &lt;a href=&#34;#eq:inversevariance&#34;&gt;(2)&lt;/a&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
B_3 = \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k}.
\]&lt;/span&gt;
Thus, the full &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; term reduces to
&lt;span class=&#34;math display&#34;&gt;\[
B = \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) + \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k}
\]&lt;/span&gt;
and the multivariate log likelihood contribution is
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
l^{MV}_k\left(\boldsymbol\beta, \tau^2\right) &amp;amp;= -\frac{1}{2} \log(\tau^2 + V_k) + \frac{1}{2} \log(V_k) - \frac{1}{2}\log \left|\mathbf{S}_k\right| - \frac{1}{2} \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right) -\frac{1}{2} \frac{\left(\bar{T}_k - \mathbf{x}_k \boldsymbol\beta\right)^2}{\tau^2 + V_k} \\
&amp;amp;= l^U_k\left(\boldsymbol\beta, \tau^2\right) + \frac{1}{2} \log(V_k) - \frac{1}{2}\log \left|\mathbf{S}_k\right| - \frac{1}{2} \left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right)&amp;#39; \mathbf{S}_k^{-1}\left(\mathbf{T}_k - \bar{T}_k \mathbf{1}_k\right).
\end{aligned}
\]&lt;/span&gt;
The last three terms depend on the data (&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}_k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}_k\)&lt;/span&gt;) but not on the parameters &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\beta\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt;. Therefore, the univariate and multivariate likelihoods will be maximized at the same parameter values, i.e., the FML estimators are identical.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;restricted-likelihood&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Restricted likelihood&lt;/h2&gt;
&lt;p&gt;In practice, it is more common to use RML estimation rather than FML.
The RML estimators maximize a different objective function that includes the full likelihood, plus an additional term. The RML objective function for the univariate model is
&lt;span class=&#34;math display&#34;&gt;\[
\sum_{k=1}^K l^U_k(\boldsymbol\beta, \tau^2) - \frac{1}{2} R^U(\tau^2)
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
R^U(\tau^2) = \log \left|\sum_{k=1}^k\frac{\mathbf{x}_k&amp;#39; \mathbf{x}_k}{\tau^2 + V_k} \right|.
\]&lt;/span&gt;
For the multivariate model, the RML objective is
&lt;span class=&#34;math display&#34;&gt;\[
\sum_{k=1}^K l^{MV}_k(\boldsymbol\beta, \tau^2) - \frac{1}{2} R^{MV}(\tau^2).
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
R^{MV}(\tau^2) &amp;amp;= \log \left|\sum_{k=1}^k \mathbf{x}_k&amp;#39;\mathbf{1}_k&amp;#39;\left(\tau^2\mathbf{1}_k\mathbf{1}_k&amp;#39; + \mathbf{S}_k\right)^{-1}\mathbf{1}_k \mathbf{x}_k \right|\\
&amp;amp;= \log \left|\sum_{k=1}^k\frac{\mathbf{x}_k&amp;#39; \mathbf{x}_k}{\tau^2 + V_k} \right| \\
&amp;amp;= R^U(\tau^2)
\end{aligned}
\]&lt;/span&gt;
because of &lt;a href=&#34;#eq:inversevariance&#34;&gt;(2)&lt;/a&gt;. Thus, the univariate and multivariate models also have the same RML estimators.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;so-what&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;So what?&lt;/h1&gt;
&lt;p&gt;Beyond being a good excuse to write a bunch of matrix algebra, why does any of this matter? I think there are two main implications. First, it is useful to recognize the equivalence of these models in order to understand when the multivariate model is &lt;em&gt;necessary&lt;/em&gt;. If both of the conditions that I’ve described hold, then it is entirely acceptable to use aggregation rather than the more complicated multivariate model.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; Using the simpler univariate model might be desirable in practice because it makes the analysis easier to follow, because it makes it easier to run diagnostics or create illustrations of the results, or because of software limitations. Conversely, if either of the conditions does not hold, then there may be differences between the two approaches and the analyst will need to think carefully about which method better addresses their research questions.&lt;/p&gt;
&lt;p&gt;A second implication is computational: because it gives the same results, the univariate model could be used as a short-cut for fitting the multivariate model. Compare the differences in computational time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(microbenchmark)
microbenchmark(
  uni = rma.uni(es ~ college + males, vi = var, 
                data = corrdat_agg, method = &amp;quot;REML&amp;quot;),
  multi = rma.mv(effectsize ~ college + males, V = V_list, 
                 random = ~ 1 | studyid,
                 data = corrdat, method = &amp;quot;REML&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##   expr     min      lq     mean   median       uq      max neval
##    uni  8.5638  8.7961 11.13178  8.96360  9.20370 110.2299   100
##  multi 78.7393 82.2588 85.56066 83.22175 84.71775 182.2056   100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the aggregation is done in advance, it is &lt;em&gt;way&lt;/em&gt; quicker to fit the univariate model. The short-cut would be useful if we needed to estimate &lt;em&gt;lots&lt;/em&gt; of multi-variate meta-regressions (as long as the equivalence conditions hold). For example, if we needed to bootstrap the multivariate model, we could pre-compute the aggregated effects and then just bootstrap the much simpler, much quicker univariate model.&lt;/p&gt;
&lt;p&gt;I suspect that the results I’ve presented here can be further generalized, but this will need a bit of further investigation. For one, there are also equivalences between variance estimators: using the CR2 cluster-robust variance estimator for the multivariate model is equivalent to using the HC2 heteroskedasticity-robust variance estimator for the univariate model with aggregated effects.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;
For another, the same sort of equivalence relationships hold even if there are additional random effects in the model, so long as the random effects are at the study level or higher levels of aggregation (e.g., lab effects, where labs are nested within studies).
I’ll leave these generalizations as exercises for a future rainy day.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Becker2000multivariate&#34;&gt;
&lt;p&gt;Becker, B. J. (2000). Multivariate meta-analysis. In S. D. Brown &amp;amp; H. E. A. Tinsley (Eds.), &lt;em&gt;Handbook of applied multivariate statistics and mathematical modeling&lt;/em&gt; (pp. 499–525). Academic Press. &lt;a href=&#34;https://doi.org/10.1016/B978-012691360-6/50018-5&#34;&gt;https://doi.org/10.1016/B978-012691360-6/50018-5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-borenstein2009introduction&#34;&gt;
&lt;p&gt;Borenstein, M., Hedges, L. V., Higgins, J. P. T., &amp;amp; Rothstein, H. R. (2009). &lt;em&gt;Introduction to Meta-Analysis&lt;/em&gt;. John Wiley &amp;amp; Sons, Ltd. &lt;a href=&#34;https://doi.org/10.1002/9780470743386&#34;&gt;https://doi.org/10.1002/9780470743386&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Hedges2010robust&#34;&gt;
&lt;p&gt;Hedges, L. V., Tipton, E., &amp;amp; Johnson, M. C. (2010). Robust variance estimation in meta-regression with dependent effect size estimates. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(1), 39–65. &lt;a href=&#34;https://doi.org/10.1002/jrsm.5&#34;&gt;https://doi.org/10.1002/jrsm.5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Kalaian1996multivariate&#34;&gt;
&lt;p&gt;Kalaian, H. a., &amp;amp; Raudenbush, S. W. (1996). A multivariate mixed linear model for meta-analysis. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(3), 227–235. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.1.3.227&#34;&gt;https://doi.org/10.1037/1082-989X.1.3.227&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-TannerSmith2013robust&#34;&gt;
&lt;p&gt;Tanner-Smith, E. E., &amp;amp; Tipton, E. (2013). Robust variance estimation with dependent effect sizes: Practical considerations including a software tutorial in Stata and SPSS. &lt;em&gt;Research Synthesis Methods&lt;/em&gt;, &lt;em&gt;5&lt;/em&gt;(1), 1–34. &lt;a href=&#34;https://doi.org/10.1002/jrsm.1091&#34;&gt;https://doi.org/10.1002/jrsm.1091&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-VandenNoortgate2013threelevel&#34;&gt;
&lt;p&gt;Van den Noortgate, W., López-López, J. A., Marín-Martínez, F., &amp;amp; Sánchez-Meca, J. (2013). Three-level meta-analysis of dependent effect sizes. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;45&lt;/em&gt;(2), 576–594. &lt;a href=&#34;https://doi.org/10.3758/s13428-012-0261-6&#34;&gt;https://doi.org/10.3758/s13428-012-0261-6&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-VandenNoortgate2015metaanalysis&#34;&gt;
&lt;p&gt;Van den Noortgate, W., López-López, J. A., Marín-Martínez, F., &amp;amp; Sánchez-Meca, J. (2015). Meta-analysis of multiple outcomes: A multilevel approach. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;47&lt;/em&gt;(4), 1274–1294. &lt;a href=&#34;https://doi.org/10.3758/s13428-014-0527-2&#34;&gt;https://doi.org/10.3758/s13428-014-0527-2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;A common special case is that the sampling variances for effect sizes within a given study &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; are &lt;em&gt;all equal&lt;/em&gt;, so that &lt;span class=&#34;math inline&#34;&gt;\(S_{ik} = s_{jk} = S_k\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i,j = 1,...,J_ik\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;. We might further posit that there is a constant sampling correlation between every pair of effect sizes within a given study, so that &lt;span class=&#34;math inline&#34;&gt;\(\rho_{ijk} = \rho_k\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(i,j = 1,...,J_ik\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = 1,...,K\)&lt;/span&gt;. If both of these conditions hold, then the inverse-variance weighted average effect size simplifies to the arithmetic average
&lt;span class=&#34;math display&#34;&gt;\[
\bar{T}_k = \frac{1}{J_k} \sum_{j=1}^{J_k} T_{jk}
\]&lt;/span&gt;
with sampling variance
&lt;span class=&#34;math display&#34;&gt;\[
V_k = \frac{(J_k - 1)\rho_k + 1}{J} \times S_k^2
\]&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;(cf. Borenstein et al., &lt;a href=&#34;#ref-borenstein2009introduction&#34; role=&#34;doc-biblioref&#34;&gt;2009&lt;/a&gt;, Eq. (24.6), p. 230)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;The same thing holds if we use FML rather than RML estimation—try it for yourself and see!&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;As RVE and MLMA become more wide-spread, I could imagine it happening that a meta-analyst who uses aggregation and a univariate model might get push-back from a reviewer, who uncritically recommends using a “more advanced” method to handle dependence. The results in this post provide a way for the meta-analyst to establish that doing so would be unnecessary.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Here’s verification with the computational example from above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# multivariate CR2
coef_test(MV_fit, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Coef. Estimate      SE t-stat d.f. p-val (Satt) Sig.
## 1 intrcpt  0.64656 0.17647   3.66 11.5      0.00345   **
## 2 college  0.37027 0.18648   1.99 11.9      0.07053    .
## 3   males -0.00763 0.00287  -2.66 14.5      0.01826    *&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# univariate HC2
coef_test(uni_fit, vcov = &amp;quot;CR2&amp;quot;, cluster = corrdat_agg$studyid)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Coef. Estimate      SE t-stat d.f. p-val (Satt) Sig.
## 1 intrcpt  0.64656 0.17622   3.67 11.5      0.00342   **
## 2 college  0.37027 0.18597   1.99 11.9      0.06985    .
## 3   males -0.00763 0.00287  -2.66 14.5      0.01808    *&lt;/code&gt;&lt;/pre&gt;
&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating the Transition to College Mathematics Course in Texas high schools: Findings from the first year of implementation</title>
      <link>http://localhost:4321/publication/transition-to-college-mathematics-year-1/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/transition-to-college-mathematics-year-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interventions to enhance self-efficacy in cancer patients and survivors: A meta-analysis of randomized controlled trials</title>
      <link>http://localhost:4321/publication/interventions-to-enhance-self-efficacy-in-cancer-patients/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/interventions-to-enhance-self-efficacy-in-cancer-patients/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Log response ratio effect sizes: Rationale and methods for single case designs with behavioral outcomes</title>
      <link>http://localhost:4321/talk/abai-2019-log-response-ratios/</link>
      <pubDate>Sun, 26 May 2019 17:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/abai-2019-log-response-ratios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Converting from odds ratios to standardized mean differences: What to do with logistic regression coefficients?</title>
      <link>http://localhost:4321/converting-odds-ratios-to-standardized-mean-differences/</link>
      <pubDate>Sun, 26 May 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/converting-odds-ratios-to-standardized-mean-differences/</guid>
      <description>


&lt;p&gt;One of the central problems in research synthesis is that studies use a variety of different types of outcome measures to assess a construct. This is the main reason that meta-analysis often uses standardized, scale-free effect sizes (such as standardized mean differences), so that findings from studies that use different measures can be combined and contrasted on a common metric. In syntheses of education research (as well as other fields), a further issue that sometimes arises is that some included studies might report effects on a dichotomous outcome, while others report effects (of the same intervention, say) but using a continuous outcome measure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logit &amp;lt;- function(x) log(x) - log(1 - x)

simulate_OR_to_SMD &amp;lt;- function(p0, SMD, r, n0, n1) {
  
  # simulate data
  trt &amp;lt;- c(rep(0, n0), rep(1, n1))
  Y &amp;lt;- rlogis(n0 + n1, location = logit(p0) + trt * SMD * pi / sqrt(3))
  X &amp;lt;- r * (Y - trt * SMD) * sqrt(3) / pi + rnorm(n0 + n1, sd = sqrt(1 - r^2))
  B &amp;lt;- Y &amp;gt; 0

  # calculate LORs
  logit_fit &amp;lt;- glm(B ~ trt + X, family = &amp;quot;binomial&amp;quot;)
  LOR_marginal &amp;lt;- as.numeric(diff(logit(tapply(B, trt, mean))))
  LOR_logit &amp;lt;- coef(logit_fit)[[&amp;quot;trt&amp;quot;]]
  LORs &amp;lt;- c(LOR_marginal, LOR_logit)
  
  # convert to SMDs
  SMDs &amp;lt;- LORs * sqrt(3) / pi
  
  data.frame(type = c(&amp;quot;marginal&amp;quot;,&amp;quot;conditional&amp;quot;), LOR_est = LORs, SMD_est = SMDs)
} 

simulate_OR_to_SMD(p0 = 0.6, SMD = 0.4, r = 0.7, n0 = 10000, n1 = 10000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          type   LOR_est   SMD_est
## 1    marginal 0.7468089 0.4117373
## 2 conditional 0.8711806 0.4803070&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Attaching packages ------------------------------------------------------ tidyverse 1.2.1 --&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## v ggplot2 3.3.0     v purrr   0.3.3
## v tibble  3.0.0     v dplyr   0.8.3
## v tidyr   1.0.0     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.4.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -- Conflicts --------------------------------------------------------- tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;params &amp;lt;- 
  list(
    p0 = seq(0.2, 0.8, 0.2),
    SMD = seq(0.2, 0.8, 0.2),
    r = seq(0, 0.9, 0.1)
  ) %&amp;gt;%
  cross_df()

SMDs &amp;lt;- 
  params %&amp;gt;%
  mutate(res = pmap(., simulate_OR_to_SMD, n0 = 50000, n1 = 50000)) %&amp;gt;%
  unnest() %&amp;gt;%
  mutate(RB = SMD_est / SMD)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `cols` is now required.
## Please use `cols = c(res)`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(SMDs, aes(r, RB, color = type)) + 
  geom_point() + geom_line() + 
  facet_grid(SMD ~ p0, labeller = &amp;quot;label_both&amp;quot;) + 
  theme_light()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Converting-odds-ratios-to-standardized-mean-differences_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Effects of psychosocial interventions on meaning and purpose in adults with cancer: A systematic review and meta-analysis</title>
      <link>http://localhost:4321/publication/psychosocial-interventions-meaning-and-purpose/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/psychosocial-interventions-meaning-and-purpose/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Code folding with blogdown &#43; Academic theme</title>
      <link>http://localhost:4321/code-folding-with-blogdown-academic/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/code-folding-with-blogdown-academic/</guid>
      <description>


&lt;p&gt;&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;2020-05-03&lt;/strong&gt; This post describes an implementation of code folding for an older version of the Academic Theme. It does not work with Academic 4.+. See &lt;a href=&#34;http://localhost:4321/code-folding-update/&#34;&gt;my updated instructions&lt;/a&gt; to get it working with newer versions of Academic.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Rmarkdown documents now have a very nifty &lt;a href=&#34;https://bookdown.org/yihui/rmarkdown/html-document.html#code-folding&#34;&gt;code folding option&lt;/a&gt;, which allows the reader of a compiled html document to toggle whether to view or hide code chunks. However, the feature is &lt;a href=&#34;https://github.com/rstudio/blogdown/issues/214&#34;&gt;not supported in blogdown&lt;/a&gt;, the popular Rmarkdown-based website/blog creation package. I recently ran across an implementation of codefolding for blogdown, developed by &lt;a href=&#34;https://statnmap.com/2017-11-13-enable-code-folding-in-bookdown-and-blogdown/&#34;&gt;Sébastien Rochette&lt;/a&gt;. I have been putzing around, trying to get it to work with my blog, which uses the Hugo &lt;a href=&#34;https://sourcethemes.com/academic/&#34;&gt;Academic theme&lt;/a&gt;—alas, to no avail. To my amazement and good fortune, Sébastien swooped in with &lt;a href=&#34;https://github.com/jepusto/jepusto.com/pull/9&#34;&gt;a pull request&lt;/a&gt; that cleaned up my blundering attempts at implementation. Now all of &lt;a href=&#34;http://localhost:4321/package-downloads&#34;&gt;my posts&lt;/a&gt; have &lt;a href=&#34;http://localhost:4321/handmade-clubSandwich&#34;&gt;working&lt;/a&gt; &lt;a href=&#34;http://localhost:4321/effective-sample-size-aggregation&#34;&gt;code folding&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/mIZ9rPeMKefm0/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this post, I’ll lay out how to make Sébastien’s code folding feature work with the Academic theme. To be totally clear, all of the hard bits of this were &lt;a href=&#34;https://statnmap.com/2017-11-13-enable-code-folding-in-bookdown-and-blogdown/&#34;&gt;solved by Sébastien&lt;/a&gt;. I don’t know javascript to save my life, and my only contribution is to write down the instructions in what I hope is a coherent fashion, so that you too can soon be doing the happy code folding dance if you so desire.&lt;/p&gt;
&lt;div id=&#34;code-folding-with-the-academic-theme&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Code folding with the Academic theme&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;You’ll first need to pull in some javascript assets. Create a folder called &lt;code&gt;js&lt;/code&gt; under the &lt;code&gt;\static&lt;/code&gt; directory of your site. Add the files &lt;code&gt;transition.js&lt;/code&gt;, &lt;code&gt;collapse.js&lt;/code&gt;, and &lt;code&gt;dropdown.js&lt;/code&gt; from &lt;a href=&#34;https://github.com/twbs/bootstrap/tree/v3.3.7/js&#34;&gt;bootstrap&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Also add Sébastien’s codefolding javascript, &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/static/js/codefolding.js&#34;&gt;&lt;code&gt;codefolding.js&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a folder called &lt;code&gt;css&lt;/code&gt; under the &lt;code&gt;\static&lt;/code&gt; directory of your site. Add the file &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/static/css/codefolding.css&#34;&gt;&lt;code&gt;codefolding.css&lt;/code&gt;&lt;/a&gt;. This is the css for the buttons that will appear on your posts.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the file &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/partials/article_footer_js.html&#34;&gt;&lt;code&gt;article_footer_js.html&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;\layouts\partials&lt;/code&gt; directory of your site.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the file &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/partials/header_maincodefolding.html&#34;&gt;&lt;code&gt;header_maincodefolding.html&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;\layouts\partials&lt;/code&gt; directory of your site.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you do not already have a file &lt;code&gt;head_custom.html&lt;/code&gt; in the &lt;code&gt;\layouts\partials&lt;/code&gt; directory, create it.. Add the following lines of code to the file:&lt;/p&gt;
&lt;pre class=&#34;js&#34;&gt;&lt;code&gt;{{ if not .Site.Params.disable_codefolding }}
  &amp;lt;script src=&amp;quot;{{ &amp;quot;js/collapse.js&amp;quot; | relURL }}&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;script src=&amp;quot;{{ &amp;quot;js/dropdown.js&amp;quot; | relURL }}&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;script src=&amp;quot;{{ &amp;quot;js/transition.js&amp;quot; | relURL }}&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
{{ end }}&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you do not already have a file &lt;code&gt;footer.html&lt;/code&gt; in the &lt;code&gt;\layouts\partials&lt;/code&gt; directory, copy it over from &lt;code&gt;\themes\hugo-academic\layouts\partials&lt;/code&gt;. Add the following lines of code to it, somewhere towards the bottom (see &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/partials/footer.html&#34;&gt;my version&lt;/a&gt; for example):&lt;/p&gt;
&lt;pre class=&#34;js&#34;&gt;&lt;code&gt;&amp;lt;!-- Init code folding --&amp;gt;
{{ partial &amp;quot;article_footer_js.html&amp;quot; . }}&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you do not already have the file &lt;code&gt;single.html&lt;/code&gt; in the directory &lt;code&gt;\layouts\_default&lt;/code&gt;, copy it over from &lt;code&gt;\themes\hugo-academic\layouts\_default&lt;/code&gt;. Add the following line of code at an appropriate point so that your posts will include the “Show/hide code” button (I put it after the title, before the meta-data; &lt;a href=&#34;https://github.com/jepusto/jepusto.com/blob/master/layouts/_default/single.html&#34;&gt;see here&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&#34;js&#34;&gt;&lt;code&gt; {{ partial &amp;quot;header_maincodefolding&amp;quot; . }}&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modify your &lt;code&gt;config.toml&lt;/code&gt; file (in the base directory of your site) to include the following lines:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set to true to disable code folding
disable_codefolding = false
# Set to &amp;quot;hide&amp;quot; or &amp;quot;show&amp;quot; all codes by default
codefolding_show = &amp;quot;show&amp;quot;
# Set to true to exclude the &amp;quot;Show/hide all&amp;quot; button
codefolding_nobutton = false&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also edit the &lt;code&gt;custom_css&lt;/code&gt; parameter so that the &lt;code&gt;codefolding.css&lt;/code&gt; file will get loaded:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;custom_css = [&amp;quot;codefolding.css&amp;quot;]&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-codefolding-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the codefolding parameters&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;config.toml&lt;/code&gt; file now has three parameters that control code folding:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;disable_codefolding&lt;/code&gt; controls whether to load the code folding scripts on your site. Set it to &lt;code&gt;true&lt;/code&gt; to disable code folding globally.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;codefolding_show&lt;/code&gt; controls whether code blocks will be shown or hidden by default. If your previous posts have lots of code in them, set the default to &lt;code&gt;show&lt;/code&gt; to minimize changes in the appearance of your site.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;codefolding_nobutton&lt;/code&gt; controls whether the “Show/hide code” button will appear at the top of posts that include code blocks. Set it to &lt;code&gt;true&lt;/code&gt; to disable the button but keep the other code folding functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above parameters are defaults for your entire site. To over-ride the defaults, you can also set the parameters in the YAML header of any post:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set &lt;code&gt;disable_codefolding: true&lt;/code&gt; to turn off code folding for the post.&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;codefolding_show: hide&lt;/code&gt; to hide the code blocks in the post (as in &lt;a href=&#34;\package-downloads&#34;&gt;this post&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;codefolding_nobutton: true&lt;/code&gt; to turn off the “Show/hide code” button at the top of the post (as in the present post).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I hope these instructions work for you. If not, questions, corrections, and clarifications are welcome. Thanks again to &lt;a href=&#34;https://statnmap.com/&#34;&gt;Sébastien Rochette&lt;/a&gt; for working out this solution and for graciously troubleshooting my attempt at implementation. Happy blogging, y’all!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>CRAN downloads of my packages</title>
      <link>http://localhost:4321/package-downloads/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/package-downloads/</guid>
      <description>
&lt;script src=&#34;http://localhost:4321/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;http://localhost:4321/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;p&gt;At AERA this past weekend, one of the recurring themes was how software availability (and its usability and default features) influences how people conduct meta-analyses. That got me thinking about the R packages that I’ve developed, how to understand the extent to which people are using them, how they’re being used, and so on. I’ve had badges on my github repos for a while now:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clubSandwich: &lt;a href=&#34;https://CRAN.R-project.org/package=clubSandwich&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/clubSandwich&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ARPobservation: &lt;a href=&#34;https://CRAN.R-project.org/package=ARPobservation&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/ARPobservation&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;scdhlm: &lt;a href=&#34;https://CRAN.R-project.org/package=scdhlm&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/scdhlm&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SingleCaseES: &lt;a href=&#34;https://CRAN.R-project.org/package=SingleCaseES&#34;&gt;&lt;img src = &#34;https://cranlogs.r-pkg.org/badges/last-month/SingleCaseES&#34; style=&#34;display: inline-block; margin:0;&#34;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These statistics come from the &lt;a href=&#34;https://www.r-pkg.org/&#34;&gt;METACRAN&lt;/a&gt; site, which makes available data on daily downloads of all packages on CRAN (one of the main repositories for sharing R packages). The downloads are from the RStudio mirror of CRAN, which is only one of many mirrors around the world. Although the data do not represent complete tallies of all package downloads, they are nonetheless the best available source that I’m aware of.&lt;/p&gt;
&lt;p&gt;The thing is, the download numbers are rather hard to interpret. Beyond knowing that somebody out there is at least &lt;em&gt;trying&lt;/em&gt; to use the tools I’ve made, it’s pretty hard to gauge whether 300 or 3000 or 3 million downloads a month is a good usage level. In this post, I’ll attempt to put just a little bit of context around these numbers. Emphasis on &lt;em&gt;little bit&lt;/em&gt;, as I’m not all that satisfied with what I’ll show below, but at least it’s something beyond four numbers floating in the air.&lt;/p&gt;
&lt;div id=&#34;getting-package-download-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting package download data&lt;/h3&gt;
&lt;p&gt;I used the &lt;code&gt;cranlogs&lt;/code&gt; package to get daily download counts of all currently available CRAN packages over the period 2018-04-05 18:00:00 through 2019-04-06. I then limited the sample to packages that had been downloaded at least once between 2018-04-05 18:00:00 and 2018-10-05. This had the effect of excluding about 1000 packages that were either only recently added to CRAN or that had been discontinued but were still sitting on CRAN.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(cranlogs)

to_date &amp;lt;- &amp;quot;2019-04-06&amp;quot;
from_date &amp;lt;- as.character(as_date(to_date) - duration(1, &amp;quot;year&amp;quot;))
file_name &amp;lt;- paste0(&amp;quot;CRAN package downloads &amp;quot;, to_date, &amp;quot;.rds&amp;quot;)

pkg_downloads &amp;lt;-
  available.packages() %&amp;gt;%
  as_tibble() %&amp;gt;%
  select(Package, Version) %&amp;gt;%
  mutate(grp = 1 + trunc((row_number() - 1) / 100)) %&amp;gt;%
  nest(Package, Version) %&amp;gt;%
  mutate(downloads = map(.$data, ~ cran_downloads(packages = .$Package, 
                                                  from = from_date, 
                                                  to = to_date))) %&amp;gt;%
  select(-data) %&amp;gt;%
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;downloaded_last_yr &amp;lt;- 
  pkg_downloads %&amp;gt;%
  filter(date &amp;lt;= as_date(as_date(to_date) - duration(6, &amp;quot;months&amp;quot;))) %&amp;gt;%
  group_by(package) %&amp;gt;%
  summarise(
    count = sum(count),
    .groups = &amp;quot;drop&amp;quot;
  ) %&amp;gt;%
  filter(count &amp;gt; 0) %&amp;gt;%
  select(package)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This yielded 12925 packages. For each of these packages, I then calculated the average monthly download rate over the most recent six months, along with where that rate falls as a percentile of all packages in the sample.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;downloads_past_six &amp;lt;-
  pkg_downloads %&amp;gt;%
  filter(date &amp;gt; as_date(as_date(to_date) - duration(6, &amp;quot;months&amp;quot;))) %&amp;gt;%
  semi_join(downloaded_last_yr, by = &amp;quot;package&amp;quot;) %&amp;gt;%
  group_by(package) %&amp;gt;%
  summarise(
    count = sum(count) / 6,
    .groups = &amp;quot;drop&amp;quot;
  ) %&amp;gt;%
  mutate(
    package = fct_reorder(factor(package), count),
    pct_less = cume_dist(count)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pustos-packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Pusto’s packages&lt;/h3&gt;
&lt;p&gt;I have developed four packages that are currently available on CRAN:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;clubSandwich&lt;/code&gt; package provides cluster-robust variance estimators for a variety of different linear models (including meta-regression, hierarchical linear models, panel data models, etc.), as well as (more recently) some instrumental variables models. The package has received some attention in connection with estimating meta-analysis and meta-regression models, and it’s also relevant to applied micro-economics, field experiments, and other fields.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;scdhlm&lt;/code&gt; and &lt;code&gt;SingleCaseES&lt;/code&gt; packages provide functions and interactive web apps for calculating various effect sizes for single-case experimental designs. The &lt;code&gt;SingleCaseES&lt;/code&gt; package is fairly new and I haven’t yet written any articles that feature it. Both it and &lt;code&gt;scdhlm&lt;/code&gt; are relevant in fairly specialized fields where single-case experimental designs are commonly used—and where there is a need to meta-analyze results from such designs—and so I would not expect them to be widely downloaded.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;ARPobservation&lt;/code&gt; package provides tools for simulating behavioral observation data based on an alternating renewal process model. I developed this package for my own dissertation work, and my students and I have used it in some subsequent work. I think of it mostly as a tool for my group’s work on statistical methods for single-case experimental designs, and so would not expect to be widely downloaded or used outside of this area.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As points of comparison to my contributions, it is perhaps useful to look at two popular packages for conducting meta-analysis, the &lt;code&gt;metafor&lt;/code&gt; package and the &lt;code&gt;robumeta&lt;/code&gt; package:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;metafor&lt;/code&gt; package, developed by Wolfgang Viechtbauer, has been around for 10 years and includes all sorts of incredible tools for calculating effect sizes, estimating meta-analysis and meta-regression models, investigating fitted models, and representing the results graphically. In contrast, the &lt;code&gt;clubSandwich&lt;/code&gt; package is narrower in scope—it just calculates robust standard errors, confidence intervals, etc.—so &lt;code&gt;metafor&lt;/code&gt; is not a perfect point of comparison.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;robumeta&lt;/code&gt; package, by Zachary Fisher and Elizabeth Tipton, is a closer match in terms of scope. It is used for estimating meta-regression models with robust variance estimation, using specific methods proposed by Hedges, Tipton, and Johnson (2010).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am having a harder time thinking of good comparables for the &lt;code&gt;scdhlm&lt;/code&gt;, &lt;code&gt;SingleCaseES&lt;/code&gt;, and &lt;code&gt;ARPobservation&lt;/code&gt; packages due to their specialized focus. (Ideas? Suggestions? I’m all ears!)&lt;/p&gt;
&lt;p&gt;With that background, here are the average monthly download rates (over the past six months) for each of my four packages, along with &lt;code&gt;metafor&lt;/code&gt; and &lt;code&gt;robumeta&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(knitr)
library(kableExtra)

Pusto_pkgs &amp;lt;- c(&amp;quot;ARPobservation&amp;quot;,&amp;quot;scdhlm&amp;quot;,&amp;quot;SingleCaseES&amp;quot;,&amp;quot;clubSandwich&amp;quot;)
meta_pkgs &amp;lt;- c(&amp;quot;metafor&amp;quot;,&amp;quot;robumeta&amp;quot;)

focal_downloads &amp;lt;- 
  downloads_past_six %&amp;gt;%
  filter(package %in% c(Pusto_pkgs, meta_pkgs)) %&amp;gt;%
  mutate(
    count = round(count),
    pct_less = round(100 * pct_less, 1)
  ) %&amp;gt;%
  arrange(desc(count))

focal_downloads %&amp;gt;%
  rename(`Average monthly downloads` = count, 
         `Percentile of CRAN packages` = pct_less) %&amp;gt;%
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;), full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-hover table-condensed&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
package
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Average monthly downloads
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Percentile of CRAN packages
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
metafor
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7348
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
94.0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
clubSandwich
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2992
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90.3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
robumeta
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2025
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
87.9
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ARPobservation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
387
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
SingleCaseES
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
306
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
scdhlm
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
229
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Thus, &lt;code&gt;clubSandwich&lt;/code&gt; sits in between &lt;code&gt;metafor&lt;/code&gt; and &lt;code&gt;robumeta&lt;/code&gt;, at the 90th percentile among all active packages on CRAN. The other packages are much less widely downloaded, averaging between 200 and 400 downloads per month. The distribution of monthly download rates is &lt;em&gt;highly&lt;/em&gt; skewed, as can be seen in the figure below. About 68% of packages are downloaded 500 times or fewer per month, while only 7% of packages get more than 5000 downloads per month.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(colorspace)
library(ggrepel)

downloads_sample &amp;lt;- 
  downloads_past_six %&amp;gt;%
  arrange(count) %&amp;gt;%
  mutate(
    focal = package %in% c(Pusto_pkgs,meta_pkgs),
    tenth = (row_number(count) %% 10) == 1
  ) %&amp;gt;%
  filter(focal | tenth)

focal_pkg_dat &amp;lt;- 
  downloads_sample %&amp;gt;%
  filter(focal) %&amp;gt;%
  mutate(Pusto = if_else(package %in% Pusto_pkgs, &amp;quot;Pusto&amp;quot;,&amp;quot;comparison&amp;quot;))

title_str &amp;lt;- paste(&amp;quot;Average monthly downloads of R packages from&amp;quot;, as_date(as_date(to_date) - duration(6, &amp;quot;months&amp;quot;)),&amp;quot;through&amp;quot;,to_date)

qualitative_hcl(n = 2, h = c(140, -30), c = 90, l = 40, register = &amp;quot;custom-qual&amp;quot;)

ggplot(downloads_sample, aes(x = package, y = count)) +
  geom_col() + 
  geom_col(data = focal_pkg_dat, aes(color = Pusto, fill = Pusto), size = 1.5) + 
  geom_label_repel(
    data = focal_pkg_dat, aes(color = Pusto, label = package),
    segment.size = 0.4,
    segment.color = &amp;quot;grey50&amp;quot;,
    nudge_y = 0.5,
    point.padding = 0.3
  ) + 
  scale_y_log10(breaks = c(20, 50, 200, 500, 2000, 5000, 20000, 50000, 200000), labels = scales::comma) + 
  scale_fill_discrete_qualitative(palette = &amp;quot;custom-qual&amp;quot;) + 
  scale_color_discrete_qualitative(palette = &amp;quot;custom-qual&amp;quot;) + 
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;Downloads (per month)&amp;quot;, title = title_str) + 
  theme(legend.position = &amp;quot;none&amp;quot;, axis.line.x = element_blank(), axis.ticks.x = element_blank(), axis.text.x = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/CRAN-package-downloads_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;downloads-over-time&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Downloads over time&lt;/h3&gt;
&lt;p&gt;Here are the weekly download rates for each of my packages over the past two years. (Note that the vertical scales of the graphs differ.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weekly_downloads &amp;lt;- 
  pkg_downloads %&amp;gt;%
  mutate(
    yr = year(date),
    wk = week(date)
  ) %&amp;gt;%
  group_by(package, yr, wk) %&amp;gt;%
  mutate(
    date = max(date)
  ) %&amp;gt;%
  group_by(package, date) %&amp;gt;%
  summarise(
    count = sum(count),
    days = n(),
    .groups = &amp;quot;drop&amp;quot;
  )

weekly_downloads %&amp;gt;%
  filter(
    days == 7,
    package %in% Pusto_pkgs
  ) %&amp;gt;%
  ggplot(aes(date, count, color = package)) + 
  geom_line() + 
  expand_limits(y = 0) + 
  facet_wrap(~ package, scales = &amp;quot;free&amp;quot;, ncol = 2) + 
  theme_minimal() + 
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;Downloads (per month)&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/CRAN-package-downloads_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are a couple of curious features in these plots. For one, there are big spikes in downloads of &lt;code&gt;ARPobservation&lt;/code&gt; and &lt;code&gt;SingleCaseES&lt;/code&gt;. The &lt;code&gt;ARPobservation&lt;/code&gt; spike was in mid-June of 2018, when I was at the IES Single-Case Design training institute and demonstrated some of the package’s tools. The &lt;code&gt;SingleCaseES&lt;/code&gt; spike was in early January, 2019. Perhaps someone was teaching a class in single-case research and demonstrated the package? Or something at the IES PI meeting (January 9-10, 2019)?&lt;/p&gt;
&lt;p&gt;Another interesting pattern is in the download rate of &lt;code&gt;scdhlm&lt;/code&gt;, which looks like it increased systematically starting in September, 2018. I wonder if this was the result of someone demonstrating or incorporating use of the package into a course. Lacking details about where the downloads are coming from, it’s hard to do anything but speculate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;caveats-and-musings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Caveats and musings&lt;/h3&gt;
&lt;p&gt;Clearly, download counts are only a very rough proxy for package usage. In marketing-speak, they might be more like leads than conversion, in that people might be downloading a package only to discover that it’s not good for anything and then never use it to accomplish anything. Downloads are also not one-time events. If they use it in their work, a single person will likely download a package many times, over a span of time as new versions are released, onto multiple machines that they might use, by accident in the process of trying to install some other package, and so on. Downloads of inter-related packages are likely to be highly correlated too, as they will be with release of new major versions of R, which probably makes it a bit tricky to do event studies.&lt;/p&gt;
&lt;p&gt;Ultimately, I don’t know that knowing where my packages stand in terms of download rankings is all that useful. The packages that I’ve developed are all aimed at fairly academic audiences, which means that citations would probably be a better measure of contribution. The problem is, many people don’t know that they should be citing software, or how to do it. As usual, there’s an R function for that. Here’s how to get the citation for &lt;code&gt;clubSandwich&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;citation(package=&amp;quot;clubSandwich&amp;quot;) %&amp;gt;%
  print(style = &amp;quot;textVersion&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which returns the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;James Pustejovsky (2020). clubSandwich: Cluster-Robust (Sandwich) Variance Estimators with Small-Sample
Corrections. R package version 0.5.0. &lt;a href=&#34;https://CRAN.R-project.org/package=clubSandwich&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/package=clubSandwich&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating meta-analytic methods to detect outcome reporting bias in the presence of dependent effect sizes</title>
      <link>http://localhost:4321/talk/aera-2019-orb-dependence/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2019-orb-dependence/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An examination of measurement procedures and baseline behavioral outcomes in single-case research</title>
      <link>http://localhost:4321/talk/aera-2019-outcome-measurement-procedures/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2019-outcome-measurement-procedures/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The impact of response-guided designs on count outcomes in single-case design baselines</title>
      <link>http://localhost:4321/talk/aera-2019-response-guided-algorithms/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2019-response-guided-algorithms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Procedural sensitivities of effect sizes for single-case designs with behavioral outcome measures</title>
      <link>http://localhost:4321/publication/procedural-sensitivities-of-scd-effect-sizes/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/procedural-sensitivities-of-scd-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Systematic Reviews and Meta-analysis SIG at AERA 2019</title>
      <link>http://localhost:4321/aera-2019-srma-sig/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/aera-2019-srma-sig/</guid>
      <description>


&lt;p&gt;This year, &lt;a href=&#34;https://pure.qub.ac.uk/portal/en/persons/laura-dunne(7bf21af1-3fa0-4c1b-aab9-7b5f526cb1c9).html&#34;&gt;Dr. Laura Dunne&lt;/a&gt; and I are serving as program co-chairs for the AERA special interest group on &lt;a href=&#34;http://www.aera.net/SIG176/Systematic-Reviews-and-Meta-Analysis-SIG176&#34;&gt;Systematic Reviews and Meta-Analysis&lt;/a&gt;, which is a great group of scholars interested in the methodology and application of research synthesis to questions in education and the broader social sciences. We had a strong batch of submissions to the SIG and (since we’re new and still a fairly small group) only a few sessions to fill with them. In assembling this year’s program, Laura and I noted a few common themes that stood out to us. In this post, I’ll highlight a few of them and hopefully whet your appetite to hear more during our sessions at this year’s convention. And if you want to skip the details for now, just take a look at our handy pdf with &lt;a href=&#34;http://localhost:4321/files/2019_SRMA_Schedule.pdf&#34;&gt;the full SIG program&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;sig-highlights&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;SIG highlights&lt;/h2&gt;
&lt;p&gt;First, two of this year’s presentations deal with &lt;strong&gt;&lt;em&gt;network meta-analysis&lt;/em&gt;&lt;/strong&gt;, an approach that goes beyond a single intervention-control comparison, to instead synthesize evidence on the comparative effects of multiple alternative interventions (not just red pill vs blue pill, but also red versus green, green versus blue, etc.). Network meta-analysis is increasingly important in clinical medicine (for example, &lt;a href=&#34;https://ora.ox.ac.uk/objects/uuid:95a796fa-e842-4e11-bee6-b0b2237a2541&#34;&gt;here’s a recent synthesis&lt;/a&gt; examining the relative efficacy of 21 different anti-depressant drugs) but it is still relatively rare in education and other social science meta-analyses. Not in this year’s SIG program though! Both our &lt;a href=&#34;http://tinyurl.com/ybfxaqq9&#34;&gt;Sunday morning paper session&lt;/a&gt; and &lt;a href=&#34;http://tinyurl.com/y773wb5x&#34;&gt;Monday round table&lt;/a&gt; feature applications of network meta-analysis: one on &lt;a href=&#34;http://tinyurl.com/y7ehtuhf&#34;&gt;distance and face-to-face learning&lt;/a&gt;, and one on &lt;a href=&#34;http://tinyurl.com/y8x5dh7f&#34;&gt;interventions for treatment of post-traumatic stress disorder&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Second, &lt;strong&gt;&lt;em&gt;publication bias&lt;/em&gt;&lt;/strong&gt; and other forms of &lt;strong&gt;&lt;em&gt;outcome reporting bias&lt;/em&gt;&lt;/strong&gt; remain one of the most vexing challenges for meta-analysis. Our &lt;a href=&#34;http://tinyurl.com/ybfxaqq9&#34;&gt;Sunday morning paper session&lt;/a&gt; includes an innovative methodological study on &lt;a href=&#34;http://tinyurl.com/yaze63jr&#34;&gt;how to detect selective outcome reporting in multi-level meta-analyses&lt;/a&gt;—an important setting where publication bias techniques have yet to be explored. Even with very sophisticated statistical tools, though, the best way to address publication bias is probably to try and prevent it in the first place. To that end, our &lt;a href=&#34;http://tinyurl.com/y773wb5x&#34;&gt;Monday round table session&lt;/a&gt; includes a presentation on &lt;a href=&#34;http://tinyurl.com/y6vslf6m&#34;&gt;locating unreported outcome data for use in meta-analysis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Third, the Systematic Reviews and Meta-Analysis SIG has always included &lt;strong&gt;&lt;em&gt;a mix of theory and practice&lt;/em&gt;&lt;/strong&gt;. In this year’s program, we’ve tried to preserve that mix within each of our sessions, so that our Sunday paper session and Monday round table each include both methodological research and substantive applications of meta-analysis. We hope that this will promote interesting and valuable dialogues within our community.&lt;/p&gt;
&lt;p&gt;Finally, I am very excited that &lt;a href=&#34;http://tinyurl.com/y45wbgfe&#34;&gt;our business meeting&lt;/a&gt; will feature an address by &lt;strong&gt;&lt;em&gt;&lt;a href=&#34;https://scholar.gse.upenn.edu/maynard&#34;&gt;Dr. Rebecca Maynard&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;, who is the University Trustee Chair Professor of Education and Social Policy at the University of Pennsylvania Graduate School of Education, and an influential voice in the use of research synthesis methods to inform education and social policy. She’ll be speaking on &lt;strong&gt;&lt;em&gt;Expanded Roles for Meta-Analysis in Supporting Evidence-Based Policy and Practice&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Be sure to check out &lt;a href=&#34;http://localhost:4321/files/2019_SRMA_Schedule.pdf&#34;&gt;the SIG program&lt;/a&gt; for more details and other sessions of interest. I look forward to seeing everyone in Toronto!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A handmade clubSandwich for multi-site trials</title>
      <link>http://localhost:4321/clustered-and-interacted/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/clustered-and-interacted/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
data(STAR, package = &amp;quot;AER&amp;quot;)

STAR_urban &amp;lt;-
  STAR %&amp;gt;%
  filter(
    # limit to urban/inner city schools
    schoolk %in% c(&amp;quot;urban&amp;quot;,&amp;quot;inner-city&amp;quot;),
    # limit to complete outcome data
    !is.na(readk), !is.na(mathk)
  ) %&amp;gt;%
  droplevels() %&amp;gt;%
  # collapse control conditions
  mutate(
    stark = fct_collapse(stark, regular = c(&amp;quot;regular&amp;quot;,&amp;quot;regular+aide&amp;quot;))
  ) %&amp;gt;%
  # calculate inverse-propensity weight
  group_by(schoolidk) %&amp;gt;%
  mutate(
    n = n(),
    nT = sum(stark==&amp;quot;small&amp;quot;),
    wt = ifelse(stark==&amp;quot;small&amp;quot;, n / nT, n / (n - nT))
  ) %&amp;gt;%
  select(schoolidk, stark, readk, mathk, wt)

STAR_summary &amp;lt;- 
  STAR_urban %&amp;gt;%
  count(schoolidk)

STAR_urban %&amp;gt;%
  group_by(schoolidk, stark) %&amp;gt;%
  summarise(
    n = n(),
    wt = sum(wt)
  ) %&amp;gt;%
  mutate(n = sum(n)) %&amp;gt;%
  spread(stark, wt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 23 x 4
## # Groups:   schoolidk [23]
##    schoolidk     n regular small
##    &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2            52      52    52
##  2 9           120     120   120
##  3 10           51      51    51
##  4 14           34      34    34
##  5 15           55      55    55
##  6 16          105     105   105
##  7 18           79      79    79
##  8 19           99      99    99
##  9 22          129     129   129
## 10 26           49      49    49
## # ... with 13 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After these exclusions, the data include a total of 1810 students from 23 schools, ranging in size from 34 to 134 students.&lt;/p&gt;
&lt;p&gt;For starters, let’s get the average impacts using a seeming unrelated regression specification, with both conventional and clubSandwich standard errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;STAR_wt &amp;lt;- lm(cbind(readk, mathk) ~ 0 + schoolidk + stark, weights = wt, data = STAR_urban)

# conventional SEs
CR0 &amp;lt;- 
  coef_test(STAR_wt, vcov = &amp;quot;CR0&amp;quot;, 
            cluster = STAR_urban$schoolidk, 
            test = &amp;quot;z&amp;quot;,
            coefs = c(&amp;quot;readk:starksmall&amp;quot;,&amp;quot;mathk:starksmall&amp;quot;))
CR0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Coef. Estimate   SE t-stat p-val (z) Sig.
## 1 readk:starksmall     6.21 3.13   1.98    0.0473    *
## 2 mathk:starksmall    12.47 5.58   2.23    0.0254    *&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# clubSandwich SEs
CR2 &amp;lt;- 
  coef_test(STAR_wt, vcov = &amp;quot;CR2&amp;quot;, 
            cluster = STAR_urban$schoolidk, 
            coefs = c(&amp;quot;readk:starksmall&amp;quot;,&amp;quot;mathk:starksmall&amp;quot;))

CR2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Coef. Estimate   SE t-stat d.f. p-val (Satt) Sig.
## 1 readk:starksmall     6.21 2.70    2.3   19       0.0332    *
## 2 mathk:starksmall    12.47 4.79    2.6   19       0.0174    *&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’ll do it “by hand”—or rather, with a bit of &lt;code&gt;dplyr&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# summary statistics by site

school_summaries &amp;lt;- 
  STAR_urban %&amp;gt;%
  group_by(schoolidk, stark) %&amp;gt;%
  summarise(
    # means by arm and site
    readk = mean(readk),
    mathk = mean(mathk),
    n_arm = n()
  ) %&amp;gt;%
  summarise(
    # impact estimates by site
    readk = diff(readk),
    mathk = diff(mathk),
    n = sum(n_arm),
    p = n_arm[stark==&amp;quot;small&amp;quot;] / n
  ) %&amp;gt;%
  mutate(
    w = n
  )

# overall impacts

school_summaries %&amp;gt;%
  gather(&amp;quot;subject&amp;quot;,&amp;quot;impact_j&amp;quot;, readk, mathk) %&amp;gt;%
  group_by(subject) %&amp;gt;%
  summarise(
    impact = weighted.mean(impact_j, w = w),
    SE_CR0 = sqrt(sum(w^2 * (impact_j - impact)^2) / sum(w)^2),
    SE_CR2 = sqrt(sum(w^2 * (impact_j - impact)^2 / (1 - w / sum(w))) / sum(w)^2),
    df_CR2 = 1 / (sum(w^2 / (sum(w) - w)^2) - 
                    2 * sum(w^3 / (sum(w) - w)^2) / sum(w) + 
                    sum(w^2 / (sum(w) - w))^2 / sum(w)^2)
  ) %&amp;gt;%
  knitr::kable(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;subject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;impact&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SE_CR0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SE_CR2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df_CR2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mathk&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.47&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.58&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.76&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readk&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.13&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.23&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.07&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The CR0 and CR2 standard errors match the results from &lt;code&gt;coef_test&lt;/code&gt;, as do the Satterthwaite degrees of freedom. Note that the degrees of freedom are equal to 19 in this case, a bit less than &lt;span class=&#34;math inline&#34;&gt;\(J - 1 = 22\)&lt;/span&gt; due to variation in the weight assigned to each school.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A handmade clubSandwich for multi-site trials</title>
      <link>http://localhost:4321/handmade-clubsandwich/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/handmade-clubsandwich/</guid>
      <description>


&lt;p&gt;I’m just back from the &lt;a href=&#34;https://sree.org/conferences/2019s&#34;&gt;Society for Research on Educational Effectiveness&lt;/a&gt; meetings, where I presented work on small-sample corrections for cluster-robust variance estimators in two-stage least squares models, which I’ve implemented in the &lt;a href=&#34;http://localhost:4321/software/clubSandwich/&#34;&gt;&lt;code&gt;clubSandwich&lt;/code&gt;&lt;/a&gt; R package. &lt;a href=&#34;http://localhost:4321/files/SREE-2019-2SLS-CRVE.html&#34;&gt;Here’s my presentation&lt;/a&gt;. So I had “clubSandwich” estimators on the brain when a colleague asked me about whether the methods were implemented in SAS.&lt;/p&gt;
&lt;p&gt;The short answer is “no.”&lt;/p&gt;
&lt;p&gt;The moderately longer answer is “not unless we can find funding to pay someone who knows how to program properly in SAS.” However, for the specific model that my colleague was interested in, it turns out that the small-sample corrections implemented in clubSandwich can be expressed in closed form, and they’re simple enough that they could easily be hand-calculated. I’ll sketch out the calculations in the remainder of this post.&lt;/p&gt;
&lt;div id=&#34;a-multi-site-trial&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A multi-site trial&lt;/h2&gt;
&lt;p&gt;Consider a multi-site trial conducted across &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; sites, which we take as a sample from a larger super-population of sites. Each site consists of &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; units, of which &lt;span class=&#34;math inline&#34;&gt;\(p_j n_j\)&lt;/span&gt; are randomized to treatment and the remainder &lt;span class=&#34;math inline&#34;&gt;\((1 - p_j) n_j\)&lt;/span&gt; are randomized to control. For each unit &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in each site &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, we have an outcome &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}\)&lt;/span&gt; and a treatment indicator &lt;span class=&#34;math inline&#34;&gt;\(t_{ij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A conventional approach to estimating the overall average impact in this setting is to use a model with a treatment indicator and fixed effects for each site:
&lt;span class=&#34;math display&#34;&gt;\[
y_{ij} = \beta_j + \delta t_{ij} + e_{ij}
\]&lt;/span&gt;
and then to cluster the standard errors by site. Clustering by site makes sense here if (and only if) we’re interested in generalizing to the super-population of sites.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(\hat\delta_j\)&lt;/span&gt; denote the impact estimate from site &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, calculated as the difference in means between treated and untreated units at site &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\delta_j = \frac{1}{n_j p_j} \left(\sum_{i=1}^{n_j} t_{ij} y_{ij}\right) - \frac{1}{n_j (1 - p_j)} \left(\sum_{i=1}^{n_j} (1 - t_{ij}) y_{ij}\right).
\]&lt;/span&gt;
for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,..,J\)&lt;/span&gt;. The overall impact estimate here is a precision-weighted average of the site-specific impacts:
&lt;span class=&#34;math display&#34;&gt;\[
\hat\delta = \frac{1}{W} \sum_{j=1}^J w_j \hat\delta_j,
\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(w_j = n_j p_j (1 - p_j)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(W = \sum_j w_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sandwich-estimators&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sandwich estimators&lt;/h2&gt;
&lt;p&gt;The conventional clustered variance estimator (or sandwich estimator) for &lt;span class=&#34;math inline&#34;&gt;\(\hat\delta\)&lt;/span&gt; is a simple function of the (weighted) sample variance of the site-specific effects. It can be calculated directly as:
&lt;span class=&#34;math display&#34;&gt;\[
V^{CR0} = \frac{1}{W^2} \sum_{j=1}^J w_j^2 \left(\hat\delta_j - \hat\delta\right)^2.
\]&lt;/span&gt;
Under a conventional random effects model for the &lt;span class=&#34;math inline&#34;&gt;\(\delta_j\)&lt;/span&gt;s, this estimator has a downward bias in finite samples.&lt;/p&gt;
&lt;p&gt;The clubSandwich variance estimator here uses an estimator for the sample variance of site-specific effects that is unbiased under a certain working model. It is only slightly more complicated to calculate:
&lt;span class=&#34;math display&#34;&gt;\[
V^{CR2} = \frac{1}{W^2} \sum_{j=1}^J \frac{w_j^2 \left(\hat\delta_j - \hat\delta\right)^2}{1 - w_j / W}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The other difference between conventional methods and the clubSandwich approach is in the reference distribution used to calculate hypothesis tests and confidence intervals. The conventional approach uses a standard normal reference distribution (i.e., a z-test) that is asymptotically justified. The clubSandwich approach uses a &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; reference distribution, with degrees of freedom estimated using a Satterthwaite approximation. In the present context, the degrees of freedom are a little bit ugly but still not hard to calculate:
&lt;span class=&#34;math display&#34;&gt;\[
df = \left[\sum_{j=1}^J \frac{w_j^2}{(W - w_j)^2} - \frac{2}{W}\sum_{j=1}^J \frac{w_j^3}{(W - w_j)^2} + \frac{1}{W^2} \left(\sum_{j=1}^J \frac{w_j^2}{W - w_j} \right)^2 \right]^{-1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the special case that all sites are of the same size and use a constant treatment allocation, the weights become equal. The clubSandwich variance estimator then reduces to
&lt;span class=&#34;math display&#34;&gt;\[
V^{CR2} = \frac{S_\delta^2}{J} \qquad \text{where} \qquad S_\delta^2 = \frac{1}{J - 1}\sum_{j=1}^J \left(\hat\delta_j - \hat\delta\right)^2,
\]&lt;/span&gt;
and the degrees of freedom reduce to simply &lt;span class=&#34;math inline&#34;&gt;\(df = J - 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tennessee-star&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tennessee STAR&lt;/h2&gt;
&lt;p&gt;Here is a worked example of the calculations (using R of course, because my SAS programming skills atrophied years ago). I’ll use data from the famous Tennessee STAR class size experiment, which was a multi-site trial in which students were randomized to small or regular-sized kindergarten classes within each of several dozen schools. To make the small-sample issues more pronounced, I’ll limit the sample to urban schools and look at impacts of small class-size on reading and math scores at the end of kindergarten. STAR was actually a three-arm trial—the third arm being a regular-sized class but with an additional teacher aide. For simplicity (and following convention), I’ll collapse the teacher-aide condition and the regular-sized class condition into a single arm and also limit the sample to students with complete outcome data on both tests.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggplot2&amp;#39; was built under R version 4.0.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tibble&amp;#39; was built under R version 4.0.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;readr&amp;#39; was built under R version 4.0.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(STAR, package = &amp;quot;AER&amp;quot;)

STAR_urban &amp;lt;-
  STAR %&amp;gt;%
  filter(
    # limit to urban/inner city schools
    schoolk %in% c(&amp;quot;urban&amp;quot;,&amp;quot;inner-city&amp;quot;),
    # limit to complete outcome data
    !is.na(readk), !is.na(mathk)
  ) %&amp;gt;%
  droplevels() %&amp;gt;%
  # collapse control conditions
  mutate(stark = fct_collapse(stark, regular = c(&amp;quot;regular&amp;quot;,&amp;quot;regular+aide&amp;quot;))) %&amp;gt;%
  select(schoolidk, stark, readk, mathk)

STAR_summary &amp;lt;- 
  STAR_urban %&amp;gt;%
  count(schoolidk)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After these exclusions, the data include a total of 1810 students from 23 schools, ranging in size from 34 to 134 students.&lt;/p&gt;
&lt;p&gt;For starters, let’s get the average impacts using a seeming unrelated regression specification, with both conventional and clubSandwich standard errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;clubSandwich&amp;#39; was built under R version 4.0.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;STAR_fit &amp;lt;- lm(cbind(readk, mathk) ~ 0 + schoolidk + stark, data = STAR_urban)

# conventional SEs
CR0 &amp;lt;- 
  coef_test(STAR_fit, vcov = &amp;quot;CR0&amp;quot;, 
            cluster = STAR_urban$schoolidk, 
            test = &amp;quot;z&amp;quot;,
            coefs = c(&amp;quot;readk:starksmall&amp;quot;,&amp;quot;mathk:starksmall&amp;quot;))

CR0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Coef. Estimate   SE t-stat p-val (z) Sig.
## 1 readk:starksmall     6.16 2.73   2.25    0.0241    *
## 2 mathk:starksmall    12.13 4.79   2.53    0.0113    *&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# clubSandwich SEs
CR2 &amp;lt;- 
  coef_test(STAR_fit, vcov = &amp;quot;CR2&amp;quot;, 
            cluster = STAR_urban$schoolidk, 
            coefs = c(&amp;quot;readk:starksmall&amp;quot;,&amp;quot;mathk:starksmall&amp;quot;))

CR2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Coef. Estimate   SE t-stat d.f. p-val (Satt) Sig.
## 1 readk:starksmall     6.16 2.81   2.19   19       0.0409    *
## 2 mathk:starksmall    12.13 4.92   2.47   19       0.0234    *&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’ll do it “by hand”—or rather, with a bit of &lt;code&gt;dplyr&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# summary statistics by site

school_summaries &amp;lt;- 
  STAR_urban %&amp;gt;%
  group_by(schoolidk, stark) %&amp;gt;%
  summarise(
    # means by arm and site
    readk = mean(readk),
    mathk = mean(mathk),
    n_arm = n()
  ) %&amp;gt;%
  summarise(
    # impact estimates by site
    readk = diff(readk),
    mathk = diff(mathk),
    n = sum(n_arm),
    p = n_arm[stark==&amp;quot;small&amp;quot;] / n
  ) %&amp;gt;%
  mutate(w = n * p * (1 - p))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` regrouping output by &amp;#39;schoolidk&amp;#39; (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` ungrouping output (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# overall impacts

school_summaries %&amp;gt;%
  gather(&amp;quot;subject&amp;quot;,&amp;quot;impact_j&amp;quot;, readk, mathk) %&amp;gt;%
  group_by(subject) %&amp;gt;%
  summarise(
    impact = weighted.mean(impact_j, w = w),
    SE_CR0 = sqrt(sum(w^2 * (impact_j - impact)^2) / sum(w)^2),
    SE_CR2 = sqrt(sum(w^2 * (impact_j - impact)^2 / (1 - w / sum(w))) / sum(w)^2),
    df_CR2 = 1 / (sum(w^2 / (sum(w) - w)^2) - 
                    2 * sum(w^3 / (sum(w) - w)^2) / sum(w) + 
                    sum(w^2 / (sum(w) - w))^2 / sum(w)^2)
  ) %&amp;gt;%
  knitr::kable(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` ungrouping output (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;subject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;impact&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SE_CR0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SE_CR2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df_CR2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mathk&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.13&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.79&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.92&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;readk&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.73&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.81&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.99&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The CR0 and CR2 standard errors match the results from &lt;code&gt;coef_test&lt;/code&gt;, as do the Satterthwaite degrees of freedom. Note that the degrees of freedom are equal to 19 in this case, a bit less than &lt;span class=&#34;math inline&#34;&gt;\(J - 1 = 22\)&lt;/span&gt; due to variation in the weight assigned to each school.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-weights&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other weights&lt;/h2&gt;
&lt;p&gt;Some analysts might not like the approach of using precision-weighted average of the site-specific impacts, as I’ve examined here. Instead, one might choose to weight the site-specific effects by the site-specific sample sizes, or to use some sort of random effects weighting that allows for random heterogeneity across sites. The formulas given above for conventional and clubSandwich clustered variance estimators apply directly to other weighting schemes too. Just substitute your favorite weights in place of &lt;span class=&#34;math inline&#34;&gt;\(w_j\)&lt;/span&gt;. When doing so, the clubSandwich estimator will be exactly unbiased under the assumption that your preferred weighting scheme corresponds to inverse-variance weighting, and the Satterthwaite degrees of freedom approximation will be derived under the same model.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Small-sample cluster-robust variance estimators for two-stage least squares models</title>
      <link>http://localhost:4321/talk/sree-2019-2sls-crve/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sree-2019-2sls-crve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Testing for funnel plot asymmetry of standardized mean differences</title>
      <link>http://localhost:4321/publication/testing-for-funnel-plot-asymmetry-of-smds/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/testing-for-funnel-plot-asymmetry-of-smds/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>http://localhost:4321/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Effective sample size aggregation</title>
      <link>http://localhost:4321/effective-sample-size-aggregation/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/effective-sample-size-aggregation/</guid>
      <description>


&lt;p&gt;In settings with independent observations, sample size is one way to quickly characterize the precision of an estimate. But what if your estimate is based on &lt;em&gt;weighted&lt;/em&gt; data, where each observation doesn’t necessarily contribute to equally to the estimate? Here, one useful way to gauge the precision of an estimate is the &lt;em&gt;effective sample size&lt;/em&gt; or ESS. Suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; independent observations &lt;span class=&#34;math inline&#34;&gt;\(Y_1,...,Y_N\)&lt;/span&gt; drawn from a population with standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, and that observation &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; receives weight &lt;span class=&#34;math inline&#34;&gt;\(w_i\)&lt;/span&gt;. We take the weighted sample mean
&lt;span class=&#34;math display&#34;&gt;\[
\tilde{y} = \frac{1}{W} \sum_{i=1}^N w_i Y_i, \qquad \text{where} \qquad W = \sum_{i=1}^N w_i.
\]&lt;/span&gt;
with sampling variance
&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(\tilde{y}) = \frac{\sigma^2}{W^2} \sum_{i=1}^N w_i^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The ESS is the number of observations from an equally weighted sample that would yield the same level of precision as the weighted sample mean. In an equally weighted sample of size &lt;span class=&#34;math inline&#34;&gt;\(\tilde{N}\)&lt;/span&gt;, the variance would be simply &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 / \tilde{N}\)&lt;/span&gt;, and so ESS is the value of &lt;span class=&#34;math inline&#34;&gt;\(\tilde{N}\)&lt;/span&gt; that solves
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\sigma^2}{\tilde{N}} = \frac{\sigma^2}{W^2} \sum_{i=1}^N w_i^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Re-arranging, the ESS is thus defined as
&lt;span class=&#34;math display&#34;&gt;\[
\tilde{N} = \frac{W^2}{\sum_{i=1}^N w_i^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The ESS is reported in several packages for propensity score weighting, including &lt;a href=&#34;https://CRAN.R-project.org/package=twang&#34;&gt;twang&lt;/a&gt; and &lt;a href=&#34;https://CRAN.R-project.org/package=optweight&#34;&gt;optweight&lt;/a&gt;. In the propensity score context, ESS is a useful measure for comparing different sets of estimated propensity weights, in that weights (or propensity score models/matching methods) that have a larger ESS will yield a more precise estimate of a treatment effect. Given two sets of weights that achieve equivalent degrees of balance, the weights with larger ESS are thus preferable. Methods introduced by &lt;a href=&#34;https://doi.org/10.1080/01621459.2015.1023805&#34;&gt;Zubizarreta (2015)&lt;/a&gt;—and implemented in the &lt;a href=&#34;https://CRAN.R-project.org/package=optweight&#34;&gt;optweight&lt;/a&gt; package—take this logic a step further by using ESS as an objective function to be minimized, subject to specified balancing constraints.&lt;/p&gt;
&lt;div id=&#34;multi-site-effective-sample-size&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Multi-site effective sample size&lt;/h1&gt;
&lt;p&gt;Two of my recent projects have involved applying propensity score weighting methods in multi-site settings, where we are interested in estimating site-specific treatment effects as well as an overall aggregate effect. It is straight-forward to calculate an ESS for each site, but how then should we aggregate the ESS across sites to characterize the precision of the overall estimate? Several times now, I have found myself having to re-derive the aggregated ESS, and so I am going to work through it here now so as to save future-me (and perhaps you, dear reader) some time.&lt;/p&gt;
&lt;p&gt;Suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; sites, &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; observations from site &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt;, and total sample size &lt;span class=&#34;math inline&#34;&gt;\(N = \sum_{j=1}^J n_j\)&lt;/span&gt;. Observation &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from site &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; has outcome &lt;span class=&#34;math inline&#34;&gt;\(Y_{ij}\)&lt;/span&gt; and weight &lt;span class=&#34;math inline&#34;&gt;\(w_{ij}\)&lt;/span&gt;. The site-specific weighted average at site &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is then
&lt;span class=&#34;math display&#34;&gt;\[
\tilde{y}_j = \frac{1}{W_j} \sum_{i=1}^{n_j} w_{ij} Y_{ij}, \qquad \text{where} \qquad W_j = \sum_{i=1}^{n_j} w_{ij}
\]&lt;/span&gt;
and the overall average is
&lt;span class=&#34;math display&#34;&gt;\[
\tilde{y} = \frac{1}{N} \sum_{j=1}^J n_j \ \tilde{y}_j = \frac{1}{N} \sum_{j=1}^J \sum_{i=1}^{n_j} \frac{n_j w_{ij}}{W_j} Y_{ij}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For calculating the overall average, observation &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from unit &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; contributes weight &lt;span class=&#34;math inline&#34;&gt;\(u_{ij} = n_j w_{ij} / W_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Using these unit-specific weights, the effective sample size for the overall average is
&lt;span class=&#34;math display&#34;&gt;\[
ESS = \frac{N^2}{\sum_{j=1}^J \sum_{i=1}^{n_j} u_{ij}^2}.
\]&lt;/span&gt;
We can also define a site-specific ESS for site &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
ESS_j = \frac{W_j^2}{\sum_{i=1}^{n_j} w_{ij}^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Using the decomposition of the weights as &lt;span class=&#34;math inline&#34;&gt;\(u_{ij} = n_j w_{ij} / W_j\)&lt;/span&gt;, the overall ESS can be written as
&lt;span class=&#34;math display&#34;&gt;\[
ESS = \frac{N^2}{\sum_{j=1}^J n_j^2 \left(\sum_{i=1}^{n_j} w_{ij}^2 / W_j^2\right)}.
\]&lt;/span&gt;
Noting that the term in the parentheses of the denominator is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(1 / ESS_j\)&lt;/span&gt;, the overall ESS can therefore be written in terms of the site-specific ESSs and sample sizes:
&lt;span class=&#34;math display&#34;&gt;\[
ESS = \frac{N^2}{\sum_{j=1}^J n_j^2 / ESS_j}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;There you go. Future me will thank me for this!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Current practices in meta-regression in psychology, education, and medicine</title>
      <link>http://localhost:4321/publication/current-practices-in-meta-regression/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/current-practices-in-meta-regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A history of meta-regression: Technical, conceptual, and practical developments between 1974 and 2018</title>
      <link>http://localhost:4321/publication/history-of-meta-regression/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/history-of-meta-regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small sample methods for cluster-robust variance estimation and hypothesis testing in fixed effects models</title>
      <link>http://localhost:4321/publication/rve-in-fixed-effects-models/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/rve-in-fixed-effects-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Combining robust variance estimation with models for dependent effect sizes</title>
      <link>http://localhost:4321/talk/utaustin-2018-combining-rve-with-models/</link>
      <pubDate>Mon, 01 Oct 2018 12:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/utaustin-2018-combining-rve-with-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Combining robust variance estimation with models for dependent effect sizes</title>
      <link>http://localhost:4321/talk/srsm-2018-combining-rve-with-models/</link>
      <pubDate>Wed, 18 Jul 2018 09:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/srsm-2018-combining-rve-with-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>http://localhost:4321/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>http://localhost:4321/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>http://localhost:4321/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>http://localhost:4321/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Easily simulate thousands of single-case designs</title>
      <link>http://localhost:4321/easily-simulate-thousands-of-single-case-designs/</link>
      <pubDate>Thu, 21 Jun 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/easily-simulate-thousands-of-single-case-designs/</guid>
      <description>


&lt;p&gt;Earlier this month, I taught at the &lt;a href=&#34;https://scdinstitute2018.com/&#34;&gt;Summer Research Training Institute on Single-Case Intervention Design and Analysis workshop&lt;/a&gt;, sponsored by the Institute of Education Sciences’ National Center for Special Education Research.
While I was there, I shared &lt;a href=&#34;https://jepusto.shinyapps.io/ARPsimulator/&#34;&gt;a web-app for simulating data from a single-case design&lt;/a&gt;.
This is a tool that I put together a couple of years ago as part of my &lt;a href=&#34;http://localhost:4321/software/arpobservation/&#34;&gt;ARPobservation R package&lt;/a&gt;, but haven’t ever really publicized or done anything formal with.
It provides an easy way to simulate “mock” data from a single-case design where the dependent variable is measured using systematic direct observation of behavior.
The simulated data can be viewed in the form of a graph or downloaded as a csv file.
And it’s quite fast—simulating 1000’s of mock single-case designs takes only a few seconds.
The tool also provides a visualization of the distribution of effect size estimates that you could anticipate observing in a single-case design, given a set of assumptions about how the dependent variable is measured and how it changes in response to treatment.&lt;/p&gt;
&lt;div id=&#34;demo&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Demo&lt;/h1&gt;
&lt;p&gt;Here’s an example of the sort of data that the tool generates and the assumptions it asks you to make.
Say that you’re interested in evaluating the effect of a Social Stories intervention on the behavior of a child with autism spectrum disorder, and that you plan to use a treatment reversal design.
Your primary dependent variable is inappropriate play behavior, measured using frequency counts over ten minute observation sessions.&lt;br /&gt;
The initial baseline and treatment phases will be 7 sessions long.
At baseline, the child engages in inappropriate play at a rate of about 0.8 per minute.
You anticipate that the intervention could reduce inappropriate play by as much as 90% from baseline.
Enter all of these details and assumptions into the simulator, and it will generate a graph like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-A.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hit the “Simulate!” button again and you might get something like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-B.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Or one of these:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-C.png&#34; /&gt;
&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-A.png&#34; /&gt;
&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-A.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-D.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-E.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All of the above graphs were generated from the same hypothetical model—the variation in the clarity and strength of the functional relation is due to random error alone.
The simulator can also produce graphs that show multiple realizations of the data-generating process. Here’s one with five replications:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-5.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here’s the same figure, but with trend lines added:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/img/Crozier-Tincani-simulated-data-trend.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The trend lines represent the overall average level of the dependent variable during each session, across infinitely replications of the study.
The variability around the trend line provides a sense of the extent of random error in the measurements of the dependent variable.&lt;/p&gt;
&lt;p&gt;I think it’s a rather interesting exercise to try and draw inferences based on visual inspection of randomly generated graphs like this—particularly because it forces you to grapple with random measurement error in a way that using only real data (or only hand-drawn mock data) doesn’t allow.
It seems like it could really help a visual analyst to calibrate their interpretations of single-case graphs with visually apparent time trends, outliers, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-cases&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Use cases&lt;/h1&gt;
&lt;p&gt;So far, this tool is really only a toy—something that I’ve puttered with off and on for a while, but never developed or applied for any substantive purpose.
However, it occurs to me that it (or something similar to it) might have a number of purposes related to planning single-case studies, studying the process of visual inspection, or training single-case researchers.&lt;/p&gt;
&lt;p&gt;When I originally put the tool together, the leading case I imagined was to use the tool to help researchers make principled decisions about how to measure dependent variables in single-case designs.
By using the tool to simulate hypothetical single-case studies, a researcher would be able to experiment with different measurement strategies—such as using partial interval recording instead of continuous duration recording, using shorter or longer observation sessions, or using short or longer baseline phases—before collecting data on real-life behavior in the field.
I’m not sure if this is something that well-trained single-case researchers would actually find helpful, but it seems like it might help a novice (like me!) to temper one’s expectations or to move towards a more reliable measurement system.&lt;/p&gt;
&lt;p&gt;There’s been quite a bit of research examining the reliability and error rates of inferences based on visual inspection (see &lt;a href=&#34;http://dx.doi.org/10.1037/14376-004&#34;&gt;Chapter 4 of Kratochwill &amp;amp; Levin, 2014&lt;/a&gt; for a review of some of this literature).
Some of this work has compared the inferences drawn by novices versus experts or by un-aided visual inspection versus visual inspection supplemented with graphical guides (like trend lines).
But there are many other factors that could be investigated too, such as phase lengths (this could help to better justify the WWC single-case design standards around minimum phase lengths), use of different measurement systems, or use of different design elements on single-case graphs (can we get some color on these graphs, folks?!? And stop plotting 14 different dependent variables on the same graph?!?).
The simulator would be an easy way to generate the stimuli one would need to do this sort of work.&lt;/p&gt;
&lt;p&gt;A closely related use-case is to generate stimuli for training researchers to do systematic visual inspection.
Some of the SCD Institute instructors (including Tom Kratochwill, Rob Horner, Joel Levin, along with some of their other colleagues) have developed the website &lt;a href=&#34;http://www.singlecase.org&#34;&gt;www.singlecase.org&lt;/a&gt; with a bunch of exercises meant to help researchers develop and test their visual analysis skills.
It looks to me like the site uses simulated data (though I’m not entirely sure).
The ARPsimulator tool could be used to do something similar, but based on a data-generating process that captures many of the features of systematic direct observation data.
This might let researchers test their skills under more challenging and ambiguous, yet plausible, conditions, similar to what they will encounter when collecting real data in the field.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;future-directions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Future directions&lt;/h1&gt;
&lt;p&gt;A number of future directions for this project have crossed my mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Currently, the outcome data are simulated as independent across observation sessions (given the true time trend). It wouldn’t be too hard to add a further option to generate auto-correlated data, although this would further increase the complexity of the model. Perhaps there would be a way to add this as an “advanced” option that would be concealed unless the user asks for it (i.e., “Are you Really Sure you want to go down this rabbit hole?”). So far, I have avoided adding these features because I’m not sure what reasonable defaults would be.&lt;/li&gt;
&lt;li&gt;Joel Levin, John Ferron, and some of the other SCD Institute instructors are big proponents of incorporating randomization procedures into the design of single-case studies, at least when circumstances allow. Currently, the ARPsimulator generates data based on a fixed, pre-specified design, such as an ABAB design with 6 sessions per phase or a multiple baseline design with 25 sessions total and intervention start-times of 8, 14, and 20. It wouldn’t be too hard to incorporate randomized phase-changes into the simulator. This might make a nice, contained project for a student who wants to learn more about randomization designs.&lt;/li&gt;
&lt;li&gt;Along similar lines, John Ferron has &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.3200/JEXE.75.1.66-81&#34;&gt;developed&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.1002/jaba.410&#34;&gt;evaluated&lt;/a&gt; masked visual analysis procedures, which blend randomization and traditional response-guided approaches to designing single-case studies. It would take a bit more work, but it would be pretty nifty to incorporate these designs into ARPsimulator too.&lt;/li&gt;
&lt;li&gt;Currently, the model behind ARPsimulator asks the user to specify a fixed baseline level of behavior, and this level of behavior is used for every simulated case—even in designs involving multiple cases. A more realistic (albeit more complicated) data-generating model would allow for between-case variation in the baseline level of behavior.&lt;/li&gt;
&lt;li&gt;Perhaps the most important outstanding question about the premise of this work is just how well the alternating renewal process model captures the features of real single-case data. Validating the model against empirical data from single-case studies would allow use to assess whether it is really a realistic approach to simulation, at least for certain classes of behavior. Another product of such an investigation would be to develop realistic default assumptions for the model’s parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the moment I have no plans to implement any of these unless there’s a reasonably focused need (sadly, I don’t have time to putter and putz to the same extent that I used to).
If you, dear reader, would be interested in helping to pursue any of these directions, or if you have other, better ideas for how to make use of this tool, I would love to hear from you.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Between-case standardized effect size analysis of single case design: Examination of the two methods</title>
      <link>http://localhost:4321/publication/bcsmd-examination-of-two-methods/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/bcsmd-examination-of-two-methods/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New paper: A gradual effects model for single-case designs</title>
      <link>http://localhost:4321/gradual-effects-model-paper/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/gradual-effects-model-paper/</guid>
      <description>


&lt;p&gt;I’m very happy to share a new paper, co-authored with my student Danny Swan, “A gradual effects model for single-case designs,” which is now available online at &lt;em&gt;Multivariate Behavioral Research&lt;/em&gt;. You can access the published version &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1080/00273171.2018.1466681?journalCode=hmbr20&#34;&gt;at the journal website&lt;/a&gt; (&lt;a href=&#34;https://www.tandfonline.com/eprint/dkVfazwZaxnyaa9MfUjw/full&#34;&gt;click here for free access while supplies last&lt;/a&gt;) or &lt;a href=&#34;https://psyarxiv.com/vh964/&#34;&gt;the pre-print on PsyArxiv&lt;/a&gt; (always free!). Here’s &lt;a href=&#34;http://localhost:4321/publication/gradual-effects-model&#34;&gt;the abstract&lt;/a&gt; and &lt;a href=&#34;https://osf.io/uzkq6/&#34;&gt;the supplementary materials&lt;/a&gt;. Danny wrote R functions for fitting the model, (available as part of the &lt;a href=&#34;http://localhost:4321/software/singlecasees/&#34;&gt;SingleCaseES package&lt;/a&gt;) as well as a &lt;a href=&#34;https://jepusto.shinyapps.io/gem-scd/&#34;&gt;slick web interface&lt;/a&gt;, if you prefer to point-and-click.&lt;/p&gt;
&lt;p&gt;This paper grew out of Danny’s qualifying process (QP), which is the major exam that our doctoral students have to pass before they can begin their dissertation work. For the QP, students work with a faculty advisor to develop an extensive literature review and proposal for an original research project. They produce a written research proposal, then take written and oral exams on their work. For Danny’s QP, he picked up one of the many loose ends in &lt;a href=&#34;http://localhost:4321/publication/operationally-comparable-effect-sizes&#34;&gt;my dissertation&lt;/a&gt;, studied up on generalized linear models to understand how to express and fit the model, and developed a simulation study evaluating the model. After he successfully passed his QP, we worked together to refine the estimation methods and the simulation design, and then draft a manuscript (much of it cribbed from his QP proposal). I’m very proud and pleased that Danny continued to develop the work and saw it through to a first-authored publication.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Causal Inference</title>
      <link>http://localhost:4321/teaching/causal-inference/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/teaching/causal-inference/</guid>
      <description>&lt;p&gt;This course introduces the contemporary statistical approach to addressing questions about the causal effects of programs, policies, or interventions, with a focus on applied data-analysis strategies and interpretation. The course begins with an introduction to the potential outcomes framework for expressing causal quantities, followed by an examination of (idealized) simple and block randomized experiments as prototypes for learning about causal effects. The remainder of the course covers theory and data-analysis strategies for drawing causal inferences from observational studies, in which treatment conditions are not randomly assigned. Analysis techniques such as matching methods, propensity-score methods, and instrumental variables are covered both in theory and in application. Further, advanced topics are covered based on student interest.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP-381C-10930-Causal-inference-2020S.pdf&#34;&gt;2020 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP-381C-10705-Causal-inference-2017F.pdf&#34;&gt;2017 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP-384-25-Causal-inference-2014F-syllabus.pdf&#34;&gt;2014 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Data Analysis, Simulation, and Programming in R</title>
      <link>http://localhost:4321/teaching/daspir/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/teaching/daspir/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;For a long time I have thought I was a statistician, interested in inferences from the particular to the general. But as I have watched mathematical statistics evolve, I have had cause to wonder and to doubt…. All in all, I have come to feel that my central interest is in data analysis, which I take to include, among other things: procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data. [Tukey, J., 1962. The future of data analysis. &lt;em&gt;The Annals of Mathematical Statistics, 33&lt;/em&gt;(1), 1–67.]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This course provides training in using the open-source statistical programming environment called R to accomplish 1) real-world, reproducible data analysis and 2) design and implementation of statistical simulations, which are an important tool for evaluating the performance of statistical estimation and inference procedures. Topics covered include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the logic of R’s primary data structures and how to work with functions&lt;/li&gt;
&lt;li&gt;tools and best practices for accessing, cleaning, and manipulating data&lt;/li&gt;
&lt;li&gt;reproducibility as a fundamental tenet of high-quality data analysis&lt;/li&gt;
&lt;li&gt;data visualization techniques&lt;/li&gt;
&lt;li&gt;selected statistical models and methods that are useful for data-analysis, including linear regression models and generalized linear models.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Content relevant to designing and implementing Monte Carlo simulation studies is interwoven throughout the course.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP380C-20-10745-Data-Analysis-Simulation-and-Programming-in-R-2019S.pdf&#34;&gt;2019 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP384-10875-Data-Analysis-Simulation-and-Programming-in-R-2017S.pdf&#34;&gt;2017 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP384-10585-Data-Analysis-Simulation-and-Programming-in-R-2015S.pdf&#34;&gt;2015 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Research Design and Methods for Psychology and Education</title>
      <link>http://localhost:4321/teaching/research-design/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/teaching/research-design/</guid>
      <description>&lt;p&gt;This course surveys essential concepts and methods used in quantitative empirical research in the fields of education and psychology, in order to prepare students both to be informed consumers of research and to conduct empirical research of their own. The course is organized around four main themes: measurement, populations and sampling, experimental causal research, and quasi-experimental causal research. On each theme, we read relevant theoretical and methodological literature, discuss empirical research in light of those concepts, and develop research proposals using the methods that we discuss. Throughout, emphasis is on building intuition and heuristics regarding research designs and methods.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10575-Research-Design-2019F.pdf&#34;&gt;2019 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10775-Research-Design-2019S.pdf&#34;&gt;2019 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10540-Research-Design-2018F.pdf&#34;&gt;2018 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10200-Research-Design-2018S.pdf&#34;&gt;2018 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10895-Research-Design-2017S.pdf&#34;&gt;2017 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10770-Research-Design-2016F.pdf&#34;&gt;2016 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10790-Research-Design-2016S.pdf&#34;&gt;2016 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP381C-2-10790-Research-Design-2015F.pdf&#34;&gt;2015 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP384-10594-Research-Design-2015S.pdf&#34;&gt;2015 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP384-10977-Research-Design-2014F.pdf&#34;&gt;2014 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP384-11212-Research-Design-2014S.pdf&#34;&gt;2014 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP384-10615-Research-Design-2013F.pdf&#34;&gt;2013 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Statistical Analysis of Experimental Data</title>
      <link>http://localhost:4321/teaching/experimental-data/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/teaching/experimental-data/</guid>
      <description>&lt;p&gt;This course covers the principles and procedures involved in analyzing data from experimental designs. Approaches for analyzing simple (one-way) designs, factorial designs, and repeated measures designs are presented using the analysis of variance (ANOVA) framework. Lectures focus on developing conceptual understanding of the experimental designs and corresponding analytical models and on interpreting the results of analysis procedures. Laboratory sections focus on using statistical software for data analysis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP380C-6-Statistical-Analysis-of-Experimental-Data-2016S.pdf&#34;&gt;2016 (Spring) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/files/syllabi/EDP380C-6-Statistical-Analysis-of-Experimental-Data-2015F.pdf&#34;&gt;2015 (Fall) Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A gradual effects model for single-case designs</title>
      <link>http://localhost:4321/publication/gradual-effects-model/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/gradual-effects-model/</guid>
      <description></description>
    </item>
    
    <item>
      <title>clubSandwich at the Austin R User Group Meetup</title>
      <link>http://localhost:4321/clubsandwich-at-rug/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/clubsandwich-at-rug/</guid>
      <description>


&lt;p&gt;Last night I attended a joint meetup between the &lt;a href=&#34;https://www.meetup.com/Austin-R-User-Group/&#34;&gt;Austin R User Group&lt;/a&gt; and &lt;a href=&#34;https://www.meetup.com/rladies-austin/&#34;&gt;R Ladies Austin&lt;/a&gt;, which was great fun. The evening featured several lightning talks on a range of topics, from breaking into data science to network visualization to starting your own blog. I gave a talk about sandwich standard errors and my &lt;a href=&#34;http://localhost:4321/software/clubsandwich&#34;&gt;clubSandwich R package&lt;/a&gt;. Here are links to some of the talks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/beeonaposy&#34;&gt;Caitlin Hudon&lt;/a&gt;: &lt;a href=&#34;https://www.slideshare.net/CaitlinGarrett1/getting-plugged-into-data-science-87767332&#34;&gt;Getting Plugged into Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/clairemcwhite&#34;&gt;Claire McWhite&lt;/a&gt;: &lt;a href=&#34;https://speakerdeck.com/clairemcwhite/a-quick-intro-to-networks&#34;&gt;A quick intro to networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/NathanielRaley&#34;&gt;Nathaniel Woodward&lt;/a&gt;: &lt;a href=&#34;http://goo.gl/vJs8kD&#34;&gt;Blogdown Demo!&lt;/a&gt; (link includes his slides and a demo screencast)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/jepusto&#34;&gt;me&lt;/a&gt;: &lt;a href=&#34;http://localhost:4321/files/clubSandwich.html&#34;&gt;Robust, easy standard errors with the clubSandwich package&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Sampling variance of Pearson r in a two-level design</title>
      <link>http://localhost:4321/variance-of-r-in-two-level-design/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/variance-of-r-in-two-level-design/</guid>
      <description>


&lt;p&gt;Consider Pearson’s correlation coefficient, &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;, calculated from two variables &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; with population correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. If one calculates &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; from a simple random sample of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; observations, then its sampling variance will be approximately&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(r) \approx \frac{1}{N}\left(1 - \rho^2\right)^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;But what if the observations are drawn from a multi-stage sample? If one uses the raw correlation between the observations (ignoring the multi-level structure), then the &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; will actually be a weighted average of within-cluster and between-cluster correlations (see Snijders &amp;amp; Bosker, 2012). Intuitively, I would expect that the sampling variance of the between-cluster correlation will be a function of the number of clusters (regardless of the number of observations per cluster), so the variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; from a multi-stage sample would not necessarily be the same as that from a simple random sample. What is the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; in this design?&lt;/p&gt;
&lt;p&gt;Let me be more precise here by formalizing the sampling process. Suppose that we have a sample with &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; clusters, &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; observations in cluster &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and total sample size &lt;span class=&#34;math inline&#34;&gt;\(N = \sum_{j=1}^m n_j\)&lt;/span&gt;. Assume that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
X_{ij} &amp;amp;= \mu_x + v^x_j + e^x_{ij} \\
Y_{ij} &amp;amp;= \mu_y + v^y_j + e^y_{ij},
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(i=1,...,n_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j=1,...,m\)&lt;/span&gt;, where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\left[\begin{array}{c} v^x_j \\ v^y_j \end{array}\right] &amp;amp;\sim N\left(\left[\begin{array}{c}0 \\ 0 \end{array}\right], \left[\begin{array}{cc}\omega_x^2 &amp;amp; \phi \omega_x \omega_y \\ \phi \omega_x \omega_y &amp;amp; \omega_y^2\end{array}\right]\right) \\ 
\left[\begin{array}{c} e^x_{ij} \\ e^y_{ij} \end{array}\right] &amp;amp;\sim N\left(\left[\begin{array}{c}0 \\ 0 \end{array}\right], \left[\begin{array}{cc}\sigma_x^2 &amp;amp; \rho \sigma_x \sigma_y \\ \rho \sigma_x \sigma_y &amp;amp; \sigma_y^2\end{array}\right]\right)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the error terms are mutually independent unless otherwise noted. The raw Pearson’s &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is calculated using the total sums of squares and cross-products:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
r = \frac{SS_{xy}}{\sqrt{SS_{xx} SS_{yy}}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
SS_{xx} &amp;amp;= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(X_{ij} - \bar{\bar{x}}\right)^2, \qquad \bar{\bar{x}} = \frac{1}{N} \sum_{j=1}^m \sum_{i=1}^{n_j} X_{ij} \\
SS_{xy} &amp;amp;= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(Y_{ij} - \bar{\bar{y}}\right)^2, \qquad \bar{\bar{y}} = \frac{1}{N} \sum_{j=1}^m \sum_{i=1}^{n_j} Y_{ij} \\
SS_{xy} &amp;amp;= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(X_{ij} - \bar{\bar{x}}\right) \left(Y_{ij} - \bar{\bar{y}}\right).
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;common-correlation-and-icc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Common correlation and ICC&lt;/h3&gt;
&lt;p&gt;The distribution of the total correlation seems to be pretty complicated. So far, I’ve been able to obtain the variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; for a special case that makes some further, fairly restrictive assumptions. Specifically, assume that the correlation is constant across the two levels, so that &lt;span class=&#34;math inline&#34;&gt;\(\phi = \rho\)&lt;/span&gt;, and that the intra-class correlation of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is the same as that of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(k = \omega_x^2 / \sigma_x^2 = \omega_y^2 / \sigma_y^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\psi = k / (k + 1) = \omega_x^2 / (\omega_x^2 + \sigma_x^2)\)&lt;/span&gt;. Then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(r) \approx \frac{(1 - \rho^2)^2}{\tilde{N}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{N} = \frac{N[g_1 k + 1]^2}{g_2 k^2 + 2 g_1 k + 1} \approx \frac{N}{1 + (g_2 - g_1^2)\psi^2},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{g_1 = 1 - \frac{1}{N^2}\sum_{j=1}^m n_j^2}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{g_2 = \frac{1}{N}\sum_{j=1}^m n_j^2 - \frac{2}{N^2}\sum_{j=1}^m n_j^3 + \frac{1}{N^3} \left(\sum_{j=1}^m n_j^2 \right)^2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;If the clusters are all of equal size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{N} = \frac{nm[k(m - 1) / m + 1]^2}{k^2 n (m - 1)/m + 2 k (m - 1) / m + 1} \approx \frac{N}{1 + (n - 1) \psi^2},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The right-hand expression is a further approximation that will be very close to right so long as &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; is not too too small.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;z-transformation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Z-transformation&lt;/h3&gt;
&lt;p&gt;Under the (restrictive) assumptions of common correlation and equal ICCs, Fisher’s z transformation is variance-stabilizing (as it is under simple random sampling), so it seems reasonable to use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(z(r)\right) \approx \frac{1}{\tilde{N} - 3}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;design-effect&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Design effect&lt;/h3&gt;
&lt;p&gt;The design effect (&lt;span class=&#34;math inline&#34;&gt;\(DEF\)&lt;/span&gt;) is the ratio of the actual sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; to the sampling variance in a simple random sample of the same size. For the special case that I’ve described,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
DEF = \frac{N}{\tilde{N}} = 1 + (g_2 - g_1^2) \psi^2,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or with equal cluster-sizes, &lt;span class=&#34;math inline&#34;&gt;\(DEF = 1 + (n - 1)\psi^2\)&lt;/span&gt;. These expressions make it clear that the design effect for the correlation is &lt;em&gt;not&lt;/em&gt; equivalent to the well-known design effect for means or mean differences in cluster-randomized designs, which is &lt;span class=&#34;math inline&#34;&gt;\(1 + (n - 1)\psi\)&lt;/span&gt;. We need to take the &lt;em&gt;square&lt;/em&gt; of the ICC here, which will make the design effect for &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; &lt;em&gt;smaller&lt;/em&gt; than the design effect for a mean (or difference in means) based on the same sample.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-special-cases&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other special cases&lt;/h3&gt;
&lt;p&gt;There are some further special cases that are not to hard to work out and could be useful as rough approximations at least. One is if the within-cluster correlation is zero &lt;span class=&#34;math inline&#34;&gt;\((\rho = 0)\)&lt;/span&gt; and we’re interested in the between-cluster correlation &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. Then the total correlation can be corrected for what is essentially measurement error using formulas from &lt;a href=&#34;https://www.amazon.com/Methods-Meta-Analysis-Correcting-Research-Findings/dp/141290479X&#34;&gt;Hunter and Schmidt (2004)&lt;/a&gt;. A further specialization is if &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is a cluster-level measure, so that &lt;span class=&#34;math inline&#34;&gt;\(\sigma_x^2 = 0\)&lt;/span&gt;. I’ll consider these in a later post, perhaps.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Meta-analysis of dependent effects: A review and consolidation of methods</title>
      <link>http://localhost:4321/talk/aera-2018-dependent-effects/</link>
      <pubDate>Sun, 15 Apr 2018 08:15:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2018-dependent-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meta-analysis of single-case research: A brief and breezy tour</title>
      <link>http://localhost:4321/talk/aera-2018-meta-analysis-of-single-case-research/</link>
      <pubDate>Sun, 15 Apr 2018 08:15:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2018-meta-analysis-of-single-case-research/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The multivariate delta method</title>
      <link>http://localhost:4321/multivariate-delta-method/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/multivariate-delta-method/</guid>
      <description>


&lt;p&gt;The delta method is surely one of the most useful techniques in classical statistical theory. It’s perhaps a bit odd to put it this way, but I would say that the delta method is something like the precursor to the bootstrap, in terms of its utility and broad range of applications—both are “first-line” tools for solving statistical problems. There are many good references on the delta-method, ranging from &lt;a href=&#34;https://en.wikipedia.org/wiki/Delta_method&#34;&gt;the Wikipedia page&lt;/a&gt; to a short introduction in &lt;em&gt;The American Statistician&lt;/em&gt; (&lt;a href=&#34;https://doi.org/10.1080%2F00031305.1992.10475842&#34;&gt;Oehlert, 1992&lt;/a&gt;). Many statistical theory textbooks also include a longer or shorter discussion of the method (e.g., Stuart &amp;amp; Ord, 1996; Casella &amp;amp; Berger, 2002).&lt;/p&gt;
&lt;p&gt;I use the delta method all the time in my work, especially to derive approximations to the sampling variance of some estimator (or covariance between two estimators). Here I’ll give one formulation of the multivariate delta method that I find particularly useful for this purpose. (This is nothing at all original. I’m only posting it on the off chance that others might find my crib notes helpful—and by “others” I mostly mean myself in six months…)&lt;/p&gt;
&lt;div id=&#34;multi-variate-delta-method-covariances&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multi-variate delta method covariances&lt;/h3&gt;
&lt;p&gt;Suppose that we have a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-dimensional vector of statistics &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T} = \left(T_1,...,T_p \right)\)&lt;/span&gt; that converge in distribution to the parameter vector &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta = \left(\theta_1,...,\theta_p\right)\)&lt;/span&gt; and have asymptotic covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma / n\)&lt;/span&gt;, i.e.,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sqrt{n} \left(\mathbf{T} - \boldsymbol\theta\right) \stackrel{D}{\rightarrow} N\left( \mathbf{0}, \boldsymbol\Sigma \right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now consider two functions &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;, both of which take vectors as inputs, return scalar quantities, and don’t have funky (discontinuous) derivatives. The asymptotic covariance between &lt;span class=&#34;math inline&#34;&gt;\(f(\mathbf{T})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(g(\mathbf{T})\)&lt;/span&gt; is then approximately&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Cov} \left(f(\mathbf{T}), g(\mathbf{T}) \right) \approx \frac{1}{n} \sum_{j=1}^p \sum_{k=1}^p  \frac{\partial f}{ \partial \theta_j}\frac{\partial g}{ \partial \theta_k}\sigma_{jk}, 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{jk}\)&lt;/span&gt; is the entry in row &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and column &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; of the matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma\)&lt;/span&gt;. If the entries of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt; are asymptotically uncorrelated , then this simplifies to&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Cov} \left(f(\mathbf{T}), g(\mathbf{T}) \right) \approx \frac{1}{n} \sum_{j=1}^p \frac{\partial f}{ \partial \theta_j}\frac{\partial g}{ \partial \theta_j} \sigma_{jj}. 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we are interested in the variance of a single statistic, then the above formulas simplify further to&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var} \left(f(\mathbf{T})\right) \approx \frac{1}{n} \sum_{j=1}^p \sum_{k=1}^p  \frac{\partial f}{ \partial \theta_j}\frac{\partial f}{ \partial \theta_k}\sigma_{jk} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var} \left(f(\mathbf{T}) \right) \approx \frac{1}{n}\sum_{j=1}^p \left(\frac{\partial f}{ \partial \theta_j}\right)^2 \sigma_{jj}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;in the case of uncorrelated &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, if we are dealing with a univariate transformation &lt;span class=&#34;math inline&#34;&gt;\(f(\theta)\)&lt;/span&gt;, then of course the above simplifies even further to&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(f(T)\right) = \left(\frac{\partial f}{\partial \theta}\right)^2 \text{Var}(T)
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pearsons-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Pearson’s &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;These formulas are useful for all sorts of things. For example, they can be used to derive the sampling variance of Pearson’s correlation coefficient. Suppose we have a simple random sample of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations from a multivariate normal distribution with mean 0 and variance-covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Phi = \left[\begin{array}{cc}\phi_{xx} &amp;amp; \phi_{xy} \\ \phi_{xy} &amp;amp; \phi_{yy} \end{array}\right]\)&lt;/span&gt;. Pearson’s correlation is calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
r = \frac{s_{xy}}{\sqrt{s_{xx} s_{yy}}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(s_{xx}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_{yy}\)&lt;/span&gt; are sample variances and &lt;span class=&#34;math inline&#34;&gt;\(s_{xy}\)&lt;/span&gt; is the sample covariance. These sample variances and covariances are unbiased estimates of &lt;span class=&#34;math inline&#34;&gt;\(\phi_{xx}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\phi_{yy}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\phi_{xy}\)&lt;/span&gt;, respectively. So in terms of the above notation, we have &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T} = \left(s_{xx}, s_{yy}, s_{xy}\right)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta = \left(\phi_{xx}, \phi_{yy}, \phi_{xy}\right)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\rho = \phi_{xy} / \sqrt{\phi_{xx} \phi_{yy}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;From &lt;a href=&#34;http://localhost:4321/distribution-of-sample-variances&#34;&gt;a previous post&lt;/a&gt;, we can work out the variance-covariance matrix of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(\sqrt{n - 1} \left[\begin{array}{c} s_{xx} \\ s_{yy} \\ s_{xy}\end{array}\right]\right) = \boldsymbol\Sigma = \left[\begin{array}{ccc} 2 \phi_{xx}^2 &amp;amp; &amp;amp; \\ 2 \phi_{xy}^2 &amp;amp; 2 \phi_{yy}^2 &amp;amp; \\ 2 \phi_{xy} \phi_{xx} &amp;amp; 2 \phi_{xy} \phi_{yy} &amp;amp; \phi_{xy}^2 + \phi_{xx} \phi_{yy}\end{array}\right].
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The last piece is to find the derivatives of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; with respect to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{T}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{\partial r}{\partial \phi_{xy}} &amp;amp;= \phi_{xx}^{-1/2} \phi_{yy}^{-1/2} \\
\frac{\partial r}{\partial \phi_{xx}} &amp;amp;= -\frac{1}{2} \phi_{xy} \phi_{xx}^{-3/2} \phi_{yy}^{-1/2} \\
\frac{\partial r}{\partial \phi_{yy}} &amp;amp;= -\frac{1}{2} \phi_{xy} \phi_{xx}^{-1/2} \phi_{yy}^{-3/2}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Putting the pieces together, we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
(n - 1) \text{Var}(r) &amp;amp;\approx \sigma_{11} \left(\frac{\partial r}{\partial \phi_{xy}}\right)^2 + \sigma_{22} \left(\frac{\partial r}{ \partial \phi_{xx}}\right)^2 + \sigma_{33} \left(\frac{\partial r}{ \partial \phi_{yy}}\right)^2 \\
&amp;amp; \qquad \qquad + 2 \sigma_{12} \frac{\partial r}{\partial \phi_{xy}}\frac{\partial r}{\partial \phi_{xx}} + 2 \sigma_{13} \frac{\partial r}{\partial \phi_{xy}}\frac{\partial r}{\partial \phi_{yy}}+ 2 \sigma_{23} \frac{\partial r}{\partial \phi_{xx}}\frac{\partial r}{\partial \phi_{yy}} \\
&amp;amp;= \frac{\phi_{xy}^2 + \phi_{xx} \phi_{yy}}{\phi_{xx} \phi_{yy}} + \frac{\phi_{xy}^2\phi_{xx}^2}{2 \phi_{xx}^3 \phi_{yy}} + \frac{\phi_{xy}^2\phi_{yy}^2}{2 \phi_{xx} \phi_{yy}^3} \\
&amp;amp; \qquad \qquad - \frac{2\phi_{xy} \phi_{xx}}{\phi_{xx}^2 \phi_{yy}} - \frac{2\phi_{xy} \phi_{yy}}{\phi_{xx} \phi_{yy}^2} + \frac{\phi_{xy}^4}{\phi_{xx}^2 \phi_{yy}^2} \\
&amp;amp;= 1 - 2\frac{\phi_{xy}^2}{\phi_{xx} \phi_{yy}} + \frac{\phi_{xy}^4}{\phi_{xx}^2 \phi_{yy}^2} \\
&amp;amp;= \left(1 - \rho^2\right)^2.
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fishers-z-transformation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fisher’s &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-transformation&lt;/h3&gt;
&lt;p&gt;Meta-analysts will be very familiar with Fisher’s &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-transformation of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;, given by &lt;span class=&#34;math inline&#34;&gt;\(z(\rho) = \frac{1}{2} \log\left(\frac{1 + \rho}{1 - \rho}\right)\)&lt;/span&gt;.
Fisher’s &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; is the variance-stabilizing (and also normalizing) transformation of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;, meaning that &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}\left(z(r)\right)\)&lt;/span&gt; is approximately a constant function of sample size, not depending on the degree of correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. We can see this using another application of the delta method:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial z}{\partial \rho} = \frac{1}{1 - \rho^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(z(r)\right) \approx \frac{1}{(1 - \rho^2)^2} \times \text{Var}(r) = \frac{1}{n - 1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The variance of &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; is usually given as &lt;span class=&#34;math inline&#34;&gt;\(1 / (n - 3)\)&lt;/span&gt;, which is even closer to exact. Here we’ve obtained the variance of &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; using two applications of the delta-method. Because of &lt;a href=&#34;https://en.wikipedia.org/wiki/Chain_rule&#34;&gt;the chain rule&lt;/a&gt;, we’d have ended up with the same result if we’d gone straight from the sample variances and covariances, using the multivariate delta method and the derivatives of &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; with respect to &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;covariances-between-correlations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Covariances between correlations&lt;/h3&gt;
&lt;p&gt;These same techniques can be used to work out expressions for the covariances between correlations estimated on the same sample. For instance, suppose you’ve measured four variables, &lt;span class=&#34;math inline&#34;&gt;\(W\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt;, on a simple random sample of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations. What is &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(r_{xy}, r_{xz})\)&lt;/span&gt;? What is &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(r_{wx}, r_{yz})\)&lt;/span&gt;? I’ll leave the derivations for you to work out. See &lt;a href=&#34;http://dx.doi.org/10.1037//0033-2909.87.2.245&#34;&gt;Steiger (1980)&lt;/a&gt; for solutions.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New paper: Using response ratios for meta-analyzing SCDs with behavioral outcomes</title>
      <link>http://localhost:4321/using-response-ratios-paper/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/using-response-ratios-paper/</guid>
      <description>


&lt;p&gt;I’m pleased to announce that my article “Using response ratios for meta-analyzing SCDs with behavioral outcomes” has been accepted at &lt;em&gt;Journal of School Psychology&lt;/em&gt;. There’s a multitude of ways that you can access this work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the next 6 weeks or so, the published version of the article will be &lt;a href=&#34;https://authors.elsevier.com/a/1Wj5D56ZN7p98&#34;&gt;available at the journal website&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The pre-print will always remain &lt;a href=&#34;https://psyarxiv.com/nj28d/&#34;&gt;available at PsyArXiv&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Some supporting materials and replication code are &lt;a href=&#34;https://osf.io/c3fe9/&#34;&gt;available on the Open Science Framework&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s the abstract of the paper:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Methods for meta-analyzing single-case designs (SCDs) are needed to inform evidence-based practice in clinical and school settingsand to draw broader and more defensible generalizations in areas where SCDs comprise a large part of the research base. The most widely used outcomesin single-case research are measures of behavior collected using systematic direct observation, which typically take the form of rates or proportions. For studies that use such measures, one simple and intuitive way to quantify effect sizes is in terms of proportionate change from baseline, using an effect size known as the log response ratio. This paper describes methods for estimating log response ratios and combining the estimates using meta-analysis. The methods are based on a simple model for comparing two phases, where the level of the outcome is stable within each phase and the repeated outcome measurements are independent. Although auto-correlation will lead to biased estimates of the sampling variance of the effect size, meta-analysis of response ratios can be conducted with robust variance estimation procedures that remain valid even when sampling variance estimates are biased. The methods are demonstrated using data from a recent meta-analysis on group contingency interventions for student problem behavior.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Single-case synthesis tools II: Comparing overlap measures and parametric effect sizes for synthesizing antecedent sensory-based interventions</title>
      <link>http://localhost:4321/publication/scd-synthesis-tools-ii/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/scd-synthesis-tools-ii/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Single-case synthesis tools I: Evaluating the quality and rigor of research on antecedent sensory-based interventions</title>
      <link>http://localhost:4321/publication/scd-synthesis-tools-i/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/scd-synthesis-tools-i/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Using response ratios for meta-analyzing single-case designs with behavioral outcomes</title>
      <link>http://localhost:4321/publication/using-response-ratios/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/using-response-ratios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New paper: procedural sensitivities of effect size measures for SCDs</title>
      <link>http://localhost:4321/procedural-sensitivities-paper/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/procedural-sensitivities-paper/</guid>
      <description>


&lt;p&gt;I’m very happy to share that my article “Procedural sensitivities of effect sizes for single-case designs with directly observed behavioral outcome measures” has been accepted at &lt;em&gt;Psychological Methods&lt;/em&gt;. There’s no need to delay in reading it, since you can check out the &lt;a href=&#34;https://psyarxiv.com/vxa86&#34;&gt;pre-print&lt;/a&gt; and &lt;a href=&#34;https://osf.io/hkzsm/&#34;&gt;supporting materials&lt;/a&gt;. Here’s the abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A wide variety of effect size indices have been proposed for quantifying the magnitude of treatment effects in single-case designs. Commonly used measures include parametric indices such as the standardized mean difference, as well as non-overlap measures such as the percentage of non-overlapping data, improvement rate difference, and non-overlap of all pairs. Currently, little is known about the properties of these indices when applied to behavioral data collected by systematic direct observation, even though systematic direct observation is the most common method for outcome measurement in single-case research. This study uses Monte Carlo simulation to investigate the properties of several widely used single-case effect size measures when applied to systematic direct observation data. Results indicate that the magnitude of the non-overlap measures and of the standardized mean difference can be strongly influenced by procedural details of the study’s design, which is a significant limitation to using these indices as effect sizes for meta-analysis of single-case designs. A less widely used parametric index, the log-response ratio, has the advantage of being insensitive to sample size and observation session length, although its magnitude is influenced by the use of partial interval recording.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This paper was a long time coming. The core idea came out of a grant proposal I wrote during the summer of 2014, which I fleshed out for a &lt;a href=&#34;http://localhost:4321/files/AERA-2015-poster-Non-overlap-measures.pdf&#34;&gt;poster presented at AERA&lt;/a&gt; in April of 2015. After finishing a draft of the paper, I tried to publish it in a special education journal, reasoning that the main audience for the paper is researchers interested in meta-analyzing single case research studies that are commonly used in some parts of special education. That turned out to be a non-starter. Four rejection letters later, I re-worked the paper a bit to give more technical details, then submitted it to a more methods-ish journal. This yielded an R&amp;amp;R, I revised the paper extensively, resubmitted it, and it was declined. Buying in fully to the sunk costs fallacy, I sent the paper to Psychological Methods. This time, I received very extensive and helpful feedback from several anonymous reviewers and an associate editor (thank you, anonymous peers!), which helped me to revise the paper yet again, and this time it was accepted. Sixth time is the charm, as they say.&lt;/p&gt;
&lt;p&gt;Here’s the complete time-line of submissions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;August 5, 2015: submitted to journal #1 (special education)&lt;/li&gt;
&lt;li&gt;August 28, 2015: desk reject decision from journal #1&lt;/li&gt;
&lt;li&gt;September 3, 2015: submitted to journal #2 (special education)&lt;/li&gt;
&lt;li&gt;November 6, 2015: reject decision (after peer review) from journal #2&lt;/li&gt;
&lt;li&gt;November 18, 2015: submitted to journal #3 (special education)&lt;/li&gt;
&lt;li&gt;November 22, 2015: desk reject decision from journal #3 as not appropriate for their audience. I was grateful to get a quick decision.&lt;/li&gt;
&lt;li&gt;November 23, 2015: submitted to journal #4 (special education)&lt;/li&gt;
&lt;li&gt;February 17, 2016: reject decision (after peer review) from journal #4&lt;/li&gt;
&lt;li&gt;April 19, 2016: submitted to journal #5 (methods)&lt;/li&gt;
&lt;li&gt;August 16, 2016: revise-and-resubmit decision from journal #5&lt;/li&gt;
&lt;li&gt;October 14, 2016: re-submitted to journal #5&lt;/li&gt;
&lt;li&gt;February 2, 2017: reject decision from journal #5&lt;/li&gt;
&lt;li&gt;May 10, 2017: submitted to &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;September 1, 2017: revise-and-resubmit decision from &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;September 26, 2017: re-submitted to &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;November 22, 2017: conditional acceptance&lt;/li&gt;
&lt;li&gt;December 6, 2017: re-submitted with minor revisions&lt;/li&gt;
&lt;li&gt;January 10, 2018: accepted at &lt;em&gt;Psychological Methods&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A gradual effects model for single case designs</title>
      <link>http://localhost:4321/talk/ies-2018-gradual-effects-model/</link>
      <pubDate>Wed, 10 Jan 2018 08:15:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/ies-2018-gradual-effects-model/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Randomization inference for single-case experimental designs</title>
      <link>http://localhost:4321/talk/ies-2018-randomization-inference/</link>
      <pubDate>Wed, 10 Jan 2018 08:15:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/ies-2018-randomization-inference/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Back from the IES PI meeting</title>
      <link>http://localhost:4321/back-from-ies-pi-meeting/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/back-from-ies-pi-meeting/</guid>
      <description>


&lt;p&gt;I’m just back from the Institute of Education Sciences’ Principle Investigators conference in Washington D.C. It was an envigorating trip for me, and not only because of the opportunity to catch up with colleagues and friends from across the country. A running theme across several of the keynote addresses was the importance of increasing the transparency and replicability of education research, and it was exciting to hear about promising reforms underway and to talk about how to change the norms of our discipline(s).&lt;/p&gt;
&lt;p&gt;I contributed to the conference in two ways. First, I gave a presentation on incorporating randomization and randomization inference into single-case designs, as part of a session on innovations in single-case research methods organized by Dr. Wendy Machalicek. You can a static version of &lt;a href=&#34;http://localhost:4321/files/Randomization-inference-for-SCED-2018-01-10.pdf&#34;&gt;my slides here&lt;/a&gt;; unfortunately the animations don’t work in pdf.&lt;/p&gt;
&lt;p&gt;Second, I brought &lt;a href=&#34;http://localhost:4321/files/Gradual-effects-model-poster-IES-2018-01-10.pdf&#34;&gt;a poster&lt;/a&gt; presenting some work from my IES-funded methods grant. Thanks very much to the folks who stopped by to talk during the poster session! Y’all gave me some very helpful feedback about technical aspects of the work and about how to better contextualize it for single case researchers.&lt;/p&gt;
&lt;p&gt;If you didn’t make it: this project was joint work with Danny Swan, a doctoral student in our Quantitative Methods program. It involved developing a model for estimating effect sizes from single-case designs where the effects of the intervention take time to reach full potency. Rather than assuming that the intervention produces immediate shifts in the level of the outcome, we model the effects using an impulse response function (cribbed from &lt;a href=&#34;http://www.jstor.org/stable/2285379&#34;&gt;an old paper by Box and Tiao&lt;/a&gt;) that leads to non-linear trends in response to the introduction of the intervention. Using an impulse response function also makes it possible to model more complex design patterns, like treatment reversal designs with returns-to-baseline and treatment re-introduction phases, in a very parsimonious way. Check out &lt;a href=&#34;https://osf.io/gaxrv/&#34;&gt;the full paper&lt;/a&gt;, the &lt;a href=&#34;https://github.com/jepusto/SingleCaseES&#34;&gt;accompanying R package&lt;/a&gt;, and Danny’s &lt;a href=&#34;https://jepusto.shinyapps.io/gem-scd/&#34;&gt;interactive web-app&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to the special issue on single-case systematic reviews and meta-analysis</title>
      <link>http://localhost:4321/publication/rase-special-issue-introduction/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/rase-special-issue-introduction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2SLS standard errors and the delta-method</title>
      <link>http://localhost:4321/delta-method-and-2sls-ses/</link>
      <pubDate>Sat, 07 Oct 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/delta-method-and-2sls-ses/</guid>
      <description>


&lt;p&gt;I just covered instrumental variables in my course on causal inference, and so I have two-stage least squares (2SLS) estimation on the brain. In this post I’ll share something I realized in the course of prepping for class: that standard errors from 2SLS estimation are equivalent to delta method standard errors based on the Wald IV estimator. (I’m no econometrician, so this had never occurred to me before. Perhaps it will be interesting to other non-econometrician readers. And perhaps the econometricians can point me to the relevant page in Wooldridge or Angrist and Pischke or whomever that explains this better than I have.)&lt;/p&gt;
&lt;p&gt;Let’s consider a system with an outcome &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;, a focal treatment &lt;span class=&#34;math inline&#34;&gt;\(t_i\)&lt;/span&gt; identified by a single instrument &lt;span class=&#34;math inline&#34;&gt;\(z_i\)&lt;/span&gt;, along with a row-vector of exogenous covariates &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i\)&lt;/span&gt;, all for &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,n\)&lt;/span&gt;. The usual estimating equations are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
y_i &amp;amp;= \mathbf{x}_i \delta_0 + t_i \delta_1 + e_i \\
t_i &amp;amp;= \mathbf{x}_i \alpha_0 + z_i \alpha_1 + u_i.
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With a single-instrument, the 2SLS estimator of &lt;span class=&#34;math inline&#34;&gt;\(\delta_1\)&lt;/span&gt; is exactly equivalent to the Wald estimator&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\delta_1 = \frac{\hat\beta_1}{\hat\alpha_1},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\hat\alpha_1\)&lt;/span&gt; is the OLS estimator from the first-stage regression of &lt;span class=&#34;math inline&#34;&gt;\(t_i\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(z_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; is the OLS estimator from the regression&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_i = \mathbf{x}_i \beta_0 + z_i \beta_1 + v_i.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The delta-method approximation for &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\hat\delta_1)\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(\hat\delta_1\right) \approx \frac{1}{\alpha_1^2}\left[ \text{Var}\left(\hat\beta_1\right) + \delta_1^2 \text{Var}\left(\hat\alpha_1\right) - 2 \delta_1 \text{Cov}\left(\hat\beta_1, \hat\alpha_1\right) \right]. 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Substituting the estimators in place of parameters, and using heteroskedasticity-consistent (HC0, to be precise) estimators for &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}\left(\hat\beta_1\right)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}\left(\hat\alpha_1\right)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}\left(\hat\beta_1, \hat\alpha_1\right)\)&lt;/span&gt;, it turns out the feasible delta-method variance estimator is &lt;em&gt;exactly&lt;/em&gt; equivalent to the HC0 variance estimator from 2SLS.&lt;/p&gt;
&lt;div id=&#34;connecting-delta-method-and-2sls&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Connecting delta-method and 2SLS&lt;/h3&gt;
&lt;p&gt;To demonstrate this claim, let’s first partial out the covariates, taking &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{y}} = \left[\mathbf{I} - \mathbf{X}\left(\mathbf{X}&amp;#39;\mathbf{X}\right)^{-1}\mathbf{X}&amp;#39;\right]\mathbf{y}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{t}} = \left[\mathbf{I} - \mathbf{X}\left(\mathbf{X}&amp;#39;\mathbf{X}\right)^{-1}\mathbf{X}&amp;#39;\right]\mathbf{t}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{z}} = \left[\mathbf{I} - \mathbf{X}\left(\mathbf{X}&amp;#39;\mathbf{X}\right)^{-1}\mathbf{X}&amp;#39;\right]\mathbf{z}\)&lt;/span&gt;. The OLS estimators of &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1\)&lt;/span&gt; are then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\beta_1 = \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{y}}, \qquad \text{and} \qquad \hat\alpha_1 = \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{t}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The HC0 variance and covariance estimators for these coefficients have the usual sandwich form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
V^{\beta_1} &amp;amp;= \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}\left(\sum_{i=1}^n \ddot{z}_i^2 \ddot{v}_i^2\right) \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1} \\
V^{\alpha_1} &amp;amp;= \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}\left(\sum_{i=1}^n \ddot{z}_i^2 \ddot{u}_i^2\right) \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1} \\
V^{\alpha_1\beta_1} &amp;amp;= \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}\left(\sum_{i=1}^n \ddot{z}_i^2 \ddot{u}_i \ddot{v}_i\right) \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1},
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\ddot{v}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\ddot{u}_i\)&lt;/span&gt; are the residuals from the regressions of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{y}}\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{z}}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{t}}\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{z}}\)&lt;/span&gt;, respectively. Combining all these terms, the delta-method variance estimator is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V^{\delta_1} = \frac{1}{\hat\alpha_1^2}\left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}\left[\sum_{i=1}^n \ddot{z}_i^2\left(\ddot{v}_i^2 + \hat\delta_1^2 \ddot{u}_i^2 - 2 \hat\delta_1\ddot{u}_i \ddot{v}_i\right)\right] \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Remember this formula because we’ll return to it shortly.&lt;/p&gt;
&lt;p&gt;Now consider the 2SLS estimator. To calculate this, we begin by taking the fitted values from the regression of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{t}}\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{z}}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mathbf{\tilde{t}} = \mathbf{\ddot{z}}\left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1}\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{t}} = \mathbf{\ddot{z}} \hat\alpha_1.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We then regress &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\ddot{y}}\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\tilde{t}}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\delta_1 = \left(\mathbf{\tilde{t}}&amp;#39;\mathbf{\tilde{t}}\right)^{-1} \mathbf{\tilde{t}}&amp;#39; \mathbf{\ddot{y}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The HC0 variance estimator corresponding to the 2SLS estimator is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V^{2SLS} = \left(\mathbf{\tilde{t}}&amp;#39;\mathbf{\tilde{t}}\right)^{-1} \left(\sum_{i=1}^n \tilde{t}_i^2 \tilde{e}_i^2 \right) \left(\mathbf{\tilde{t}}&amp;#39;\mathbf{\tilde{t}}\right)^{-1},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{e}_i = \ddot{y}_i - \ddot{t}_i \hat\delta_1\)&lt;/span&gt;. Note that these residuals are calculated based on &lt;span class=&#34;math inline&#34;&gt;\(\ddot{t}_i\)&lt;/span&gt;, the &lt;em&gt;full&lt;/em&gt; treatment variable, not the fitted values &lt;span class=&#34;math inline&#34;&gt;\(\tilde{t}_i\)&lt;/span&gt;. The full treatment variable can be expressed as &lt;span class=&#34;math inline&#34;&gt;\(\ddot{t}_i = \tilde{t}_i + \ddot{u}_i\)&lt;/span&gt;, by which it follows that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{e}_i = \ddot{y}_i - \tilde{t}_i \hat\delta_1 - \ddot{u}_i \hat\delta_1.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;But &lt;span class=&#34;math inline&#34;&gt;\(\tilde{t}_i \hat\delta_1 = \ddot{z}_i \hat\alpha_1 \hat\delta_1 = \ddot{z}_i \hat\beta_1\)&lt;/span&gt;, and so&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{e}_i = \ddot{y}_i - \ddot{z}_i \hat\beta_1 - \ddot{u}_i \hat\delta_1 = \ddot{v}_i - \ddot{u}_i \hat\delta_1.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The 2SLS variance estimator is therefore&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
V^{2SLS} &amp;amp;= \left(\mathbf{\tilde{t}}&amp;#39;\mathbf{\tilde{t}}\right)^{-1} \left(\sum_{i=1}^n \tilde{t}_i^2 \tilde{e}_i^2 \right) \left(\mathbf{\tilde{t}}&amp;#39;\mathbf{\tilde{t}}\right)^{-1} \\
&amp;amp;= \left(\hat\alpha_1^2 \mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1} \left(\sum_{i=1}^n \hat\alpha_1^2 \ddot{z}_i^2 \tilde{e}_i^2 \right) \left(\hat\alpha_1^2 \mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1} \\
&amp;amp;= \frac{1}{\hat\alpha_1^2}\left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1} \left(\sum_{i=1}^n \ddot{z}_i^2 \tilde{e}_i^2 \right) \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1} \\
&amp;amp;= \frac{1}{\hat\alpha_1^2}\left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1} \left[\sum_{i=1}^n \ddot{z}_i^2 \left(\ddot{v}_i - \ddot{u}_i \hat\delta_1\right)^2 \right] \left(\mathbf{\ddot{z}}&amp;#39;\mathbf{\ddot{z}}\right)^{-1},
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which agrees with &lt;span class=&#34;math inline&#34;&gt;\(V^{\delta_1}\)&lt;/span&gt; as given above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;so-what&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;So what?&lt;/h3&gt;
&lt;p&gt;If you’ve continued reading this far…I’m slightly amazed…but if you have, you may be wondering why it’s worth knowing about this relationship. The equivalence between the 2SLS variance estimator and the delta method interests me for a couple of reasons.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First is that I had always taken the 2SLS variance estimator as being conditional on &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{t}\)&lt;/span&gt;–that is, not accounting for random variation in the treatment assignment. The delta-method form of the variance makes it crystal clear that this isn’t the case—the variance &lt;em&gt;does&lt;/em&gt; include terms for &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\hat\alpha_1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}(\hat\beta_1, \hat\alpha_1)\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;On the other hand, there’s perhaps a sense that equivalence with the 2SLS variance estimator (the more familiar form) validates the delta method variance estimator—that is, we wouldn’t be doing something fundamentally different by using the delta method variance with a Wald estimator. For instance, we might want to estimate &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1\)&lt;/span&gt; and/or &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; by some other means (e.g., by estimating &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1\)&lt;/span&gt; as a marginal effect from a logistic regression or estimating &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; with a multi-level model). It would make good sense in this instance to use the Wald estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1 / \hat\alpha_1\)&lt;/span&gt; and to estimate its variance using the delta method form.&lt;/li&gt;
&lt;li&gt;One last reason I’m interested in this is that writing out the variance estimators will likely help in understanding how to approach small-sample corrections to &lt;span class=&#34;math inline&#34;&gt;\(V^{2SLS}\)&lt;/span&gt;. But I’ll save that for another day.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Pooling clubSandwich results across multiple imputations</title>
      <link>http://localhost:4321/mi-with-clubsandwich/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/mi-with-clubsandwich/</guid>
      <description>


&lt;p&gt;A colleague recently asked me about how to apply cluster-robust hypothesis tests and confidence intervals, as calculated with the &lt;a href=&#34;https://CRAN.R-project.org/package=clubSandwich&#34;&gt;clubSandwich package&lt;/a&gt;, when dealing with multiply imputed datasets.
Standard methods (i.e., Rubin’s rules) for pooling estimates from multiple imputed datasets are developed under the assumption that the full-data estimates are approximately normally distributed. However, this might not be reasonable when working with test statistics based on cluster-robust variance estimators, which can be imprecise when the number of clusters is small or the design matrix of predictors is unbalanced in certain ways. &lt;a href=&#34;https://doi.org/10.1093/biomet/86.4.948&#34;&gt;Barnard and Rubin (1999)&lt;/a&gt; proposed a small-sample correction for tests and confidence intervals based on multiple imputed datasets. In this post, I’ll show how to implement their technique using the output of &lt;code&gt;clubSandwich&lt;/code&gt;, with multiple imputations generated using the &lt;a href=&#34;https://cran.r-project.org/package=mice&#34;&gt;&lt;code&gt;mice&lt;/code&gt; package&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setup&lt;/h3&gt;
&lt;p&gt;To begin, let me create missingness in a dataset containing multiple clusters of observations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mlmRev)
library(mice)
library(dplyr)

data(bdf)

bdf &amp;lt;- bdf %&amp;gt;%
  select(schoolNR, IQ.verb, IQ.perf, sex, ses, langPRET, aritPRET, aritPOST) %&amp;gt;%
  mutate(
    schoolNR = factor(schoolNR),
    sex = as.numeric(sex)
    ) %&amp;gt;%
  filter(as.numeric(schoolNR) &amp;lt;= 30) %&amp;gt;%
  droplevels()

bdf_missing &amp;lt;- 
  bdf %&amp;gt;% 
  select(-schoolNR) %&amp;gt;%
  ampute(run = TRUE)

bdf_missing &amp;lt;- 
  bdf_missing$amp %&amp;gt;%
  mutate(schoolNR = bdf$schoolNR)

summary(bdf_missing)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     IQ.verb         IQ.perf            sex             ses       
##  Min.   : 4.00   Min.   : 5.333   Min.   :1.000   Min.   :10.00  
##  1st Qu.:10.50   1st Qu.: 9.333   1st Qu.:1.000   1st Qu.:20.00  
##  Median :11.50   Median :10.667   Median :1.000   Median :27.00  
##  Mean   :11.72   Mean   :10.733   Mean   :1.462   Mean   :28.58  
##  3rd Qu.:13.00   3rd Qu.:12.333   3rd Qu.:2.000   3rd Qu.:38.00  
##  Max.   :18.00   Max.   :16.667   Max.   :2.000   Max.   :50.00  
##  NA&amp;#39;s   :37      NA&amp;#39;s   :39       NA&amp;#39;s   :40      NA&amp;#39;s   :37     
##     langPRET        aritPRET        aritPOST        schoolNR  
##  Min.   :15.00   Min.   : 1.00   Min.   : 2.00   40     : 35  
##  1st Qu.:30.00   1st Qu.: 9.00   1st Qu.:12.00   54     : 31  
##  Median :34.00   Median :11.00   Median :18.00   55     : 30  
##  Mean   :33.87   Mean   :11.64   Mean   :17.57   38     : 28  
##  3rd Qu.:39.00   3rd Qu.:14.00   3rd Qu.:23.00   1      : 25  
##  Max.   :48.00   Max.   :20.00   Max.   :30.00   18     : 24  
##  NA&amp;#39;s   :32      NA&amp;#39;s   :31      NA&amp;#39;s   :36      (Other):354&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’ll use &lt;code&gt;mice&lt;/code&gt; to create 10 multiply imputed datasets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Impute_bdf &amp;lt;- mice(bdf_missing, m=10, meth=&amp;quot;norm.nob&amp;quot;, seed=24)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Am I imputing while ignoring the hierarchical structure of the data? Yes, yes I am. Is this is a good way to do imputation? Probably not. But this is a quick and dirty example, so we’re going to have to live with it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model&lt;/h3&gt;
&lt;p&gt;Suppose that the goal of our analysis is to estimate the coefficients of the following regression model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{aritPOST}_{ij} = \beta_0 + \beta_1 \text{aritPRET}_{ij} + \beta_2 \text{langPRET}_{ij} + \beta_3 \text{sex}_{ij} + \beta_4 \text{SES}_{ij} + e_{ij},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; indexes students and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes schools, and where we allow for the possibility that errors from the same cluster are correlated in an unspecified way. With complete data, we could estimate the model by ordinary least squares and then use &lt;code&gt;clubSandwich&lt;/code&gt; to get standard errors that are robust to within-cluster dependence and heteroskedasticity. The code for this is as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_full &amp;lt;- lm(aritPOST ~ aritPRET + langPRET + sex + ses, data = bdf)
coef_test(lm_full, cluster = bdf$schoolNR, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         Coef. Estimate     SE t-stat d.f. p-val (Satt) Sig.
## 1 (Intercept)  -2.1921 1.3484 -1.626 22.9       0.1177     
## 2    aritPRET   1.0053 0.0833 12.069 23.4       &amp;lt;0.001  ***
## 3    langPRET   0.2758 0.0294  9.371 24.1       &amp;lt;0.001  ***
## 4         sex  -1.2040 0.4706 -2.559 23.8       0.0173    *
## 5         ses   0.0233 0.0266  0.876 20.5       0.3909&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If cluster dependence were no concern, we could simply use the model-based standard errors and test statistics. The &lt;code&gt;mice&lt;/code&gt; package provides functions that will fit the model to each imputed dataset and then combine them by Rubin’s rules. The code is simply:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(data = Impute_bdf, 
     lm(aritPOST ~ aritPRET + langPRET + sex + ses)
     ) %&amp;gt;%
  pool() %&amp;gt;%
  summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          term    estimate  std.error statistic       df      p.value
## 1 (Intercept) -2.28650029 1.11111424 -2.057844 417.9634 4.022469e-02
## 2    aritPRET  0.97135842 0.07152843 13.580033 250.9260 0.000000e+00
## 3    langPRET  0.27866679 0.03722404  7.486205 308.6377 7.474021e-13
## 4         sex -1.06494919 0.41317983 -2.577447 272.5258 1.047928e-02
## 5         ses  0.03220417 0.02142008  1.503457 124.5671 1.352524e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this approach ignores the possibility of correlation in the errors of units in the same cluster, which is clearly a concern in this dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ratio of CRVE to conventional variance estimates
diag(vcovCR(lm_full, cluster = bdf$schoolNR, type = &amp;quot;CR2&amp;quot;)) / 
  diag(vcov(lm_full))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (Intercept)    aritPRET    langPRET         sex         ses 
##   1.5296837   1.5493134   0.6938735   1.4567650   2.0053186&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we need a way to pool results based on the cluster-robust variance estimators, while also accounting for the relatively small number of clusters in this dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;barnard-rubin-1999&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Barnard &amp;amp; Rubin (1999)&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.1093/biomet/86.4.948&#34;&gt;Barnard and Rubin (1999)&lt;/a&gt; proposed a small-sample correction for tests and confidence intervals based on multiple imputed datasets that seems to work in this context. Rather than using large-sample normal approximations for inference, they derive an approximate degrees-of-freedom that combines uncertainty in the standard errors calculated from each imputed dataset with between-imputation uncertainty. The method is as follows.&lt;/p&gt;
&lt;p&gt;Suppose that we have &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; imputed datasets. Let &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_{(j)}\)&lt;/span&gt; be the estimated regression coefficient from imputed dataset &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, with (in this case cluster-robust) sampling variance estimate &lt;span class=&#34;math inline&#34;&gt;\(V_{(j)}\)&lt;/span&gt;. Further, let &lt;span class=&#34;math inline&#34;&gt;\(\eta_{(j)}\)&lt;/span&gt; be the degrees of freedom corresponding to &lt;span class=&#34;math inline&#34;&gt;\(V_{(j)}\)&lt;/span&gt;. To combine these estimates, calculate the averages across multiply imputed datasets:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\bar\beta = \frac{1}{m}\sum_{j=1}^m \hat\beta_{(j)}, \qquad \bar{V} = \frac{1}{m}\sum_{j=1}^m V_{(j)}, \qquad \bar\eta = \frac{1}{m}\sum_{j=1}^m \eta_{(j)}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Also calculate the between-imputation variance&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
B = \frac{1}{m - 1} \sum_{j=1}^m \left(\hat\beta_{(j)} - \bar\beta\right)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And then combine the between- and within- variance estimates using Rubin’s rules:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_{total} = \bar{V} + \frac{m + 1}{m} B.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The degrees of freedom associated with &lt;span class=&#34;math inline&#34;&gt;\(V_{total}\)&lt;/span&gt; modify the estimated complete-data degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\bar\eta\)&lt;/span&gt; using quantities that depend on the fraction of missing information in a coefficient. The fraction of missing information is given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\gamma_m = \frac{(m+1)B}{m V_{total}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The degrees of freedom are then given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu_{total} = \left(\frac{1}{\nu_m} + \frac{1}{\nu_{obs}}\right)^{-1},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu_m = \frac{(m - 1)}{\hat\gamma_m^2}, \quad \text{and} \quad \nu_{obs} = \frac{\bar\eta (\bar\eta + 1) (1 - \hat\gamma)}{\bar\eta + 3}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Hypothesis tests and confidence intervals are based on the approximation&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\bar\beta - \beta_0}{\sqrt{V_{total}}} \ \stackrel{\cdot}{\sim} \ t(\nu_{total})
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;implementation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Implementation&lt;/h3&gt;
&lt;p&gt;Here is how to carry out these calculations using the results of &lt;code&gt;clubSandwich::coef_test&lt;/code&gt; and a bit of &lt;code&gt;dplyr&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit results with clubSandwich standard errors

models_robust &amp;lt;- with(data = Impute_bdf, 
                      lm(aritPOST ~ aritPRET + langPRET + sex + ses) %&amp;gt;% 
                         coef_test(cluster=bdf$schoolNR, vcov=&amp;quot;CR2&amp;quot;)
                      ) 


# pool results with clubSandwich standard errors

robust_pooled &amp;lt;- 
  models_robust$analyses %&amp;gt;%
  
  # add coefficient names as a column
  lapply(function(x) {
    x$coef &amp;lt;- row.names(x)
    x
  }) %&amp;gt;%
  bind_rows() %&amp;gt;%
  as.data.frame() %&amp;gt;%
  
  # summarize by coefficient
  group_by(coef) %&amp;gt;%
  summarise(
    m = n(),
    B = var(beta),
    beta_bar = mean(beta),
    V_bar = mean(SE^2),
    eta_bar = mean(df)
  ) %&amp;gt;%
  
  mutate(
    
    # calculate intermediate quantities to get df
    V_total = V_bar + B * (m + 1) / m,
    gamma = ((m + 1) / m) * B / V_total,
    df_m = (m - 1) / gamma^2,
    df_obs = eta_bar * (eta_bar + 1) * (1 - gamma) / (eta_bar + 3),
    df = 1 / (1 / df_m + 1 / df_obs),
    
    # calculate summary quantities for output
    se = sqrt(V_total),
    t = beta_bar / se,
    p_val = 2 * pt(abs(t), df = df, lower.tail = FALSE),
    crit = qt(0.975, df = df),
    lo95 = beta_bar - se * crit,
    hi95 = beta_bar + se * crit
  )

robust_pooled %&amp;gt;%
  select(coef, est = beta_bar, se, t, df, p_val, lo95, hi95, gamma) %&amp;gt;%
  mutate_at(vars(est:gamma), round, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 9
##   coef           est    se     t    df p_val   lo95   hi95 gamma
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) -2.29  1.34  -1.70  20.4 0.104 -5.08   0.51  0.039
## 2 aritPRET     0.971 0.092 10.5   19.0 0      0.778  1.16  0.076
## 3 langPRET     0.279 0.036  7.71  19.5 0      0.203  0.354 0.106
## 4 ses          0.032 0.03   1.09  16.3 0.292 -0.03   0.095 0.117
## 5 sex         -1.06  0.472 -2.26  19.6 0.036 -2.05  -0.08  0.089&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is instructive to compare the calculated &lt;code&gt;df&lt;/code&gt; to &lt;code&gt;eta_bar&lt;/code&gt; and &lt;code&gt;df_m&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;robust_pooled %&amp;gt;%
  select(coef, df, df_m, eta_bar) %&amp;gt;%
  mutate_at(vars(df, df_m, eta_bar), round, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 4
##   coef           df  df_m eta_bar
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)  20.4 6006.    23  
## 2 aritPRET     19   1550.    22.5
## 3 langPRET     19.5  806.    24.1
## 4 ses          16.3  657.    20.7
## 5 sex          19.6 1138.    23.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, &lt;code&gt;eta_bar&lt;/code&gt; is the average of the complete data degrees of freedom, and it can be seen that the total degrees of freedom are somewhat less than the average complete-data degrees of freedom. This is by construction. Further &lt;code&gt;df_m&lt;/code&gt; is the conventional degrees of freedom used in multiple-imputation, which assume that the complete-data estimates are normally distributed, and in this example they are way far off.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further thoughts&lt;/h3&gt;
&lt;p&gt;How well does this method perform in practice? I’m not entirely sure—I’m just trusting that Barnard and Rubin’s approximation is sound and would work in this setting (I mean, they’re smart people!). Are there other, better approaches? Totally possible. I have done zero literature review beyond the Barnard and Rubin paper. In any case, exploring the performance of this method (and any other alternatives) seems like it would make for a very nice student project.&lt;/p&gt;
&lt;p&gt;There’s also the issue of how to do tests of multi-dimensional constraints (i.e., F-tests). The &lt;code&gt;clubSandwich&lt;/code&gt; package implements Wald-type tests for multi-dimensional constraints, using a small-sample correction that we developed (&lt;a href=&#34;http://journals.sagepub.com/doi/abs/10.3102/1076998615606099&#34;&gt;Tipton &amp;amp; Pustejovsky, 2015&lt;/a&gt;; &lt;a href=&#34;http://www.tandfonline.com/doi/full/10.1080/07350015.2016.1247004&#34;&gt;Pustejovsky &amp;amp; Tipton, 2016&lt;/a&gt;). But it would take some further thought to figure out how to handle multiply imputed data with this type of test…&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Imputing covariance matrices for meta-analysis of correlated effects</title>
      <link>http://localhost:4321/imputing-covariance-matrices-for-multi-variate-meta-analysis/</link>
      <pubDate>Thu, 10 Aug 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/imputing-covariance-matrices-for-multi-variate-meta-analysis/</guid>
      <description>


&lt;p&gt;In many systematic reviews, it is common for eligible studies to contribute effect size estimates from not just one, but &lt;em&gt;multiple&lt;/em&gt; relevant outcome measures, for a common sample of participants. If those outcomes are correlated, then &lt;a href=&#34;http://localhost:4321/Correlations-between-SMDs&#34;&gt;so too will be the effect size estimates&lt;/a&gt;. To estimate the degree of correlation, you would need the sample correlation among the outcomes—information that is woefully uncommon for primary studies to report (and best of luck to you if you try to follow up with author queries). Thus, the meta-analyst is often left in a situation where the sampling &lt;em&gt;variances&lt;/em&gt; of the effect size estimates can be reasonably well approximated, but the sampling &lt;em&gt;covariances&lt;/em&gt; are unknown for some or all studies.&lt;/p&gt;
&lt;p&gt;Several solutions to this conundrum have been proposed in the meta-analysis methodology literature. One possible strategy is to just impute a correlation based on subject-matter knowledge (or at least feigned expertise), and assume that this correlation is constant across studies. This analysis could be supplemented with sensitivity analyses to examine the extent to which the parameter estimates and inferences are sensitive to alternative assumptions about the inter-correlation of effects within studies. A related strategy, described by &lt;a href=&#34;https://dx.doi.org/10.1002/sim.5679&#34;&gt;Wei and Higgins (2013)&lt;/a&gt;, is to meta-analyze any available correlation estimates and then use the results to impute correlations for any studies with missing correlations.&lt;/p&gt;
&lt;p&gt;Both of these approaches require the meta-analyst to calculate block-diagonal sampling covariance matrices for the effect size estimates, which can be a bit unwieldy. I often use the impute-the-correlation strategy in my meta-analysis work and have written a helper function to compute covariance matrices, given known sampling variances and imputed correlations for each study. In the interest of not repeating myself, I’ve added the function to the latest version of my clubSandwich package. In this post, I’ll explain the function and demonstrate how to use it for conducting meta-analysis of correlated effect size estimates.&lt;/p&gt;
&lt;div id=&#34;an-r-function-for-block-diagonal-covariance-matrices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An R function for block-diagonal covariance matrices&lt;/h2&gt;
&lt;p&gt;Here is the function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;impute_covariance_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## function (vi, cluster, r, return_list = identical(as.factor(cluster), 
##     sort(as.factor(cluster)))) 
## {
##     cluster &amp;lt;- droplevels(as.factor(cluster))
##     vi_list &amp;lt;- split(vi, cluster)
##     r_list &amp;lt;- rep_len(r, length(vi_list))
##     vcov_list &amp;lt;- Map(function(V, rho) (rho + diag(1 - rho, nrow = length(V))) * 
##         tcrossprod(sqrt(V)), V = vi_list, rho = r_list)
##     if (return_list) {
##         return(vcov_list)
##     }
##     else {
##         vcov_mat &amp;lt;- metafor::bldiag(vcov_list)
##         cluster_index &amp;lt;- order(order(cluster))
##         return(vcov_mat[cluster_index, cluster_index])
##     }
## }
## &amp;lt;bytecode: 0x0000000018309e80&amp;gt;
## &amp;lt;environment: namespace:clubSandwich&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function takes three required arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;vi&lt;/code&gt; is a vector of sampling variances.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cluster&lt;/code&gt; is a vector identifying the study from which effect size estimates are drawn. Effects with the same value of &lt;code&gt;cluster&lt;/code&gt; will be treated as correlated.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;r&lt;/code&gt; is the assumed value(s) of the correlation between effect size estimates from each study. Note that &lt;code&gt;r&lt;/code&gt; can also be a vector with separate values for each study.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a simple example to demonstrate how the function works. Say that there are just three studies, contributing 2, 3, and 4 effects, respectively. I’ll just make up some values for the effect sizes and variances:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- data.frame(study = rep(LETTERS[1:3], 2:4), 
                  yi = rnorm(9), 
                  vi = 4:12)
dat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   study          yi vi
## 1     A -1.33148823  4
## 2     A -0.02725897  5
## 3     B -0.70125406  6
## 4     B -1.71119746  7
## 5     B -0.70957554  8
## 6     C -0.40639264  9
## 7     C -0.13290344 10
## 8     C -1.10272160 11
## 9     C -0.38033372 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll assume that effect size estimates from a given study are correlated at 0.7:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_list &amp;lt;- impute_covariance_matrix(vi = dat$vi, cluster = dat$study, r = 0.7)
V_list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $A
##          [,1]     [,2]
## [1,] 4.000000 3.130495
## [2,] 3.130495 5.000000
## 
## $B
##          [,1]     [,2]     [,3]
## [1,] 6.000000 4.536518 4.849742
## [2,] 4.536518 7.000000 5.238320
## [3,] 4.849742 5.238320 8.000000
## 
## $C
##          [,1]      [,2]      [,3]      [,4]
## [1,] 9.000000  6.640783  6.964912  7.274613
## [2,] 6.640783 10.000000  7.341662  7.668116
## [3,] 6.964912  7.341662 11.000000  8.042388
## [4,] 7.274613  7.668116  8.042388 12.000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a list of matrices, where each entry corresponds to the variance-covariance matrix of effects from a given study. To see that the results are correct, let’s examine the correlation matrix implied by these correlation matrices:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov2cor(V_list$A)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]  1.0  0.7
## [2,]  0.7  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov2cor(V_list$B)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3]
## [1,]  1.0  0.7  0.7
## [2,]  0.7  1.0  0.7
## [3,]  0.7  0.7  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov2cor(V_list$C)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4]
## [1,]  1.0  0.7  0.7  0.7
## [2,]  0.7  1.0  0.7  0.7
## [3,]  0.7  0.7  1.0  0.7
## [4,]  0.7  0.7  0.7  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As requested, effects are assumed to be equi-correlated with r = 0.7.&lt;/p&gt;
&lt;p&gt;If the data are sorted in order of the cluster IDs, then the list of matrices returned by &lt;code&gt;impute_covariance_matrix()&lt;/code&gt; can be fed directly into the &lt;code&gt;rma.mv&lt;/code&gt; function in metafor (as I demonstrate below). However, if the data are not sorted by &lt;code&gt;cluster&lt;/code&gt;, then feeding in the list of matrices will not work correctly. Instead, the full &lt;span class=&#34;math inline&#34;&gt;\(N \times N\)&lt;/span&gt; variance-covariance matrix (where &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; is the total number of effect size estimates) will need to be calculated so that the rows and columns appear in the correct order. To address this possibility, the function includes an optional argument, &lt;code&gt;return_list&lt;/code&gt;, which determines whether to output a list of matrices (one matrix per study/cluster) or a single matrix corresponding to the full variance-covariance matrix across all studies. By default, &lt;code&gt;return_list&lt;/code&gt; tests for whether the &lt;code&gt;cluster&lt;/code&gt; argument is sorted and returns the appropriate form. The argument can also be set directly by the user.&lt;/p&gt;
&lt;p&gt;Here’s what happens if we feed in the data in a different order:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_scramble &amp;lt;- dat[sample(nrow(dat)),]
dat_scramble&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   study          yi vi
## 9     C -0.38033372 12
## 3     B -0.70125406  6
## 8     C -1.10272160 11
## 5     B -0.70957554  8
## 6     C -0.40639264  9
## 2     A -0.02725897  5
## 1     A -1.33148823  4
## 4     B -1.71119746  7
## 7     C -0.13290344 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_mat &amp;lt;- round(impute_covariance_matrix(vi = dat_scramble$vi, cluster = dat_scramble$study, r = 0.7), 3)
V_mat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         [,1]  [,2]   [,3]  [,4]  [,5] [,6] [,7]  [,8]   [,9]
##  [1,] 12.000 0.000  8.042 0.000 7.275 0.00 0.00 0.000  7.668
##  [2,]  0.000 6.000  0.000 4.850 0.000 0.00 0.00 4.537  0.000
##  [3,]  8.042 0.000 11.000 0.000 6.965 0.00 0.00 0.000  7.342
##  [4,]  0.000 4.850  0.000 8.000 0.000 0.00 0.00 5.238  0.000
##  [5,]  7.275 0.000  6.965 0.000 9.000 0.00 0.00 0.000  6.641
##  [6,]  0.000 0.000  0.000 0.000 0.000 5.00 3.13 0.000  0.000
##  [7,]  0.000 0.000  0.000 0.000 0.000 3.13 4.00 0.000  0.000
##  [8,]  0.000 4.537  0.000 5.238 0.000 0.00 0.00 7.000  0.000
##  [9,]  7.668 0.000  7.342 0.000 6.641 0.00 0.00 0.000 10.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see that this is correct, check that the diagonal entries of &lt;code&gt;V_mat&lt;/code&gt; are the same as &lt;code&gt;vi&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(dat_scramble$vi, diag(V_mat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-with-real-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An example with real data&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://dx.doi.org/10.1037/1082-989X.1.3.227&#34;&gt;Kalaian and Raudenbush (1996)&lt;/a&gt; introduced a multi-variate random effects model, which can be used to perform a joint meta-analysis of studies that contribute effect sizes on distinct, related outcome constructs. They demonstrate the model using data from a synthesis on the effects of SAT coaching, where many studies reported effects on both the math and verbal portions of the SAT. The data are available in the &lt;code&gt;clubSandwich&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr, warn.conflicts=FALSE)
data(SATcoaching)

# calculate the mean of log of coaching hours
mean_hrs_ln &amp;lt;- 
  SATcoaching %&amp;gt;% 
  group_by(study) %&amp;gt;%
  summarise(hrs_ln = mean(log(hrs))) %&amp;gt;%
  summarise(hrs_ln = mean(hrs_ln, na.rm = TRUE))

# clean variables, sort by study ID
SATcoaching &amp;lt;- 
  SATcoaching %&amp;gt;%
  mutate(
    study = as.factor(study),
    hrs_ln = log(hrs) - mean_hrs_ln$hrs_ln
  ) %&amp;gt;%
  arrange(study, test)

SATcoaching %&amp;gt;%
  select(study, year, test, d, V, hrs_ln) %&amp;gt;%
  head(n = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    study year   test     d      V      hrs_ln
## 1  Alderman &amp;amp; Powers (A) 1980 Verbal  0.22 0.0817 -0.54918009
## 2  Alderman &amp;amp; Powers (B) 1980 Verbal  0.09 0.0507 -0.19250515
## 3  Alderman &amp;amp; Powers (C) 1980 Verbal  0.14 0.1045 -0.14371499
## 4  Alderman &amp;amp; Powers (D) 1980 Verbal  0.14 0.0442 -0.19250515
## 5  Alderman &amp;amp; Powers (E) 1980 Verbal -0.01 0.0535 -0.70333077
## 6  Alderman &amp;amp; Powers (F) 1980 Verbal  0.14 0.0557 -0.88565233
## 7  Alderman &amp;amp; Powers (G) 1980 Verbal  0.18 0.0561 -0.09719497
## 8  Alderman &amp;amp; Powers (H) 1980 Verbal  0.01 0.1151  1.31157225
## 9              Burke (A) 1986 Verbal  0.50 0.0825  1.41693276
## 10             Burke (B) 1986 Verbal  0.74 0.0855  1.41693276
## 11                Coffin 1987   Math  0.33 0.2534  0.39528152
## 12                Coffin 1987 Verbal -0.23 0.2517  0.39528152
## 13            Curran (A) 1988   Math -0.08 0.1065 -0.70333077
## 14            Curran (A) 1988 Verbal -0.10 0.1066 -0.70333077
## 15            Curran (B) 1988   Math -0.29 0.1015 -0.70333077
## 16            Curran (B) 1988 Verbal -0.14 0.1007 -0.70333077
## 17            Curran (C) 1988   Math -0.34 0.1104 -0.70333077
## 18            Curran (C) 1988 Verbal -0.16 0.1092 -0.70333077
## 19            Curran (D) 1988   Math -0.06 0.1089 -0.70333077
## 20            Curran (D) 1988 Verbal -0.07 0.1089 -0.70333077&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The correlation betwen math and verbal test scores are not available, but it seems reasonable to use a correlation of r = 0.66, as reported in the SAT technical information. To synthesize these effects, I’ll first compute the required variance-covariances:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_list &amp;lt;- impute_covariance_matrix(vi = SATcoaching$V, 
                                   cluster = SATcoaching$study, 
                                   r = 0.66)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This can then be fed into &lt;code&gt;metafor&lt;/code&gt; to estimate a fixed effect or random effects meta-analysis or meta-regression models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor, quietly = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading &amp;#39;metafor&amp;#39; package (version 2.1-0). For an overview 
## and introduction to the package please type: help(metafor).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate fixed effect meta-analysis
MVFE_null &amp;lt;- rma.mv(d ~ 0 + test, V = V_list, data = SATcoaching)
MVFE_null&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 67; method: REML)
## 
## Variance Components: none
## 
## Test for Residual Heterogeneity:
## QE(df = 65) = 72.1630, p-val = 0.2532
## 
## Test of Moderators (coefficients 1:2):
## QM(df = 2) = 19.8687, p-val &amp;lt; .0001
## 
## Model Results:
## 
##             estimate      se    zval    pval   ci.lb   ci.ub 
## testMath      0.1316  0.0331  3.9783  &amp;lt;.0001  0.0668  0.1965  *** 
## testVerbal    0.1215  0.0313  3.8783  0.0001  0.0601  0.1829  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate fixed effect meta-regression
MVFE_hrs &amp;lt;- rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, 
                   data = SATcoaching)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, data = SATcoaching):
## Rows with NAs omitted from model fitting.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVFE_hrs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 65; method: REML)
## 
## Variance Components: none
## 
## Test for Residual Heterogeneity:
## QE(df = 61) = 67.9575, p-val = 0.2523
## 
## Test of Moderators (coefficients 1:4):
## QM(df = 4) = 23.7181, p-val &amp;lt; .0001
## 
## Model Results:
## 
##                    estimate      se    zval    pval    ci.lb   ci.ub 
## testMath             0.0946  0.0402  2.3547  0.0185   0.0159  0.1734   * 
## testVerbal           0.1119  0.0341  3.2762  0.0011   0.0449  0.1788  ** 
## testMath:hrs_ln      0.1034  0.0546  1.8946  0.0581  -0.0036  0.2103   . 
## testVerbal:hrs_ln    0.0601  0.0442  1.3592  0.1741  -0.0266  0.1467     
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate random effects meta-analysis
MVRE_null &amp;lt;- rma.mv(d ~ 0 + test, V = V_list, data = SATcoaching, 
                 random = ~ test | study, struct = &amp;quot;UN&amp;quot;)
MVRE_null&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 67; method: REML)
## 
## Variance Components:
## 
## outer factor: study (nlvls = 47)
## inner factor: test  (nlvls = 2)
## 
##             estim    sqrt  k.lvl  fixed   level 
## tau^2.1    0.0122  0.1102     29     no    Math 
## tau^2.2    0.0026  0.0507     38     no  Verbal 
## 
##         rho.Math  rho.Vrbl    Math  Vrbl 
## Math           1   -1.0000       -    no 
## Verbal   -1.0000         1      20     - 
## 
## Test for Residual Heterogeneity:
## QE(df = 65) = 72.1630, p-val = 0.2532
## 
## Test of Moderators (coefficients 1:2):
## QM(df = 2) = 18.1285, p-val = 0.0001
## 
## Model Results:
## 
##             estimate      se    zval    pval   ci.lb   ci.ub 
## testMath      0.1379  0.0434  3.1783  0.0015  0.0528  0.2229   ** 
## testVerbal    0.1168  0.0337  3.4603  0.0005  0.0506  0.1829  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bivariate random effects meta-regression
MVRE_hrs &amp;lt;- rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, 
                   data = SATcoaching,
                   random = ~ test | study, struct = &amp;quot;UN&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in rma.mv(d ~ 0 + test + test:hrs_ln, V = V_list, data = SATcoaching, :
## Rows with NAs omitted from model fitting.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVRE_hrs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 65; method: REML)
## 
## Variance Components:
## 
## outer factor: study (nlvls = 46)
## inner factor: test  (nlvls = 2)
## 
##             estim    sqrt  k.lvl  fixed   level 
## tau^2.1    0.0152  0.1234     28     no    Math 
## tau^2.2    0.0014  0.0373     37     no  Verbal 
## 
##         rho.Math  rho.Vrbl    Math  Vrbl 
## Math           1   -1.0000       -    no 
## Verbal   -1.0000         1      19     - 
## 
## Test for Residual Heterogeneity:
## QE(df = 61) = 67.9575, p-val = 0.2523
## 
## Test of Moderators (coefficients 1:4):
## QM(df = 4) = 23.6459, p-val &amp;lt; .0001
## 
## Model Results:
## 
##                    estimate      se    zval    pval    ci.lb   ci.ub 
## testMath             0.0893  0.0507  1.7631  0.0779  -0.0100  0.1887   . 
## testVerbal           0.1062  0.0357  2.9738  0.0029   0.0362  0.1762  ** 
## testMath:hrs_ln      0.1694  0.0725  2.3354  0.0195   0.0272  0.3116   * 
## testVerbal:hrs_ln    0.0490  0.0459  1.0681  0.2855  -0.0409  0.1389     
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results of fitting this model using restricted maximum likelihood with metafor are actually a bit different from the estimates reported in the original paper, potentially because Kalaian and Raudenbush use a Cholesky decomposition of the sampling covariances, which alters the interpretation of the random effects variance components. The metafor fit is also a bit goofy because the correlation between the random effects for math and verbal scores is very close to -1, although evidently it is not uncommon to obtain such degenerate estimates of the random effects structure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;robust-variance-estimation.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Robust variance estimation.&lt;/h2&gt;
&lt;p&gt;Experienced meta-analysts will no doubt point out that a further, alternative analytic strategy to the one described above would be to use robust variance estimation methods (RVE; &lt;a href=&#34;https://dx.doi.org/10.1002/jrsm.5&#34;&gt;Hedges, Tipton, &amp;amp; Johnson&lt;/a&gt;). However, RVE is not so much an alternative strategy as it is a complementary technique, which can be used in combination with any of the models estimated above. Robust standard errors and hypothesis tests can readily be obtained with the &lt;a href=&#34;https://cran.r-project.org/package=clubSandwich&#34;&gt;clubSandwich package&lt;/a&gt;. Here’s how to do it for the random effects meta-regression model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clubSandwich)
coef_test(MVRE_hrs, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               Coef. Estimate     SE t-stat  d.f. p-val (Satt) Sig.
## 1          testMath   0.0893 0.0360   2.48 20.75       0.0218    *
## 2        testVerbal   0.1062 0.0215   4.94 16.45       &amp;lt;0.001  ***
## 3   testMath:hrs_ln   0.1694 0.1010   1.68  7.90       0.1325     
## 4 testVerbal:hrs_ln   0.0490 0.0414   1.18  7.57       0.2725&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RVE is also available in the &lt;a href=&#34;https://CRAN.R-project.org/package=robumeta&#34;&gt;robumeta R package&lt;/a&gt;, but there are several differences between the implementation there and the method I’ve demonstrated here. From the user’s perspective, an advantage of robumeta is that it does all of the covariance imputation calculations “under the hood,” whereas with metafor the calculations need to be done prior to fitting the model. Beyond this, differences include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;robumeta uses a specific random effects structure that can’t be controlled by the user, whereas metafor can be used to estimate a variety of different random effects structures;&lt;/li&gt;
&lt;li&gt;robumeta uses a moment estimator for the between-study variance, whereas metafor provides FML or REML estimation;&lt;/li&gt;
&lt;li&gt;robumeta uses semi-efficient, diagonal weights when fitting the meta-regression, whereas metafor uses weights that are fully efficient (exactly inverse-variance) under the working model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The advantages and disadvantages of these two approaches involve some subtleties that I’ll get into in a future post.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A meta-analysis of school-based group contingency interventions for students with challenging behavior: An update</title>
      <link>http://localhost:4321/publication/school-based-group-contingencies-meta-analysis/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/school-based-group-contingencies-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A meta-analysis of technology-aided instruction and intervention for students with ASD</title>
      <link>http://localhost:4321/publication/taii-meta-analysis/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/taii-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The siren song of significance</title>
      <link>http://localhost:4321/siren-song-of-significance/</link>
      <pubDate>Mon, 19 Jun 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/siren-song-of-significance/</guid>
      <description>


&lt;p&gt;How is statistical analysis like the Odyssey? Here’s an analogy that I used in my research methods course last semester to explain the purpose of study pre-registration. If you’ve ever read the Odyssey, you’ll recall the story of the Sirens, the enchanting lady-monsters whose singing lures to certain death any sailor who hears them. (&lt;a href=&#34;https://en.wikipedia.org/wiki/Siren_(mythology)#Odyssey&#34;&gt;See Wikipedia for crib notes.&lt;/a&gt;) On the advise of his witch-friend Circe, Odysseus pulls a stunt so that he can hear the song of the Sirens while still making it safely past. He instructs his crew to plug their ears with beeswax and then lash him to the mast of his boat. As they sail past the Sirens, Odysseus hears the beautiful voices come-hithering and begs his men to free him, but they tie him up tighter until they are all safely out of ear-shot.&lt;/p&gt;
&lt;p&gt;I think this is a good analogy for the benefits of pre-registering your experiments. Statistical significance testing is an alluring thing. It provides us, as data-analysts, with a way of drawing a definitive conclusion about whatever phenomenon we’re studying—“This effect is non-zero!”—and thus to write compelling articles and get published and get tenure and so on. But we also now know that statistical significance testing is easily abused. Using &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf&#34;&gt;flexible data analysis procedures&lt;/a&gt;, it is easy to obtain statistically significant results from &lt;a href=&#34;http://journals.sagepub.com/doi/abs/10.1177/0956797611417632&#34;&gt;totally meaningless data&lt;/a&gt;. And statistical significance is so alluring, why should any scholar believe that you haven’t hacked your way to get there? Is there any way to conduct hypothesis tests and actually believe (and convince others) that you’ve ruled out a null at the end of it?&lt;/p&gt;
&lt;p&gt;That’s where study pre-registration comes in. Pre-registration involves creating a public record of the exact plans you intend to follow when collecting and analyzing data, &lt;em&gt;in advance&lt;/em&gt; of conducting the study. It is like tying your arms and legs to the mast of your ship as you sail through the straights of data collection and analysis. No matter how tempting it is to control for a couple of other covariates…no matter how much cleaner that log-transformation looks…your pre-registered protocol keeps you tied down, preventing you from throwing yourself overboard into the sea of questionable research practices. And as you come out the other side, you can actually put stock in your findings, having heard the siren song of statistical significance and lived to tell the tale.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Heteroskedasticity-robust tests in linear regression: A review and evaluation of small-sample corrections</title>
      <link>http://localhost:4321/talk/aera-2017-hc-t-tests/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2017-hc-t-tests/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A nonlinear intervention analysis model for treatment reversal single-case designs</title>
      <link>http://localhost:4321/talk/aera-2017-intervention-analysis/</link>
      <pubDate>Fri, 28 Apr 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2017-intervention-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Using response ratios for meta-analyzing single-case designs with behavioral outcomes</title>
      <link>http://localhost:4321/talk/aera-2017-response-ratios/</link>
      <pubDate>Fri, 28 Apr 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2017-response-ratios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>You wanna PEESE of d&#39;s?</title>
      <link>http://localhost:4321/pet-peese-performance/</link>
      <pubDate>Thu, 27 Apr 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/pet-peese-performance/</guid>
      <description>


&lt;p&gt;Publication bias—or more generally, outcome reporting bias or dissemination bias—is recognized as a critical threat to the validity of findings from research syntheses. In the areas with which I am most familiar (education and psychology), it has become more or less a requirement for research synthesis projects to conduct analyses to detect the presence of systematic outcome reporting biases. Some analyses go further by trying correct for its distorting effects on average effect size estimates. Widely known analytic techniques for doing so include Begg and Mazumdar’s &lt;a href=&#34;https://dx.doi.org/10.2307/2533446&#34;&gt;rank-correlation test&lt;/a&gt;, the Trim-and-Fill technique proposed by &lt;a href=&#34;https://dx.doi.org/10.2307/2669529&#34;&gt;Duval and Tweedie&lt;/a&gt;, and &lt;a href=&#34;https://dx.doi.org/10.1136/bmj.315.7109.629&#34;&gt;Egger regression&lt;/a&gt; (in its &lt;a href=&#34;https://dx.doi.org/10.1186/1471-2288-9-2&#34;&gt;many variants&lt;/a&gt;). Another class of methods involves selection models (or weight function models), as proposed by &lt;a href=&#34;https://dx.doi.org/10.1007/BF02294384&#34;&gt;Hedges and Vevea&lt;/a&gt;, &lt;a href=&#34;https://dx.doi.org/10.1037/1082-989X.10.4.428&#34;&gt;Vevea and Woods&lt;/a&gt;, and others. As far as I can tell, selection models are well known among methodologists but very seldom applied due to their complexity and lack of ready-to-use software (though &lt;a href=&#34;https://CRAN.R-project.org/package=weightr&#34;&gt;an R package&lt;/a&gt; has recently become available). More recent proposals include the PET-PEESE technique introduced by &lt;a href=&#34;https://dx.doi.org/10.1002/jrsm.1095&#34;&gt;Stanley and Doucouliagos&lt;/a&gt;; Simonsohn, Nelson, and Simmon’s &lt;a href=&#34;https://dx.doi.org/10.1177/1745691614553988&#34;&gt;p-curve technique&lt;/a&gt;; Van Assen, Van Aert, and Wichert’s &lt;a href=&#34;http://dx.doi.org/10.1037/met0000025&#34;&gt;p-uniform&lt;/a&gt;, and others. The list of techniques grows by the day.&lt;/p&gt;
&lt;p&gt;Among these methods, Egger regression, PET, and PEESE are superficially quite appealing due to their simplicity. These methods each involve estimating a fairly simple meta-regression model, using as the covariate the sampling variance of the effect size or some transformation thereof. PET uses the standard error of the effect size as the regressor; PEESE uses the sampling variance (i.e., the squared standard error); PET-PEESE involves first testing whether the PET estimate is statistically significant, using PEESE if it is or PET otherwise. The intercept from one of these regressions is the average effect size estimate from a study with zero sampling variance; the estimated intercept is used as a “bias-corrected” estimator of the population average effect. These methods are also appealing due to their extensibility. Because they are just meta-regressions, it is comparatively easy to extend them to meta-regression models that control for further covariates, to use robust variance estimation to account for dependencies among effect size estimates, etc.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;http://datacolada.org/59&#34;&gt;a recent blog post&lt;/a&gt;, Uri Simonsohn reports some simulation evidence indicating that the PET-PEESE estimator can have large biases under certain conditions, &lt;em&gt;even in the absence of publication bias&lt;/em&gt;. The simulations are based on standardized mean differences from two-group experiments and involve simulating collections of studies that include many with small sample sizes, as might be found in certain areas of psychology. On the basis of these performance assessments, he argues that this purported cure is actually worse than the disease—that PET-PEESE should &lt;em&gt;not&lt;/em&gt; be used in meta-analyses of psychological research because it performs too poorly to be trusted. In &lt;a href=&#34;http://datacolada.org/wp-content/uploads/2017/04/Response-by-Joe-Hilgard-to-Colada-59.pdf&#34;&gt;a response to Uri’s post&lt;/a&gt;, &lt;a href=&#34;http://crystalprisonzone.blogspot.com/&#34;&gt;Joe Hilgard&lt;/a&gt; suggests that some simple modifications to the method can improve its performance. Specifically, Joe suggests using a function of sample size as the covariate (in place of the standard error or sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;), and also using PET or PEESE as stand-alone estimators, rather than using them contingent on a significance test.&lt;/p&gt;
&lt;p&gt;In this post, I follow up Joe’s suggestions while replicating and expanding upon Uri’s simulations, to try and provide a fuller picture of the relative performance of these estimators. In brief, the simulations show that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tests for small-sample bias that use PET or PEESE can have wildly incorrect type-I error rates in the absence of publication bias. Don’t use them.&lt;/li&gt;
&lt;li&gt;The sample-size variants of PET and PEESE &lt;strong&gt;do&lt;/strong&gt; maintain the correct type-I error rates in the absence of publication bias.&lt;/li&gt;
&lt;li&gt;The sample-size variants of PET and PEESE are exactly unbiased in the absence of publication bias.&lt;/li&gt;
&lt;li&gt;However, these adjusted estimators still have a cost, being less precise than the conventional fixed-effect estimator.&lt;/li&gt;
&lt;li&gt;In the presence of varying degrees of publication bias, none of the estimators consistently out-perform the others. If you really really need to use a regression-based correction, the sample-size variant of PEESE seems like it might be a reasonable default method, but it’s still really pretty rough.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;why-use-sample-size&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why use sample size?&lt;/h1&gt;
&lt;p&gt;To see why it makes sense to use a function of sample size as the covariate for PET-PEESE analyses, rather than using the standard error of the effect size estimate, let’s look at the formulas. Say that we have a standardized mean difference estimate from a two-group design (without covariates) with sample sizes &lt;span class=&#34;math inline&#34;&gt;\(n_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_1\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_1 - \bar{y}_0}{s_p},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_1\)&lt;/span&gt; are the sample means within each group and &lt;span class=&#34;math inline&#34;&gt;\(s_p^2\)&lt;/span&gt; is the pooled sample variance. Following convention, we’ll assume that the outcomes are normally distributed within each group, and the groups have common variance. The exact sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is a rather complicated formula, but one which can be approximated reasonably well as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}(d) \approx \frac{n_0 + n_1}{n_0 n_1} + \frac{\delta^2}{2(n_0 + n_1)},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; is the &lt;em&gt;true&lt;/em&gt; standardized mean difference parameter. This formula is a delta-method approximation. The first term captures the variance of the numerator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, so it gets at how precisely the &lt;em&gt;unstandardized&lt;/em&gt; difference in means is estimated. The second term captures the variance of the denominator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, so it gets at how precisely the &lt;em&gt;scale&lt;/em&gt; of the outcome is estimated. The second term also involves the unknown parameter &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;, which must be estimated in practice. The conventional formula for the estimated sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; substitutes &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; in place of &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V = \frac{n_0 + n_1}{n_0 n_1} + \frac{d^2}{2(n_0 + n_1)}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In PET-PEESE analysis, &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; or its square root is used as a covariate in a regression of the effect sizes, as a means of adjusting for publication bias. There are two odd things about this. First, publication bias is about the statistical significance of the group differences, but statistical significance &lt;strong&gt;&lt;em&gt;does not depend on the scale of the outcome&lt;/em&gt;&lt;/strong&gt;. The test of the null hypothesis of no differences between groups is &lt;strong&gt;&lt;em&gt;not&lt;/em&gt;&lt;/strong&gt; based on &lt;span class=&#34;math inline&#34;&gt;\(d / \sqrt{V}\)&lt;/span&gt;. Instead, it is a function of the &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; statistic:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
t = d / \sqrt{\frac{n_0 + n_1}{n_0 n_1}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Consequently, it makes sense to use &lt;strong&gt;&lt;em&gt;only the first term of &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt; as a covariate for purposes of detecting publication biases.&lt;/p&gt;
&lt;p&gt;The second odd thing is that &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; is generally going to be correlated with &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; because we have to use &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; to calculate &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;. As &lt;a href=&#34;http://datacolada.org/wp-content/uploads/2017/04/Response-by-Joe-Hilgard-to-Colada-59.pdf&#34;&gt;Joe explained in his response to Uri&lt;/a&gt;, this means that there will be a non-zero correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; (or between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{V}\)&lt;/span&gt;) except in some very specific cases, even in the absence of any publication bias. Pretty funky.&lt;/p&gt;
&lt;p&gt;This second problem with regression tests for publication bias has been recognized for a while in the literature (e.g., &lt;a href=&#34;https://dx.doi.org/10.1002/sim.698&#34;&gt;Macaskill, Walter, &amp;amp; Irwig, 2001&lt;/a&gt;; &lt;a href=&#34;https://dx.doi.org/10.1001/jama.295.6.676&#34;&gt;Peters et al., 2006&lt;/a&gt;; &lt;a href=&#34;https://dx.doi.org/10.1186/1471-2288-9-2&#34;&gt;Moreno et al., 2009&lt;/a&gt;), but most of the work here has focused on other effect size measures, like odds ratios, that are relevant in clinical medicine. The behavior of these estimators might well differ for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;’s because the dependence between the effect measure and its variance has a different structure.&lt;/p&gt;
&lt;p&gt;Below I’ll investigate how this stuff works with standardized mean differences, which haven’t been studied as extensively as odds ratios. Actually, I know of only two simulation studies that examined the performance of PET-PEESE methods with standardized mean difference estimates: &lt;a href=&#34;http://dx.doi.org/10.2139/ssrn.2659409&#34;&gt;Inzlicht, Gervais, and Berkman (2015)&lt;/a&gt; and &lt;a href=&#34;https://dx.doi.org/10.1177/1948550617693062&#34;&gt;Stanley (2017)&lt;/a&gt;. (Know of others? Leave a comment!) Neither considered using sample-size variants of PET-PEESE. The only source I know of that &lt;em&gt;did&lt;/em&gt; consider this is this &lt;a href=&#34;http://willgervais.com/blog/2015/6/29/pet-peese-vs-peters&#34;&gt;blog post from Will Gervais&lt;/a&gt;, which starts out optimistic about the sample-size variants but ends on a discouraged note. The simulations below build upon Will’s work, as well as Uri’s, by 1) considering a more extensive set of data-generating processes and 2) examining accuracy in addition to bias.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulation model&lt;/h1&gt;
&lt;p&gt;The simulations are based on the following data-generating model, which closely follows &lt;a href=&#34;http://datacolada.org/59&#34;&gt;the structure that Uri used&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Per-cell sample size is generated as &lt;span class=&#34;math inline&#34;&gt;\(n = 12 + B (n_{max} - 12)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(B \sim Beta(\alpha, \beta)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_{max}\)&lt;/span&gt; is the maximum observed sample size. I take &lt;span class=&#34;math inline&#34;&gt;\(n_{max} = 50\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(120\)&lt;/span&gt; and look at three sample size distributions (note that these distributions are pre-selection, so the observed sample size distributions will deviate from these if there is selective publication):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha = \beta = 1\)&lt;/span&gt; corresponds to a uniform distribution on &lt;span class=&#34;math inline&#34;&gt;\([12,n_{max}]\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha = 1, \beta = 3\)&lt;/span&gt; is a distribution with more small studies; and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha = 3, \beta = 1\)&lt;/span&gt; is a distribution with more large studies.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;True effects are simulated as &lt;span class=&#34;math inline&#34;&gt;\(\delta \sim N(\mu, \sigma^2)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(\mu = 0, 0.1, 0.2, ..., 1.0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.0, 0.1, 0.2, 0.4\)&lt;/span&gt;. Note that the values of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; are &lt;em&gt;standard deviations&lt;/em&gt; of the true effects, with &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.0\)&lt;/span&gt; corresponding to the constant effect model and &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.4\)&lt;/span&gt; corresponding to rather substantial effect heterogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Standardized mean difference effect size estimates are generated as in a two-group between-subjects experiment with equal per-cell sample sizes. I do this by taking &lt;span class=&#34;math inline&#34;&gt;\(t = D / \sqrt{S / [2(n - 1)]}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(D \sim N(\delta \sqrt{n / 2}, 1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S \sim \chi^2_{2(n - 1)}\)&lt;/span&gt;, then calculating&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
  d = \left(1 - \frac{3}{8 n - 9}\right) \times \sqrt{\frac{2}{n}} \times t.
  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(That first term is Hedges’ &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; correction, cuz that’s how I roll.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Observed effects are filtered based on statistical significance. Let &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; be the p-value corresponding to the observed &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; and the one-tailed hypothesis test of &lt;span class=&#34;math inline&#34;&gt;\(\delta \leq 0\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .025\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is observed with probability 1. If &lt;span class=&#34;math inline&#34;&gt;\(p \geq .025\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is observed with probability &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;. Noted that this mechanism corresponds to filtering based on two-sided hypothesis tests, where effects are filtered if they are statistically non-significant effects or statistically significant but in the wrong direction. I look at three scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi = 1.0\)&lt;/span&gt; corresponds to no selective publication (all simulated effects are observed);&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi = 0.2\)&lt;/span&gt; corresponds to an intermediate degree of selective publication (some but not non-significant effects are observed); and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi = 0.0\)&lt;/span&gt; corresponds to very strong selective publication (only statistically significant effects are observed).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Each meta-analysis includes a total of &lt;span class=&#34;math inline&#34;&gt;\(k = 100\)&lt;/span&gt; observed studies. Note that in scenarios with publication bias, more (sometimes many more) than 100 studies are generated in order to get 100 observed effects.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each simulated meta-sample, I calculated the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the usual fixed-effect meta-analytic average (I skipped random effects for simplicity);&lt;/li&gt;
&lt;li&gt;the PET estimator (including intercept and slope);&lt;/li&gt;
&lt;li&gt;the PEESE estimator (including intercept and slope);&lt;/li&gt;
&lt;li&gt;PET-PEESE, which is equal to the PEESE intercept if &lt;span class=&#34;math inline&#34;&gt;\(H_0: \beta_0 \leq 0\)&lt;/span&gt; is rejected at the 10% level, and is otherwise equal to the PET intercept (this definition follows &lt;a href=&#34;https://dx.doi.org/10.1177/1948550617693062&#34;&gt;Stanley, 2017&lt;/a&gt;);&lt;/li&gt;
&lt;li&gt;the modified PET estimator, which I’ll call “SPET” for “sample-size PET” (suggestions for better names welcome);&lt;/li&gt;
&lt;li&gt;the modified PEESE estimator, which I’ll call “SPEESE”; and&lt;/li&gt;
&lt;li&gt;SPET-SPEESE, which follows the same conditional logic as PET-PEESE.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Simulation results are summarized across 4000 replications. The R code for all this &lt;a href=&#34;http://localhost:4321/R/PET-PEESE-performance-simulations.R&#34;&gt;lives here&lt;/a&gt;. Complete numerical results &lt;a href=&#34;http://localhost:4321/files/PET-PEESE-Simulation-Results.Rdata&#34;&gt;live here&lt;/a&gt;. Code for creating the graphs below &lt;a href=&#34;http://localhost:4321/R/PET-PEESE-performance-graphs.R&#34;&gt;lives here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;div id=&#34;false-positive-rates-for-publication-bias-detection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;False-positive rates for publication bias detection&lt;/h3&gt;
&lt;p&gt;First, let’s consider the performance of PET and PEESE as tests for detecting publication bias. Here, a statistically significant estimate for the coefficient on the SE (for PET) or on &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; (for PEESE) is taken as evidence of small-sample bias. For that logic to hold, the tests should maintain the nominal error rates in the absence of publication bias.&lt;/p&gt;
&lt;p&gt;The figure below depicts the Type-I error rates of the PET and PEESE tests when &lt;span class=&#34;math inline&#34;&gt;\(\pi = 1\)&lt;/span&gt; (so no publication bias at all), for a one-sided test of &lt;span class=&#34;math inline&#34;&gt;\(H_0: \beta_1 \leq 0\)&lt;/span&gt; at the nominal level of &lt;span class=&#34;math inline&#34;&gt;\(\alpha = .05\)&lt;/span&gt;. Rejection rates are plotted for varying true mean effects, levels of heterogeneity, and sample size distributions. Separate colors are used for maximum sample sizes of 50 or 120.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PET-PEESE-performance_files/figure-html/PET-PEESE-rejection-rates-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both tests are horribly mis-calibrated, tending to reject the null hypothesis far more often than they should. This happens because there is a non-zero correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;, even in the absence of publication bias. Thus, it does not follow that rejecting &lt;span class=&#34;math inline&#34;&gt;\(H_0: \beta_1 \leq 0\)&lt;/span&gt; implies rejection of the hypothesis that there is no publication bias. (Sorry, that’s at least a triple negative!)&lt;/p&gt;
&lt;p&gt;Here’s the same graph, but using the SPET and SPEESE estimators:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PET-PEESE-performance_files/figure-html/SPET-SPEESE-rejection-rates-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, this may be the World’s Most Boring Figure, but it does make clear that both the SPET and SPEESE tests maintain the correct Type-I error rate. (Any variation in rejection rates is just Monte Carlo error.) Thus, it seems pretty clear that if we want to test for small-sample bias, SPET or SPEESE should be used rather than PET or PEESE.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bias-of-bias-corrected-estimators&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bias of bias-corrected estimators&lt;/h3&gt;
&lt;p&gt;Now let’s consider the performance of these methods as estimators of the population mean effect. &lt;a href=&#34;http://datacolada.org/59&#34;&gt;Uri’s analysis&lt;/a&gt; focused on the bias of the estimators, meaning the difference between the average value of the estimator (across repeated samples) and the true parameter. The plot below depicts the expected level of PET, PEESE, and PET-PEESE as a function of the true mean effect, using the uniform distribution of studies and a maximum sample size of &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PET-PEESE-performance_files/figure-html/bias-of-PET-PEESE-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All three of these estimators are pretty bad in terms of bias. In the absence of publication bias, they consistently &lt;em&gt;under&lt;/em&gt;-estimate the true mean effect. With intermediate or strong publication bias, PET and PET-PEESE have a consistent downward bias. As an unconditional estimator, PEESE tends to have a positive bias when the true effect is small, but this decreases and becomes negative as the true effect increases. For all three estimators, bias increases as the degree of heterogeneity increases.&lt;/p&gt;
&lt;p&gt;Here is how these estimators compare to the modified SPET, SPEESE, and SPET-SPEESE estimators, as well as to the usual fixed-effect average with no correction for publication bias:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PET-PEESE-performance_files/figure-html/bias-of-SPET-SPEESE-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the left column, we see that SPET and SPEESE are exactly unbiased (and SPET-SPEESE is nearly so) in the absence of selective publication. So is regular old fixed effect meta-analysis, of course. In the middle and right columns, studies are selected based partially or fully on statistical significance, and things get messy. Overall, there’s no consistent winner between PEESE versus SPEESE. At small or moderate levels of between-study heterogeneity, and when the true mean effect is small, PEESE, SPEESE, and SPET-SPEESE have fairly similar biases, but PEESE appears to have a slight edge. This seems to me to be nothing but a fortuitous accident, in that the bias induced by the correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; just happens to work in the right direction. Then, as the true mean effect increases, SPEESE and SPET-SPEESE start to edge out PEESE. This makes sense because the bias induced by the correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; will be larger when the true effect sizes are larger.&lt;br /&gt;
These trends seem mostly to hold for the other sample size distributions I examined too, although the biases of PEESE and PET-PEESE aren’t as severe when the maximum sample size is larger. You can see for yourself here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-1.png&#34;&gt;Uniform distribution of studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-2.png&#34;&gt;More small studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-3.png&#34;&gt;More small studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-4.png&#34;&gt;More large studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-bias-of-SPET-SPEESE-5.png&#34;&gt;More large studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;accuracy-of-bias-corrected-estimators&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Accuracy of bias-corrected estimators&lt;/h3&gt;
&lt;p&gt;Bias isn’t everything, of course. Now let’s look at the overall accuracy of these estimators, as measured by root mean squared error (RMSE). RMSE is a function of both bias and sampling variance, and so is one way to weigh an estimator that is biased but fairly precise against an estimator that is perfectly unbiased but noisy. The following chart plots the RMSE of all of the estimators (following the same layout as above, just with a different vertical axis):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PET-PEESE-performance_files/figure-html/RMSE-plots-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Starting in the left column where there’s no selective publication, we can see that the normal fixed-effect average has the smallest RMSE (and so is most accurate). The next most accurate is SPEESE, which uniformly beats out PEESE, PET-PEESE, SPET, and SPET-SPEESE. It’s worth noting, though, that there is a fairly large penalty for using SPEESE when it is unnecessary: even with a quite large sample of 100 studies, SPEESE still has twice the RMSE of the FE estimator.&lt;/p&gt;
&lt;p&gt;The middle column shows these estimators’ RMSE when there is an intermediate degree of selective publication. Because of the “fortuitous accident” of how the correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; affects the PEESE estimator, it is more accurate than SPEESE for small values of the true mean effect. Its advantage is larger when heterogeneity is larger, and heterogeneity also affects the point (i.e., what true mean effect) at which SPEESE catches up with PEESE. Then at larger true mean effects, the accuracy of SPEESE continues to improve while the accuracy of PEESE degrades. It is also interesting to note that at this intermediate degree of selective publication, none of the other bias-correction estimators (PET-PEESE, SPET, SPET-SPEESE) compete with PEESE and SPEESE.&lt;/p&gt;
&lt;p&gt;Finally, the right column plots RMSE when there’s strong selective publication, so only statistically significant effects appear. Just as in the middle column, PEESE edges out SPEESE for smaller values of the true mean effect. For very small true effects, both of these estimators are edged out by PET-PEESE and SPET-SPEESE. This only holds over a very small range for the true mean effect though, and for true effects above that range these conditional estimators perform poorly—consistently worse than just using PEESE or SPEESE.&lt;/p&gt;
&lt;p&gt;Here are charts for the other sample size distributions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-RMSE-plots-1.png&#34;&gt;Uniform distribution of studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-RMSE-plots-2.png&#34;&gt;More small studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-RMSE-plots-3.png&#34;&gt;More small studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-RMSE-plots-4.png&#34;&gt;More large studies, maximum sample size of 50&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/rmarkdown-libs/figure-html4/more-RMSE-plots-5.png&#34;&gt;More large studies, maximum sample size of 120&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The trends that I’ve noted mostly seem to hold for the other sample size distributions (but correct me if you disagree! I’m getting kind of bleary-eyed at the moment…). One difference worth noting is that when the sample size distribution skews towards having more large studies, the accuracy of the regular fixed-effect estimator improves a bit. At intermediate degrees of selective publication, the fixed-effect estimator is &lt;em&gt;consistently&lt;/em&gt; more accurate than SPEESE, and mostly more accurate than PEESE too. With strong selective publication, though, the FE estimator blows up just as before.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions-caveats-further-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions, caveats, further thoughts&lt;/h1&gt;
&lt;p&gt;Where does this leave us? The one thing that seems pretty clear is that if the meta-analyst’s goal is to test for potential small-sample bias, then SPET or SPEESE should be used rather than PET or PEESE. Beyond that, we’re in a bit of a morass. None of the estimators consistently out-performs the others across the conditions of the simulation. It’s only under certain conditions that any of the bias-correction methods are more accurate than using the regular FE estimator, and those conditions aren’t easy to identify in a real data analysis because they depend on the degree of publication bias.&lt;/p&gt;
&lt;div id=&#34;caveats&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Caveats&lt;/h3&gt;
&lt;p&gt;These findings are also pretty tentative because of the limitations of the simulation conditions examined here. The distribution of sample sizes seems to affect the relative accuracy of the estimators to a certain degree, but I’ve only looked at a limited set of possibilities, and also limited consideration to rather large meta-samples of 100 studies.&lt;/p&gt;
&lt;p&gt;Another caveat is that the simulations are based on &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; estimates from a two-group, between-subjects design with no covariates. In many applications, there is considerably more diversity in study designs. A given meta-analysis might include two-group, post-test only designs as well as between-subjects designs with a pre-test covariate or with repeated measures, as well as two-group designs with multiple (or multi-dimensional) outcomes. All of this introduces further layers of complexity into the relationship between sample size, effect magnitude, and selective publication.&lt;/p&gt;
&lt;p&gt;A further, quite important caveat is that selective publication is not the only possible explanation for a correlation between effect size and sample sizes. &lt;a href=&#34;http://datacolada.org/58&#34;&gt;In another recent post&lt;/a&gt;, Uri sketches a scenario where investigators choose sample size to achieve adequate power (so following best practice!) for predicted effect sizes. If 1) true effects are heterogeneous and 2) investigators’ predictions are correlated with true effect sizes, then a meta-analysis will have effect size estimates that are correlated with sample size even in the absence of publication bias. A &lt;a href=&#34;http://bayesfactor.blogspot.com/2016/01/asymmetric-funnel-plots-without.html&#34;&gt;blog post by Richard Morey&lt;/a&gt; illustrates another possibility that leads to effect-sample size correlation, in which resource constraints induce negative correlation between sample size and the reliability of the outcome measure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hold-me-hostage&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Hold me hostage&lt;/h3&gt;
&lt;p&gt;It seems to me that one lesson we can draw from this is that these regression-based corrections are pretty meager as analytic methods. We need to understand the &lt;em&gt;mechanism&lt;/em&gt; of selective publication in order to be able to correct for its consequences, but the regression-based corrections don’t provide direct information here (even though their performance depends on it!). I think this speaks to the need for methods that directly model the mechanism, which means turning to selection models and studying the distribution of p-values. Also, without bringing in other pieces of information (like p-values), it seems more or less impossible to tease apart selective publication from other possible explanations for effect-sample size correlation.&lt;/p&gt;
&lt;p&gt;If I had to pick one of the regression-based bias-correction method to use in an application—as in, if you handcuffed me to my laptop and threatened to not let me go until I analyzed your effect sizes—then on the basis of these simulation exercises, I think I would probably go with SPEESE as a default, and perhaps also report PEESE, but I wouldn’t bother with any of the others. Even though SPEESE is less accurate than PEESE and some other estimators under certain conditions, on a practical level it seems kind of silly to use different estimators when testing for publication bias versus trying to correct for it. And whatever advantage that regular PEESE has over SPEESE strikes me as kind of like cheating—it relies on an induced correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; to gain an accuracy advantage under certain conditions, but that correlation causes big problems under other conditions.&lt;/p&gt;
&lt;p&gt;Even if you chained me to the laptop, I would also definitely include a caution that these estimators should be interpreted more as sensitivity analyses than as bias-corrected estimates of the overall mean effect. This is roughly in line with the conclusions of &lt;a href=&#34;http://dx.doi.org/10.2139/ssrn.2659409&#34;&gt;Inzlicht, Gervais, and Berkman (2015)&lt;/a&gt;. From their abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our simulations revealed that not one of the bias-correction techniques revealed itself superior in all conditions, with corrections performing adequately in some situations but inadequately in others. Such a result implies that meta-analysts ought to present a range of possible effect sizes and to consider them all as being possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Their conclusion was in reference to PET, PEESE, and PET-PEESE. Unfortunately, the tweaks of SPET and SPEESE don’t clarify the situation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;outstanding-questions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Outstanding questions&lt;/h3&gt;
&lt;p&gt;These exercises have left me wondering about a couple of things, which I’ll just mention briefly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I haven’t calculated confidence interval coverage levels for these simulations. I should probably add that but need to move on at the moment.&lt;/li&gt;
&lt;li&gt;The ever-popular Trim-and-Fill procedure is based on the assumption that a funnel plot will be symmetric in the absence of publication bias. This assumption won’t hold if there’s correlation between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;, and so it would be interesting to see if using a function of sample size (i.e., just the first term of &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;) could improve the performance of Trim-and-Fill.&lt;/li&gt;
&lt;li&gt;Under the model examined here, the bias in PET, PEESE, SPET, and SPEESE comes from the fact that the relevant regression relationships aren’t actually linear under selective publication. I do wonder whether using some more flexible sort of regression model (perhaps including a non-linear term) could reduce bias. The trick would be to find something that’s still constrained enough so that bias improvements aren’t swamped by increased variance.&lt;/li&gt;
&lt;li&gt;Many of the applications that I am familiar with involve syntheses where some studies contribute multiple effect size estimates, which might also be inter-correlated. Very little work has examined how regression corrections like PET-PEESE perform in such settings (the only study I know of is &lt;a href=&#34;http://www.economics-ejournal.org/economics/discussionpapers/2015-9&#34;&gt;Reed, 2015&lt;/a&gt;, which involves a specialized and I think rather unusual data-generating model). For that matter, I don’t know of any work that looks at other publication bias correction methods either. Or what selective publication even means in this setting. Somebody should really work on that.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New working paper: Using log response ratios for meta-analyzing SCDs with behavioral outcomes</title>
      <link>http://localhost:4321/using-log-response-ratios/</link>
      <pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/using-log-response-ratios/</guid>
      <description>


&lt;p&gt;One of the papers that came out of my dissertation work (&lt;a href=&#34;http://localhost:4321/files/Measurement-comparable-ES.pdf&#34;&gt;Pustejovsky, 2015&lt;/a&gt;) introduced an effect size metric called the &lt;strong&gt;log response ratio&lt;/strong&gt; (or LRR) for use in meta-analysis of single-case research—particularly for single-case studies that measure behavioral outcomes through systematic direct observation. The original paper was pretty technical since it focused mostly on a formal measurement model for behavioral observation data. I’ve just completed a tutorial paper that demonstrates how to use the LRR for meta-analyzing single-case studies with behavioral outcomes. In this paper, I’ve tried to present the methods in as accessible a manner as I could muster, to provide a sort of “user’s guide” for researchers wanting to apply the LRR for their own work. You can find the &lt;a href=&#34;https://osf.io/4fe6u/&#34;&gt;working paper&lt;/a&gt; and &lt;a href=&#34;https://osf.io/c3fe9/&#34;&gt;supplementary materials&lt;/a&gt; (including data and replication code) on the Open Science Framework. I would welcome your feedback and questions about this work!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Small sample corrections for use of cluster-robust standard errors in the analysis of school-based experiments</title>
      <link>http://localhost:4321/talk/sree-2017-small-sample-corrections/</link>
      <pubDate>Thu, 02 Mar 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sree-2017-small-sample-corrections/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Functional assessment-based interventions for students with or at-risk for high incidence disabilities: Field-testing single-case synthesis methods</title>
      <link>http://localhost:4321/publication/fabi-meta-analysis/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/fabi-meta-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research synthesis and meta-analysis of single-case designs</title>
      <link>http://localhost:4321/publication/meta-analysis-of-scd/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/meta-analysis-of-scd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Between-case standardized mean difference effect sizes for single-case designs: A primer and tutorial using the scdhlm web application</title>
      <link>http://localhost:4321/publication/bc-smd-primer-and-tutorial/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/bc-smd-primer-and-tutorial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect sizes for single-case research</title>
      <link>http://localhost:4321/talk/ies-2016-single-case-effect-sizes/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/ies-2016-single-case-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New tutorial paper on BC-SMD effect sizes</title>
      <link>http://localhost:4321/scdhlm-tutorial/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/scdhlm-tutorial/</guid>
      <description>


&lt;p&gt;I’m pleased to announce that the &lt;a href=&#34;https://www.campbellcollaboration.org/&#34;&gt;Campbell Collaboration&lt;/a&gt; has just published a new discussion paper that I wrote with my colleagues Jeff Valentine and Emily Tanner-Smith about &lt;a href=&#34;https://campbellcollaboration.org/library/effect-sizes-single-case-designs-campbell-discussion-paper-1.html&#34;&gt;between-case standardized mean difference effect sizes for single-case designs&lt;/a&gt;.
The paper provides a relatively non-technical introduction to BC-SMD effect sizes and a tutorial on how to use the &lt;a href=&#34;https://jepusto.shinyapps.io/scdhlm/&#34;&gt;scdhlm web-app&lt;/a&gt; for calculating estimates of the BC-SMD for user-provided data.
If you have any questions or feedback about the app, please feel free to contact me!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Presentation at IES 2016 PI meeting</title>
      <link>http://localhost:4321/ies-2016-pi-meeting/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/ies-2016-pi-meeting/</guid>
      <description>


&lt;p&gt;I am just back from the Institute of Education Sciences 2016 Principal Investigators meeting. Rob Horner had organized a session titled “Single-case methods: Current status and needed directions” as a tribute to our colleague Will Shadish, who passed away this past year. Rob invited me to give some brief remarks about Will as a mentor, and then to present some of my work with Will and Larry Hedges on effect sizes for single-case research. Here are &lt;a href=&#34;http://localhost:4321/files/Single-case-methods-IES-PI-meeting-2016.pdf&#34;&gt;the slides from my part of the presentation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bug in nlme::lme with fixed sigma and REML estimation</title>
      <link>http://localhost:4321/bug-in-nlme-with-fixed-sigma/</link>
      <pubDate>Mon, 07 Nov 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/bug-in-nlme-with-fixed-sigma/</guid>
      <description>


&lt;p&gt;About one year ago, the &lt;code&gt;nlme&lt;/code&gt; package introduced a feature that allowed the user to specify a fixed value for the residual variance in linear mixed effect models fitted with &lt;code&gt;lme()&lt;/code&gt;. This feature is interesting to me because, when used with the &lt;code&gt;varFixed()&lt;/code&gt; specification for the residual weights, it allows for estimation of a wide variety of meta-analysis models, including basic random effects models, bivariate models for estimating effects by trial arm, and other sorts of multivariate/multi-level random effects models. However, in kicking the tires on this feature, I noticed that the results that it produces are not quite consistent with the results produced by &lt;code&gt;metafor&lt;/code&gt;, which is the main package I use for fitting meta-analytic models.&lt;/p&gt;
&lt;p&gt;In this post, I document several examples of discrepant estimates between &lt;code&gt;lme()&lt;/code&gt; and &lt;code&gt;rma.mv()&lt;/code&gt;, using standard datasets included in the &lt;code&gt;metafor&lt;/code&gt; package. The main take-aways are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The discrepancies arise only with &lt;code&gt;REML&lt;/code&gt; estimation (not with &lt;code&gt;ML&lt;/code&gt; estimation).&lt;/li&gt;
&lt;li&gt;The discrepancies are present whether or not the &lt;code&gt;varFixed&lt;/code&gt; specification is used.&lt;/li&gt;
&lt;li&gt;The discrepancies are mostly small (with minimal impact on the standard errors of the fixed effect estimates), but are larger than I would expect from computational/convergence differences alone.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another example, based on a different dataset, is documented in &lt;a href=&#34;https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16975&#34;&gt;this bug report&lt;/a&gt;. Wolfgang Viechtbauer, author of the &lt;code&gt;metafor&lt;/code&gt; package, identified this problem with &lt;code&gt;lme&lt;/code&gt; a few months ago already (see his responses in &lt;a href=&#34;https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q2/024862.html&#34;&gt;this thread&lt;/a&gt; on the R mixed models mailing list) and noted that the issue was localized to REML estimation. My thanks to Wolfgang for providing feedback on this post.&lt;/p&gt;
&lt;div id=&#34;basic-random-effects-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Basic random effects model&lt;/h3&gt;
&lt;p&gt;This example fits a basic random effects model to the BCG vaccine data, available within &lt;code&gt;metafor&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
library(nlme)

bcg_example &amp;lt;- function(method = &amp;quot;REML&amp;quot;, constant_var = FALSE) {
  
  data(dat.bcg)
  dat &amp;lt;- escalc(measure=&amp;quot;OR&amp;quot;, ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
  
  v_bar &amp;lt;- mean(dat$vi)
  if (constant_var) dat$vi &amp;lt;- v_bar
  
  # random-effects model using rma.uni()
  LOR_uni_fit &amp;lt;- rma(yi, vi, data=dat, method = method)
  LOR_uni &amp;lt;- with(LOR_uni_fit, 
                  data.frame(f = &amp;quot;rma.uni&amp;quot;, 
                             logLik = logLik(LOR_uni_fit),
                             est = as.numeric(b), 
                             se = se, 
                             tau = sqrt(tau2)))
  
  # random-effects model using rma.mv()
  LOR_mv_fit &amp;lt;- rma.mv(yi, vi, random = ~ 1 | trial, data=dat, method = method)
  LOR_mv &amp;lt;- with(LOR_mv_fit, 
                 data.frame(f = &amp;quot;rma.mv&amp;quot;, 
                            logLik = logLik(LOR_mv_fit),
                            est = as.numeric(b), 
                            se = se, 
                            tau = sqrt(sigma2)))
  
  # random-effects model using lme()
  if (constant_var) {
    LOR_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                       random = ~ 1 | trial,
                       control = lmeControl(sigma = sqrt(v_bar)))
    tau &amp;lt;- sqrt(as.numeric(coef(LOR_lme_fit$modelStruct$reStruct, unconstrained = FALSE)) * v_bar) 
  } else {
    LOR_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                       random = ~ 1 | trial,
                       weights = varFixed(~ vi),
                       control = lmeControl(sigma = 1))
    tau &amp;lt;- sqrt(as.numeric(coef(LOR_lme_fit$modelStruct$reStruct, unconstrained = FALSE)))
  }
  LOR_lme &amp;lt;- data.frame(f = &amp;quot;lme&amp;quot;, 
                        logLik = logLik(LOR_lme_fit),
                        est = as.numeric(fixef(LOR_lme_fit)), 
                        se = as.numeric(sqrt(vcov(LOR_lme_fit))), 
                        tau = tau)
  
  rbind(LOR_uni, LOR_mv, LOR_lme)
  
}

bcg_example(&amp;quot;REML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f    logLik        est        se       tau
## 1 rma.uni -12.57566 -0.7451778 0.1860279 0.5811816
## 2  rma.mv -12.57566 -0.7451778 0.1860280 0.5811818
## 3     lme -13.34043 -0.7471979 0.1916902 0.6030524&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_example(&amp;quot;REML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f    logLik        est        se       tau
## 1 rma.uni -12.96495 -0.7716272 0.1977007 0.5911451
## 2  rma.mv -12.96495 -0.7716272 0.1977007 0.5911452
## 3     lme -15.62846 -0.7716272 0.1899448 0.5571060&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_example(&amp;quot;ML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f    logLik        est        se       tau
## 1 rma.uni -13.07276 -0.7419668 0.1779534 0.5499605
## 2  rma.mv -13.07276 -0.7419669 0.1779534 0.5499608
## 3     lme -13.07276 -0.7419668 0.1779534 0.5499605&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_example(&amp;quot;ML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         f     logLik        est        se       tau
## 1 rma.uni -13.525084 -0.7716272 0.1899447 0.5571059
## 2  rma.mv -13.525084 -0.7716272 0.1899447 0.5571059
## 3     lme  -2.479133 -0.7716272 0.1899447 0.5571060&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bi-variate-random-effects-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bi-variate random effects model&lt;/h3&gt;
&lt;p&gt;This example fits a bi-variate random effects model, also to the BCG vaccine data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate &amp;lt;- function(method = &amp;quot;REML&amp;quot;, constant_var = FALSE) {
  data(dat.bcg)
  dat_long &amp;lt;- to.long(measure=&amp;quot;OR&amp;quot;, ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
  levels(dat_long$group) &amp;lt;- c(&amp;quot;exp&amp;quot;, &amp;quot;con&amp;quot;)
  dat_long$group &amp;lt;- relevel(dat_long$group, ref=&amp;quot;con&amp;quot;)
  dat_long &amp;lt;- escalc(measure=&amp;quot;PLO&amp;quot;, xi=out1, mi=out2, data=dat_long)

  v_bar &amp;lt;- mean(dat_long$vi)
  
  if (constant_var) dat_long$vi &amp;lt;- v_bar
  
  # bivariate random-effects model using rma.mv()
  
  bv_rma_fit &amp;lt;- rma.mv(yi, vi, mods = ~ group, 
                       random = ~ group | study, 
                       struct = &amp;quot;UN&amp;quot;, method = method,
                       data=dat_long)
  bv_rma &amp;lt;- with(bv_rma_fit, data.frame(f = &amp;quot;rma.mv&amp;quot;,
                                        logLik = logLik(bv_rma_fit),
                                        tau1 = sqrt(tau2[1]),
                                        tau2 = sqrt(tau2[2])))
  
  # bivariate random-effects model using lme()
  if (constant_var) {
    bv_lme_fit &amp;lt;- lme(yi ~ group, data = dat_long, method = method, 
                      random = ~ group | study,
                      control = lmeControl(sigma = sqrt(v_bar)))
    tau_sq &amp;lt;- colSums(coef(bv_lme_fit$modelStruct$reStruct, unconstrained = FALSE) * matrix(c(1,0,0, 1,2,1), 3, 2)) * v_bar
    
  } else {
    bv_lme_fit &amp;lt;- lme(yi ~ group, data = dat_long, method = method, 
                      random = ~ group | study,
                      weights = varFixed(~ vi),
                      control = lmeControl(sigma = 1))
    
    tau_sq &amp;lt;- colSums(coef(bv_lme_fit$modelStruct$reStruct, unconstrained = FALSE) * matrix(c(1,0,0, 1,2,1), 3, 2))
    
  }
  
  bv_lme &amp;lt;- data.frame(f = &amp;quot;lme&amp;quot;,
                       logLik = logLik(bv_lme_fit),
                       tau1 = sqrt(tau_sq[1]),
                       tau2 = sqrt(tau_sq[2]))
  
  rbind(bv_rma, bv_lme)
  
}

bcg_bivariate(&amp;quot;REML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik     tau1     tau2
## 1 rma.mv -31.50167 1.617807 1.244429
## 2    lme -32.32612 1.631619 1.254437&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate(&amp;quot;REML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik     tau1     tau2
## 1 rma.mv -31.09623 1.644897 1.191679
## 2    lme -37.06035 1.578435 1.142260&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate(&amp;quot;ML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik     tau1     tau2
## 1 rma.mv -33.08793 1.551558 1.196399
## 2    lme -33.08793 1.551558 1.196399&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bcg_bivariate(&amp;quot;ML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f     logLik     tau1    tau2
## 1 rma.mv -32.647023 1.578434 1.14226
## 2    lme  -2.237355 1.578434 1.14226&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;three-level-random-effects-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Three-level random-effects model&lt;/h3&gt;
&lt;p&gt;This example fits a three-level random-effects model to the data from Konstantopoulos (2011):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos &amp;lt;- function(method = &amp;quot;REML&amp;quot;, constant_var = FALSE) {
  
  dat &amp;lt;- get(data(dat.konstantopoulos2011))
  v_bar &amp;lt;- mean(dat$vi)
  if (constant_var) dat$vi &amp;lt;- v_bar
  
  # multilevel random-effects model using rma.mv()
  ml_rma_fit &amp;lt;- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat, method = method)
  
  ml_rma &amp;lt;- with(ml_rma_fit, 
                 data.frame(f = &amp;quot;rma.mv&amp;quot;, 
                            logLik = logLik(ml_rma_fit),
                            est = as.numeric(b), 
                            se = se, 
                            tau1 = sqrt(sigma2[1]), 
                            tau2 = sqrt(sigma2[2])))
  
  # multilevel random-effects model using lme()
  if (constant_var) {
    ml_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                      random = ~ 1 | district / school,
                      control = lmeControl(sigma = sqrt(v_bar)))
    tau &amp;lt;- sqrt(as.numeric(coef(ml_lme_fit$modelStruct$reStruct, unconstrained = FALSE)) * v_bar)
    
  } else {
    ml_lme_fit &amp;lt;- lme(yi ~ 1, data = dat, method = method, 
                      random = ~ 1 | district / school,
                      weights = varFixed(~ vi),
                      control = lmeControl(sigma = 1))
    tau &amp;lt;- sqrt(as.numeric(coef(ml_lme_fit$modelStruct$reStruct, unconstrained = FALSE)))
    
  }  
  ml_lme &amp;lt;- data.frame(f = &amp;quot;lme&amp;quot;,
                       logLik = logLik(ml_lme_fit),
                       est = as.numeric(fixef(ml_lme_fit)),
                       se = as.numeric(sqrt(diag(vcov(ml_lme_fit)))),
                       tau1 = tau[2],
                       tau2 = tau[1])
  
  rbind(ml_rma, ml_lme)
  
}

Konstantopoulos(&amp;quot;REML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f     logLik       est         se      tau1      tau2
## 1 rma.mv  -7.958724 0.1847132 0.08455592 0.2550724 0.1809324
## 2    lme -10.716781 0.1841827 0.08641374 0.2605790 0.1884588&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos(&amp;quot;REML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f     logLik       est         se      tau1      tau2
## 1 rma.mv  -9.724839 0.1724309 0.08052701 0.2401816 0.1878155
## 2    lme -16.119274 0.1724309 0.07980479 0.2380275 0.1848778&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos(&amp;quot;ML&amp;quot;, constant_var = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik       est         se      tau1      tau2
## 1 rma.mv -8.394936 0.1844554 0.08048168 0.2402881 0.1812865
## 2    lme -8.394936 0.1844554 0.08048168 0.2402881 0.1812865&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Konstantopoulos(&amp;quot;ML&amp;quot;, constant_var = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        f    logLik       est         se      tau1      tau2
## 1 rma.mv -10.11095 0.1712365 0.07645094 0.2250687 0.1881229
## 2    lme  90.21692 0.1712365 0.07645093 0.2250687 0.1881228&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What is Tau-U?</title>
      <link>http://localhost:4321/what-is-tau-u/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/what-is-tau-u/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://dx.doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber (2011)&lt;/a&gt; proposed the Tau-U index—actually several indices, rather—as effect size measures for single-case designs. The original paper describes several different indices that involve corrections for trend during the baseline phase, treatment phase, both phases, or neither phase. Without correcting for trends in either phase, the index is equal to the Mann-Whitney &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; statistic calculated by comparing every pair of observations containing one point from each phase, scaled by the total number of such pairs. This version, which I’ll call just “Tau”, is simply a &lt;a href=&#34;http://localhost:4321/NAP-SEs-and-CIs&#34;&gt;linear re-scaling of the NAP statistic&lt;/a&gt; to the range [-1,1].&lt;/p&gt;
&lt;p&gt;To correct for baseline trend, the original paper proposes to calculate Kendall’s rank correlation (&lt;span class=&#34;math inline&#34;&gt;\(\tau_A\)&lt;/span&gt;) between the phase A outcome data and the session numbers and use the result to make an adjustment to Tau. The other analyses presented in the original paper (incorporating adjustments for time trends during the treatment phase) are not presented in subsequent review papers, nor are they implemented in &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;the web-calculator&lt;/a&gt; created by the authors, and so I won’t discuss them further here. Instead, in this post I will examine the calculation of the version of Tau-U that incorporates a baseline trend correction. This version seems to be the most widely applied in practice (likely due to the availability of the web-calculator) and is presented in several review papers by the same authors. It turns out though, that the definition of the index has shifted from the original paper to subsequent presentations.&lt;/p&gt;
&lt;p&gt;To make this concrete, let me first define a couple of things. Suppose that we have data from the baseline and treatment phases for a single case, where the baseline phase has &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; observations and treatment phase has &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations. Let &lt;span class=&#34;math inline&#34;&gt;\(y^A_1,...,y^A_m\)&lt;/span&gt; denote the baseline phase data and &lt;span class=&#34;math inline&#34;&gt;\(y^B_1,...,y^B_n\)&lt;/span&gt; denote the treatment phase data. Let &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; denote Kendall’s S statistic calculated for the comparison between phases and &lt;span class=&#34;math inline&#34;&gt;\(S_A\)&lt;/span&gt; denote Kendall’s S statistic calculated on the baseline trend. More precisely,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
S_P &amp;amp;= \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) - I\left(y^B_j &amp;lt; y^A_i\right)\right] \\
S_A &amp;amp;= \sum_{i=1}^{m - 1} \sum_{j = i + 1}^m \left[I\left(y^A_j &amp;gt; y^A_i\right) - I\left(y^A_j &amp;lt; y^A_i\right)\right].
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; is calculated from &lt;span class=&#34;math inline&#34;&gt;\(m \times n\)&lt;/span&gt; pairs of observations, and Tau (without trend correction) is equal to &lt;span class=&#34;math inline&#34;&gt;\(\text{Tau} = S_P / (m n)\)&lt;/span&gt;. Furthermore, &lt;span class=&#34;math inline&#34;&gt;\(S_A\)&lt;/span&gt; is calculated from &lt;span class=&#34;math inline&#34;&gt;\(m (m - 1) / 2\)&lt;/span&gt; pairs of observations and Kendall’s rank correlation coefficient for the baseline phase observations is &lt;span class=&#34;math inline&#34;&gt;\(t_A = S_A / [m (m - 1) / 2]\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;the-original-version&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The original version&lt;/h2&gt;
&lt;p&gt;In the original paper, the authors explain that values of Tau-U can be calculated by adding or substracting values of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;, weighted by the corresponding number of pairs. Thus, Tau-U would be calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau-U} = \frac{S_P - S_A}{mn + m(m - 1) / 2} = \frac{2n}{2n + m - 1} \text{Tau} - \frac{m - 1}{2n + m - 1} t_A.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Both &lt;span class=&#34;math inline&#34;&gt;\(\text{Tau}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t_A\)&lt;/span&gt; have range [-1,1], and so Tau-U has the same range. This version of Tau-U can be calculated using &lt;a href=&#34;https://manolov.shinyapps.io/Overlap/&#34;&gt;this web app by Rumen Manolov&lt;/a&gt;, which is based on &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2842869/Tau_U.R&#34;&gt;this R code by Kevin Tarlow&lt;/a&gt;. (The app and the R script also provide the other variants of Tau-U described in &lt;a href=&#34;http://dx.doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber (2011)&lt;/a&gt;.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-revised-version&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The revised (?) version&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://dx.doi.org/10.1177/0145445511399147&#34;&gt;Parker, Vannest, and Davis (2011)&lt;/a&gt; reviewed nine different non-overlap indices for use with data from single-case designs, including Tau-U. Rather than describing all four variations from the original paper, the authors define the index as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tau-U (Parker et al., in press) extends [Tau] to control for undesirable positive baseline trend (monotonic trend). Monotonic trend is the upward progression of data points in any configuration, whether linear, curvilinear, or even in a mixed pattern of “fits and starts” (p. 11).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this and subsequent review articles, Tau-U seems to refer exclusively to the variant involving comparison between phases A and B, with an adjustment for phase A trend. That seems a sensible enough choice, which could have been due to space limitations, guidance from the journal editor, or further refinement of the methods (i.e., recognizing which of the variants would be most useful in application). However, the presentation of Tau-U in this article involved more than a change in emphasis—the definition of the index also changed. Following the notation above, Tau-U was now defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau-U} = \frac{S_P - S_A}{mn} = \text{Tau} - \frac{m - 1}{2n} t_A.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The logical range of this version of the index is from &lt;span class=&#34;math inline&#34;&gt;\(-(2n + m - 1) / (2n)\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\((2n + m - 1) / (2n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This is the version of Tau-U implemented in the &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;singlecaseresearch.org&lt;/a&gt; web calculator. It is also the version described in a later chapter by the same authors (&lt;a href=&#34;http://dx.doi.org/10.1037/14376-005&#34;&gt;Parker, Vannest, &amp;amp; Davis, 2014&lt;/a&gt;) and a review article by &lt;a href=&#34;http://dx.doi.org/10.1111/1467-8578.12091&#34;&gt;Rakap (2015)&lt;/a&gt;. &lt;a href=&#34;http://localhost:4321/Tau-U&#34;&gt;My previous post about Tau-U&lt;/a&gt; also presented this version of the index and noted that its magnitude is sensitive to the lengths of the baseline and treatment phases, which makes it rather difficult to interpret the Tau-U index as a measure of treatment effect magnitude.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparison&lt;/h2&gt;
&lt;p&gt;Here is an R function for calculating the original or revised versions of Tau-U:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Tau_U &amp;lt;- function(A_data, B_data, version = &amp;quot;revised&amp;quot;) {
    m &amp;lt;- length(A_data)
    n &amp;lt;- length(B_data)
    Q_A &amp;lt;- sapply(A_data, function(j) (j &amp;gt; A_data) - (j &amp;lt; A_data))
    Q_P &amp;lt;- sapply(B_data, function(j) (j &amp;gt; A_data) - (j &amp;lt; A_data))
    
    if (version==&amp;quot;original&amp;quot;) {
      (sum(Q_P) - sum(Q_A[upper.tri(Q_A)])) / (m * n + m * (m - 1) / 2)
    } else {
      (sum(Q_P) - sum(Q_A[upper.tri(Q_A)])) / (m * n)
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The papers I’ve mentioned above all provide examples of the calculation of Tau-U. The following table reports the data from each of these examples (&lt;a href=&#34;http://dx.doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber, 2011a&lt;/a&gt;; &lt;a href=&#34;http://dx.doi.org/10.1177/0145445511399147&#34;&gt;Parker, Vannest, and Davis, 2011b&lt;/a&gt;; &lt;a href=&#34;http://dx.doi.org/10.1037/14376-005&#34;&gt;Parker, Vannest, &amp;amp; Davis, 2014&lt;/a&gt;), along with the value of Tau-U based on the original and revised formulas. The differences in magnitude are non-trivial.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Source&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Phase A data&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Phase B data&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;original&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;revised&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2011a, Figure 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2, 3, 5, 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4, 5, 5, 7, 6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6500000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2011b, Figure 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20, 20, 26, 25, 22, 23&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28, 25, 24, 27, 30, 30, 29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5438596&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7380952&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2011b, Table 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3, 3, 4, 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4, 5, 6, 7, 7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4230769&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5500000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2014, Figure 4.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22, 21, 23, 23, 23, 22&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;24, 22, 23, 23, 24, 26, 25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4385965&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5952381&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;implications&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Implications&lt;/h2&gt;
&lt;p&gt;Rather than one effect size index called “Tau-U”, there are instead two different definitions, which can lead to quite different values of the index. Given this, researchers who apply Tau-U should endeavor to &lt;strong&gt;be clear and unambiguous about which version of the index they use&lt;/strong&gt;. This can be done by stating exactly which software routine, web-app, or formula was used in making the calculations. If the calculations are done using a computer script, then the script should be made available (e.g., through the &lt;a href=&#34;https://osf.io/&#34;&gt;Open Science Framework&lt;/a&gt;) so that other researchers can replicate the calculations.&lt;/p&gt;
&lt;p&gt;Furthermore, researchers need to &lt;strong&gt;be careful about applying interpretive guidelines for Tau-U&lt;/strong&gt;, since those guidelines will not apply uniformly across the different versions of the index.&lt;/p&gt;
&lt;p&gt;Finally, I would recommend that any researchers who conduct a meta-analysis of single-case research &lt;strong&gt;make available the raw data used for effect size calculations&lt;/strong&gt;, so that other researchers can scrutinize, replicate, and extend their analyses. The whole enterprise of research synthesis rests on the availability of data from primary studies (at least in summary form). It seems to me that meta-analysts thus have a duty to make the data that they assemble and organize readily accessible for others to use. Particularly in the context of meta-analysis of single-case research—where new methods are developing rapidly and there is not currently consensus around best practices—it seems especially appropriate and prudent to make one’s data available for future re-analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New working paper: Procedural sensitivities of SCD effect sizes</title>
      <link>http://localhost:4321/scd-effect-size-sensitivities/</link>
      <pubDate>Mon, 17 Oct 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/scd-effect-size-sensitivities/</guid>
      <description>


&lt;p&gt;I’ve just posted a new version of my working paper, &lt;em&gt;Procedural sensitivities of effect sizes for single-case designs with behavioral outcome measures&lt;/em&gt;. The abstract is below. This version is a major update of an &lt;a href=&#34;http://localhost:4321/files/Pustejovsky-2015-Nov-Non-overlap-measures.pdf&#34;&gt;earlier paper&lt;/a&gt; that focused only on the non-overlap measures. The new version also includes analysis of two other effect sizes (the within-case standardized mean difference and the log response ratio) as well as additional results and more succinct summaries of the main findings.&lt;/p&gt;
&lt;p&gt;The paper itself is available on the Open Science Framework (&lt;a href=&#34;https://osf.io/pxn24/&#34;&gt;here&lt;/a&gt;), as are the &lt;a href=&#34;https://osf.io/hkzsm/&#34;&gt;supplementary materials&lt;/a&gt; and &lt;a href=&#34;https://osf.io/j4gvt/&#34;&gt;Source code&lt;/a&gt;. I also created interaction versions of the graphics from the main paper and the supplementary materials, which can be viewed in &lt;a href=&#34;https://jepusto.shinyapps.io/SCD-effect-size-sensitivities/&#34;&gt;this shiny app&lt;/a&gt;. I would welcome any comments, questions, or feedback that readers may have.&lt;/p&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Abstract&lt;/h3&gt;
&lt;p&gt;A wide variety of effect size indices have been proposed for quantifying the magnitude of treatment effects in single-case designs. Commonly used measures include parametric indices such as the standardized mean difference, as well as non-overlap measures, such as the percentage of non-overlapping data, improvement rate difference, and non-overlap of all pairs. Currently, little is known about the properties of these indices when applied to behavioral data collected by systematic direct observation, even though systematic direct observation is the most common approach to outcome measurement in single-case research. This study uses computer simulation to investigate the properties of several single-case effect size measures when applied to systematic direct observation data. Results indicate that the magnitude of the non-overlap measures and of the standardized mean difference can be strongly influenced by procedural details of the study’s design, which is a significant limitation to using these indices as effect sizes for meta-analysis of single-case designs. A less widely used parametric index, the log-response ratio, has the advantage of being insensitive to sample size and observation session length, although its magnitude is influenced by the use of partial interval recording.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulation studies in R (Fall, 2016 version)</title>
      <link>http://localhost:4321/simulation-studies-in-r-2016/</link>
      <pubDate>Wed, 28 Sep 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/simulation-studies-in-r-2016/</guid>
      <description>


&lt;p&gt;In today’s Quant Methods colloquium, I gave an introduction to the logic and purposes of Monte Carlo simulation studies, with examples written in R.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:4321/files/Simulations-in-R-2016.html&#34;&gt;Here are the slides&lt;/a&gt; from my presentation.&lt;/li&gt;
&lt;li&gt;You can find the code that generates the slides &lt;a href=&#34;https://gist.github.com/jepusto/bf6cdb6e393f54470ba4d016199c6eb8&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Here is my &lt;a href=&#34;http://localhost:4321/Designing-simulation-studies-using-R&#34;&gt;presentation on the same topic&lt;/a&gt; from a couple of years ago.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://varianceexplained.org/r/beta_binomial_baseball/&#34;&gt;David Robinson’s blog&lt;/a&gt; has a much more in-depth discussion of beta-binomial regression.&lt;/li&gt;
&lt;li&gt;The data I used is from &lt;a href=&#34;http://www.seanlahman.com/baseball-database.html&#34;&gt;Lahman’s baseball database&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Bug in nlme::getVarCov</title>
      <link>http://localhost:4321/bug-in-nlme-getvarcov/</link>
      <pubDate>Wed, 10 Aug 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/bug-in-nlme-getvarcov/</guid>
      <description>


&lt;p&gt;I have recently been working to ensure that &lt;a href=&#34;https://github.com/jepusto/clubSandwich&#34;&gt;my &lt;code&gt;clubSandwich&lt;/code&gt; package&lt;/a&gt; works correctly on fitted &lt;code&gt;lme&lt;/code&gt; and &lt;code&gt;gls&lt;/code&gt; models from the &lt;code&gt;nlme&lt;/code&gt; package, which is one of the main R packages for fitting hierarchical linear models. In the course of digging around in the guts of &lt;code&gt;nlme&lt;/code&gt;, I noticed a bug in the &lt;code&gt;getVarCov&lt;/code&gt; function. The purpose of the function is to extract the estimated variance-covariance matrix of the errors from a fitted &lt;code&gt;lme&lt;/code&gt; or &lt;code&gt;gls&lt;/code&gt; model.&lt;/p&gt;
&lt;p&gt;It seems that this function is sensitive to the order in which the input data are sorted. &lt;a href=&#34;https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16744&#34;&gt;This bug report&lt;/a&gt; noted the problem, but unfortunately their proposed fix doesn’t seem to solve the problem. In this post I’ll demonstrate the bug and a solution. (I’m posting this here because the R project’s bug reporting system is currently closed to people who were not registered as of early July, evidently due to some sort of spamming problem.)&lt;/p&gt;
&lt;div id=&#34;the-issue&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The issue&lt;/h1&gt;
&lt;p&gt;Here’s a simple demonstration of the problem. I’ll first fit a &lt;code&gt;gls&lt;/code&gt; model with a heteroskedastic variance function and an AR(1) auto-correlation structure (no need to worry about the substance of the specification—we’re just worried about computation here) and then extract the variances for each of the units.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Demonstrate the problem with gls model

library(nlme)
data(Ovary)

gls_raw &amp;lt;- gls(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), data = Ovary,
               correlation = corAR1(form = ~ 1 | Mare),
               weights = varPower())

Mares &amp;lt;- levels(gls_raw$groups)
V_raw &amp;lt;- lapply(Mares, function(g) getVarCov(gls_raw, individual = g))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’ll repeat the process using the same data, but sorted in a different order&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Ovary_sorted &amp;lt;- Ovary[with(Ovary, order(Mare, Time)),]
gls_sorted &amp;lt;- update(gls_raw, data = Ovary_sorted)

V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov(gls_sorted, individual = g))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variance component estimates are essentially equal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(gls_raw$modelStruct, gls_sorted$modelStruct)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the extracted variance-covariance matrices are not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Component 1: Mean relative difference: 0.03256&amp;quot;   
## [2] &amp;quot;Component 3: Mean relative difference: 0.05830791&amp;quot;
## [3] &amp;quot;Component 4: Mean relative difference: 0.1142209&amp;quot; 
## [4] &amp;quot;Component 5: Mean relative difference: 0.03619692&amp;quot;
## [5] &amp;quot;Component 6: Mean relative difference: 0.09260648&amp;quot;
## [6] &amp;quot;Component 8: Mean relative difference: 0.08650327&amp;quot;
## [7] &amp;quot;Component 9: Mean relative difference: 0.07627162&amp;quot;
## [8] &amp;quot;Component 10: Mean relative difference: 0.018103&amp;quot; 
## [9] &amp;quot;Component 11: Mean relative difference: 0.1020658&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the code of the relevant function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nlme:::getVarCov.gls&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## function (obj, individual = 1, ...) 
## {
##     S &amp;lt;- corMatrix(obj$modelStruct$corStruct)[[individual]]
##     if (!is.null(obj$modelStruct$varStruct)) {
##         ind &amp;lt;- obj$groups == individual
##         vw &amp;lt;- 1/varWeights(obj$modelStruct$varStruct)[ind]
##     }
##     else vw &amp;lt;- rep(1, nrow(S))
##     vars &amp;lt;- (obj$sigma * vw)^2
##     result &amp;lt;- t(S * sqrt(vars)) * sqrt(vars)
##     class(result) &amp;lt;- c(&amp;quot;marginal&amp;quot;, &amp;quot;VarCov&amp;quot;)
##     attr(result, &amp;quot;group.levels&amp;quot;) &amp;lt;- names(obj$groups)
##     result
## }
## &amp;lt;bytecode: 0x000000001bc39d00&amp;gt;
## &amp;lt;environment: namespace:nlme&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The issue is in the 4th line of the body. &lt;code&gt;getVarCov.gls&lt;/code&gt; assumes that &lt;code&gt;varWeights(obj$modelStruct$varStruct)&lt;/code&gt; is sorted in the same order as &lt;code&gt;obj$groups&lt;/code&gt;, which is not necessarily true. Instead, &lt;code&gt;varWeights&lt;/code&gt; seem to return the weights sorted according to the grouping variable. For this example, that means that the &lt;code&gt;varWeights&lt;/code&gt; will not depend on the order in which the groups are sorted.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;identical(gls_raw$groups, gls_sorted$groups)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;identical(varWeights(gls_raw$modelStruct$varStruct), 
          varWeights(gls_sorted$modelStruct$varStruct))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fix-for-nlmegetvarcov.gls&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fix for &lt;code&gt;nlme:::getVarCov.gls&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;I think this can be solved by either&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;putting the &lt;code&gt;varWeights&lt;/code&gt; back into the same order as the raw data or&lt;/li&gt;
&lt;li&gt;sorting &lt;code&gt;obj$groups&lt;/code&gt; before identifying the rows corresponding to the specified &lt;code&gt;individual&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s a revised function that takes the second approach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# proposed patch for getVarCov.gls

getVarCov_revised_gls &amp;lt;- function (obj, individual = 1, ...) {
    S &amp;lt;- corMatrix(obj$modelStruct$corStruct)[[individual]]
    if (!is.null(obj$modelStruct$varStruct)) {
        ind &amp;lt;- sort(obj$groups) == individual
        vw &amp;lt;- 1 / varWeights(obj$modelStruct$varStruct)[ind]
    }
    else vw &amp;lt;- rep(1, nrow(S))
    vars &amp;lt;- (obj$sigma * vw)^2
    result &amp;lt;- t(S * sqrt(vars)) * sqrt(vars)
    class(result) &amp;lt;- c(&amp;quot;marginal&amp;quot;, &amp;quot;VarCov&amp;quot;)
    attr(result, &amp;quot;group.levels&amp;quot;) &amp;lt;- names(obj$groups)
    result
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Testing that it works correctly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_raw &amp;lt;- lapply(Mares, function(g) getVarCov_revised_gls(gls_raw, individual = g))
V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov_revised_gls(gls_sorted, individual = g))
all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fix-for-nlmegetvarcov.lme&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fix for &lt;code&gt;nlme:::getVarCov.lme&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The same issue comes up in &lt;code&gt;getVarCov.lme&lt;/code&gt;. Here’s the fix and verification:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# proposed patch for getVarCov.lme

getVarCov_revised_lme &amp;lt;- function (obj, individuals, type = c(&amp;quot;random.effects&amp;quot;, &amp;quot;conditional&amp;quot;, &amp;quot;marginal&amp;quot;), ...) {
    type &amp;lt;- match.arg(type)
    if (any(&amp;quot;nlme&amp;quot; == class(obj))) 
        stop(&amp;quot;not implemented for \&amp;quot;nlme\&amp;quot; objects&amp;quot;)
    if (length(obj$group) &amp;gt; 1) 
        stop(&amp;quot;not implemented for multiple levels of nesting&amp;quot;)
    sigma &amp;lt;- obj$sigma
    D &amp;lt;- as.matrix(obj$modelStruct$reStruct[[1]]) * sigma^2
    if (type == &amp;quot;random.effects&amp;quot;) {
        result &amp;lt;- D
    }
    else {
        result &amp;lt;- list()
        groups &amp;lt;- sort(obj$groups[[1]])
        ugroups &amp;lt;- unique(groups)
        if (missing(individuals)) 
            individuals &amp;lt;- as.matrix(ugroups)[1, ]
        if (is.numeric(individuals)) 
            individuals &amp;lt;- ugroups[individuals]
        for (individ in individuals) {
            indx &amp;lt;- which(individ == ugroups)
            if (!length(indx)) 
                stop(gettextf(&amp;quot;individual %s was not used in the fit&amp;quot;, 
                  sQuote(individ)), domain = NA)
            if (is.na(indx)) 
                stop(gettextf(&amp;quot;individual %s was not used in the fit&amp;quot;, 
                  sQuote(individ)), domain = NA)
            ind &amp;lt;- groups == individ
            if (!is.null(obj$modelStruct$corStruct)) {
                V &amp;lt;- corMatrix(obj$modelStruct$corStruct)[[as.character(individ)]]
            }
            else V &amp;lt;- diag(sum(ind))
            if (!is.null(obj$modelStruct$varStruct)) 
                sds &amp;lt;- 1/varWeights(obj$modelStruct$varStruct)[ind]
            else sds &amp;lt;- rep(1, sum(ind))
            sds &amp;lt;- obj$sigma * sds
            cond.var &amp;lt;- t(V * sds) * sds
            dimnames(cond.var) &amp;lt;- list(1:nrow(cond.var), 1:ncol(cond.var))
            if (type == &amp;quot;conditional&amp;quot;) 
                result[[as.character(individ)]] &amp;lt;- cond.var
            else {
                Z &amp;lt;- model.matrix(obj$modelStruct$reStruc, getData(obj))[ind, 
                  , drop = FALSE]
                result[[as.character(individ)]] &amp;lt;- cond.var + 
                  Z %*% D %*% t(Z)
            }
        }
    }
    class(result) &amp;lt;- c(type, &amp;quot;VarCov&amp;quot;)
    attr(result, &amp;quot;group.levels&amp;quot;) &amp;lt;- names(obj$groups)
    result
}

lme_raw &amp;lt;- lme(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), 
               random = ~ 1 | Mare,
               correlation = corExp(form = ~ Time),
               weights = varPower(),
               data=Ovary)

lme_sorted &amp;lt;- update(lme_raw, data = Ovary_sorted)

all.equal(lme_raw$modelStruct, lme_sorted$modelStruct)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# current getVarCov
V_raw &amp;lt;- lapply(Mares, function(g) getVarCov(lme_raw, individual = g, type = &amp;quot;marginal&amp;quot;))
V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov(lme_sorted, individual = g, type = &amp;quot;marginal&amp;quot;))
all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Component 1: Component 1: Mean relative difference: 0.003989954&amp;quot; 
##  [2] &amp;quot;Component 3: Component 1: Mean relative difference: 0.003784181&amp;quot; 
##  [3] &amp;quot;Component 4: Component 1: Mean relative difference: 0.003028662&amp;quot; 
##  [4] &amp;quot;Component 5: Component 1: Mean relative difference: 0.0005997944&amp;quot;
##  [5] &amp;quot;Component 6: Component 1: Mean relative difference: 0.002350456&amp;quot; 
##  [6] &amp;quot;Component 7: Component 1: Mean relative difference: 0.007103733&amp;quot; 
##  [7] &amp;quot;Component 8: Component 1: Mean relative difference: 0.001887638&amp;quot; 
##  [8] &amp;quot;Component 9: Component 1: Mean relative difference: 0.0009601843&amp;quot;
##  [9] &amp;quot;Component 10: Component 1: Mean relative difference: 0.004748783&amp;quot;
## [10] &amp;quot;Component 11: Component 1: Mean relative difference: 0.001521097&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# revised getVarCov 
V_raw &amp;lt;- lapply(Mares, function(g) getVarCov_revised_lme(lme_raw, individual = g, type = &amp;quot;marginal&amp;quot;))
V_sorted &amp;lt;- lapply(Mares, function(g) getVarCov_revised_lme(lme_sorted, individual = g, type = &amp;quot;marginal&amp;quot;))
all.equal(V_raw, V_sorted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Session info&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.3 (2020-02-29)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17763)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] nlme_3.1-144
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.4.6    bookdown_0.14   lattice_0.20-38 digest_0.6.25  
##  [5] grid_3.6.3      magrittr_1.5    evaluate_0.14   blogdown_0.18  
##  [9] rlang_0.4.5     stringi_1.4.3   rmarkdown_2.1   tools_3.6.3    
## [13] stringr_1.4.0   xfun_0.12       yaml_2.2.0      compiler_3.6.3 
## [17] htmltools_0.4.0 knitr_1.28&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Small-sample methods for cluster-robust variance estimation and hypothesis testing in fixed effects models</title>
      <link>http://localhost:4321/talk/jsm-2016-small-sample-crve/</link>
      <pubDate>Sun, 31 Jul 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/jsm-2016-small-sample-crve/</guid>
      <description></description>
    </item>
    
    <item>
      <title>When large samples act small: The importance of small-sample adjustments for cluster-robust inference in impact evaluations</title>
      <link>http://localhost:4321/talk/air-2016-when-large-samples-act-small/</link>
      <pubDate>Mon, 18 Jul 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/air-2016-when-large-samples-act-small/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Alternative formulas for the standardized mean difference</title>
      <link>http://localhost:4321/alternative-formulas-for-the-smd/</link>
      <pubDate>Fri, 03 Jun 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/alternative-formulas-for-the-smd/</guid>
      <description>


&lt;p&gt;The standardized mean difference (SMD) is surely one of the best known and most widely used effect size metrics used in meta-analysis. In generic terms, the SMD parameter is defined as the difference in population means between two groups (often this difference represents the effect of some intervention), scaled by the population standard deviation of the outcome metric. Estimates of the SMD can be obtained from a wide variety of experimental designs, ranging from simple, completely randomized designs, to repeated measures designs, to cluster-randomized trials.&lt;/p&gt;
&lt;p&gt;There’s some nuance involved in figuring out how to calculate estimates of the SMD from each design, mostly to do with exactly what sort of standard deviation to use in the denominator of the effect size. I’ll leave that discussion for another day. Here, I’d like to look at the question of how to estimate the sampling variance of the SMD. An estimate of the sampling variance is needed in order to meta-analyze a collection of effect sizes, and so getting the variance calculations right is an important (and sometimes time consuming) part of any meta-analysis project. However, the standard textbook treatments of effect size calculations cover this question only for a limited number of simple cases. I’d like to suggest a different, more general way of thinking about it, which provides a way to estimate the SMD and its variance in some non-standard cases (and also leads to slight differences from conventional formulas for the standard ones). All of this will be old hat for seasoned synthesists, but I hope it might be useful for students and researchers just getting started with meta-analysis.&lt;/p&gt;
&lt;p&gt;To start, let me review (regurgitate?) the standard presentation.&lt;/p&gt;
&lt;div id=&#34;smd-from-a-simple-independent-groups-design&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;SMD from a simple, independent groups design&lt;/h3&gt;
&lt;p&gt;Textbook presentations of the SMD estimator almost always start by introducing the estimator in the context of a &lt;strong&gt;simple, independent groups design&lt;/strong&gt;. Call the groups T and C, the sample sizes &lt;span class=&#34;math inline&#34;&gt;\(n_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_C\)&lt;/span&gt;, the sample means &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_C\)&lt;/span&gt;, and the sample variances &lt;span class=&#34;math inline&#34;&gt;\(s_T^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_C^2\)&lt;/span&gt;. A basic moment estimator of the SMD is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_T - \bar{y}_C}{s_p}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(s_p^2 = \frac{\left(n_T - 1\right)s_T^2 + \left(n_C - 1\right) s_C^2}{n_T + n_C - 2}\)&lt;/span&gt; is a pooled estimator of the population variance. The standard estimator for the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = \frac{n_T + n_C}{n_T n_C} + \frac{d^2}{2\left(n_T + n_C - 2\right)},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or some slight variant thereof. This estimator is based on a delta-method approximation for the asymptotic variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It is well known that &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; has a small sample bias that depends on sample sizes. Letting&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
J(x) = 1 - \frac{3}{4x - 1},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the bias-corrected estimator is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
g = J\left(n_T + n_C - 2\right) \times d,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and is often referred to as Hedges’ &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; because it was proposed in &lt;a href=&#34;http://doi.org/10.3102/10769986006002107&#34;&gt;Hedges (1981)&lt;/a&gt;. Some meta-analysts use &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt;, but with &lt;span class=&#34;math inline&#34;&gt;\(d^2\)&lt;/span&gt; replaced by &lt;span class=&#34;math inline&#34;&gt;\(g^2\)&lt;/span&gt;, as an estimator of the large-sample variance of &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;; others use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_g = J^2\left(n_T + n_C - 2\right) \left(\frac{n_T + n_C}{n_T n_C} + \frac{g^2}{2\left(n_T + n_C - 2\right)}\right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.3102/1076998606298034&#34;&gt;Viechtbauer (2007)&lt;/a&gt; provides further details on variance estimation and confidence intervals for the SMD in this case.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-general-formula-for-g-and-its-sampling-variance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A general formula for &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; and its sampling variance&lt;/h3&gt;
&lt;p&gt;The above formulas are certainly useful, but in practice meta-analyses often include studies that use other, more complex designs.
Good textbook presentations also cover computation of &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; and its variance for some other cases (e.g., Borenstein, 2009, also covers one-group pre/post designs and analysis of covariance). Less careful presentations only cover the simple, independent groups design and thus may inadvertently leave the impression that the variance estimator &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; given above applies in general. With other types of studies, &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; can be a wildly biased estimator of the actual sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, because it is derived under the assumption that the numerator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is estimated as the difference in means of two simple random samples. In some designs (e.g., ANCOVA designs, randomized block designs, repeated measures designs), the treatment effect estimate will be much more precise than this; in other designs (e.g., cluster-randomized trials), it will be less precise.&lt;/p&gt;
&lt;p&gt;Here’s what I think is a more useful way to think about the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. Let’s suppose that we have an unbiased estimator for the difference in means that goes into the numerator of the SMD. Call this estimator &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, its sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(b)\)&lt;/span&gt;, and its standard error &lt;span class=&#34;math inline&#34;&gt;\(se_{b}\)&lt;/span&gt;. Also suppose that we have an unbiased (or reasonably close-to-unbiased) estimator of the population variance of the outcome, the square root of which goes into the denominator of the SMD. Call this estimator &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;, with expectation &lt;span class=&#34;math inline&#34;&gt;\(\text{E}\left(S^2\right) = \sigma^2\)&lt;/span&gt; and sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(S^2)\)&lt;/span&gt;. Finally, suppose that &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; are independent (which will often be a pretty reasonable assumption). A delta-method approximation for the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d = b / S\)&lt;/span&gt; is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(d\right) \approx \frac{\text{Var}(b)}{\sigma^2} + \frac{\delta^2}{2 \nu},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\nu = 2 \left[\text{E}\left(S^2\right)\right]^2 / \text{Var}\left(S^2\right)\)&lt;/span&gt;. Plugging in sample estimates of the relevant parameters provides a reasonable estimator for the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = \left(\frac{se_b}{S}\right)^2 + \frac{d^2}{2 \nu}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This estimator has two parts. The first part involves &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt;, which is just the standard error of &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, but re-scaled into standard deviation units; this part captures the variability in &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; from its numerator. This scaled standard error can be calculated directly if an article reports &lt;span class=&#34;math inline&#34;&gt;\(se_b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The second part of &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(d^2 / (2 \nu)\)&lt;/span&gt;, which captures the variability in &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; due to its denominator. More precise estimates of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; will have larger degrees of freedom, so that the second part will be smaller. For some designs, the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; depend only on sample sizes, and thus can be calculated exactly. For some other designs, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; must be estimated.&lt;/p&gt;
&lt;p&gt;The same degrees of freedom can also be used in the small-sample correction for the bias of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, as given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
g = J(\nu) \times d.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This small-sample correction is based on a Satterthwaite-type approximation to the distribution of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Here’s another way to express the variance estimator for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = d^2 \left(\frac{1}{t^2} + \frac{1}{2 \nu}\right),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is the test statistic corresponding to the hypothesis test for no difference between groups. I’ve never seen that formula in print before, but it could be convenient if an article reports the &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; statistic (or &lt;span class=&#34;math inline&#34;&gt;\(F = t^2\)&lt;/span&gt; statistic).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;non-standard-estimators-of-d&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Non-standard estimators of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The advantage of this formulation of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; is that it can be applied in quite a wide variety of circumstances, including cases that aren’t usually covered in textbook treatments. Rather than having to use separate formulas for every combination of design and analytic approach under the sun, the same formulas apply throughout. What changes are the components of the formulas: the scaled standard error &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt; and the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. The general formulation also makes it easier to swap in different estimates of &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;—i.e., if you estimate the numerator a different way but keep the denominator the same, you’ll need a new scaled standard error but can still use the same degrees of freedom. A bunch of examples:&lt;/p&gt;
&lt;div id=&#34;independent-groups-with-different-variances&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Independent groups with different variances&lt;/h4&gt;
&lt;p&gt;Suppose that we’re looking at two independent groups but do not want to assume that their variances are the same. In this case, it would make sense to standardize the difference in means by the control group standard deviation (without pooling), so that &lt;span class=&#34;math inline&#34;&gt;\(d = \left(\bar{y}_T - \bar{y}_C\right) / s_C\)&lt;/span&gt;. Since &lt;span class=&#34;math inline&#34;&gt;\(s_C^2\)&lt;/span&gt; has &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C - 1\)&lt;/span&gt; degrees of freedom, the small-sample bias correction will then need to be &lt;span class=&#34;math inline&#34;&gt;\(J(n_C - 1)\)&lt;/span&gt;. The scaled standard error will be&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{s_C} = \sqrt{\frac{s_T^2}{s_C^2 n_T} + \frac{1}{n_C}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is then everything that we need to calculate &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(V_g\)&lt;/span&gt;, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-independent-groups&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Multiple independent groups&lt;/h4&gt;
&lt;p&gt;Suppose that the study involves &lt;span class=&#34;math inline&#34;&gt;\(K - 1\)&lt;/span&gt; treatment groups, 1 control group, and &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; total participants. If the meta-analysis will include SMDs comparing &lt;em&gt;each&lt;/em&gt; treatment group to the control group, it would make sense to pool the sample variance across all &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; groups rather than just the pair of groups, so that a common estimate of scale is used across all the effect sizes. The pooled standard deviation is then calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
s_p^2 = \frac{1}{N - K} \sum_{k=0}^K (n_k - 1) s_k^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a comparison between treatment group &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and the control group, we would then use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_k - \bar{y}_C}{s_p}, \qquad \nu = N - K, \qquad \frac{se_b}{s_p} = \sqrt{\frac{1}{n_C} + \frac{1}{n_k}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(n_k\)&lt;/span&gt; is the sample size for treatment group &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; (cf. Gleser &amp;amp; Olkin, 2009).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;single-group-pre-test-post-test-design&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Single group, pre-test post-test design&lt;/h4&gt;
&lt;p&gt;Suppose that a study involves taking pre-test and post-test measurements on a single group of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; participants. Borenstein (2009) recommends calculating the standardized mean difference for this study as the difference in means between the post-test and pre-test, scaled by the pooled (across pre- and post-test measurements) standard deviation. With obvious notation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{\bar{y}_{post} - \bar{y}_{pre}}{s_p}, \qquad \text{where} \qquad s_p^2 = \frac{1}{2}\left(s_{pre}^2 + s_{post}^2\right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In this design,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{s_p} = \sqrt{\frac{2(1 - r)}{n}},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the sample correlation between the pre- and post-tests. The remaining question is what to use for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. Borenstein (2009) uses &lt;span class=&#34;math inline&#34;&gt;\(\nu = n - 1\)&lt;/span&gt;. My previous post &lt;a href=&#34;http://localhost:4321/distribution-of-sample-variances/&#34;&gt;on the sampling covariance of sample variances&lt;/a&gt; gave the result that &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(s_p^2) = \sigma^4 (1 + \rho^2) / (n - 1)\)&lt;/span&gt;, which would instead suggest using&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu = \frac{2 (n - 1)}{1 + r^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This formula will tend to give slightly larger degrees of freedom, but probably won’t be that discrepant from Borenstein’s approach except in quite small samples. It would be interesting to investigate which approach is better in small samples (i.e., leading to less biased estimates of the SMD and more accurate estimates of sampling variance, and by how much), although its possible than neither is all that good because the variance estimator itself is based on a large-sample approximation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-group-pre-test-post-test-design-ancova-estimation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Two group, pre-test post-test design: ANCOVA estimation&lt;/h4&gt;
&lt;p&gt;Suppose that a study involves taking pre-test and post-test measurements on two groups of participants, with sample sizes &lt;span class=&#34;math inline&#34;&gt;\(n_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_C\)&lt;/span&gt; respectively. One way to analyze this design is via ANCOVA using the pre-test measure as the covariate, so that the treatment effect estimate is the difference in adjusted post-test means. In this design, the scaled standard error will be approximately&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{S} = \sqrt{ \frac{(n_C + n_T)(1 - r^2)}{n_C n_T} },
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the pooled, within-group sample correlation between the pre-test and the post-test measures (this approximation assumes that the pre-test SMD between groups is relatively small). Alternately, if &lt;span class=&#34;math inline&#34;&gt;\(se_b\)&lt;/span&gt; is provided then the scaled standard error could be calculated directly.&lt;/p&gt;
&lt;p&gt;Borenstein (2009) suggests calculating &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; as the difference in adjusted means, scaled by the pooled sample variances on the post-test measures. The post-test pooled sample variance will have the same degrees of freedom as in the two-sample t-test case: &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;. (Borenstein instead uses &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2 - q\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; is the number of covariates in the analysis, but this won’t usually make much difference unless the total sample size is quite small.)&lt;/p&gt;
&lt;p&gt;Scaling by the pooled post-test sample variance isn’t the only reasonable way to estimate the SMD though. If the covariate is a true pre-test, then why not scale by the pooled pre-test sample variance instead? To do so, you would need to calculate &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt; directly and use &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;. If it is reasonable to assume that the pre- and post-test population variances are equal, then another alternative would be to pool across the pre-test &lt;em&gt;and&lt;/em&gt; post-test sample variances in each group. Using this approach, you would again need to calculate &lt;span class=&#34;math inline&#34;&gt;\(se_b / S\)&lt;/span&gt; directly and then use &lt;span class=&#34;math inline&#34;&gt;\(\nu = 2(n_C + n_T - 2) / (1 + r^2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-group-pre-test-post-test-design-repeated-measures-estimation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Two group, pre-test post-test design: repeated measures estimation&lt;/h4&gt;
&lt;p&gt;Another way to analyze the data from the same type of study design is to use repeated measures ANOVA. I’ve recently encountered a number of studies that use this approach (here’s a recent example from &lt;a href=&#34;http://dx.doi.org/10.1371/journal.pone.0154075&#34;&gt;a highly publicized study in PLOS ONE&lt;/a&gt;—see Table 2). The studies I’ve seen typically report the sample means and variances in each group and at each time point, from which the difference in change scores can be calculated. Let &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{gt}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_{gt}^2\)&lt;/span&gt; denote the sample mean and sample variance in group &lt;span class=&#34;math inline&#34;&gt;\(g = T, C\)&lt;/span&gt; at time &lt;span class=&#34;math inline&#34;&gt;\(t = 0, 1\)&lt;/span&gt;. The numerator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; would then be calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
b = \left(\bar{y}_{T1} - \bar{y}_{T0}\right) - \left(\bar{y}_{C1} - \bar{y}_{C0}\right),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which has sampling variance &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(b) = 2(1 - \rho)\sigma^2\left(n_C + n_T \right) / (n_C n_T)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is the correlation between the pre-test and the post-test measures. Thus, the scaled standard error is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{se_b}{S} = \sqrt{\frac{2(1 - r)(n_C + n_T)}{n_C n_T}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As with ANCOVA, there are several potential options for calculating the denominator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using the pooled sample variances on the post-test measures, with &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using the pooled sample variances on the pre-test measures, with &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_C + n_T - 2\)&lt;/span&gt;; or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using the pooled sample variances at both time points and in both groups, i.e.,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
  S^2 = \frac{(n_C - 1)(s_{C0}^2 + s_{C1}^2) + (n_T - 1)(s_{T0}^2 + s_{T1}^2)}{2(n_C + n_T - 2)},
  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\nu = 2(n_C + n_T - 2) / (1 + r^2)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The range of approaches to scaling is the same as for ANCOVA. This makes sense because both analyses are based on data from the same study design, so the parameter of interest should be the same (i.e., the target parameter should not change based on the analytic method). Note that all of these approaches are a bit different than the effect size estimator proposed by &lt;a href=&#34;http://doi.org/10.1037//1082-989X.7.1.105&#34;&gt;Morris and DeShon (2002)&lt;/a&gt; for the two-group, pre-post design; their approach does not fit into my framework because it involves taking a difference between standardized effect sizes (and therefore involves two separate estimates of scale, rather than just one).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;randomized-trial-with-longitudinal-follow-up&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Randomized trial with longitudinal follow-up&lt;/h4&gt;
&lt;p&gt;Many independent-groups designs—especially randomized trials in field settings—involve repeated, longitudinal follow-up assessments. An increasingly common approach to analysis of such data is through hierarchical linear models, which can be used to account for the dependence structure among measurements taken on the same individual. In this setting, &lt;a href=&#34;http://doi.org/10.1037/a0014699&#34;&gt;Feingold (2009)&lt;/a&gt; proposes that the SMD be calculated as the model-based estimate of the treatment effect at the final follow-up time, scaled by the within-groups variance of the outcome at that time point. Let &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; denote the estimated difference in slopes (change per unit time) between groups in a linear growth model, &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; denote the duration of the study, and &lt;span class=&#34;math inline&#34;&gt;\(s_{pF}^2\)&lt;/span&gt; denote the pooled sample variance of the outcome at the final time point. For this model, Feingold (2009) proposes to calculate the standardized mean difference as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \frac{F \hat\beta_1}{s_{pF}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In a later paper, &lt;a href=&#34;http://doi.org/10.1037/a0037721&#34;&gt;Feingold (2015)&lt;/a&gt; proposes that the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; be estimated as &lt;span class=&#34;math inline&#34;&gt;\(F \times se_{\hat\beta_1} / s_{pF}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(se_{\hat\beta_1}\)&lt;/span&gt; is the standard error of the estimated slope. My framework suggests that a better estimate of the sampling variance, which accounts for the uncertainty of the scale estimate, would be to use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_d = \left(\frac{F \times se_{\hat\beta_1}}{s_{pF}}\right)^2 + \frac{d^2}{2 \nu},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\nu = n_T + n_C - 2\)&lt;/span&gt;. The same &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; could be used to bias-correct the effect size estimate.&lt;/p&gt;
&lt;p&gt;If estimates of the variance components of the HLM are reported, one could use them to construct a model-based estimate of the scale parameter in the denominator of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. I explored this approach in a paper that uses HLM to model single-case designs, which are a certain type of longitudinal experiment that typically involve a very small number of participants (&lt;a href=&#34;http://doi.org/10.3102/1076998614547577&#34;&gt;Pustejovsky, Hedges, &amp;amp; Shadish, 2014&lt;/a&gt;). Estimates of the scale parameter can usually be written as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
S_{model}^2 = \mathbf{r}&amp;#39;\boldsymbol\omega,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\omega\)&lt;/span&gt; is a vector of all the variance components in the model and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{r}\)&lt;/span&gt; is a vector of weights that depend on the model specification and length of follow-up. This estimate of scale will usually be more precise than &lt;span class=&#34;math inline&#34;&gt;\(s_{pF}^2\)&lt;/span&gt; because it makes use of all of the data (and modeling assumptions). However, it can be challenging to determine appropriate degrees of freedom for &lt;span class=&#34;math inline&#34;&gt;\(S_{model}^2\)&lt;/span&gt;. For single-case designs, I used estimates of &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}(\boldsymbol\omega)\)&lt;/span&gt; based on the inverse of the expected information matrix—call the estimate &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{V}_{\boldsymbol\omega}\)&lt;/span&gt;—in which case&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu = \frac{2 S_{model}^4}{\mathbf{r}&amp;#39; \mathbf{V}_{\boldsymbol\omega} \mathbf{r}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;However, most published articles will not provide estimates of the sampling variances of the variance components—in fact, a lot of software for estimating HLMs does not even provide these. It would be useful to work out some reasonable approximations for the degrees of freedom in these models—approximations that can be calculated based on the information that’s typically available—and to investigate the extent to which there’s any practical benefit to using &lt;span class=&#34;math inline&#34;&gt;\(S_{model}^2\)&lt;/span&gt; over &lt;span class=&#34;math inline&#34;&gt;\(s_{pF}^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cluster-randomized-trials&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Cluster-randomized trials&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.3102/1076998606298043&#34;&gt;Hedges (2007)&lt;/a&gt; addresses estimation of standardized mean differences for cluster-randomized trials, in which the units of measurement are nested within higher-level clusters that comprise the units of randomization. Such designs involve two variance components (within- and between-cluster variance), and thus there are three potential approaches to scaling the treatment effect: standardize by the total variance (i.e., the sum of the within- and between-cluster components), standardize by the within-cluster variance, or standardize by the between-cluster variance. Furthermore, some of the effect sizes can be estimated in several different ways, each with a different sampling variance. &lt;a href=&#34;http://doi.org/10.3102/1076998606298043&#34;&gt;Hedges (2007)&lt;/a&gt; gives sampling variance estimates for each estimator of each effect size, but they all follow the same general formula as given above. (The appendix of the article actually gives the same formula as above, but using a more abstract formulation.)&lt;/p&gt;
&lt;p&gt;For example, suppose the target SMD parameter uses the total variance and that we have data from a two-level, two-arm cluster randomized trial with &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; clusters, &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations per cluster, and total sample sizes in each arm of &lt;span class=&#34;math inline&#34;&gt;\(N_T\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_C\)&lt;/span&gt;, respectively. Let &lt;span class=&#34;math inline&#34;&gt;\(\tau^2\)&lt;/span&gt; be the between-cluster variance, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; be the within-cluster variance, and &lt;span class=&#34;math inline&#34;&gt;\(\rho = \tau^2 / (\tau^2 + \sigma^2)\)&lt;/span&gt;. The target parameter is &lt;span class=&#34;math inline&#34;&gt;\(\delta = \left(\mu_T - \mu_C\right) / \left(\tau^2 + \sigma^2\right)\)&lt;/span&gt;. The article assumes that the treatment effect will be estimated by the difference in grand means, &lt;span class=&#34;math inline&#34;&gt;\(\bar{\bar{y}}_T - \bar{\bar{y}}_C\)&lt;/span&gt;. Letting &lt;span class=&#34;math inline&#34;&gt;\(S_B^2\)&lt;/span&gt; be the pooled sample variance of the cluster means within each arm and &lt;span class=&#34;math inline&#34;&gt;\(S_W^2\)&lt;/span&gt; be the pooled within-cluster sample variance, the total variance is estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
S_{total}^2 = S_B^2 + \frac{n - 1}{n} S_W^2.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;An estimate of the SMD is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d = \left(\bar{\bar{y}}_T - \bar{\bar{y}}_C \right) / \sqrt{S_{total}^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The scaled standard error of &lt;span class=&#34;math inline&#34;&gt;\(\bar{\bar{y}}_T - \bar{\bar{y}}_C\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
se_b = \sqrt{\left(\frac{N_C + N_T}{N_C N_T}\right)\left[1 + (n - 1)\rho\right]}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The appendix of the article demonstrates that &lt;span class=&#34;math inline&#34;&gt;\(\text{E}\left(S_{total}^2\right) = \tau^2 + \sigma^2\)&lt;/span&gt; and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left( S_{total}^2 \right) = \frac{2}{n^2}\left(\frac{(n \tau^2 + \sigma^2)^2}{M - 2} + \frac{(n - 1)^2 \sigma^4}{N_C + N_T - M}\right),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;by which it follows that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nu = \frac{n^2 M (M - 2)}{M[(n - 1)\rho + 1]^2 + (M - 2)(n - 1)(1 - \rho)^2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Substituting &lt;span class=&#34;math inline&#34;&gt;\(se_b / S_{total}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; into the formula for &lt;span class=&#34;math inline&#34;&gt;\(V_d\)&lt;/span&gt; gives the same as Expression (14) in the article.&lt;/p&gt;
&lt;p&gt;A limitation of &lt;a href=&#34;http://doi.org/10.3102/1076998606298043&#34;&gt;Hedges (2007)&lt;/a&gt; is that it only covers the case where the treatment effect is estimated by the difference in grand means (although it does cover the case of unequal cluster sizes, which gets quite messy). In practice, every cluster-randomized trial I’ve ever seen uses baseline covariates to adjust the mean difference (often based on a hierarchical linear model) and improve the precision of the treatment effect estimate. The SMD estimate should also be based on this covariate-adjustment estimate, scaled by the total variance &lt;em&gt;without adjusting for the covariate&lt;/em&gt;. An advantage of the general formulation given above is that its clear how to estimate the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. I would guess that it will often be possible to calculate the scaled standard error directly, given the standard error of the covariate-adjusted treatment effect estimate. And since &lt;span class=&#34;math inline&#34;&gt;\(S_{total}\)&lt;/span&gt; would be estimated just as before, its degrees of freedom remain the same.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.3102/1076998610376617&#34;&gt;Hedges (2011)&lt;/a&gt; discusses estimation of SMDs in three-level cluster-randomized trials—an even more complicated case. However, the general approach is the same; all that’s needed are the scaled standard error and the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; of whatever combination of variance components go into the denominator of the effect size. In both the two-level and three-level cases, the degrees of freedom get quite complicated in unbalanced samples and are probably not calculable from the information that is usually provided in an article. Hedges (2007, 2011) comments on a couple of cases where more tractable approximations can be used, although it seems like there might be room for further investigation here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Closing thoughts&lt;/h3&gt;
&lt;p&gt;I think this framework is useful in that it unifies a large number of cases that have been treated separately, and can also be applied (more-or-less immediately) to &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; estimators that haven’t been widely considered before, such as the &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; that involves scaling by the pooled pre-and-post, treatment-and-control sample variance. I hope it also illustrates that, while the point estimator &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; can be applied across a large number of study designs, the sampling variance of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; depends on the details of the design and estimation methods. The same is true for other families of effect sizes as well. For example, in other work I’ve demonstrated that the sampling variance of the correlation coefficient depends on the design from which the correlations are estimated (&lt;a href=&#34;http://doi.org/10.1037/a0033788&#34;&gt;Pustejovsky, 2014&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;If you have read this far, I’d love to get your feedback about whether you think this is a useful way to organize the calculations of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; estimators. Is this helpful? Or nothing you didn’t already know? Or still more complicated than it should be? Leave a comment!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Borenstein, M. (2009). Effect sizes for continuous data. In H. M. Cooper, L. V Hedges, &amp;amp; J. C. Valentine (Eds.), The Handbook of Research Synthesis and Meta-Analysis (pp. 221–236). New York, NY: Russell Sage Foundation.&lt;/p&gt;
&lt;p&gt;Feingold, A. (2009). Effect sizes for growth-modeling analysis for controlled clinical trials in the same metric as for classical analysis. Psychological Methods, 14(1), 43–53. &lt;a href=&#34;doi:10.1037/a0014699&#34; class=&#34;uri&#34;&gt;doi:10.1037/a0014699&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Feingold, A. (2015). Confidence interval estimation for standardized effect sizes in multilevel and latent growth modeling. Journal of Consulting and Clinical Psychology, 83(1), 157–168. &lt;a href=&#34;doi:10.1037/a0037721&#34; class=&#34;uri&#34;&gt;doi:10.1037/a0037721&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gleser, L. J., &amp;amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp;amp; J. C. Valentine (Eds.), The Handbook of Research Synthesis and Meta-Analysis (2nd ed., pp. 357–376). New York, NY: Russell Sage Foundation.&lt;/p&gt;
&lt;p&gt;Hedges, L. V. (2007). Effect sizes in cluster-randomized designs. Journal of Educational and Behavioral Statistics, 32(4), 341–370. &lt;a href=&#34;doi:10.3102/1076998606298043&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998606298043&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hedges, L. V. (2011). Effect sizes in three-level cluster-randomized experiments. Journal of Educational and Behavioral Statistics, 36(3), 346–380. &lt;a href=&#34;doi:10.3102/1076998610376617&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998610376617&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Morris, S. B., &amp;amp; DeShon, R. P. (2002). Combining effect size estimates in meta-analysis with repeated measures and independent-groups designs. Psychological Methods, 7(1), 105–125. &lt;a href=&#34;doi:10.1037//1082-989X.7.1.105&#34; class=&#34;uri&#34;&gt;doi:10.1037//1082-989X.7.1.105&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pustejovsky, J. E. (2014). Converting from d to r to z when the design uses extreme groups, dichotomization, or experimental control. Psychological Methods, 19(1), 92–112. &lt;a href=&#34;doi:10.1037/a0033788&#34; class=&#34;uri&#34;&gt;doi:10.1037/a0033788&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pustejovsky, J. E., Hedges, L. V, &amp;amp; Shadish, W. R. (2014). Design-comparable effect sizes in multiple baseline designs: A general modeling framework. Journal of Educational and Behavioral Statistics, 39(5), 368–393. &lt;a href=&#34;doi:10.3102/1076998614547577&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998614547577&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Viechtbauer, W. (2007). Approximate confidence intervals for standardized effect sizes in the two-independent and two-dependent samples design. Journal of Educational and Behavioral Statistics, 32(1), 39–60. &lt;a href=&#34;doi:10.3102/1076998606298034&#34; class=&#34;uri&#34;&gt;doi:10.3102/1076998606298034&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Assigning after dplyr</title>
      <link>http://localhost:4321/assigning-after-dplyr/</link>
      <pubDate>Fri, 13 May 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/assigning-after-dplyr/</guid>
      <description>


&lt;p&gt;Hadley Wickham’s &lt;a href=&#34;https://github.com/hadley/dplyr&#34;&gt;dplyr&lt;/a&gt; and &lt;a href=&#34;https://github.com/hadley/tidyr&#34;&gt;tidyr&lt;/a&gt; packages completely changed the way I do data manipulation/munging in R. These packages make it possible to write shorter, faster, more legible, easier-to-intepret code to accomplish the sorts of manipulations that you have to do with practically any real-world data analysis. The legibility and interpretability benefits come from&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using functions that are simple verbs that do exactly what they say (e.g., &lt;code&gt;filter&lt;/code&gt;, &lt;code&gt;summarize&lt;/code&gt;, &lt;code&gt;group_by&lt;/code&gt;) and&lt;/li&gt;
&lt;li&gt;chaining multiple operations together, through the pipe operator &lt;code&gt;%&amp;gt;%&lt;/code&gt; from the &lt;a href=&#34;https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html&#34;&gt;magrittr&lt;/a&gt; package.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Chaining is particularly nice because it makes the code read like a story. For example, here’s the code to calculate sample means for the baseline covariates in a little experimental dataset I’ve been working with recently:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
dat &amp;lt;- read.csv(&amp;quot;http://jepusto.com/data/Mineo_2009_data.csv&amp;quot;)

dat %&amp;gt;%
  group_by(Condition) %&amp;gt;%
  select(Age, starts_with(&amp;quot;Baseline&amp;quot;)) %&amp;gt;%
  summarise_each(funs(mean)) -&amp;gt;
  baseline_means&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: funs() is soft deprecated as of dplyr 0.8.0
## Please use a list of either functions or lambdas: 
## 
##   # Simple named list: 
##   list(mean = mean, median = median)
## 
##   # Auto named with `tibble::lst()`: 
##   tibble::lst(mean, median)
## 
##   # Using lambdas
##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))
## This warning is displayed once per session.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each line of the code is a different action: first group the data by &lt;code&gt;Condition&lt;/code&gt;, then select the relevant variables, then summarise each of the variables with its sample mean in each group. The results are stored in a dataset called &lt;code&gt;baseline_means&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As I’ve gotten familiar with &lt;code&gt;dplyr&lt;/code&gt;, I’ve adopted the style of using the backwards assignment operator (&lt;code&gt;-&amp;gt;&lt;/code&gt;) to store the results of a chain of manipulations. This is perhaps a little bit odd—in all the rest of my code I stick with the forward assignment operator (&lt;code&gt;&amp;lt;-&lt;/code&gt;) with the object name on the left—but the alternative is to break the “flow” of the story, effectively putting the punchline before the end of the joke. Consider:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseline_means &amp;lt;- dat %&amp;gt;%
  group_by(Condition) %&amp;gt;%
  select(Age, starts_with(&amp;quot;Baseline&amp;quot;)) %&amp;gt;%
  summarise_each(funs(mean))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `Condition`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s just confusing to me. So backward assignment operator it is.&lt;/p&gt;
&lt;div id=&#34;assigning-as-a-verb&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Assigning as a verb&lt;/h3&gt;
&lt;p&gt;My only problem with this convention is that, with complicated chains of manipulations, I often find that I need to tweak the order of the verbs in the chain. For example, I might want to summarize &lt;em&gt;all&lt;/em&gt; of the variables, and only then select which ones to store:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  group_by(Condition) %&amp;gt;%
  summarise_each(funs(mean)) %&amp;gt;%
  select(Age, starts_with(&amp;quot;Baseline&amp;quot;)) -&amp;gt;
  baseline_means&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in mean.default(Expressive.Language): argument is not numeric or
## logical: returning NA

## Warning in mean.default(Expressive.Language): argument is not numeric or
## logical: returning NA

## Warning in mean.default(Expressive.Language): argument is not numeric or
## logical: returning NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In revising the code, it’s necessary to change the symbols at the end of the second and third steps, which is a minor hassle. It’s possible to do it by very carefully cutting-and-pasting the end of the second step through everything but the &lt;code&gt;-&amp;gt;&lt;/code&gt; after the third step, but that’s a delicate operation, prone to error if you’re programming after hours or after beer. Wouldn’t it be nice if every step in the chain ended with &lt;code&gt;%&amp;gt;%&lt;/code&gt; so that you could move around whole lines of code without worrying about the bit at the end?&lt;/p&gt;
&lt;p&gt;Here’s one crude way to end each link in the chain with a pipe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  group_by(Condition) %&amp;gt;%
  select(Age, starts_with(&amp;quot;Baseline&amp;quot;)) %&amp;gt;%
  summarise_each(funs(mean)) %&amp;gt;%
  identity() -&amp;gt; baseline_means&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `Condition`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But this is still pretty ugly—it’s got an extra function call that’s not a verb, and the name of the resulting object is tucked away in the middle of a line. What I need is a verb to take the results of a chain of operations and assign to an object. Base R has a suitable candidate here: the &lt;code&gt;assign&lt;/code&gt; function. How about the following?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  group_by(Condition) %&amp;gt;%
  select(Age, starts_with(&amp;quot;Baseline&amp;quot;)) %&amp;gt;%
  summarise_each(funs(mean)) %&amp;gt;%
  assign(&amp;quot;baseline_means_new&amp;quot;, .)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `Condition`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;exists(&amp;quot;baseline_means_new&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This doesn’t work because of some subtlety with the environment into which &lt;code&gt;baseline_means_new&lt;/code&gt; is assigned. A brute-force fix would be to specify that the assign should be into the global environment. This will probably work 90%+ of the time, but it’s still not terribly elegant.&lt;/p&gt;
&lt;p&gt;Here’s a function that searches the call stack to find the most recent invocation of itself that does not involve non-standard evaluation, then assigns to its parent environment:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;put &amp;lt;- function(x, name, where = NULL) {
  if (is.null(where)) {
    sys_calls &amp;lt;- sys.calls()
    put_calls &amp;lt;- grepl(&amp;quot;\\&amp;lt;put\\(&amp;quot;, sys_calls) &amp;amp; !grepl(&amp;quot;\\&amp;lt;put\\(\\.&amp;quot;,sys_calls)
    where &amp;lt;- sys.frame(max(which(put_calls)) - 1)
  }
  assign(name, value = x, pos = where)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are my quick tests that this function is assigning to the right environment:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;put(dat, &amp;quot;dat1&amp;quot;)
dat %&amp;gt;% put(&amp;quot;dat2&amp;quot;)

f &amp;lt;- function(dat, name) {
  put(dat, &amp;quot;dat3&amp;quot;)
  dat %&amp;gt;% put(&amp;quot;dat4&amp;quot;)
  put(dat, name)
  c(exists(&amp;quot;dat3&amp;quot;), exists(&amp;quot;dat4&amp;quot;), exists(name))
}

f(dat,&amp;quot;dat5&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE TRUE TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grep(&amp;quot;dat&amp;quot;,ls(), value = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;dat&amp;quot;  &amp;quot;dat1&amp;quot; &amp;quot;dat2&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This appears to work even if you’ve got multiple nested calls to &lt;code&gt;put&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;put(f(dat, &amp;quot;dat6&amp;quot;), &amp;quot;dat7&amp;quot;)
grep(&amp;quot;dat&amp;quot;,ls(), value = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;dat&amp;quot;  &amp;quot;dat1&amp;quot; &amp;quot;dat2&amp;quot; &amp;quot;dat7&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat7&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE TRUE TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(dat, &amp;quot;dat8&amp;quot;) %&amp;gt;% put(&amp;quot;dat9&amp;quot;)
grep(&amp;quot;dat&amp;quot;,ls(), value = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;dat&amp;quot;  &amp;quot;dat1&amp;quot; &amp;quot;dat2&amp;quot; &amp;quot;dat7&amp;quot; &amp;quot;dat9&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat9&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE TRUE TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;it-works-i-think&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;It works! (I think…)&lt;/h3&gt;
&lt;p&gt;To be consistent with the style of dplyr, let me also tweak the function to allow &lt;code&gt;name&lt;/code&gt; to be the unquoted object name:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;put &amp;lt;- function(x, name, where = NULL) {
  name_string &amp;lt;- deparse(substitute(name))
  if (is.null(where)) {
    sys_calls &amp;lt;- sys.calls()
    put_calls &amp;lt;- grepl(&amp;quot;\\&amp;lt;put\\(&amp;quot;, sys_calls) &amp;amp; !grepl(&amp;quot;\\&amp;lt;put\\(\\.&amp;quot;,sys_calls)
    where &amp;lt;- sys.frame(max(which(put_calls)) - 1)
  }
  assign(name_string, value = x, pos = where)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returning to my original chain of manipulations, here’s how it looks with the new function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat %&amp;gt;%
  group_by(Condition) %&amp;gt;%
  select(Age, starts_with(&amp;quot;Baseline&amp;quot;)) %&amp;gt;%
  summarise_each(funs(mean)) %&amp;gt;%
  put(baseline_means_new)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `Condition`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(baseline_means_new)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 4
##   Condition   Age Baseline.Gaze Baseline.Vocalizations
##   &amp;lt;fct&amp;gt;     &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;                  &amp;lt;dbl&amp;gt;
## 1 OtherVR    122.          91.9                   2.86
## 2 SelfVid    121.         102.                    1.86
## 3 SelfVR     139.          95.5                   1.43&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’ve been following along, let me know what you think of this. Is it a good idea, or is it dangerous? Are there cases where this will break? Can you think of a better name?&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Unlucky randomization</title>
      <link>http://localhost:4321/unlucky-randomization/</link>
      <pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/unlucky-randomization/</guid>
      <description>


&lt;p&gt;A colleague asked me the other day:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I wonder if you have any suggestions for what to do if random assignment results in big group differences on the pre-test scores of the main outcome measure? My default is just to shrug, use the pretest scores as a covariate and interpret with caution, but if there’s a suggestion you have I’d be most grateful for being pointed in the right direction. These are paid participants (otherwise I’d ask the student to collect more data), 25 and 28 in each group, randomization done by Qualtrics survey program, pretest differences are pronounced (p = .002) and NOT attributable to outliers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I would guess that many statisticians probably get a question along these lines on a pretty regular basis. So as not to repeat myself in the future, I’m posting my response here.&lt;/p&gt;
&lt;p&gt;These sorts of things happen just by dumb luck sometimes, and the possibility of unlucky randomizations like this are one of the primary reasons to collect pre-test data and use it in the analysis. My main advice would therefore be to do just as you’ve described: control for the covariate just as you would otherwise. There are certainly other analyses you could run (such as using propensity scores to re-balance the data), but whatever advantages they offer might well be offset by the cost of 1) deviating from your initial protocol and 2) having to explain a less familiar and more complicated analysis.&lt;/p&gt;
&lt;p&gt;If I were analyzing these data, I would do the following:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Check that the randomization software was actually working correctly, and that the unbalanced data wasn’t the result of a glitch in Qualtrics or something like that.&lt;/li&gt;
&lt;li&gt;Look at histograms of the pretest scores for each group to get a sense of how big the difference in the distributions is.&lt;/li&gt;
&lt;li&gt;If there are other baseline variables, check to see whether there are big group differences on any of those as well.&lt;/li&gt;
&lt;li&gt;Ensure that the write-up characterizes the magnitude of observed differences on the pre-test and any other baseline variables (i.e., report an effect size like the standardized mean difference, in addition to the p-value).&lt;/li&gt;
&lt;li&gt;Larger baseline differences tend to make the results more sensitive to how the data are analyzed. As a result, I would be extra thorough in checking the required assumptions for an analysis of covariance—especially linearity and homogeneity of slopes—and would examine whether the treatment effect estimates are sensitive to including a pretest-by-treatment interaction.&lt;/li&gt;
&lt;li&gt;For future studies, investigate whether it would be possible to block-randomize (e.g., block by low/middle/high scores on the pretest) in order to insure against the possibility of getting big baseline differences.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>ARPobservation</title>
      <link>http://localhost:4321/software/arpobservation/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/arpobservation/</guid>
      <description>&lt;p&gt;An R package for simulating different methods of recording data based on direct observation of behavior, where behavior is modeled by an alternating renewal process.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://cran.r-project.org/package=ARPobservation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/getting-started-with-ARPobservation&#34;&gt;Installation instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/ARPobservation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Source code on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jepusto.shinyapps.io/ARPsimulator/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ARPsimulator&lt;/a&gt;: An interactive web application for simulating systematic direct observation data based on the alternating renewal process model.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>clubSandwich</title>
      <link>http://localhost:4321/software/clubsandwich/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/clubsandwich/</guid>
      <description>&lt;p&gt;R and Stata packages for calculating cluster-robust variance estimators (i.e., sandwich estimators) with small-sample corrections, including the bias-reduced linearization estimator of 
&lt;a href=&#34;http://www.statcan.gc.ca/pub/12-001-x/2002002/article/9058-eng.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bell and McCaffrey (2002)&lt;/a&gt; and extensions proposed in 
&lt;a href=&#34;http://psycnet.apa.org/record/2014-14616-001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tipton (2015)&lt;/a&gt;, 
&lt;a href=&#34;http://localhost:4321/publication/rve-for-meta-regression/&#34;&gt;Tipton and Pustejovsky (2015)&lt;/a&gt;, and 
&lt;a href=&#34;http://localhost:4321/publication/rve-in-fixed-effects-models/&#34;&gt;Pustejovsky and Tipton (2016)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R package 
&lt;a href=&#34;https://cran.r-project.org/package=clubSandwich&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/clubSandwich&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R source code on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stata package 
&lt;a href=&#34;https://ideas.repec.org/c/boc/bocode/s458352.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available on the SSC Archive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/clubSandwich-Stata&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stata source code on Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://localhost:4321/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/project/deep-learning/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>http://localhost:4321/project/example-external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/project/example-external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>scdhlm</title>
      <link>http://localhost:4321/software/scdhlm/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/scdhlm/</guid>
      <description>&lt;p&gt;An R package implementing several methods of estimating a design-comparable standardized mean difference effect size based on data from a single-case design. Methods include those from Hedges, Pustejovsky, &amp;amp; Shadish (
&lt;a href=&#34;http://localhost:4321/publication/SMD-for-SCD&#34;&gt;2012&lt;/a&gt;, 
&lt;a href=&#34;http://localhost:4321/publication/SMD-for-MBD&#34;&gt;2013&lt;/a&gt;) and 
&lt;a href=&#34;http://localhost:4321/publication/design-comparable-effect-sizes/&#34;&gt;Pustejovsky, Hedges, &amp;amp; Shadish (2014)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://CRAN.R-project.org/package=scdhlm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://localhost:4321/getting-started-with-scdhlm&#34;&gt;Installation instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/scdhlm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Source code on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jepusto.shinyapps.io/scdhlm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scdhlm&lt;/a&gt;: An interactive web application for calculating design-comparable standardized mean difference effect sizes.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SingleCaseES</title>
      <link>http://localhost:4321/software/singlecasees/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/singlecasees/</guid>
      <description>&lt;p&gt;An R package for calculating basic effect size indices for single-case designs, including several non-overlap measures and parametric effect size measures, and for estimating the gradual effects model developed by Swan and Pustejovsky (2017).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://CRAN.R-project.org/package=SingleCaseES&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Available on the Comprehensive R Archive Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/jepusto/SingleCaseES&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Source code and installation instructions on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jepusto.shinyapps.io/SCD-effect-sizes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Single case effect size calculator&lt;/a&gt;: An interactive web application for calculating basic effect size indices.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jepusto.shinyapps.io/gem-scd/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gradual Effect Model calculator&lt;/a&gt;: An interactive web application for estimating effect sizes using the gradual effects model.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>wildmeta</title>
      <link>http://localhost:4321/software/wildmeta/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/software/wildmeta/</guid>
      <description>&lt;p&gt;An R package for conducting hypothesis tests of meta-regression models using cluster wild bootstrapping, based on methods examined in 
&lt;a href=&#34;http://localhost:4321/publication/cluster-wild-bootstrap-for-meta-analysis/&#34;&gt;Joshi, Pustejovsky, and Beretvas (2021)&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The sampling distribution of sample variances</title>
      <link>http://localhost:4321/distribution-of-sample-variances/</link>
      <pubDate>Mon, 25 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/distribution-of-sample-variances/</guid>
      <description>


&lt;p&gt;A colleague and her students asked me the other day whether I knew of a citation that gives the covariance between the sample variances of two outcomes from a common sample. This sort of question comes up in meta-analysis problems occasionally. I didn’t know of a convenient reference that directly answers the question, but I was able to suggest some references that would help (listed below). While the students work on deriving it, I’ll provide the answer here so that they can check their work.&lt;/p&gt;
&lt;p&gt;Suppose that we have a sample of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}_1,...,\mathbf{y}_n\)&lt;/span&gt; from a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-dimensional multivariate normal distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\mu\)&lt;/span&gt; and covariance &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma = \left[\sigma_{jk}\right]_{j,k=1,...,p}\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\bar{y}}\)&lt;/span&gt; denote the (multivariate) sample mean, with entries &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_1,...,\bar{y}_p\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{S}\)&lt;/span&gt; denote the sample covariance matrix, with entries &lt;span class=&#34;math inline&#34;&gt;\(\left[s_{jk}\right]_{j,k=1,...,p}\)&lt;/span&gt; where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
s_{jk} = \frac{1}{n - 1}\sum_{i=1}^n (y_{ij} - \bar{y}_j)(y_{ik} - \bar{y}_k).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Then &lt;span class=&#34;math inline&#34;&gt;\((n - 1)\mathbf{S}\)&lt;/span&gt; follows a Wishart distribution with &lt;span class=&#34;math inline&#34;&gt;\(n - 1\)&lt;/span&gt; degrees of freedom and scale matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol\Sigma\)&lt;/span&gt; (Searle, 2006, p. 352; Muirhead, 1982, p. 86; or any textbook on multivariate analysis).&lt;/p&gt;
&lt;p&gt;The sampling covariance between two sample covariances, say &lt;span class=&#34;math inline&#34;&gt;\(s_{jk}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_{lm}\)&lt;/span&gt;, can then be derived from the properties of the Wishart distribution. Expressions for this are available in Searle (2006) or Muirhead (1982). The former is a bit hard to parse because it uses the &lt;span class=&#34;math inline&#34;&gt;\(\text{vec}\)&lt;/span&gt; and Kronecker product operators; Muirhead (1982, p. 90) gives the following simple expression:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Cov}\left(s_{jk}, s_{lm}\right) = \frac{\sigma_{jl}\sigma_{km} + \sigma_{jm}\sigma_{kl}}{n - 1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For sample variances, this reduces to&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Cov}\left(s_j^2, s_l^2\right) = \frac{2\sigma_{jl}^2}{n - 1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The formula also reduces to the well-known result that the sampling variance of the sample variance is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Var}\left(s_j^2\right) = \frac{2 \sigma_{jj}^2}{n - 1}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;One application of this bit of distribution theory is to find the sampling variance of an average of sample variances. Suppose that we have a bivariate normal distribution where both measures have the same variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{11} = \sigma_{22} = \sigma^2\)&lt;/span&gt; and correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. One estimate of this common variance is to take the simple average of the sample variances, &lt;span class=&#34;math inline&#34;&gt;\(s_{\bullet}^2 = \left(s_1^2 + s_2^2\right) / 2\)&lt;/span&gt;. Then using the above:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\text{Var}\left(s_{\bullet}^2\right) &amp;amp;= \frac{1}{4}\left[\text{Var}\left(s_1^2\right) + \text{Var}\left(s_2^2\right) + 2\text{Cov}\left(s_1^2, s_2^2\right) \right] \\
&amp;amp;= \frac{\sigma^4 \left(1 + \rho^2\right)}{n - 1}.
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To see that this is correct, consider the extreme cases. If the two measures are perfectly correlated, then averaging the sample variances has no benefit because &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}\left(s_{\bullet}^2\right) = \text{Var}\left(s_1^2\right) = \text{Var}\left(s_2^2\right)\)&lt;/span&gt;. If they are exactly uncorrelated, then averaging the sample variances is equivalent to pooling the sample variance from two independent samples.&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Muirhead, R. J. (1982). Aspects of Multivariate Statistical Theory. New York, NY: John Wiley &amp;amp; Sons.&lt;/p&gt;
&lt;p&gt;Searle, S. R. (2006). Matrix Algebra Useful for Statistics. Hoboken, NJ: John Wiley &amp;amp; Sons.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tau-U</title>
      <link>http://localhost:4321/tau-u/</link>
      <pubDate>Wed, 23 Mar 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/tau-u/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, and Sauber (2011)&lt;/a&gt; proposed Tau-U as an effect size measure for use in single-case designs that exhibit baseline trend. In their original paper, they actually conceptualize Tau-U as a family of four distinct indices, distinguished by a) whether the index includes an adjustment for the presence of baseline trend and b) whether the index incorporates information about trend during the intervention phase. However, in subsequent presentations the authors seem to have focused exclusively on the index that adjusts for baseline trend but not for intervention phase trend, and so I’ll do the same here. (This version is also the one available in the web-tool at &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;singlecaseresearch.org&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Tau-U is an elaboration on their previously proposed effect sizes &lt;a href=&#34;http://localhost:4321/NAP-SEs-and-CIs&#34;&gt;NAP and Tau&lt;/a&gt;, which do not account for baseline trends. The index is calculated as follows. Suppose that we have data from A and B phases from a single case, where the baseline phase has &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; observations and treatment phase has &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations. Let &lt;span class=&#34;math inline&#34;&gt;\(y^A_1,...,y^A_m\)&lt;/span&gt; denote the baseline phase data and &lt;span class=&#34;math inline&#34;&gt;\(y^B_1,...,y^B_n\)&lt;/span&gt; denote the treatment phase data. Tau-U is then calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau-U} = \frac{S_P - S_B}{mn}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; is Kendall’s S statistic calculated for the comparison between phases and &lt;span class=&#34;math inline&#34;&gt;\(S_B\)&lt;/span&gt; is Kendall’s S statistic calculated on the baseline trend. More precisely,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
S_P &amp;amp;= \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) - I\left(y^B_j &amp;lt; y^A_i\right)\right] \\
S_B &amp;amp;= \sum_{i=1}^{m - 1} \sum_{j = i + 1}^m \left[I\left(y^A_j &amp;gt; y^A_i\right) - I\left(y^A_j &amp;lt; y^A_i\right)\right].
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that the first term in Tau-U is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(\text{Tau} = S_P / (m n)\)&lt;/span&gt;, which in turn is a re-scaling of NAP. The second term is related to the rank-correlation between the measurement occasions and outcomes in the baseline phase. Subtracting the second from the first thus adjusts for baseline trend, in the sense that more pronounced baseline trends will lead to smaller values of Tau-U. But looking at the measure a bit more deeply, it has some very odd features. In this post, I’ll show that the distribution of Tau-U is sensitive to the number of observations in each phase.&lt;/p&gt;
&lt;div id=&#34;sample-size-sensitivity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sample size sensitivity&lt;/h2&gt;
&lt;p&gt;Consider first the logical range of Tau-U. The minimum and maximum possible values of &lt;span class=&#34;math inline&#34;&gt;\(S_P\)&lt;/span&gt; are &lt;span class=&#34;math inline&#34;&gt;\(-m n\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(m n\)&lt;/span&gt;; the minimum and maximum of &lt;span class=&#34;math inline&#34;&gt;\(S_B\)&lt;/span&gt; are &lt;span class=&#34;math inline&#34;&gt;\(-m (m-1) / 2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(m (m - 1) / 2\)&lt;/span&gt;. Consequently, the logical range of Tau-U is from &lt;span class=&#34;math inline&#34;&gt;\(-(2n + m - 1) / (2n)\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\((2n + m - 1) / (2n)\)&lt;/span&gt;. If the treatment phase is quite long compared to the baseline phase, then this range will be close to [-1, 1]. On the other hand, in a study with a baseline that is twice as long as the treatment phase, the range of Tau-U will be closer to [-2, 2]. That’s a very odd property.&lt;/p&gt;
&lt;p&gt;The average magnitude of Tau-U is similarly influenced by the lengths of each phase. To see this, it’s helpful to think first about its target parameter–the quantity that is estimated when calculating Tau-U based on a sample of data. Since Tau-U is not defined in parametric terms, I will assume that the Tau-U statistic is an unbiased estimator of its target parameter &lt;span class=&#34;math inline&#34;&gt;\(\tau_U = \text{E}\left(\text{Tau-U}\right)\)&lt;/span&gt;. It follows that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tau_U = \tau_P - \frac{m - 1}{2n} \tau_B,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau_P\)&lt;/span&gt; is Kendall’s rank correlation between the outcomes and an indicator for the treatment phase and &lt;span class=&#34;math inline&#34;&gt;\(\tau_B\)&lt;/span&gt; is Kendall’s rank correlation between the measurement occasions and outcomes during baseline:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tau_P &amp;amp;= \frac{1}{mn}\sum_{i=1}^m \sum_{j=1}^n \left[\text{Pr}\left(Y^B_j &amp;gt; Y^A_i\right) - \text{Pr}\left(Y^B_j &amp;lt; Y^A_i\right)\right] \\
\tau_B &amp;amp;= \frac{2}{m(m-1)} \sum_{i=1}^{m - 1} \sum_{j = i + 1}^m \left[\text{Pr}\left(Y^A_j &amp;gt; Y^A_i\right) - \text{Pr}\left(Y^A_j &amp;lt; Y^A_i\right)\right].
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now consider a positive a baseline trend, so that &lt;span class=&#34;math inline&#34;&gt;\(\tau_B &amp;gt; 0\)&lt;/span&gt;, and assume that &lt;span class=&#34;math inline&#34;&gt;\(\tau_P\)&lt;/span&gt; is constant. A longer baseline phase will then lead to smaller values of Tau-U (on average), while a longer treatment phase will lead to larger values of Tau-U (on average). Again, that’s really weird. This is not a good feature for an effect size measure because it means that Tau-U values from different cases are only on the same scale if the cases have identical baseline and treatment phase lengths. In a multiple baseline study, each case is necessarily observed for a different number of occasions in baseline (otherwise it wouldn’t be a multiple baseline). Thus, it seems inadvisable to use Tau-U to quantify the magnitude of treatment effects in a multiple baseline study.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sensitivity-under-a-parametric-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sensitivity under a parametric model&lt;/h2&gt;
&lt;p&gt;Things may be different if we allow for the magnitude of &lt;span class=&#34;math inline&#34;&gt;\(\tau_P\)&lt;/span&gt; to change along with the sample size. Such would be the case under a model where the intervention phase also exhibits a trend. For example, let’s suppose that the outcome follows a linear model with a non-zero trend and the intervention leads to an immediate shift in the outcome, as in the model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_t = \beta_0 + \beta_1 t + \beta_2 I(t &amp;gt; m) + \epsilon_t.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For simplicity, I’ll assume that the errors in this model are normally distributed with unit variance. Under this model,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\tau_B &amp;amp;= \frac{4}{m (m - 1)} \left[\sum_{i=1}^{m-1} \sum_{j=i+1}^m \Phi\left[\beta_1\left(j - i\right) / \sqrt{2}\right]\right] - 1, \\
\tau_P &amp;amp;= \frac{2}{m n} \left[\sum_{i=1}^m \sum_{j=1}^n \Phi\left[\left(\beta_1 (m + j - i) + \beta_2\right) / \sqrt{2}\right]\right] - 1,
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\Phi()\)&lt;/span&gt; is the standard normal cumulative distribution function. I can use the above formulas to calculate the average value of Tau-U for various degrees of baseline trend &lt;span class=&#34;math inline&#34;&gt;\((\beta_1)\)&lt;/span&gt;, level shift &lt;span class=&#34;math inline&#34;&gt;\((\beta_2)\)&lt;/span&gt;, and phase lengths &lt;span class=&#34;math inline&#34;&gt;\((m,n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;E_TauU &amp;lt;- function(b1, b2, m, n) {
  tau_B &amp;lt;- sum(sapply(1:(m - 1), function(i) 
    sum(pnorm(b1 * ((i+1):m - i) / sqrt(2))))) * 4 / (m * (m - 1)) - 1
  tau_P &amp;lt;- sum(sapply(1:m, function(i) 
    sum(pnorm((b1 * (m + 1:n - i) + b2) / sqrt(2))))) * 2 / (m * n) - 1
  tau_P - tau_B * (m - 1) / (2 * n)
}

library(dplyr)
library(tidyr)
b1 &amp;lt;- c(-0.2, -0.1, 0, 0.1, 0.2)
b2 &amp;lt;- c(0, 0.5, 1.0, 2.0)
m &amp;lt;- c(5, 10, 15, 20)
n &amp;lt;- 5:20

expand.grid(b1 = b1, b2 = b2, m = m, n = n) %&amp;gt;%
  group_by(b1, b2, m, n) %&amp;gt;% 
  mutate(TauU = E_TauU(b1, b2, m, n)) -&amp;gt;
  TauU_values
ex &amp;lt;- filter(TauU_values, b1 == -0.2 &amp;amp; b2 == 0)


library(ggplot2)
ggplot(TauU_values, aes(n, TauU, color = factor(m))) + 
  facet_grid(b1 ~ b2, labeller = &amp;quot;label_both&amp;quot;) + 
  geom_line() + 
  labs(y = &amp;quot;Expected magnitude of Tau-U&amp;quot;, color = &amp;quot;m&amp;quot;) + 
  theme_bw() + theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Tau-U_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the figure above, each plot corresponds to a different value of the baseline slope (&lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, ranging from -0.2 in the top row to 0.2 in the bottom row) and treatment shift (&lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt;, ranging from 0 in the first column to 2 in the last column). Within each plot, the x axis corresponds to treatment phase length and the different lines correspond to different baseline phase lengths. The thing to note is that, when the baseline slope is non-zero, the expected value of Tau-U ranges quite widely within each plot, depending on the values of &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. For example, when &lt;span class=&#34;math inline&#34;&gt;\(\beta_2 = 0\)&lt;/span&gt; (in the first column), the data follow a simple linear trend with no shift. If the slope of the trend is equal to -0.2 (the first row), then the expected magnitude of Tau-U ranges from -0.8 to 0.3 depending on the phase lengths, which is quite a wide range.&lt;/p&gt;
&lt;p&gt;Generally, the degree of sample size sensitivity depends on the absolute magnitude of the baseline slope, with steeper slopes leading to increased sensitivity. For steeper values of slope, it appears that the degree to which the measure is affected by sample size even swamps the degree to which the measure is sensitive to the magnitude of the treatment effect. Very peculiar.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-final-thought&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A final thought&lt;/h2&gt;
&lt;p&gt;Of course, these results are contingent on the particular model under which I derived the expected magnitude of Tau-U. If the data followed some other model, such as a log-linear model with Poisson-distributed outcomes, then the behavior described above might change. Still, I think all of this raises the reasonable question: under what model (i.e., what sort of patterns of baseline trend, what sort of patterns of response to the intervention) does Tau-U provide a meaningful effect size measure that clearly quantifies the magnitude of treatment effects without being strongly affected by phase lengths? Unless and until such a model can be identified, I would be wary of interpreting Tau-U as a measure of treatment effect magnitude.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Standard errors and confidence intervals for NAP</title>
      <link>http://localhost:4321/nap-ses-and-cis/</link>
      <pubDate>Sun, 28 Feb 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/nap-ses-and-cis/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://doi.org/10.1016/j.beth.2008.10.006&#34;&gt;Parker and Vannest (2009)&lt;/a&gt; proposed non-overlap of all pairs (NAP) as an effect size index for use in single-case research. NAP is defined in terms of all pair-wise comparisons between the data points in two different phases for a given case (i.e., a treatment phase versus a baseline phase). For an outcome that is desirable to increase, NAP is the proportion of all such pair-wise comparisons where the treatment phase observation exceeds the baseline phase observation, with pairs that are exactly tied getting a weight of 1/2. NAP belongs to the family of non-overlap measures, which also includes the percentage of non-overlapping data, the improvement rate difference, and several other indices. It is exactly equivalent to &lt;a href=&#34;http://doi.org/10.2307/1165329&#34;&gt;Vargha and Delaney’s (2000)&lt;/a&gt; modified Common Language Effect Size and has been proposed as an effect size index in other contexts too (e.g., &lt;a href=&#34;http://doi.org/10.1002/sim.2256&#34;&gt;Acion, Peterson, Temple, &amp;amp; Arndt, 2006&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The developers of NAP have created a &lt;a href=&#34;http://singlecaseresearch.org/calculators&#34;&gt;web-based tool&lt;/a&gt; for calculating it (as well as several other non-overlap indices), and I have the impression that the tool is fairly widely used. For example, &lt;a href=&#34;http://doi.org/10.1007%2Fs10864-013-9189-x&#34;&gt;Roth, Gillis, and DiGennaro Reed (2014)&lt;/a&gt; and &lt;a href=&#34;http://doi.org/10.1007/s10803-015-2373-1&#34;&gt;Whalon, Conroy, Martinez, and Welch (2015)&lt;/a&gt; both used NAP in their meta-analyses of single-case research, and both noted that they used &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; for calculating the effect size measure. Given that the web tool is being used, it is worth scrutinizing the methods behind the calculations it reports. As of this writing, the standard error and confidence intervals reported along with the NAP statistic are incorrect, and should not be used. After introducing a bit of notation, I’ll explain why the existing methods are deficient. I’ll also suggest some methods for calculating standard errors and confidence intervals that are potentially more accurate.&lt;/p&gt;
&lt;div id=&#34;preliminaries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;Suppose that we have data from the baseline phase and treatment phase for a single case. Let &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; denote the number of baseline observations and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; denote the number of treatment phase observations. Let &lt;span class=&#34;math inline&#34;&gt;\(y^A_1,...,y^A_m\)&lt;/span&gt; denote the baseline phase data and &lt;span class=&#34;math inline&#34;&gt;\(y^B_1,...,y^B_n\)&lt;/span&gt; denote the treatment phase data. Then NAP is calculated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{NAP} = \frac{1}{m n} \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) + 0.5 I\left(y^B_j = y^A_i\right)\right]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;What is NAP an estimate of? The parameter of interest is the probability that a randomly selected treatment phase observation will exceed a randomly selected baseline phase observation (again, with an adjustment for ties):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\theta = \text{Pr}(Y^B &amp;gt; Y^A) + 0.5 \text{Pr}(Y^B = Y^A).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Vargha and Delaney call &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; the &lt;em&gt;measure of stochastic superiority&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;NAP is very closely related to another non-overlap index called Tau (&lt;a href=&#34;http://doi.org/10.1016/j.beth.2010.08.006&#34;&gt;Parker, Vannest, Davis, &amp;amp; Sauber, 2011&lt;/a&gt;). Tau is nothing more than a linear re-scaling of NAP to the range of [-1, 1]:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau} = \frac{S}{m n} = 2 \times \text{NAP} - 1,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
S = \sum_{i=1}^m \sum_{j=1}^n \left[I\left(y^B_j &amp;gt; y^A_i\right) - I\left(y^B_j &amp;lt; y^A_i\right)\right].
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is Kendall’s S statistic, which is closely related to the Mann-Whitney &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; test.&lt;/p&gt;
&lt;p&gt;Here is an R function for calculating NAP:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NAP &amp;lt;- function(yA, yB) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  U &amp;lt;- sum(sapply(yA, function(i) sapply(yB, function(j) (j &amp;gt; i) + 0.5 * (j == i))))
  U / (m * n)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the data from the worked example in &lt;a href=&#34;http://doi.org/10.1016/j.beth.2008.10.006&#34;&gt;Parker and Vannest (2009)&lt;/a&gt;, the function result agrees with their reported NAP of 0.96:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;yA &amp;lt;- c(4, 3, 4, 3, 4, 7, 5, 2, 3, 2)
yB &amp;lt;- c(5, 9, 7, 9, 7, 5, 9, 11, 11, 10, 9)
NAP(yA, yB)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9636364&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-errors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Standard errors&lt;/h2&gt;
&lt;p&gt;The webtool at &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; reports a standard error for NAP (it is labelled as “SDnap”), which from what I can tell is based on the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{SE}_{\text{Tau}} = \sqrt{\frac{m + n + 1}{3 m n}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This formula appears to actually be the standard error for Tau, rather than for NAP. Since &lt;span class=&#34;math inline&#34;&gt;\(\text{NAP} = \left(\text{Tau} + 1\right) / 2\)&lt;/span&gt;, the standard error for NAP should be half as large:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{SE}_{null} = \sqrt{\frac{m + n + 1}{12 m n}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(cf. &lt;a href=&#34;http://dx.doi.org/10.1037/1082-989X.6.2.135&#34;&gt;Grissom &amp;amp; Kim, 2001, p. 141&lt;/a&gt;). However, even the latter formula is not always correct. It is valid only when the observations are all mutually independent and when the treatment phase data are drawn from the same distribution as the baseline phase data—that is, when the treatment has no effect on the outcome. I’ve therefore denoted it as &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;other-standard-error-estimators&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other standard error estimators&lt;/h3&gt;
&lt;p&gt;Because an equivalent effect size measure is used in other contexts like clinical medicine, there has actually been a fair bit of research into better approaches for assessing the uncertainty in NAP. &lt;a href=&#34;http://dx.doi.org/10.1148/radiology.143.1.7063747&#34;&gt;Hanley and McNeil (1982)&lt;/a&gt; proposed an estimator for the sampling variance of NAP that is designed for continuous outcome measures, where exact ties are impossible. Modifying it slightly (and in entirely ad hoc fashion) to account for ties, let&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Q_1 &amp;amp;= \frac{1}{m n^2}\sum_{i=1}^m \left[\sum_{j=1}^n I\left(y^B_j &amp;gt; y^A_i\right) + 0.5 I\left(y^B_j = y^A_i\right)\right]^2 \\
Q_2 &amp;amp;= \frac{1}{m^2 n}\sum_{j=1}^n \left[\sum_{i=1}^m I\left(y^B_j &amp;gt; y^A_i\right) + 0.5 I\left(y^B_j = y^A_i\right)\right]^2.
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Then the Hanley-McNeil variance estimator is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_{HM} = \frac{1}{mn} \left[\text{NAP}\left(1 - \text{NAP}\right) + (n - 1)\left(Q_1 - \text{NAP}^2\right) + (m - 1)\left(Q_2 - \text{NAP}^2\right)\right],
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{HM} = \sqrt{V_{HM}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The same authors also propose a different estimator, which is based on the assumption that the outcome data are exponentially distributed. Even though this is a strong and often inappropriate assumption, there is evidence that this estimator works even for other, non-exponential distributions. &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt; suggested a further modification of their estimator, and I’ll describe his version. Let &lt;span class=&#34;math inline&#34;&gt;\(h = (m + n) / 2 - 1\)&lt;/span&gt;. Then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_{New} = \frac{h}{mn} \text{NAP}\left(1 - \text{NAP}\right)\left[\frac{1}{h} + \frac{1 - \text{NAP}}{2 - \text{NAP}} + \frac{\text{NAP}}{1 + \text{NAP}}\right],
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{New} = \sqrt{V_{New}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Here are R functions to calculate each of these variance estimators.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V_HM &amp;lt;- function(yA, yB) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  U &amp;lt;- sapply(yB, function(j) (j &amp;gt; yA) + 0.5 * (j == yA))
  t &amp;lt;- sum(U) / (m * n)
  Q1 &amp;lt;- sum(rowSums(U)^2) / (m * n^2)
  Q2 &amp;lt;- sum(colSums(U)^2) / (m^2 * n)
  (t * (1 - t) + (n - 1) * (Q1 - t^2) + (m - 1) * (Q2 - t^2)) / (m * n)
}

V_New &amp;lt;- function(yA, yB) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  t &amp;lt;- NAP(yA, yB)
  h &amp;lt;- (m + n) / 2 - 1
  t * (1 - t) * (1 + h * (1 - t) / (2 - t) + h * t / (1 + t)) / (m * n)
}

sqrt(V_HM(yA, yB))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.03483351&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(V_New(yA, yB))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04370206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the worked example dataset from Parker and Vannest, the Newcombe estimator yields a standard error that is about 25% larger than the Hanley-McNeil estimator. Both of these are substantially smaller than the null standard error, which in this example is &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null} = 0.129\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-small-simulation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A small simulation&lt;/h3&gt;
&lt;p&gt;Simulation methods can be used to examine how well these various standard error formulas estimate the actual sampling variation of NAP. For simplicity, I’ll simulate normally distributed data where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y^A \sim N(0, 1) \qquad \text{and} \qquad Y^B \sim N\left(\sqrt{2}\Phi^{-1}(\theta), 1\right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for varying values of the effect size estimand (&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;) and a couple of different sample sizes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_NAP &amp;lt;- function(delta, m, n, iterations) {
  NAPs &amp;lt;- replicate(iterations, {
    yA &amp;lt;- rnorm(m)
    yB &amp;lt;- rnorm(n, mean = delta)
    c(NAP = NAP(yA, yB), V_HM = V_HM(yA, yB), V_New = V_New(yA, yB))
  })
  data.frame(sd = sd(NAPs[&amp;quot;NAP&amp;quot;,]), 
             SE_HM = sqrt(mean(NAPs[&amp;quot;V_HM&amp;quot;,])), 
             SE_New = sqrt(mean(NAPs[&amp;quot;V_New&amp;quot;,])))
}

library(dplyr)
library(tidyr)
theta &amp;lt;- seq(0.5, 0.95, 0.05)
m &amp;lt;- c(5, 10, 15, 20, 30)
n &amp;lt;- c(5, 10, 15, 20, 30)

expand.grid(theta = theta, m = m, n = n) %&amp;gt;%
  group_by(theta, m, n) %&amp;gt;% 
  mutate(delta = sqrt(2) * qnorm(theta)) -&amp;gt;
  params 

params %&amp;gt;%
  do(sample_NAP(.$delta, .$m, .$n, iterations = 2000)) %&amp;gt;%
  mutate(se_null = sqrt((m + n + 1) / (12 * m * n))) %&amp;gt;%
  gather(&amp;quot;sd&amp;quot;,&amp;quot;val&amp;quot;, sd, SE_HM, SE_New, se_null) -&amp;gt;
  NAP_sim&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
ggplot(NAP_sim, aes(theta, val, color = sd)) + 
  facet_grid(n ~ m, labeller = &amp;quot;label_both&amp;quot;) + 
  geom_line() + 
  theme_bw() + theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/NAP-SEs-and-CIs_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the above figure, the actual sampling standard deviation of NAP (in red) and the value of &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt; (in purple) are plotted against the true value of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, with separate plots for various combinations of &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. The expected value of the standard errors &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{HM}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{New}\)&lt;/span&gt; (actually the square root of the expectation of the variance estimators) are depicted in green and blue, respectively. The value of &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt; agrees with the actual standard error when &lt;span class=&#34;math inline&#34;&gt;\(\delta = 0\)&lt;/span&gt;, but the two diverge when there is a positive treatment effect. It appears that &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{HM}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{New}\)&lt;/span&gt; both under-estimate the actual standard error when &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is equal to 5, and over-estimate for the largest values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. However, both of these estimators offer a marked improvement over &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;confidence-intervals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Confidence intervals&lt;/h2&gt;
&lt;p&gt;The webtool at &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; also reports 85% and 90% confidence intervals for NAP. These confidence intervals appear to have the same two problems as the standard errors. First, they are constructed as CIs for Tau rather than for NAP. For the &lt;span class=&#34;math inline&#34;&gt;\(100\% \times (1 - \alpha)\)&lt;/span&gt; CI, let &lt;span class=&#34;math inline&#34;&gt;\(z_{\alpha / 2}\)&lt;/span&gt; be the appropriate critical value from a standard normal distribution. The CIs reported by the webtool are given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{Tau} \pm \text{SE}_{\text{Tau}} \times z_{\alpha / 2}. 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is probably just an oversight in the programming, which could be corrected by instead using&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{NAP} \pm \text{SE}_{null} \times z_{\alpha / 2}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In parallel with the standard error formulas, I’ll call this formula the null confidence interval. Funnily enough, the upper bound of the null CI is the same as the upper bound of the Tau CI. However, the lower bound is going to be quite a bit larger than the lower bound for the Tau CI, so that the null CI will be much narrower.&lt;/p&gt;
&lt;p&gt;The second problem is that even the null CI has poor coverage properties because it is based on &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}_{null}\)&lt;/span&gt;, which can drastically over-estimate the standard error of NAP for non-null values.&lt;/p&gt;
&lt;div id=&#34;other-confidence-intervals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other confidence intervals&lt;/h3&gt;
&lt;p&gt;As I noted above, there has been a fair amount of previous research into how to construct CIs for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, the parameter estimated by NAP. As is often the case with these sorts of problems, there are many different methods available, scattered across the literature. Fortunately, there are two (at least) fairly comprehensive simulation studies that compare the performance of various methods under a wide range of conditions. &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt; examined a range of methods based on inverting Wald-type test statistics (which give CIs of the form &lt;span class=&#34;math inline&#34;&gt;\(\text{estimate} \pm \text{SE} \times z_{\alpha / 2}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\text{SE}\)&lt;/span&gt; is some standard error estimate) and score-based methods (in which the standard error is estimated using the candidate parameter value). Based on an extensive simulation, he suggested a score-based method in which the end-points of the CI are defined the values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; that satisfy:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
(\text{NAP} - \theta)^2 = \frac{z^2_{\alpha / 2} h \theta (1 - \theta)}{mn}\left[\frac{1}{h} + \frac{1 - \theta}{2 - \theta} + \frac{\theta}{1 + \theta}\right],
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(h = (m + n) / 2 - 1\)&lt;/span&gt;. This equation is a fourth-degree polynomial in &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, easily solved using a numerical root-finding algorithm.&lt;/p&gt;
&lt;p&gt;In a different simulation study, &lt;a href=&#34;http://dx.doi.org/10.1080/00273171.2012.658329&#34;&gt;Ruscio and Mullen (2012)&lt;/a&gt; examined the performance of a selection of different confidence intervals for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, including several methods not considered by Newcombe. Among the methods that they examined, they find that the bias-corrected, accelerated (BCa) bootstrap CI performs particularly well (and seems to outperform the score-based CI recommended by Newcombe).&lt;/p&gt;
&lt;p&gt;Neither &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt; nor &lt;a href=&#34;http://dx.doi.org/10.1080/00273171.2012.658329&#34;&gt;Ruscio and Mullen (2012)&lt;/a&gt; considered constructing a confidence interval by directly pivoting the Mann-Whitney U test (the same technique used to construct confidence intervals for the Hodges-Lehmann estimator of location shift), although it seems to me that this would be possible and potentially an attractive approach in the context of SCDs. The main caveat is that such a CI would require stronger distributional assumptions than those studied in the simulations, such as that the distributions of &lt;span class=&#34;math inline&#34;&gt;\(Y^A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y^B\)&lt;/span&gt; differ by an additive (or multiplicative) constant. In any case, it seems like it would be worth exploring this approach too.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-small-simulation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Another small simulation&lt;/h3&gt;
&lt;p&gt;Here is an R function for calculating several different CIs for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, including the null CI, Wald-type CIs based on &lt;span class=&#34;math inline&#34;&gt;\(V_{HM}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V_{New}\)&lt;/span&gt;, and the score-type CI recommended by &lt;a href=&#34;http://dx.doi.org/10.1002/sim.2324&#34;&gt;Newcombe (2006)&lt;/a&gt;. I haven’t programmed the BCa bootstrap because it would take a bit more thought to figure out how to simulate it efficiently.&lt;/p&gt;
&lt;p&gt;The following code simulates the coverage rates of nominal 90% CIs based on each of these methods, following the same simulation set-up as above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NAP_CIs &amp;lt;- function(yA, yB, alpha = .05) {
  m &amp;lt;- length(yA)
  n &amp;lt;- length(yB)
  U &amp;lt;- sapply(yB, function(j) (j &amp;gt; yA) + 0.5 * (j == yA))
  t &amp;lt;- sum(U) / (m * n)
  
  # variance estimators
  V_null &amp;lt;- (m + n + 1) / (12 * m * n)
  
  Q1 &amp;lt;- sum(rowSums(U)^2) / (m * n^2)
  Q2 &amp;lt;- sum(colSums(U)^2) / (m^2 * n)
  V_HM &amp;lt;- (t * (1 - t) + (n - 1) * (Q1 - t^2) + (m - 1) * (Q2 - t^2)) / (m * n)
  
  h &amp;lt;- (m + n) / 2 - 1
  V_New &amp;lt;- t * (1 - t) * (1 + h * (1 - t) / (2 - t) + h * t / (1 + t)) / (m * n)
  
  # Wald-type confidence intervals
  z &amp;lt;- qnorm(1 - alpha / 2)
  SEs &amp;lt;- sqrt(c(null = V_null, HM = V_HM, Newcombe = V_New))
  Wald_lower &amp;lt;- t - z * SEs
  Wald_upper &amp;lt;- t + z * SEs
  
  # score-type confidence interval
  f &amp;lt;- function(x) m * n * (t - x)^2 * (2 - x) * (1 + x) - 
    z^2 * x * (1 - x) * (2 + h + (1 + 2 * h) * x * (1 - x))
  score_lower &amp;lt;- if (t &amp;gt; 0) uniroot(f, c(0, t))$root else 0
  score_upper &amp;lt;- if (t &amp;lt; 1) uniroot(f, c(t, 1))$root else 1
  list(NAP = t, 
       CI = data.frame(lower = c(Wald_lower, score = score_lower), 
                       upper = c(Wald_upper, score = score_upper)))
}

NAP_CIs(yA, yB)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $NAP
## [1] 0.9636364
## 
## $CI
##              lower     upper
## null     0.7106061 1.2166666
## HM       0.8953639 1.0319088
## Newcombe 0.8779819 1.0492908
## score    0.7499741 0.9950729&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_CIs &amp;lt;- function(delta, m, n, alpha = .05, iterations) {
  NAPs &amp;lt;- replicate(iterations, {
    yA &amp;lt;- rnorm(m)
    yB &amp;lt;- rnorm(n, mean = delta)
    NAP_CIs(yA, yB, alpha = alpha)
  }, simplify = FALSE)
  theta &amp;lt;- mean(sapply(NAPs, function(x) x$NAP))
  coverage &amp;lt;- rowMeans(sapply(NAPs, function(x) (x$CI$lower &amp;lt; theta) &amp;amp; (theta &amp;lt; x$CI$upper)))
  data.frame(CI = rownames(NAPs[[1]]$CI), coverage = coverage)
}

params %&amp;gt;% 
  do(sample_CIs(delta = .$delta, m = .$m, n = .$n, alpha = .10, iterations = 5000)) -&amp;gt;
  NAP_CI_sim&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(NAP_CI_sim, aes(theta, coverage, color = CI)) + 
  facet_grid(n ~ m, labeller = &amp;quot;label_both&amp;quot;, scales = &amp;quot;free_y&amp;quot;) + 
  geom_line() + 
  labs(y = &amp;quot;SE&amp;quot;) + 
  geom_hline(yintercept=.90, linetype=&amp;quot;dashed&amp;quot;) +
  theme_bw() + theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/NAP-SEs-and-CIs_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The figure above plots the coverage rates of several different confidence intervals for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;: the naive CI (in blue), the HM Wald CI (red), the Newcombe Wald CI (green), and the Newcombe score CI (purple). The dashed horizontal line is the nominal coverage rate of 90%. It can be seen that the null CI has the correct coverage only when &lt;span class=&#34;math inline&#34;&gt;\(\theta \leq .6\)&lt;/span&gt;; for larger values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, its coverage becomes too conservative (tending towards 100%). The Wald-type CIs have below-nominal coverage rates, which improve as the sample size in each phase increases but remain too liberal even at the largest sample size considered. Finally, Newcombe’s score CI maintains close-to-nominal coverage over a wider range of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; values. Although these CIs have below-nominal coverage for the smallest sample sizes, they generally have good coverage for &lt;span class=&#34;math inline&#34;&gt;\(\theta &amp;lt; .9\)&lt;/span&gt; and when the sample size in each phase is 10 or more. It is also notable that their coverage rates appear to become more accurate as the sample size in a given group increases, even if the sample size in the other group is fairly small and remains constant.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;caveats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Caveats&lt;/h2&gt;
&lt;p&gt;My aim in this post was to highlight the problems with how &lt;a href=&#34;http://www.singlecaseresearch.org/calculators/nap&#34;&gt;singlecaseresearch.org&lt;/a&gt; calculates standard errors and CIs for the NAP statistic. Some of these issues could easily be resolved by correcting the relevant formulas so that they are appropriate for NAP rather than Tau. However, even with these corrections, better approaches exist for calculating standard errors and CIs. I’ve highlighted some promising ones above, which seem worthy of further investigation. But I should also emphasize that these methods do come with some important caveats too.&lt;/p&gt;
&lt;p&gt;First, all of the methods I’ve discussed are premised on having mutually independent observations. In the presence of serial correlation, I would anticipate that any of these standard errors will be too small and any of the confidence intervals will be too narrow. (This could readily be verified through simulation, although I have not done so here.)&lt;/p&gt;
&lt;p&gt;Second, my small simulations are based on the assumption of normally distributed, homoskedastic observations in each phase, which is not a particularly good model for the types of outcome measures commonly used in single case research. In some of my other work, I’ve developed statistical models for data collected by systematic direct observation of behavior, which is the most prevalent type of outcome data in single-case research. Before recommending any particular method, the performance of the standard error formulas (e.g., the Hanley-McNeil and Newcombe estimators) and CI methods (such as Newcombe’s score CI) should be examined under more realistic models for behavioral observation data.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>When large samples act small: Cluster-robust variance estimation and hypothesis testing with few clusters</title>
      <link>http://localhost:4321/talk/prc-2016-when-large-samples-act-small/</link>
      <pubDate>Fri, 19 Feb 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/prc-2016-when-large-samples-act-small/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Estimating average effects in regression discontinuities with covariate interactions</title>
      <link>http://localhost:4321/rdd-interactions-again/</link>
      <pubDate>Wed, 27 Jan 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/rdd-interactions-again/</guid>
      <description>


&lt;p&gt;Regression discontinuity designs (RDDs) are now a widely used tool for program evaluation in economics and many other fields. RDDs occur in situations where some treatment/program of interest is assigned on the basis of a numerical score (called the running variable), all units scoring above a certain threshold receiving treatment and all units scoring at or below the threshold having treatment withheld (or vice versa, with treatment assigned to units scoring below the threshold). This mechanism provides a way to identify the &lt;strong&gt;marginal average treatment effect&lt;/strong&gt; (MATE): the average effect of treatment assignment for units on the cusp of the threshold.&lt;/p&gt;
&lt;p&gt;RDDs are appealing for a couple of reasons. First and foremost, RDD-like mechanism occurs all over the place, since providing treatment on the basis of a numerical measure of need/eligibility is a natural way to allocate resources. Furthermore, analysis of the designs is straight-forward, as it involves nothing more complicated than a linear regression model, estimated using (weighted or un-weighted) least squares, and which can be represented graphically using a simple scatterplot. Things get a little bit more complicated if you are trying to account for imperfect compliance with treatment assignment—as in the “fuzzy” RDD—but for the moment let me focus on “sharp” RDDs.&lt;/p&gt;
&lt;p&gt;The simplest approach to estimating the MATE is to use a local linear regression in the neighborhood of the threshold, with the outcome regressed on the running variable, treatment indicator, and their interaction. However, in practice it is quite common to also include additional covariates in the local linear regression. If the covariates are also interacted with the treatment indicator, there is no longer a single regression coefficient corresponding to the treatment effect. In my &lt;a href=&#34;http://localhost:4321/rdd-interactions&#34;&gt;last post&lt;/a&gt;, I suggested a “centering trick” for estimating the MATE based on a model that included covariate-by-treatment interactions. In this post, I’ll explain the reasoning behind this proposal.&lt;/p&gt;
&lt;div id=&#34;gday-mate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;G’day, MATE&lt;/h3&gt;
&lt;p&gt;I think it’s helpful to start by thinking about the definition of the MATE in non-parametric terms. Let &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; be the running variable, assumed to be centered at the threshold; &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; be an indicator for treatment assignment, with &lt;span class=&#34;math inline&#34;&gt;\(T = I(R &amp;gt; 0)\)&lt;/span&gt;; and &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; be a covariate, which may be vector-valued. Denote the potential outcomes as &lt;span class=&#34;math inline&#34;&gt;\(Y^0\)&lt;/span&gt; (a unit’s outcome if not assigned to treatment) and &lt;span class=&#34;math inline&#34;&gt;\(Y^1\)&lt;/span&gt; (a unit’s outcome if assigned to treatment), so that the observed outcome is &lt;span class=&#34;math inline&#34;&gt;\(Y = Y^0 (1 - T) + Y^1 T\)&lt;/span&gt;. Now consider the potential response surfaces&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}\mu_0(x, r) &amp;amp;= \text{E}\left(\left.Y^0 \right|X = x, R = r\right) \\ \mu_1(x, r) &amp;amp;= \text{E}\left(\left.Y^1 \right|X = x, R = r\right).\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In an RDD, the average treatment effect at a given point &lt;span class=&#34;math inline&#34;&gt;\((x, r)\)&lt;/span&gt; on the response surface is not generally identified by conditioning because one of the potential outcomes will &lt;em&gt;never&lt;/em&gt; be observed: if &lt;span class=&#34;math inline&#34;&gt;\(r &amp;lt; 0\)&lt;/span&gt; then &lt;span class=&#34;math inline&#34;&gt;\(\text{Pr}( T = 0 \vert X = x, R = r) = 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{Pr}( T = 1 \vert X = x, R = r) = 0\)&lt;/span&gt; (and vice versa for &lt;span class=&#34;math inline&#34;&gt;\(r &amp;gt; 0\)&lt;/span&gt;). However, the treatment effect for the subpopulation where &lt;span class=&#34;math inline&#34;&gt;\(R = 0\)&lt;/span&gt; can be identified under the assumption that the potential response surfaces are continuous in a neighborhood of the threshold. Thus the MATE, which can be written as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\delta_M &amp;amp;= \text{E}\left(\left. Y^1 - Y^0 \right| R = 0\right) \\
&amp;amp;= \text{E}\left[\mu_1(X, 0) - \mu_0(X,0)\right].
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;regression-estimation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Regression estimation&lt;/h3&gt;
&lt;p&gt;Now assume that we have a simple random sample &lt;span class=&#34;math inline&#34;&gt;\(\left(y_i,r_i,t_i, x_i\right)_{i=1}^n\)&lt;/span&gt; of units and that each unit has a weight &lt;span class=&#34;math inline&#34;&gt;\(w_i\)&lt;/span&gt; defined based on some measure of distance from the threshold. We can use these data to estimate the response surfaces (somehow…more on that in a minute) on each side of the cut-off, with &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_0(x, r)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(r &amp;lt; 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_1(x, r)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(r &amp;gt; 0\)&lt;/span&gt;. If we then use the sample distribution of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; in the neighborhood of &lt;span class=&#34;math inline&#34;&gt;\(R = 0\)&lt;/span&gt; in place of the conditional density &lt;span class=&#34;math inline&#34;&gt;\(d\left(X = x \vert R = 0\right)\)&lt;/span&gt;, we can estimate the MATE as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\delta_M = \frac{1}{W} \sum_{i=1}^n w_i \left[\hat\mu_1(x_i, 0) - \hat\mu_0(x_i, 0)\right],\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(W = \sum_{i=1}^n w_i\)&lt;/span&gt;. This is a regression estimator for &lt;span class=&#34;math inline&#34;&gt;\(\delta_M\)&lt;/span&gt;. It could be non-, semi-, or fully parametric depending on the technique used to estimate the response surfaces. Note that this estimator is a little bit different than the regression estimator that would be used in the context of an observational study (see, e.g., &lt;a href=&#34;http://psycnet.apa.org/doi/10.1037/a0014268&#34;&gt;Shafer &amp;amp; Kang, 2008&lt;/a&gt;). In that context, one would use &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_j(x_i, r_i)\)&lt;/span&gt; rather than &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_j(x_i, 0)\)&lt;/span&gt;, but in an RDD doing so would involve extrapolating beyond the cutpoint (i.e., using &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_1(x_i, r_i)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(r_i &amp;lt; 0\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Now suppose that we again use a linear regression in some neighborhood of the cut-point to estimate the response surfaces. For the (weighted) sample in the neighborhood of the cut-point, we assume that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_{t_i}(x_i, r_i) = \beta_0 + \beta_1 r_i + \beta_2 t_i + \beta_3 r_i t_i + \beta_4 x_i + \beta_5 x_i t_i.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Substituting this into the formula for &lt;span class=&#34;math inline&#34;&gt;\(\hat\delta_M\)&lt;/span&gt; leads to&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}\hat\delta_M &amp;amp;= \frac{1}{W} \sum_{i=1}^n w_i \left[\hat\beta_2 + \hat\beta_5 x_i \right] \\
&amp;amp;= \hat\beta_2 + \hat\beta_5 \sum_{i=1}^n \frac{w_i x_i}{W}.\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now, the centering trick involves nothing more than re-centering the covariate so that &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^n w_i x_i = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat\delta_M = \hat\beta_2\)&lt;/span&gt;. Of course, one could just use the non-parametric form of the regression estimator, but the centering trick is useful because it comes along with an easy-to-calculate standard error (since it is just a regression coefficient estimate).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-covariates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple covariates&lt;/h3&gt;
&lt;p&gt;All of this works out in the exact same way if you have interactions between the treatment and multiple covariates. However, there are a few tricky cases that are worth noting. If you include interactions between the treatment indicator and a polynomial function of the treatment, each term of the polynomial has to be centered. For example, if you want to control for &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x^2\)&lt;/span&gt;, and their interactions with treatment, you will need to calculate&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\tilde{x}_{1i} = x_i - \frac{1}{W} \sum_{i=1}^n w_i x_i, \qquad \tilde{x}_{2i} = x_i^2 - \frac{1}{W} \sum_{i=1}^n w_i x_i^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and then use these re-centered covariates in the regression&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_{t_i}(x_i, r_i) = \beta_0 + \beta_1 r_i + \beta_2 t_i + \beta_3 r_i t_i + \beta_4 \tilde{x}_{1i} + \beta_5 \tilde{x}_{2i} + \beta_6 \tilde{x}_{1i} t_i + \beta_7 \tilde{x}_{2i} t_i.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The same principle will also hold if you want to include higher-order interactions between covariates and the treatment: calculate the interaction term first, then re-center it. There’s one exception though. If you want to include an interaction between a covariate &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, the &lt;em&gt;running variable&lt;/em&gt;, and the treatment indicator (who knows…you might aspire to do this some day…), then all you need to do is center &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. In particular, you should &lt;em&gt;not&lt;/em&gt; calculate the interaction &lt;span class=&#34;math inline&#34;&gt;\(x_i r_i\)&lt;/span&gt; and then re-center it (doing so could pull the average away from the threshold of &lt;span class=&#34;math inline&#34;&gt;\(R = 0\)&lt;/span&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-mates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R, MATEs!&lt;/h3&gt;
&lt;p&gt;Here’s some R code that implements the centering trick for the simulated example from my last post:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sandwich)
library(lmtest)
library(rdd)

# simulate an RDD
set.seed(20160124)
simulate_RDD &amp;lt;- function(n = 2000, R = rnorm(n, mean = qnorm(.2))) {
  n &amp;lt;- length(R)
  T &amp;lt;- as.integer(R &amp;gt; 0)
  X1 &amp;lt;- 10 + 0.6 * (R - qnorm(.2)) + rnorm(n, sd = sqrt(1 - 0.6^2))
  X2 &amp;lt;- sample(LETTERS[1:4], n, replace = TRUE, prob = c(0.2, 0.3, 0.35, 0.15))
  Y0 &amp;lt;- 0.4 * R + 0.1 * (X1 - 10) + c(A = 0, B = 0.30, C = 0.40, D = 0.55)[X2] + rnorm(n, sd = 0.9)
  Y1 &amp;lt;- 0.35 + 0.3 * R + 0.18 * (X1 - 10) + c(A = -0.50, B = 0.30, C = 0.20, D = 0.60)[X2] + rnorm(n, sd = 0.9)
  Y &amp;lt;- (1 - T) * Y0 + T * Y1
  data.frame(R, T, X1, X2, Y0, Y1, Y)
}
RD_data &amp;lt;- simulate_RDD(n = 2000)

# calculate kernel weights
bw &amp;lt;- with(RD_data, IKbandwidth(R, Y, cutpoint = 0))
RD_data$w &amp;lt;- kernelwts(RD_data$R, center = 0, bw = bw)

# center the covariates
X_mat &amp;lt;- model.matrix(~ 0 + X2 + X1, data = RD_data)
X_cent &amp;lt;- as.data.frame(apply(X_mat, 2, function(x) x - weighted.mean(x, w = RD_data$w)))
RD_data_aug &amp;lt;- cbind(X_cent, subset(RD_data, select = c(-X1, -X2)))
cov_names &amp;lt;- paste(names(X_cent)[-1], collapse = &amp;quot; + &amp;quot;)

# calculate the MATE using RDestimate
RD_form &amp;lt;- paste(&amp;quot;Y ~ R |&amp;quot;, cov_names)
summary(RDestimate(as.formula(RD_form), data = RD_data_aug))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## RDestimate(formula = as.formula(RD_form), data = RD_data_aug)
## 
## Type:
## sharp 
## 
## Estimates:
##            Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&amp;gt;|z|) 
## LATE       1.0894     1177          0.2981    0.10659     2.797    0.0051559
## Half-BW    0.5447      611          0.2117    0.14846     1.426    0.1539482
## Double-BW  2.1787     1832          0.2734    0.08305     3.292    0.0009949
##               
## LATE       ** 
## Half-BW       
## Double-BW  ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## F-statistics:
##            F      Num. DoF  Denom. DoF  p
## LATE       23.30  11        1165        0
## Half-BW    10.97  11         599        0
## Double-BW  47.41  11        1820        0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# or using lm
lm_form &amp;lt;- paste(&amp;quot;Y ~ R + T + R:T + T*(&amp;quot;, cov_names,&amp;quot;)&amp;quot;)
lm_fit &amp;lt;- lm(as.formula(lm_form), weights = w, data = subset(RD_data_aug, w &amp;gt; 0))
coeftest(lm_fit, vcov. = vcovHC(lm_fit, type = &amp;quot;HC1&amp;quot;))[&amp;quot;T&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Estimate  Std. Error     t value    Pr(&amp;gt;|t|) 
## 0.298142798 0.106588790 2.797130893 0.005240719&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;comments&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Comments&lt;/h3&gt;
&lt;p&gt;I’ve shown that the “centering trick” is just a way to express a certain regression estimator for the marginal average treatment effect in an RDD. Having suggested that this is a good idea, I should also note a few points that might bear further investigation.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;My regression estimator uses the sample distribution of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; in the neighborhood of the threshold as an estimate of &lt;span class=&#34;math inline&#34;&gt;\(d(X = x \vert R = 0)\)&lt;/span&gt;. This seems reasonable, but I wonder whether there might be a better approach to estimating this conditional density.&lt;/li&gt;
&lt;li&gt;As far as I understand, the current best practice for defining the “neighborhood” of the threshold is to use weights based on a triangular kernel and an “optimal” bandwidth proposed by &lt;a href=&#34;http://doi.org/10.1093/restud/rdr043&#34;&gt;Imbens and Kalyanaraman (2012)&lt;/a&gt;. The optimal bandwidth is derived for the simple RDD model with no covariates, though the authors comment that inclusion of additional covariates should not greatly affect the result unless the covariates are strongly correlated with the outcome, conditional on the running variable. However, what if interest centers on the covariate-by-treatment interaction itself, rather than just the MATE? It is not clear that the bandwidth is optimal for estimation/inference on the interaction term.&lt;/li&gt;
&lt;li&gt;So far I’ve considered the MATE identified by a sharp RDD, in which we examine the effects of treatment assignment, regardless of whether units assigned to treatment actually received/participated in it. In fuzzy RDDs, the target parameter is the average effect of treatment receipt for those on the threshold of eligibility and who comply with the assignment rule. The effect is estimated using two-stage least squares, taking treatment assignment as an instrument for treatment receipt. I’m not entirely sure how the regression estimator approach would work in this instrumental variables setting.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Regression discontinuities with covariate interactions in the rdd package</title>
      <link>http://localhost:4321/rdd-interactions/</link>
      <pubDate>Mon, 25 Jan 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/rdd-interactions/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;&lt;em&gt;NOTE (2019-09-24): This post pertains to version 0.56 of the &lt;code&gt;rdd&lt;/code&gt; package. The problems described in this post have been corrected in version 0.57 of the package, which was posted to CRAN on 2016-03-14.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/rdd/&#34;&gt;&lt;code&gt;rdd&lt;/code&gt; package&lt;/a&gt; in R provides a set of methods for analysis of regression discontinuity designs (RDDs), including methods to estimate marginal average treatment effects by local linear regression. I was working with the package recently and obtained some rather counter-intuitive treatment effect estimates in a sharp RDD model. After digging around a bit, I found that my perplexing results were the result of a subtle issue of model specification. Namely, in models with additional covariates (beyond just the running variable, treatment indicator, and interaction), the main estimation function in &lt;code&gt;rdd&lt;/code&gt; uses a specification in which covariates are always interacted with the treatment indicator. In this post, I’ll demonstrate the issue and comment on potential work-arounds.&lt;/p&gt;
&lt;div id=&#34;a-simulated-example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A simulated example&lt;/h3&gt;
&lt;p&gt;To make things more concrete, here’s a hypothetical RDD. I’ll use &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; to denote the running variable, with the threshold set at zero; &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; for the treatment indicator; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for the outcome. &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; is a continuous covariate that is correlated with &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt; is a categorical covariate with four levels that is independent of &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;. In order to illustrate the issue with covariate-by-treatment interactions, I use a model in which the effect of the treatment varies with &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(20160124)

simulate_RDD &amp;lt;- function(n = 2000, R = rnorm(n, mean = qnorm(.2))) {
  n &amp;lt;- length(R)
  T &amp;lt;- as.integer(R &amp;gt; 0)
  X1 &amp;lt;- 10 + 0.6 * (R - qnorm(.2)) + rnorm(n, sd = sqrt(1 - 0.6^2))
  X2 &amp;lt;- sample(LETTERS[1:4], n, replace = TRUE, prob = c(0.2, 0.3, 0.35, 0.15))
  Y0 &amp;lt;- 0.4 * R + 0.1 * (X1 - 10) + c(A = 0, B = 0.30, C = 0.40, D = 0.55)[X2] + rnorm(n, sd = 0.9)
  Y1 &amp;lt;- 0.35 + 0.3 * R + 0.18 * (X1 - 10) + c(A = -0.50, B = 0.30, C = 0.20, D = 0.60)[X2] + rnorm(n, sd = 0.9)
  Y &amp;lt;- (1 - T) * Y0 + T * Y1
  data.frame(R, T, X1, X2, Y0, Y1, Y)
}

RD_data &amp;lt;- simulate_RDD(n = 2000)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-rdd-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simple RDD analysis&lt;/h3&gt;
&lt;p&gt;The main estimand in a sharp RDD is the marginal average treatment effect (MATE)—that is, the average effect of treatment assignment for units right at/near the threshold of eligibility. Even though I simulated a treatment response surface that depends on the covariates &lt;span class=&#34;math inline&#34;&gt;\(X_1,X_2\)&lt;/span&gt;, it is not necessary to control for them in order to identify the MATE. Rather, it is sufficient to use a local linear regression of the outcome on the running variable, treatment indicator, and their interaction:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_i = \beta_0 + \beta_1 R_i + \beta_2 T_i + \beta_3 R_i T_i + \epsilon_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Typically, this regression is estimated using the observations within a certain bandwidth of the threshold, and using weights defined on the basis of some kernel. The default in the &lt;code&gt;rdd&lt;/code&gt; package is to use a triangular edge kernel, with bandwidth chosen using a formula proposed by Imbens and Kalyanaraman. The following code uses &lt;code&gt;rdd&lt;/code&gt; to estimate the MATE without controlling for covariates:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rdd)
bw &amp;lt;- with(RD_data, IKbandwidth(R, Y, cutpoint = 0))
rdd_simple &amp;lt;- RDestimate(Y ~ R, data = RD_data, cutpoint = 0, bw = bw)
summary(rdd_simple)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## RDestimate(formula = Y ~ R, data = RD_data, cutpoint = 0, bw = bw)
## 
## Type:
## sharp 
## 
## Estimates:
##            Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&amp;gt;|z|)    
## LATE       1.0894     1177          0.3035    0.11323     2.680    0.007355  **
## Half-BW    0.5447      611          0.2308    0.15471     1.492    0.135722    
## Double-BW  2.1787     1832          0.2699    0.08968     3.010    0.002613  **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## F-statistics:
##            F       Num. DoF  Denom. DoF  p        
## LATE        37.73  3         1173        0.000e+00
## Half-BW     12.64  3          607        1.006e-07
## Double-BW  104.74  3         1828        0.000e+00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using a bandwidth of 1.09, the estimated marginal average treatment effect is 0.303. The figure below illustrates the discontinuity:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/rdd-interactions_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rdd-with-covariates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;RDD with covariates&lt;/h3&gt;
&lt;p&gt;In practice, it is quite common for analysts to include additional covariates in the model specification. Doing so is not necessary for treatment effect identification, but can be useful for purposes of improving precision. For example, &lt;a href=&#34;http://doi.org/10.3368/jhr.50.1.108&#34;&gt;Cortes, Goodman, and Nomi (2015)&lt;/a&gt; use an RDD to estimate the effects of assigning low-performing 9th graders to double-dose algebra. Their main specifications include controls for student gender, race/ethnicity, free/reduced-price lunch status, etc. In the analysis that I’m working on, the data come from students nested within multiple schools, and so it seems sensible to include fixed effects for each school. There’s a direct analogy here to simple randomized experiments: the basic difference in means provides a randomization-unbiased estimate of the sample average treatment effect, but in practice it can be awfully useful to use an estimate from a model with additional covariates.&lt;/p&gt;
&lt;p&gt;Returning to my simulated example, the following table reports the estimates generated by &lt;code&gt;RDestimate&lt;/code&gt; when controlling for neither, one, or both covariates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RD_est &amp;lt;- function(mod, covariates) {
  RD_fit &amp;lt;- RDestimate(as.formula(paste(mod, covariates)), 
                       data = RD_data, cutpoint = 0)
  with(RD_fit, c(est = est[[1]], se = se[1], p = p[1]))
}

covariates &amp;lt;- list(&amp;quot;No covariates&amp;quot; = &amp;quot;&amp;quot;,
                &amp;quot;X1 only&amp;quot; = &amp;quot;| X1&amp;quot;,
                &amp;quot;X2 only&amp;quot; = &amp;quot;| X2&amp;quot;,
                &amp;quot;X1 + X2&amp;quot; = &amp;quot;| X1 + X2&amp;quot;)

library(plyr)
ldply(covariates, RD_est, mod = &amp;quot;Y ~ R&amp;quot;, .id = &amp;quot;Specification&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Specification        est        se           p
## 1 No covariates  0.3034839 0.1132266 0.007355079
## 2       X1 only -0.6861864 0.8077039 0.395574210
## 3       X2 only -0.2269958 0.1626996 0.162960539
## 4       X1 + X2 -1.2529313 0.7315106 0.086749345&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Despite using identical bandwidths, the estimates are drastically different from each other, with standard errors that are much larger than for the simple estimate without covariates.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-going-on&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What’s going on?&lt;/h3&gt;
&lt;p&gt;It is known that introducing covariates into an RDD analysis should have little effect on the MATE estimate (see, e.g., &lt;a href=&#34;http://doi.org/10.1257/jel.48.2.281&#34;&gt;Lee and Lemieux, 2010&lt;/a&gt;). It is therefore quite perplexing that the estimates in my example (and in the real study I was analyzing) were so sensitive. It turns out that this puzzling behavior arises because, for sharp RDDs only, &lt;code&gt;RDestimate&lt;/code&gt; always interacts the covariate(s) with the treatment indicator. Here is the relevant section of the function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;body(RDestimate)[[39]][[4]][[7]][[3]][[3]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## if (!is.null(covs)) {
##     data &amp;lt;- data.frame(Y, Tr, Xl, Xr, covs, w)
##     form &amp;lt;- as.formula(paste(&amp;quot;Y~Tr+Xl+Xr+&amp;quot;, paste(&amp;quot;Tr*&amp;quot;, names(covs), 
##         collapse = &amp;quot;+&amp;quot;, sep = &amp;quot;&amp;quot;), sep = &amp;quot;&amp;quot;))
## } else {
##     data &amp;lt;- data.frame(Y, Tr, Xl, Xr, w)
##     form &amp;lt;- as.formula(Y ~ Tr + Xl + Xr)
## }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a generic covariate &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, the function uses the specification:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_i = \beta_0 + \beta_1 R_i + \beta_2 T_i + \beta_3 R_i T_i + \beta_4 X_i + \beta_5 X_i T_i + \epsilon_i, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;while still taking &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; to represent the MATE. This is problematic because, as soon as the &lt;span class=&#34;math inline&#34;&gt;\(X_i T_i\)&lt;/span&gt; term is introduced into the model, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; represents the difference between treated and untreated units at the threshold (where &lt;span class=&#34;math inline&#34;&gt;\(R_i = 0\)&lt;/span&gt;) and where &lt;span class=&#34;math inline&#34;&gt;\(X_i = 0\)&lt;/span&gt;. Thus, including the &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; interaction in the model means that &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; is a difference extrapolated &lt;em&gt;way&lt;/em&gt; outside the support of the data, as in the following scatterplot of the outcome versus the covariate &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/rdd-interactions_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RDestimate&lt;/code&gt; returns as the MATE estimate the difference between the regression lines when &lt;span class=&#34;math inline&#34;&gt;\(X_1 = 0\)&lt;/span&gt;, which in this example is -0.69. Similarly, including the &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt; interaction in the model means that &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; will represent the marginal average treatment effect for only one of the categories of &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt;, rather than as some sort of average across all four categories.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-to-do-about-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What to do about this&lt;/h3&gt;
&lt;p&gt;If you’ve been using the &lt;code&gt;rdd&lt;/code&gt; package to analyze your data, I can think of a couple of ways to handle this issue, depending on whether you want to use a model that interacts the covariates with the treatment indicator. Here are some options:&lt;/p&gt;
&lt;p&gt;First, suppose that you want to estimate a model that does NOT include covariate-by-treatment interactions. The most transparent (and thus probably safest) approach is to do the estimation “by hand,” so to speak. Specifically, Use the &lt;code&gt;rdd&lt;/code&gt; package to get kernel weights, but then estimate the outcome model using plain-old &lt;code&gt;lm&lt;/code&gt;. Here’s an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sandwich)
library(lmtest)
RD_data$wt &amp;lt;- kernelwts(RD_data$R, center = 0, bw = bw)
MATE_model &amp;lt;- lm(Y ~ R + T + R * T + X1 + X2, weights = wt, data = subset(RD_data, wt &amp;gt; 0))
coeftest(MATE_model, vcov. = vcovHC(MATE_model, type = &amp;quot;HC1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&amp;gt;|t|)    
## (Intercept) -1.586191   0.374247 -4.2384 2.429e-05 ***
## R            0.183542   0.136025  1.3493 0.1774938    
## T            0.292284   0.107689  2.7142 0.0067422 ** 
## X1           0.130973   0.034704  3.7739 0.0001688 ***
## X2B          0.474403   0.091835  5.1658 2.813e-07 ***
## X2C          0.549125   0.084991  6.4610 1.523e-10 ***
## X2D          0.713331   0.096855  7.3649 3.338e-13 ***
## R:T          0.283663   0.222801  1.2732 0.2032105    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, &lt;code&gt;RDestimate&lt;/code&gt; uses the HC1 variant of heteroskedasticity-robust standard errors. To exactly replicate its behavior, I used &lt;code&gt;coeftest&lt;/code&gt; from the &lt;code&gt;lmtest&lt;/code&gt; package, combined with &lt;code&gt;vcovHC&lt;/code&gt; from the &lt;code&gt;sandwich&lt;/code&gt; package. Note that it is also necessary to estimate the model based on the subset of observations with positive weight (otherwise the sandwich standard errors will misbehave).&lt;/p&gt;
&lt;p&gt;An alternative to the first approach is to “trick” &lt;code&gt;RDestimate&lt;/code&gt; into using the desired model specification by using 2SLS estimation with &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; instrumenting itself. Because the function does not use covariate-by-treatment interactions for “fuzzy” RDDs, you get the correct model specification:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(RDestimate(Y ~ R + T| X1 + X2, data = RD_data, cutpoint = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## RDestimate(formula = Y ~ R + T | X1 + X2, data = RD_data, cutpoint = 0)
## 
## Type:
## fuzzy 
## 
## Estimates:
##            Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&amp;gt;|z|)    
## LATE       1.0894     1177          0.2923    0.10769     2.714    0.006644  **
## Half-BW    0.5447      611          0.2041    0.14911     1.369    0.171103    
## Double-BW  2.1787     1832          0.2703    0.08447     3.200    0.001374  **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## F-statistics:
##            F      Num. DoF  Denom. DoF  p        
## LATE       31.24  7         1169        7.490e-40
## Half-BW    13.84  7          603        1.110e-16
## Double-BW  68.36  7         1824        7.919e-88&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results based on the first bandwidth agree with the results from &lt;code&gt;lm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, suppose that you DO want to retain the covariate-by-treatment interactions in the model, while also estimating the MATE. To do this, you can use what I call “the centering trick,” which entails centering each covariate at the sample average (in this case, the locally-weighted sample average). For a generic covariate &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, let&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\bar{x} = \frac{\sum_{i=1}^n w_i X_i}{\sum_{i=1}^n w_i},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(w_i\)&lt;/span&gt; is the kernel weight for unit &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. Then estimate the model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_i = \beta_0 + \beta_1 R_i + \beta_2 T_i + \beta_3 R_i T_i + \beta_4 \left(X_i - \bar{x}\right) + \beta_5 \left(X_i - \bar{x}\right) T_i + \epsilon_i, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The coefficient on &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; now corresponds to the MATE. Here’s R code that implements this approach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;covariate_mat &amp;lt;- model.matrix(~ X1 + X2, data = RD_data)[,-1]
covariate_cent &amp;lt;- apply(covariate_mat, 2, function(x) x - weighted.mean(x, w = RD_data$wt))
RD_data &amp;lt;- data.frame(subset(RD_data, select = c(R, Y, T)), covariate_cent)

covariates_cent &amp;lt;- list(&amp;quot;No covariates&amp;quot; = &amp;quot;&amp;quot;,
                &amp;quot;X1 only&amp;quot; = &amp;quot;| X1&amp;quot;,
                &amp;quot;X2 only&amp;quot; = &amp;quot;| X2B + X2C + X2D&amp;quot;,
                &amp;quot;X1 + X2&amp;quot; = &amp;quot;| X1 + X2B + X2C + X2D&amp;quot;)

ldply(covariates_cent, RD_est, mod = &amp;quot;Y ~ R&amp;quot;, .id = &amp;quot;Specification&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Specification       est        se           p
## 1 No covariates 0.3034839 0.1132266 0.007355079
## 2       X1 only 0.2913246 0.1125398 0.009635680
## 3       X2 only 0.3107688 0.1071302 0.003721488
## 4       X1 + X2 0.2981428 0.1065888 0.005155864&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The estimates are now insensitive to the inclusion of the (properly centered) covariates, just as in the no-interactions model. In this example, the standard errors from the model that includes covariate-by-treatment interactions are just ever so slightly smaller than those from the model without interactions.&lt;/p&gt;
&lt;p&gt;Why does this third approach work? I’ll explain more in a later post…&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Clustered standard errors and hypothesis tests in fixed effects models</title>
      <link>http://localhost:4321/clubsandwich-for-crve-fe/</link>
      <pubDate>Sun, 10 Jan 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/clubsandwich-for-crve-fe/</guid>
      <description>


&lt;p&gt;I’ve recently been working with my colleague &lt;a href=&#34;http://blogs.cuit.columbia.edu/let2119/&#34;&gt;Beth Tipton&lt;/a&gt; on methods for cluster-robust variance estimation in the context of some common econometric models, focusing in particular on fixed effects models for panel data—or what statisticians would call “longitudinal data” or “repeated measures.” We have a new working paper, which you can &lt;a href=&#34;http://localhost:4321/files/Pustejovsky-Tipton-201601.pdf&#34;&gt;find here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The importance of using CRVE (i.e., “clustered standard errors”) in panel models is now widely recognized. Less widely recognized, perhaps, is the fact that standard methods for constructing hypothesis tests and confidence intervals based on CRVE can perform quite poorly in when you have only a limited number of independent clusters. What’s worse, it can be hard to determine what counts as a large-enough sample to trust standard CRVE methods, because the finite-sample behavior of the variance estimators and test statistics depends on the configuration of the covariates, not just the total sample size. For example, suppose you have state-level panel data from 50 states across 15 years and are trying to estimate the effect of some policy using difference-in-differences. If only 5 or 6 states have variation in the policy variable over time, then you’re almost certainly in small-sample territory. And the sample size issues can be subtler than this, too, as I’ll show below.&lt;/p&gt;
&lt;p&gt;One solution to this problem is to use bias-reduced linearization (BRL), which was proposed by Bell and McCaffrey (2002) and has recently begun to receive attention from econometricians (e.g., Cameron &amp;amp; Miller, 2015; Imbens &amp;amp; Kolesar, 2015). The idea of BRL is to correct the bias of standard CRVE based on a working model, and then to use a degrees-of-freedom correction for Wald tests based on the bias-reduced CRVE. That may seem silly (after all, the whole point of CRVE is to avoid making distributional assumptions about the errors in your model), but it turns out that the correction can help quite a bit, even when the working model is wrong. The degrees-of-freedom correction is based on a standard Satterthwaite-type approximation, and also relies on the working model. There’s now quite a bit of evidence (which we review in the working paper) that BRL performs well even in samples with a small number of clusters.&lt;/p&gt;
&lt;p&gt;In the working paper, we make two contributions to all this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;One problem with Bell and McCaffrey’s original formulation of BRL is that it does not work in some very common models for panel data, such as state-by-year panels that include fixed effects for each state and each year (Angrist and Pischke, 2009, point out this issue in their chapter on “non-standard standard error issues”). We propose a generalization of BRL that works even in models with arbitrary sets of fixed effects. We also address how to calculate the correction when the regression is fit using the “within” estimator, after absorbing the fixed effects.&lt;/li&gt;
&lt;li&gt;We propose a method for testing hypotheses that involve multiple parameter constraints (which, in classical linear regression, you would test with an F statistic). The method involves approximating the distribution of the cluster-robust Wald statistic using Hotelling’s T-squared distribution (a multiple of an F distribution), where the denominator degrees of freedom are estimated based on the working model. For one-parameter constraints, the test reduces to a t-test with Satterthwaite degrees of freedom, and so it is a natural extension of the existing BRL methods.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The paper explains all this in greater detail, and also reports a fairly extensive simulation study that we designed to emuluate the types of covariates and study designs encountered in micro-economic applications. We’ve also got &lt;a href=&#34;https://github.com/jepusto/clubSandwich&#34;&gt;an R package&lt;/a&gt; that implements our methods (plus some other variants of CRVE, which I’ll explain some other time) in a fairly streamlined way. Here’s an example of how to use the package to do inference for a fixed effects panel data model.&lt;/p&gt;
&lt;div id=&#34;effects-of-changing-the-minimum-legal-drinking-age&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Effects of changing the minimum legal drinking age&lt;/h2&gt;
&lt;p&gt;Carpenter and Dobkin (2011) analyzed the effects of changes in the minimum legal drinking age on rates of motor vehicle fatalies among 18-20 year olds, using state-level panel data from the National Highway Traffic Administration’s Fatal Accident Reporting System. In their new textbook, Angrist and Pischke (2014) developed a stylized example based on Carpenter and Dobkin’s work. I’ll use Angrist and Pischke’s data and follow their analysis, just because their data are &lt;a href=&#34;http://masteringmetrics.com/resources/&#34;&gt;easily available&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The outcome is the incidence of deaths in motor vehicle crashes among 18-20 year-olds (per 100,000 residents), for each state plus the District of Columbia, over the period 1970 to 1983. Tthere were several changes in the minimum legal drinking age during this time period, with variability in the timing of changes across states. Angrist and Pischke (following Carpenter and Dobkin) use a difference-in-differences strategy to estimate the effects of lowering the minimum legal drinking age from 21 to 18. A basic specification is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{it} = \alpha_i + \beta_t + \gamma r_{it} + \epsilon_{it},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; = 1,…,51 and &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; = 1970,…,1983. In this model, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; is a state-specific fixed effect, &lt;span class=&#34;math inline&#34;&gt;\(\beta_t\)&lt;/span&gt; is a year-specific fixed effect, &lt;span class=&#34;math inline&#34;&gt;\(r_{it}\)&lt;/span&gt; is the proportion of 18-20 year-olds in state &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in year &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; who are legally allowed to drink, and &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; captures the effect of shifting the minimum legal drinking age from 21 to 18. Following Angrist and Pischke’s analysis, I’ll estimate this model both by (unweighted) OLs and by weighted least squares with weights corresponding to population size in a given state and year.&lt;/p&gt;
&lt;div id=&#34;unweighted-ols&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Unweighted OLS&lt;/h3&gt;
&lt;p&gt;The following code does some simple data-munging and the estimates the model by OLS:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get data from Angrist &amp;amp; Pischke&amp;#39;s website
library(foreign)
deaths &amp;lt;- read.dta(&amp;quot;http://masteringmetrics.com/wp-content/uploads/2015/01/deaths.dta&amp;quot;, convert.factors=FALSE)

# subset for 18-20 year-olds, deaths in motor vehicle accidents
MVA_deaths &amp;lt;- subset(deaths, agegr==2 &amp;amp; dtype==2 &amp;amp; year &amp;lt;= 1983, select = c(-dtype, -agegr))

# fit by OLS
lm_unweighted &amp;lt;- lm(mrate ~ 0 + legal + factor(state) + factor(year), data = MVA_deaths)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;coef_test&lt;/code&gt; function from &lt;code&gt;clubSandwich&lt;/code&gt; can then be used to test the hypothesis that changing the minimum legal drinking age has no effect on motor vehicle deaths in this cohort (i.e., &lt;span class=&#34;math inline&#34;&gt;\(H_0: \gamma = 0\)&lt;/span&gt;). The usual way to test this is to cluster the standard errors by state, calculate the robust Wald statistic, and compare that to a standard normal reference distribution. The code and results are as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# devtools::install_github(&amp;quot;jepusto/clubSandwich&amp;quot;) # install the clubSandwich package
library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_test(lm_unweighted, vcov = &amp;quot;CR1&amp;quot;, cluster = MVA_deaths$state, test = &amp;quot;z&amp;quot;)[&amp;quot;legal&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Coef. Estimate   SE t-stat p-val (z) Sig.
## 1 legal     7.59 2.38   3.19   0.00143   **&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our work argues shows that a better approach would be to use the bias-reduced linearization CRVE, together with Satterthwaite degrees of freedom. In the package, the BRL adjustment is called “CR2” because it is directly analogous to the HC2 correction used in heteroskedasticity-robust variance estimation. When applied to an OLS model estimated by &lt;code&gt;lm&lt;/code&gt;, the default working model is an identity matrix, which amounts to the “working” assumption that the errors are all uncorrelated and homoskedastic. Here’s how to apply this approach in the example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_test(lm_unweighted, vcov = &amp;quot;CR2&amp;quot;, cluster = MVA_deaths$state, test = &amp;quot;Satterthwaite&amp;quot;)[&amp;quot;legal&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Coef. Estimate   SE t-stat d.f. p-val (Satt) Sig.
## 1 legal     7.59 2.43   3.12 25.7      0.00442   **&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Satterthwaite degrees of freedom will be different for each coefficient in the model, and so the &lt;code&gt;coef_test&lt;/code&gt; function reports them right alongside the standard error. In this case, the degrees of freedom are about half of what you might expect, given that there are 51 clusters. The p-value for the CR2+Satterthwaite test is about twice as large as the p-value based on the standard Wald test. But of course, the coefficient is still statistically significant at conventional levels, and so the inference doesn’t change.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unweighted-within-estimation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Unweighted “within” estimation&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;plm&lt;/code&gt; package in R provides another way to estimate the same model. It is convenient because it absorbs the state and year fixed effects before estimating the effect of &lt;code&gt;legal&lt;/code&gt;. The &lt;code&gt;clubSandwich&lt;/code&gt; package works with fitted &lt;code&gt;plm&lt;/code&gt; models too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(plm)
plm_unweighted &amp;lt;- plm(mrate ~ legal, data = MVA_deaths, 
                      effect = &amp;quot;twoways&amp;quot;, index = c(&amp;quot;state&amp;quot;,&amp;quot;year&amp;quot;))
coef_test(plm_unweighted, vcov = &amp;quot;CR1S&amp;quot;, cluster = &amp;quot;individual&amp;quot;, test = &amp;quot;z&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Coef. Estimate   SE t-stat p-val (z) Sig.
## 1 legal     7.59 2.38   3.19   0.00143   **&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_test(plm_unweighted, vcov = &amp;quot;CR2&amp;quot;, cluster = &amp;quot;individual&amp;quot;, test = &amp;quot;Satterthwaite&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Coef. Estimate   SE t-stat d.f. p-val (Satt) Sig.
## 1 legal     7.59 2.43   3.12 25.7      0.00442   **&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the standard approach, I’ve used the variant of the correction factor implemented in Stata (called &lt;code&gt;CR1S&lt;/code&gt; in the &lt;code&gt;clubSandwich&lt;/code&gt; package), but this makes very little difference in the standard error or the p-value. For the test based on CR2, the degrees of freedom are slightly different than the results based on the fitted &lt;code&gt;lm&lt;/code&gt; model, but the p-values agree to four decimals. The differences in degrees of freedom are due to numerical imprecision in the calculations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;population-weighted-estimation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Population-weighted estimation&lt;/h3&gt;
&lt;p&gt;The difference between the standard method and the new method are not terribly exciting in the above example. However, things change quite a bit if the model is estimated using population weights. As far as I know, &lt;code&gt;plm&lt;/code&gt; does not handle weighted least squares, and so I go back to fitting in &lt;code&gt;lm&lt;/code&gt; with dummies for all the fixed effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_weighted &amp;lt;- lm(mrate ~ 0 + legal + factor(state) + factor(year), 
                  weights = pop, data = MVA_deaths)
coef_test(lm_weighted, vcov = &amp;quot;CR1&amp;quot;, cluster = MVA_deaths$state, test = &amp;quot;z&amp;quot;)[&amp;quot;legal&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Coef. Estimate   SE t-stat p-val (z) Sig.
## 1 legal      7.5 2.16   3.47    &amp;lt;0.001  ***&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_test(lm_weighted, vcov = &amp;quot;CR2&amp;quot;, cluster = MVA_deaths$state, test = &amp;quot;Satterthwaite&amp;quot;)[&amp;quot;legal&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Coef. Estimate  SE t-stat d.f. p-val (Satt) Sig.
## 1 legal      7.5 2.3   3.27 8.65       0.0103    *&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using population weights slightly reduces the point estimate of the effect, while also slightly increasing its precision. If you were following the standard approach, you would probably be happy with the weighted estimates and wouldn’t think about it any further. However, our recommended approach—using the CR2 variance estimator and Satterthwaite correction—produces a p-value that is an order of magnitude larger (though still significant at the conventional 5% level). The degrees of freedom are just 8.6—drastically smaller than would be expected based on the number of clusters.&lt;/p&gt;
&lt;p&gt;Even with weights, the &lt;code&gt;coef_test&lt;/code&gt; function uses an “independent, homoskedastic” working model as a default for &lt;code&gt;lm&lt;/code&gt; objects. In the present example, the outcome is a standardized rate and so a better assumption might be that the error variances are inversely proportional to population size. The following code uses this alternate working model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_test(lm_weighted, vcov = &amp;quot;CR2&amp;quot;, 
          cluster = MVA_deaths$state, target = 1 / MVA_deaths$pop, 
          test = &amp;quot;Satterthwaite&amp;quot;)[&amp;quot;legal&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Coef. Estimate  SE t-stat d.f. p-val (Satt) Sig.
## 1 legal      7.5 2.2   3.41   13      0.00467   **&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new working model leads to slightly smaller standard errors and a couple of additional degrees of freedom, though we remain in small-sample territory.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;robust-hausman-test&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Robust Hausman test&lt;/h3&gt;
&lt;p&gt;CRVE is also used in specification tests, as in the Hausman-type test for endogeneity of unobserved effects. Suppose that the model includes an additional control for the beer taxation rate in state &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, denoted &lt;span class=&#34;math inline&#34;&gt;\(s_{it}\)&lt;/span&gt;. The (unweighted) fixed effects model is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{it} = \alpha_i + \beta_t + \gamma_1 r_{it} + \gamma_2 s_{it} + \epsilon_{it},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the estimated effects are as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_FE &amp;lt;- lm(mrate ~ 0 + legal + beertaxa + factor(state) + factor(year), data = MVA_deaths)
coef_test(lm_FE, vcov = &amp;quot;CR2&amp;quot;, cluster = MVA_deaths$state, test = &amp;quot;Satterthwaite&amp;quot;)[c(&amp;quot;legal&amp;quot;,&amp;quot;beertaxa&amp;quot;),]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Coef. Estimate   SE t-stat  d.f. p-val (Satt) Sig.
## 1    legal     7.59 2.51  3.019 24.58      0.00583   **
## 2 beertaxa     3.82 5.27  0.725  5.77      0.49663&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the unobserved effects &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1,...,\alpha_{51}\)&lt;/span&gt; are uncorrelated with the regressors, then a more efficient way to estimate &lt;span class=&#34;math inline&#34;&gt;\(\gamma_1,\gamma_2\)&lt;/span&gt; is by weighted least squares, with weights based on a random effects model. However, if the unobserved effects covary with &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{r}_i, \mathbf{s}_i\)&lt;/span&gt;, then the random-effects estimates will be biased.&lt;/p&gt;
&lt;p&gt;We can test for whether endogeneity is a problem by including group-centered covariates as additional regressors. Let &lt;span class=&#34;math inline&#34;&gt;\(\tilde{r}_{it} = r_{it} - \frac{1}{T}\sum_t r_{it}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\tilde{s}_{it}\)&lt;/span&gt; defined analogously. Now estimate the regression&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{it} = \beta_t + \gamma_1 r_{it} + \gamma_2 s_{it} + \delta_1 \tilde{r}_{it} + \delta_2 \tilde{s}_{it} + \epsilon_{it},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which does not include state fixed effects. The parameters &lt;span class=&#34;math inline&#34;&gt;\(\delta_1,\delta_2\)&lt;/span&gt; represent the differences between the random effects and fixed effects estimands of &lt;span class=&#34;math inline&#34;&gt;\(\gamma_1, \gamma_2\)&lt;/span&gt;. If these are both zero, then the random effects estimator is unbiased. Thus, the joint test for &lt;span class=&#34;math inline&#34;&gt;\(H_0: \delta_1 = \delta_2 = 0\)&lt;/span&gt; amounts to a test for non-endogeneity of the unobserved effects.&lt;/p&gt;
&lt;p&gt;For efficiency, we should estimate this using weighted least squares, but OLS will work too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MVA_deaths &amp;lt;- within(MVA_deaths, {
  legal_cent &amp;lt;- legal - tapply(legal, state, mean)[factor(state)]
  beer_cent &amp;lt;- beertaxa - tapply(beertaxa, state, mean)[factor(state)]
})

lm_Hausman &amp;lt;- lm(mrate ~ 0 + legal + beertaxa + legal_cent + beer_cent + factor(year), data = MVA_deaths)
coef_test(lm_Hausman, vcov = &amp;quot;CR2&amp;quot;, cluster = MVA_deaths$state, test = &amp;quot;Satterthwaite&amp;quot;)[1:4,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        Coef. Estimate   SE  t-stat  d.f. p-val (Satt) Sig.
## 1      legal   -9.180 7.62 -1.2042 24.94       0.2398     
## 2   beertaxa    3.395 9.40  0.3613  6.44       0.7295     
## 3 legal_cent   16.768 8.53  1.9665 33.98       0.0575    .
## 4  beer_cent    0.424 9.25  0.0458  5.86       0.9650&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To conduct a joint test on the centered covariates, we can use the &lt;code&gt;Wald_test&lt;/code&gt; function. The usual way to test this hypothesis would be to use the &lt;code&gt;CR1&lt;/code&gt; variance estimator to calculate the robust Wald statistic, then use a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2_2\)&lt;/span&gt; reference distribution (or equivalently, compare a re-scaled Wald statistic to an &lt;span class=&#34;math inline&#34;&gt;\(F(2,\infty)\)&lt;/span&gt; distribution). The &lt;code&gt;Wald_test&lt;/code&gt; function reports the latter version:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Wald_test(lm_Hausman, constraints = c(&amp;quot;legal_cent&amp;quot;,&amp;quot;beer_cent&amp;quot;), vcov = &amp;quot;CR1&amp;quot;, cluster = MVA_deaths$state, test = &amp;quot;chi-sq&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Test    F d.f.  p.val
##  chi-sq 2.93  Inf 0.0534&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The test is just shy of significance at the 5% level. If we instead use the &lt;code&gt;CR2&lt;/code&gt; variance estimator and our newly proposed approximate F-test (which is the default in &lt;code&gt;Wald_test&lt;/code&gt;), then we get:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Wald_test(lm_Hausman, constraints = c(&amp;quot;legal_cent&amp;quot;,&amp;quot;beer_cent&amp;quot;), vcov = &amp;quot;CR2&amp;quot;, cluster = MVA_deaths$state)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Test    F d.f. p.val
##   HTZ 2.57 12.4 0.117&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The low degrees of freedom of the test indicate that we’re definitely in small-sample territory and should not trust the asymptotic &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; approximation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Angrist, J. D., &amp;amp; Pischke, J.-S. (2009). &lt;em&gt;Mostly harmless econometrics: An empiricist’s companion&lt;/em&gt;. Princeton, NJ: Princeton University Press.&lt;/li&gt;
&lt;li&gt;Angrist, J. D. and Pischke, J.-S. (2014). &lt;em&gt;Mastering ’metrics: The Path from Cause to Effect&lt;/em&gt;. Princeton, NJ: Princeton University Press.&lt;/li&gt;
&lt;li&gt;Bell, R. M., &amp;amp; McCaffrey, D. F. (2002). Bias reduction in standard errors for linear regression with multi-stage samples. &lt;em&gt;Survey Methodology, 28&lt;/em&gt;(2), 169-181.&lt;/li&gt;
&lt;li&gt;Cameron, A. C., &amp;amp; Miller, D. L. (2015). A practitioner’s guide to cluster-robust inference. URL: &lt;a href=&#34;http://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf&#34; class=&#34;uri&#34;&gt;http://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Carpenter, C., &amp;amp; Dobkin, C. (2011). The minimum legal drinking age and public health. &lt;em&gt;Journal of Economic Perspectives, 25&lt;/em&gt;(2), 133-156. &lt;a href=&#34;doi:10.1257/jep.25.2.133&#34; class=&#34;uri&#34;&gt;doi:10.1257/jep.25.2.133&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Imbens, G. W., &amp;amp; Kolesar, M. (2015). Robust standard errors in small samples: Some practical advice. URL: &lt;a href=&#34;https://www.princeton.edu/~mkolesar/papers/small-robust.pdf&#34; class=&#34;uri&#34;&gt;https://www.princeton.edu/~mkolesar/papers/small-robust.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Small-sample adjustments for tests of moderators and model fit using robust variance estimation in meta-regression</title>
      <link>http://localhost:4321/publication/rve-for-meta-regression/</link>
      <pubDate>Tue, 15 Dec 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/rve-for-meta-regression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Special Education Pro-Sem</title>
      <link>http://localhost:4321/sped-pro-sem-again/</link>
      <pubDate>Tue, 24 Nov 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/sped-pro-sem-again/</guid>
      <description>


&lt;p&gt;Yesterday evening I again had the pleasure of visiting Dr. Barnes’ pro seminar for first year students in Special Education, where I shared some of my work on research synthesis and meta-analysis of single-case research. &lt;a href=&#34;http://localhost:4321/files/Barnes-Pro-Sem-2015-11.pdf&#34;&gt;Here are the slides&lt;/a&gt; from my presentation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Correlations between standardized mean differences</title>
      <link>http://localhost:4321/correlations-between-smds/</link>
      <pubDate>Thu, 17 Sep 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/correlations-between-smds/</guid>
      <description>


&lt;p&gt;Several students and colleagues have asked me recently about an issue that comes up in multivariate meta-analysis when some of the studies include multiple treatment groups and multiple outcome measures. In this situation, one might want to include effect size estimates for each treatment group and each outcome measure. In order to do so in fully multivariate meta-analysis, estimates of the covariances among all of these efffect sizes are needed. The covariance among effect sizes arises for several reasons:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For a single outcome measure, effect sizes based on different treatment groups compared to a common control group will be correlated because the same control group data is used to calculate both effect sizes;&lt;/li&gt;
&lt;li&gt;Effect sizes based on a single treatment group and a single control group, but for different outcome measures, will be correlated because the outcomes are measured on the same set of units (in both the treatment group and the control group).&lt;/li&gt;
&lt;li&gt;Effect sizes based on different treatment groups and for different outcome measures will be correlated because the outcomes are measured on the same set of units in the control group (though not in the treatment group).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For standardized mean difference (SMD) measures of effect size, formulas for the covariance are readily available for the first two cases (see e.g., Gleser &amp;amp; Olkin, 2009), but not for the third case. Below I review the formulas for the covariance between SMDs in the first two cases and provide a formula for the third case.&lt;/p&gt;
&lt;div id=&#34;notation-and-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Notation and Model&lt;/h1&gt;
&lt;p&gt;Suppose that the experiment has a control group that includes &lt;span class=&#34;math inline&#34;&gt;\(n_0\)&lt;/span&gt; units and &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; treatment groups that include &lt;span class=&#34;math inline&#34;&gt;\(n_1,...,n_T\)&lt;/span&gt; units, respectively. Also suppose that &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; outcome measures are made on each unit in each group. The formulas below assume that the data follow a one-way MANOVA model. Let &lt;span class=&#34;math inline&#34;&gt;\(y_{ijt}\)&lt;/span&gt; denote the score for unit &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in group &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Then I assume that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijt} = \mu_{jt} + \epsilon_{ijt},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the errors are multi-variate normally distributed with mean zero, variance that can differ across outcome but not across treatment group, and correlation that is constant across treatment groups, i.e. &lt;span class=&#34;math inline&#34;&gt;\(\text{Var}\left(\epsilon_{ijt}\right) = \sigma^2_j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Cov}\left(\epsilon_{ijt}, \epsilon_{ikt} \right) = \rho_{jk}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Denote the mean score on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in group &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{jt}\)&lt;/span&gt; and the standard deviation of the scores on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; in group &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(s_{jt}\)&lt;/span&gt;, both for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t = 0,...,T\)&lt;/span&gt; (with &lt;span class=&#34;math inline&#34;&gt;\(t = 0\)&lt;/span&gt; corresponding to the control group). Also required are estimates of the correlations among outcome measures 1 through &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt;, after partialling out differences between treatment groups. Let &lt;span class=&#34;math inline&#34;&gt;\(r_{jk}\)&lt;/span&gt; denote the partial correlation between measure &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and measure &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J - 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k = j + 1,...,J\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;With multiple treatment groups, one might wonder how best to compute the standard deviation for purposes of scaling the treatment effect estimates. In their discussion of SMDs from multiple treatment studies, Gleser and Olkin (2009) assume (though they don’t actually state outright) that the standard deviation will be pooled across all &lt;span class=&#34;math inline&#34;&gt;\(T + 1\)&lt;/span&gt; groups. The pooled standard deviation for outcome &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; is calculated as the square root of the pooled variance,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s_{jP}^2 = \frac{1}{N - T - 1} \sum_{t=0}^T (n_t - 1)s_{jt}^2,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(N = \sum_{t=0}^T n_t\)&lt;/span&gt;. The standardized mean difference for treatment &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; on outcome &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is then estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d_{jt} = \frac{\bar{y}_{jt} - \bar{y}_{j0}}{s_{jP}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,J\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t = 1,...,T\)&lt;/span&gt;. The conventional estimate of the large-sample variance of &lt;span class=&#34;math inline&#34;&gt;\(d_{jt}\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Var}(d_{jt}) \approx \frac{1}{n_0} + \frac{1}{n_t} + \frac{d_{jt}^2}{2 (N - T - 1)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;covariances&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Covariances&lt;/h1&gt;
&lt;p&gt;For SMDs based on a common outcome measure and a common control group, but different treatment groups, the large-sample covariance between the effect size estimates can be estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{ju}) \approx \frac{1}{n_0} + \frac{d_{jt} d_{ju}}{2 (N - T - 1)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above differs slightly from Gleser and Olkin (2009, Formula 19.19) because it uses the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(N - T - 1\)&lt;/span&gt; in the denominator of the second term, rather than the total sample size. If the total sample size is larger relative to the number of treatment groups, the discrepancy should be minor.&lt;/p&gt;
&lt;p&gt;SMDs based on a single treatment group but for different outcome measures follow a structure that is essentially equivalent to what Gleser and Olkin (2009) call a “multiple-endpoint” study. The large-sample covariance between the effect size estimates can be estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{kt}) \approx r_{jk} \left(\frac{1}{n_0} + \frac{1}{n_t}\right) + \frac{r_{jk}^2 d_{jt} d_{kt}}{2 (N - T - 1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(cf. Gleser &amp;amp; Olkin, 2009, Formula 19.19). Note that if the degrees of freedom are large relative to &lt;span class=&#34;math inline&#34;&gt;\(d_{jt}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d_{kt}\)&lt;/span&gt;, then the correlation between the effect sizes will be approximately equal to &lt;span class=&#34;math inline&#34;&gt;\(\text{Cor}(d_{jt},d_{kt}) \approx r_{jk}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, the large-sample covariance between SMDs based on different treatment groups and different outcome measures can be estimated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{ku}) \approx \frac{r_{jk}}{n_0} + \frac{r_{jk}^2 d_{jt} d_{ku}}{2 (N - T - 1)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is similar to the previous formula, but does not include the term corresponding to the covariance between different outcome measures in a common treatment group.&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(r_{jj} = 1\)&lt;/span&gt; is used for the correlation of an outcome measure with itself, all of the above formulas (including the variance of &lt;span class=&#34;math inline&#34;&gt;\(d_{jt}\)&lt;/span&gt;) can be expressed compactly as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{Cov}(d_{jt},d_{ku}) \approx r_{jk} \left(\frac{1}{n_0} + \frac{I(t = u)}{n_t}\right) + \frac{r_{jk}^2 d_{jt} d_{ku}}{2 (N - T - 1)},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(I(A)\)&lt;/span&gt; is equal to one if &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is true and equal to zero otherwise.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Gleser, L. J., &amp;amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp;amp; J. C. Valentine (Eds.), The Handbook of Research Synthesis and Meta-Analysis (2nd ed., pp. 357-376). New York, NY: Russell Sage Foundation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Measurement-comparable effect sizes for single-case studies of free-operant behavior</title>
      <link>http://localhost:4321/publication/measurement-comparable-effect-sizes/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/measurement-comparable-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fatal crashes in Austin/Travis County</title>
      <link>http://localhost:4321/fatal-crashes-in-austin/travis-county/</link>
      <pubDate>Thu, 20 Aug 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/fatal-crashes-in-austin/travis-county/</guid>
      <description>


&lt;p&gt;I have been hearing quite a bit lately about how there have been an unusually large number of fatal automobile crashes in Austin this year, resulting in a total of &lt;a href=&#34;http://kxan.com/2015/08/19/southbound-i-35-closed-at-airport-blvd-after-fatal-crash/&#34;&gt;69 fatalities (as of August 19th)&lt;/a&gt;. Terrence Henry (of KUT) recently &lt;a href=&#34;http://kut.org/post/what-can-austin-do-stop-road-deaths&#34;&gt;did a story&lt;/a&gt; on this problem, and the City of Austin has convened the &lt;a href=&#34;http://austintexas.gov/department/vision-zero-task-force&#34;&gt;Vision Zero Task Force&lt;/a&gt; to figure out what policies to implement in order to prevent these deaths. KUT published &lt;a href=&#34;http://kut.org/post/map-austins-traffic-fatalities-so-far-2015&#34;&gt;an interactive map&lt;/a&gt; showing the locations of the fatal crashes and the Vision Zero Task Force put together a &lt;a href=&#34;http://austintexas.gov/sites/default/files/files/Imagine_Austin/VisionZero/CRASHES_allmodes_revised8_6_15.pdf&#34;&gt;heat map&lt;/a&gt; showing the locations of crashes over the past five years.&lt;/p&gt;
&lt;p&gt;I was curious to understand more about how fatalities have changed over time, but the only data I could find on the time trends was &lt;a href=&#34;http://austintexas.gov/sites/default/files/images/ImagineAustin/VisionZero/67_deaths_081115.png&#34;&gt;this graphic&lt;/a&gt; on the Vision Zero website. After a bit of digging, I found that I could get annual data for Austin (2006-2014) and for Travis County (2003-2014) from the &lt;a href=&#34;http://www.txdot.gov/government/enforcement/annual-summary.html&#34;&gt;Texas Motor Vehicle Crash Statistics reports&lt;/a&gt; provided by TXDOT (though the data are trapped in pdfs). It’s also possible to get disaggregated data for the time period of 2010 through the present from the TXDOT CRIS database &lt;a href=&#34;http://www.txdot.gov/government/enforcement/data-access.html&#34;&gt;Public File Extract&lt;/a&gt;, which gets updated with new information as it comes in, and so will presumably be more current than the annual reports.&lt;/p&gt;
&lt;p&gt;The chart below plots the annual number of fatal crashes, fatalities, crashes in which incapacitating injuries occurred, incapacitating injuries, and total crashes, for both Austin and Travis County as a whole. For the current year data, I plotted both the actual numbers (through July 31, 2015) and very simple projections. (Details on how I put the figures together are at the end of this post.)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Crashes-in-Austin-and-Travis-Co_files/figure-html/crash_graph-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The first thing you can see from these graphs is that the projected number of fatal crashes and total number of fatalities is substantially higher than in previous years. In contrast, the projected number of incapacitating crashes, number of incapacitating injuries, and total number of crashes all appear to be (very roughly) consistent with the linear trends from previous years. Taken together, these trends suggest that the proportion of crashes that are fatal is higher than would be expected. Here’s a graph of the fatality rate over time:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Crashes-in-Austin-and-Travis-Co_files/figure-html/fatality_rates-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;2015 is clearly an outlier, though not as high as the proportion of fatal crashes in Travis County during 2003 and 2004 (unfortunately the data for Austin don’t go back that far). These years have higher proportions because there were fewer crashes overall in these initial years. Also note that Travis County as a whole has a higher fatality rate than the city of Austin, probably because the non-Austin roads in Travis county are larger and have higher speed limits.&lt;/p&gt;
&lt;p&gt;I think this second graph provides good justification for one of the &lt;a href=&#34;http://austintexas.gov/department/vision-zero-task-force&#34;&gt;principles of the Vision Zero task force&lt;/a&gt;, which is to focus on infrastructure improvements to improve the safety of the transformation system for &lt;strong&gt;all of the people who interact with it&lt;/strong&gt;, including pedestrians—in short, to make our streets and roads safe for humans. &lt;strong&gt;The graphs suggests that there’s more to the increase in fatal crashes than just population growth, more than just increases in vehicle miles travelled.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There’s a big limitation to using annual data for this sort of simple, “eyeballing” sort of analysis. If there are seasonal patterns in automobile crashes overall (such as more crashes during the colder months) or, more specifically, in fatal crashes, then my simple back-of-the-envelope projections could be somewhat misleading. To develop more nuanced projections, I would need to get finer-grained data on &lt;em&gt;when&lt;/em&gt; crashes occur. unfortunately, for some reasons the &lt;a href=&#34;http://www.txdot.gov/government/enforcement/data-access.html&#34;&gt;public version of the underlying data&lt;/a&gt; does not include dates of individual crashes. (This is rather perplexing, considering that the interface will let you query a date range, even down to a single day.) More to come if I can figure out how to get access to data with dates on it.&lt;/p&gt;
&lt;div id=&#34;methods&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Methods&lt;/h3&gt;
&lt;p&gt;Here’s how I constructed these figures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The data for 2003 through 2009 are drawn from the Crash Statistics reports, and the data for 2010 through 2015 are drawn from the CRIS Public File Extract.&lt;/li&gt;
&lt;li&gt;There are some discrepancies between the annual reports and the CRIS database for the latter period, so I am assuming that the latter is more accurate. Curiously, the number’s don’t quite match the Vision Zero graphic either.&lt;/li&gt;
&lt;li&gt;The incapacitating crashes and injuries numbers are only available starting in 2010, as prior to that time a different set of classifications was used that does not appear to be directly comparable.&lt;/li&gt;
&lt;li&gt;The dashed lines in each graph represent estimated linear trends, fit by ordinary least squares.&lt;/li&gt;
&lt;li&gt;The actual figures are plotted with circles. The projections for 2015 are plotted with triangles.&lt;/li&gt;
&lt;li&gt;For 2015, the projections were calculated by multiplying the actual number by 12 / 7 = 1.71 because the actuals are based on 7 out of 12 months. (Using 211 out of 365 days leads to a very similar multiplier of 1.73.)&lt;/li&gt;
&lt;li&gt;The underlying data (drawing from both the annual reports and the CRIS database) are &lt;a href=&#34;http://localhost:4321/data/Yearly_crash_data_Austin_and_Travis_County.csv&#34;&gt;available here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The code to re-create the figures is &lt;a href=&#34;https://gist.github.com/577ff8159bc0b0a58e61.git&#34;&gt;available in this Gist&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A meta-analytic approach to examine the relationship between religion/spirituality and mental health in cancer</title>
      <link>http://localhost:4321/publication/religion-spirituality-mental-health/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/religion-spirituality-mental-health/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A meta-analytic review of religious or spiritual involvement and social health among cancer patients</title>
      <link>http://localhost:4321/publication/religion-spirituality-social-health/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/religion-spirituality-social-health/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Religion, spirituality, and physical health in cancer patients: A meta-analysis</title>
      <link>http://localhost:4321/publication/religion-spirituality-physical-health/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/religion-spirituality-physical-health/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The clubSandwich package for meta-analysis with RVE</title>
      <link>http://localhost:4321/clubsandwich-for-rve-meta-analysis/</link>
      <pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/clubsandwich-for-rve-meta-analysis/</guid>
      <description>


&lt;p&gt;I’ve recently been working on small-sample correction methods for hypothesis tests in linear regression models with cluster-robust variance estimation. My colleague (and grad-schoolmate) Beth Tipton has developed small-sample adjustments for t-tests (of single regression coefficients) in the context of meta-regression models with robust variance estimation, and together we have developed methods for multiple-contrast hypothesis tests. We have an R package (called &lt;code&gt;clubSandwich&lt;/code&gt;) that implements all this stuff, not only for meta-regression models but also for other models and contexts where cluster-robust variance estimation is often used.&lt;/p&gt;
&lt;p&gt;The alpha-version of the package is currently &lt;a href=&#34;https://github.com/jepusto/clubSandwich&#34;&gt;available on Github&lt;/a&gt;. See the Github README for instructions on how to install it in R. Below I demonstrate how to use the package to get robust variance estimates, t-tests, and F-tests, all with small-sample corrections. The example uses a dataset of effect sizes from a Campbell Collaboration &lt;a href=&#34;http://www.campbellcollaboration.org/lib/project/158/&#34;&gt;systematic review of dropout prevention programs&lt;/a&gt;, conducted by Sandra Jo Wilson and her colleagues.&lt;/p&gt;
&lt;p&gt;The original analysis included a meta-regression with covariates that capture methodological, participant, and program characteristics. I’ll use a regression specification that is similar to Model III from Wilson et al. (2011), but treat the &lt;code&gt;evaluator_independence&lt;/code&gt; and &lt;code&gt;implementation_quality&lt;/code&gt; variables as categorical rather than interval-level; the original analysis clustered at the level of the sample (some studies reported results from multiple samples), whereas I will cluster at the study level.
I fit the model two ways, first using the &lt;code&gt;robumeta&lt;/code&gt; package and then using &lt;code&gt;metafor&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;robumeta-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;robumeta model&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(width=150)
library(robumeta)
library(clubSandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;clubSandwich&amp;#39;:
##   method    from    
##   bread.mlm sandwich&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(dropoutPrevention)

m3_robu &amp;lt;- robu(LOR1 ~ study_design + attrition + group_equivalence + adjusted
                + outcome + evaluator_independence
                + male_pct + white_pct + average_age
                + implementation_quality + program_site + duration + service_hrs, 
                data = dropoutPrevention, studynum = studyID, var.eff.size = varLOR, 
                modelweights = &amp;quot;HIER&amp;quot;)
print(m3_robu)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Hierarchical Effects Model with Small-Sample Corrections 
## 
## Model: LOR1 ~ study_design + attrition + group_equivalence + adjusted + outcome + evaluator_independence + male_pct + white_pct + average_age + implementation_quality + program_site + duration + service_hrs 
## 
## Number of clusters = 152 
## Number of outcomes = 385 (min = 1 , mean = 2.53 , median = 1 , max = 30 )
## Omega.sq = 0.24907 
## Tau.sq = 0.1024663 
## 
##                                                 Estimate   StdErr t-value  dfs    P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1                                 X.Intercept.  0.016899 0.615399  0.0275 16.9 0.97841541 -1.28228  1.31608    
## 2          study_designNon.random..non.matched -0.002626 0.185142 -0.0142 40.5 0.98875129 -0.37667  0.37141    
## 3                       study_designRandomized -0.086872 0.140044 -0.6203 38.6 0.53869676 -0.37024  0.19650    
## 4                                    attrition  0.118889 0.247228  0.4809 15.5 0.63732597 -0.40666  0.64444    
## 5                            group_equivalence  0.502463 0.195838  2.5657 28.7 0.01579282  0.10174  0.90318  **
## 6                        adjustedadjusted.data -0.322480 0.125413 -2.5713 33.8 0.01470796 -0.57741 -0.06755  **
## 7                              outcomeenrolled  0.097059 0.139842  0.6941 16.5 0.49727848 -0.19862  0.39274    
## 8                            outcomegraduation  0.147643 0.134938  1.0942 30.2 0.28253825 -0.12786  0.42315    
## 9                        outcomegraduation.ged  0.258034 0.169134  1.5256 16.3 0.14632629 -0.10006  0.61613    
## 10 evaluator_independenceIndirect..influential -0.765085 0.399109 -1.9170  6.2 0.10212896 -1.73406  0.20389    
## 11              evaluator_independencePlanning -0.920874 0.346536 -2.6574  5.6 0.04027061 -1.78381 -0.05794  **
## 12              evaluator_independenceDelivery -0.916673 0.304303 -3.0124  4.7 0.03212299 -1.71432 -0.11903  **
## 13                                    male_pct  0.167965 0.181538  0.9252 16.4 0.36824526 -0.21609  0.55202    
## 14                                   white_pct  0.022915 0.149394  0.1534 21.8 0.87950385 -0.28704  0.33287    
## 15                                 average_age  0.037102 0.027053  1.3715 21.2 0.18458247 -0.01913  0.09333    
## 16     implementation_qualityPossible.problems  0.411779 0.128898  3.1946 26.7 0.00358205  0.14714  0.67642 ***
## 17  implementation_qualityNo.apparent.problems  0.658570 0.123874  5.3164 34.6 0.00000635  0.40699  0.91015 ***
## 18                           program_sitemixed  0.444384 0.172635  2.5741 28.6 0.01550504  0.09109  0.79768  **
## 19                program_siteschool.classroom  0.426658 0.159773  2.6704 37.4 0.01115192  0.10303  0.75028  **
## 20    program_siteschool..outside.of.classroom  0.262517 0.160519  1.6354 30.1 0.11236814 -0.06525  0.59028    
## 21                                    duration  0.000427 0.000873  0.4895 36.7 0.62736846 -0.00134  0.00220    
## 22                                 service_hrs -0.003434 0.005012 -0.6852 36.7 0.49752503 -0.01359  0.00672    
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---
## Note: If df &amp;lt; 4, do not trust the results&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that &lt;code&gt;robumeta&lt;/code&gt; produces small-sample corrected standard errors and t-tests, and so there is no need to repeat those calculations with &lt;code&gt;clubSandwich&lt;/code&gt;. The &lt;code&gt;evaluator_independence&lt;/code&gt; variable has four levels, and it might be of interest to test whether the average program effects differ by the degree of evaluator independence. The null hypothesis in this case is that the 10th, 11th, and 12th regression coefficients are all equal to zero. A small-sample adjusted F-test for this hypothesis can be obtained as follows.
(The &lt;code&gt;vcov = &#34;CR2&#34;&lt;/code&gt; option means that the standard errors will be corrected using the bias-reduced linearization method proposed by McCaffrey, Bell, and Botts, 2001.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Wald_test(m3_robu, constraints = 10:12, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Test    F d.f.  p.val
##   HTZ 2.78 16.8 0.0732&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the &lt;code&gt;Wald_test&lt;/code&gt; function provides an F-type test with degrees of freedom estimated using the approximate Hotelling’s &lt;span class=&#34;math inline&#34;&gt;\(T^2_Z\)&lt;/span&gt; method. The test has less than 17 degrees of freedom, even though there are 152 independent studies in the data, and has a p-value of .07, so not-quite-significant at conventional levels. The low degrees of freedom are a consequence of the fact that one of the levels of &lt;code&gt;evaluator independence&lt;/code&gt; has only a few effect sizes in it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(dropoutPrevention$evaluator_independence)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##           Independent Indirect, influential              Planning              Delivery 
##                     6                    33                    43                   303&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;metafor-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;metafor model&lt;/h4&gt;
&lt;p&gt;Our package also works with models fit using the &lt;code&gt;metafor&lt;/code&gt; package. Here I re-fit the same regression specification, but use REML to estimate the variance components (&lt;code&gt;robumeta&lt;/code&gt; uses a method-of-moments estimator) and use a somewhat different weighting scheme than that used in &lt;code&gt;robumeta&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
m3_metafor &amp;lt;- rma.mv(LOR1 ~ study_design + attrition + group_equivalence + adjusted
                      + outcome + evaluator_independence
                      + male_pct + white_pct + average_age
                      + implementation_quality + program_site + duration + service_hrs, 
                      V = varLOR, random = list(~ 1 | studyID, ~ 1 | studySample),
                     data = dropoutPrevention)
summary(m3_metafor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 385; method: REML)
## 
##    logLik   Deviance        AIC        BIC       AICc 
## -489.0357   978.0714  1026.0714  1119.5371  1029.6217   
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed       factor 
## sigma^2.1  0.2274  0.4769    152     no      studyID 
## sigma^2.2  0.1145  0.3384    317     no  studySample 
## 
## Test for Residual Heterogeneity:
## QE(df = 363) = 1588.4397, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:22):
## QM(df = 21) = 293.8694, p-val &amp;lt; .0001
## 
## Model Results:
## 
##                                              estimate      se     zval    pval    ci.lb    ci.ub 
## intrcpt                                        0.5296  0.7250   0.7304  0.4651  -0.8915   1.9506      
## study_designNon-random, non-matched           -0.0494  0.1722  -0.2871  0.7741  -0.3870   0.2881      
## study_designRandomized                         0.0653  0.1628   0.4010  0.6884  -0.2538   0.3843      
## attrition                                     -0.1366  0.2429  -0.5623  0.5739  -0.6126   0.3395      
## group_equivalence                              0.4071  0.1573   2.5877  0.0097   0.0988   0.7155   ** 
## adjustedadjusted data                         -0.3581  0.1532  -2.3371  0.0194  -0.6585  -0.0578    * 
## outcomeenrolled                               -0.2831  0.0771  -3.6709  0.0002  -0.4343  -0.1320  *** 
## outcomegraduation                             -0.0913  0.0657  -1.3896  0.1646  -0.2201   0.0375      
## outcomegraduation/ged                          0.6983  0.0805   8.6750  &amp;lt;.0001   0.5406   0.8561  *** 
## evaluator_independenceIndirect, influential   -0.7530  0.4949  -1.5214  0.1282  -1.7230   0.2171      
## evaluator_independencePlanning                -0.7700  0.4869  -1.5814  0.1138  -1.7242   0.1843      
## evaluator_independenceDelivery                -1.0016  0.4600  -2.1774  0.0294  -1.9033  -0.1000    * 
## male_pct                                       0.1021  0.1715   0.5951  0.5518  -0.2341   0.4382      
## white_pct                                      0.1223  0.1804   0.6777  0.4979  -0.2313   0.4758      
## average_age                                    0.0061  0.0291   0.2091  0.8344  -0.0509   0.0631      
## implementation_qualityPossible problems        0.4738  0.1609   2.9445  0.0032   0.1584   0.7892   ** 
## implementation_qualityNo apparent problems     0.6318  0.1471   4.2965  &amp;lt;.0001   0.3436   0.9201  *** 
## program_sitemixed                              0.3289  0.2413   1.3631  0.1729  -0.1440   0.8019      
## program_siteschool classroom                   0.2920  0.1736   1.6821  0.0926  -0.0482   0.6321    . 
## program_siteschool, outside of classroom       0.1616  0.1898   0.8515  0.3945  -0.2104   0.5337      
## duration                                       0.0013  0.0009   1.3423  0.1795  -0.0006   0.0031      
## service_hrs                                   -0.0003  0.0047  -0.0654  0.9478  -0.0096   0.0090      
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;metafor&lt;/code&gt; produces model-based standard errors, t-tests, and confidence intervals. The &lt;code&gt;coef_test&lt;/code&gt; function from &lt;code&gt;clubSandwich&lt;/code&gt; will calculate robust standard errors and robust t-tests for each of the coefficients:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_test(m3_metafor, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                          Coef.  Estimate       SE  t-stat  d.f. p-val (Satt) Sig.
## 1                                      intrcpt  0.529569 0.724851  0.7306 20.08      0.47347     
## 2          study_designNon-random, non-matched -0.049434 0.204152 -0.2421 58.42      0.80952     
## 3                       study_designRandomized  0.065272 0.149146  0.4376 53.17      0.66342     
## 4                                    attrition -0.136575 0.306429 -0.4457 10.52      0.66485     
## 5                            group_equivalence  0.407108 0.210917  1.9302 23.10      0.06595    .
## 6                        adjustedadjusted data -0.358124 0.136132 -2.6307 43.20      0.01176    *
## 7                              outcomeenrolled -0.283124 0.237199 -1.1936  7.08      0.27108     
## 8                            outcomegraduation -0.091295 0.091465 -0.9981  9.95      0.34188     
## 9                        outcomegraduation/ged  0.698328 0.364882  1.9138  8.02      0.09188    .
## 10 evaluator_independenceIndirect, influential -0.752994 0.447670 -1.6820  6.56      0.13929     
## 11              evaluator_independencePlanning -0.769968 0.403898 -1.9063  6.10      0.10446     
## 12              evaluator_independenceDelivery -1.001648 0.355989 -2.8137  4.89      0.03834    *
## 13                                    male_pct  0.102055 0.148410  0.6877  9.68      0.50782     
## 14                                   white_pct  0.122255 0.141470  0.8642 16.88      0.39961     
## 15                                 average_age  0.006084 0.033387  0.1822 15.79      0.85772     
## 16     implementation_qualityPossible problems  0.473789 0.148660  3.1871 22.44      0.00419   **
## 17  implementation_qualityNo apparent problems  0.631842 0.138073  4.5761 28.68      &amp;lt; 0.001  ***
## 18                           program_sitemixed  0.328941 0.196848  1.6710 27.47      0.10607     
## 19                program_siteschool classroom  0.291952 0.146014  1.9995 42.70      0.05195    .
## 20    program_siteschool, outside of classroom  0.161640 0.171700  0.9414 29.27      0.35420     
## 21                                    duration  0.001270 0.000978  1.2988 31.96      0.20332     
## 22                                 service_hrs -0.000309 0.004828 -0.0641 49.63      0.94915&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that &lt;code&gt;coef_test&lt;/code&gt; assumed that it should cluster based on &lt;code&gt;studyID&lt;/code&gt;, which is the outer-most random effect in the metafor model. This can also be specified explicitly by including the option &lt;code&gt;cluster = dropoutPrevention$studyID&lt;/code&gt; in the call.&lt;/p&gt;
&lt;p&gt;The F-test for degree of evaluator independence uses the same syntax as before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Wald_test(m3_metafor, constraints = 10:12, vcov = &amp;quot;CR2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Test    F d.f.  p.val
##   HTZ 2.71 18.3 0.0753&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Despite some differences in weighting schemes, the p-value is very close to the result obtained using &lt;code&gt;robumeta&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Small-sample adjustments for multiple-contrast hypothesis tests of meta-regressions using robust variance estimation</title>
      <link>http://localhost:4321/talk/srsm-2015-small-sample-adjustments/</link>
      <pubDate>Wed, 08 Jul 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/srsm-2015-small-sample-adjustments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Four methods for analyzing partial interval recording data, with application to single-case research</title>
      <link>http://localhost:4321/publication/four-methods-for-pir/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/four-methods-for-pir/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Operational sensitivities of non-overlap effect sizes for single-case experimental designs</title>
      <link>http://localhost:4321/talk/aera-2015-operational-sensitivities/</link>
      <pubDate>Sun, 19 Apr 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2015-operational-sensitivities/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small-sample adjustments for F-tests using robust variance estimation in meta-regression</title>
      <link>http://localhost:4321/talk/aera-2015-small-sample-adjustments/</link>
      <pubDate>Sat, 18 Apr 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2015-small-sample-adjustments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Observation procedures and Markov Chain models for estimating the prevalence and incidence of a state behavior</title>
      <link>http://localhost:4321/talk/aera-2015-observation-procedures/</link>
      <pubDate>Thu, 16 Apr 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2015-observation-procedures/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Small-sample adjustments for tests of moderators and model fit using robust variance estimation in meta-regression</title>
      <link>http://localhost:4321/talk/sree-2015-small-sample-adjustments/</link>
      <pubDate>Fri, 06 Mar 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sree-2015-small-sample-adjustments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New article: Four methods for analyzing PIR data</title>
      <link>http://localhost:4321/four-methods-for-analyzing-pir-data/</link>
      <pubDate>Wed, 11 Feb 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/four-methods-for-analyzing-pir-data/</guid>
      <description>


&lt;p&gt;My article with Daniel Swan, “Four methods for analyzing partial interval recording data, with application to single-case research” has been accepted for publication in Multivariate Behavioral Research. In an extension of my earlier paper on &lt;a href=&#34;http://localhost:4321/files/Measurement-comparable-ES.pdf&#34;&gt;measurement-comparable effect sizes&lt;/a&gt; for single-case studies, this article provides some approaches to estimating effect sizes from single-case studies that use partial interval or whole interval recording to measure behavioral outcomes. The full abstract is below. &lt;a href=&#34;http://localhost:4321/files/4-PIR-methods-MBR.pdf&#34;&gt;Preprint&lt;/a&gt; and &lt;a href=&#34;http://localhost:4321/files/4-PIR-Methods-Appendix.pdf&#34;&gt;supporting materials&lt;/a&gt; are available. R functions that implement the proposed methods are available in the package &lt;a href=&#34;https://cran.r-project.org/web/packages/ARPobservation/&#34;&gt;ARPobservation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Partial interval recording is a procedure for collecting measurements during direct observation of behavior. It is used in several areas of educational and psychological research, particularly in connection with single-case research. Measurements collected using partial interval recording suffer from construct invalidity because they are not readily interpretable in terms of the underlying characteristics of the behavior. Using an alternating renewal process model for the behavior under observation, we demonstrate that ignoring the construct invalidity of PIR data can produce misleading inferences, such as inferring that an intervention reduces the prevalence of an undesirable behavior when in fact it has the opposite effect. We then propose four different methods for analyzing PIR summary measurements, each of which can be used to draw inferences about interpretable behavioral parameters. We demonstrate the methods by applying them to data from two single-case studies of problem behavior.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting started with scdhlm</title>
      <link>http://localhost:4321/getting-started-with-scdhlm/</link>
      <pubDate>Sun, 19 Oct 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/getting-started-with-scdhlm/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;UPDATED 10/2/2016 after posting the package to CRAN&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here are step-by-step instructions on how to download and install the scdhlm package for R. You’ll need to have a &lt;a href=&#34;http://cran.us.r-project.org/&#34;&gt;copy of R installed&lt;/a&gt;. There are two ways to do the installation: through the Comprehensive R Archive Network (CRAN) or from the source code on Github. I describe each approach in turn.&lt;/p&gt;
&lt;div id=&#34;option-1-via-cran&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Option 1: Via CRAN&lt;/h3&gt;
&lt;p&gt;Go via CRAN to install the most recent stable version of the package. Type the following commands at the R prompt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;scdhlm&amp;quot;)
library(scdhlm)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;option-2-via-github&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Option 2: Via Github&lt;/h3&gt;
&lt;p&gt;Go via Github to get the latest development version of the package. For this option, you will first need to install the devtools package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;devtools&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you have successfully installed this package, type the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(devtools)
install_github(&amp;quot;jepusto/scdhlm&amp;quot;)
library(scdhlm)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;further-instructions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further instructions&lt;/h3&gt;
&lt;p&gt;You’ll only need to do the installation once. Once you’ve got the package installed, type the following in order to access the package within an R session: &lt;code&gt;library(scdhlm)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To open the package documentation, type &lt;code&gt;package?scdhlm&lt;/code&gt;. To access the documentation for an individual function in this package, just type &lt;code&gt;?&lt;/code&gt; followed by the name of the function. For instance, one of the main functions in the package is called &lt;code&gt;g_REML&lt;/code&gt;; to access its documentation, type &lt;code&gt;?g_REML&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;web-interface-for-calculating-effect-sizes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;web-interface for calculating effect sizes&lt;/h3&gt;
&lt;p&gt;The package includes an interactive app (written with &lt;code&gt;shiny&lt;/code&gt;) for calculating design-comparable standardized mean differences. To run this app on your computer, you will first need to &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/&#34;&gt;install RStudio&lt;/a&gt; (if you don’t already have it). Then ensure that you have the &lt;code&gt;shiny&lt;/code&gt;, &lt;code&gt;markdown&lt;/code&gt;, and &lt;code&gt;ggplot2&lt;/code&gt; packages installed by running the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;shiny&amp;quot;)
install.packages(&amp;quot;markdown&amp;quot;)
install.packages(&amp;quot;ggplot2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, open the app by typing the following at the prompt within RStudio:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(scdhlm)
shine_scd()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The app should now open in your web browser.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New article: Alternating renewal process models for behavioral observation</title>
      <link>http://localhost:4321/new-article-alternating-renewal-process-models-for-behavioral-observation/</link>
      <pubDate>Thu, 16 Oct 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/new-article-alternating-renewal-process-models-for-behavioral-observation/</guid>
      <description>


&lt;p&gt;My article with Chris Runyon, titled “Alternating renewal process models for behavioral observation: Simulation methods, software , and validity illustrations” has been published in Behavioral Disorders. The abstract is below. &lt;a href=&#34;http://localhost:4321/files/Pustejovsky-Runyon-2015.pdf&#34;&gt;Postprint available here&lt;/a&gt;. All of the examples in the paper are available in the R package &lt;a href=&#34;https://cran.r-project.org/web/packages/ARPobservation/&#34;&gt;ARPobservation&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Direct observation recording procedures produce reductive summary measurements of an underlying stream of behavior. Previous methodological studies of these recording procedures have employed simulation methods for generating random behavior streams, many of which amount to special cases of a statistical model known as the alternating renewal process. This paper describes the alternating renewal process model in its general form, demonstrates how it provides an organizing framework for most past simulation research on direct observation procedures, and introduces a freely available software package that implements the model. The software can be used to simulate behavior streams as well as data from many common recording procedures, including continuous recording, momentary time sampling, event counting, and interval recording procedures. Several examples illustrate how the software can be used to study the validity and reliability of direct observation data and to develop measurement strategies during the planning phases of empirical studies.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Design-comparable effect sizes in multiple baseline designs: A general modeling framework</title>
      <link>http://localhost:4321/publication/design-comparable-effect-sizes/</link>
      <pubDate>Wed, 01 Oct 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/design-comparable-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wanted: PIR data</title>
      <link>http://localhost:4321/wanted-pir-data/</link>
      <pubDate>Wed, 03 Sep 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/wanted-pir-data/</guid>
      <description>


&lt;p&gt;Partial interval recording (PIR) is one method for recording data during systematic direct observation of a behavior. While a convenient method, PIR has the key drawback that it &lt;a href=&#34;http://localhost:4321/PIR-overestimates-prevalence&#34;&gt;systematically over-states&lt;/a&gt; the prevalence of the behavior under observation. When used in single-case research to measure changes in behavior resulting from intervention, the systematic bias in PIR data can lead to deceptive results, such as inferring that an intervention reduces the prevalence of a problem behavior when in fact the opposite is true.&lt;/p&gt;
&lt;p&gt;With my student Daniel Swan, I am currently working on developing methods for analyzing partial interval recording data that take its systematic bias into account. Some of these methods can be used with session-level summary PIR measurements (i.e., the percentage of intervals with the behavior), which are easily extracted from published single-case graphs. &lt;a href=&#34;http://localhost:4321/files/4-PIR-methods-AERA-version-20140312.pdf&#34;&gt;See here&lt;/a&gt; for the paper describing these methods.&lt;/p&gt;
&lt;p&gt;We are now turning our attention to methods that use the finer-grained, interval-by-interval PIR data to obtain better estimates of the prevalence and incidence (frequency per unit time) of the behavior. For instance, if the observer uses 15 s partial interval recording, with 5 s for recording, for a 20 min session, this is a total of 60 intervals, for each of which the presence or absence of the behavior is recorded. The methods we’re working on make use of the full set of 60 ordered data points from the session. The general idea our work is similar to the post-hoc correction techniques proposed by Suen &amp;amp; Ary (1986), but we think we can greatly improve on their proposal.&lt;/p&gt;
&lt;p&gt;To fully validate the methods we are developing, we need to test them out on real-world data. If you, dear reader, have access to PIR data and would be willing to share it with us, I would love to hear from you. We are looking specifically for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fine-grained (interval-by-interval) PIR data collected in real research contexts, such as single-case studies or observational studies involving students with behavioral disorders, children with autism-spectrum disorders, etc.&lt;/li&gt;
&lt;li&gt;Alternately, continuously-recorded behavioral observation data (e.g., as collected through MOOSES, the Direct Assessment Tracking Application, or ProCoderDV) that we could then convert into PIR data.&lt;/li&gt;
&lt;li&gt;Along with either type of behavioral observation data, a brief (or lengthier) description of the participant(s) whose behavior was measured and the context in which the measurements were collected.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can work with data in whatever format you might be willing to provide–whether that means photo-copied, paper observation forms, an Excel workbook, or a bunch of ProCoderDV data files. In return for sharing data, we will share with you the examples that we develop based on the data, which could also provide a basis for further collaboration. If you are interested in seeing your data analyzed and helping to advance this methodological work, please &lt;a href=&#34;http://localhost:4321/index.html#contact&#34;&gt;contact me&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Alternating renewal process models for behavioral observation: Simulation methods and validity implications</title>
      <link>http://localhost:4321/publication/arp-for-behavioral-observation/</link>
      <pubDate>Fri, 01 Aug 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/arp-for-behavioral-observation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New article: Design-comparable effect sizes in multiple baseline designs: A general modeling framework</title>
      <link>http://localhost:4321/design-comparable-effect-sizes-in-multiple-baseline-designs/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/design-comparable-effect-sizes-in-multiple-baseline-designs/</guid>
      <description>


&lt;p&gt;My article with Larry Hedges and Will Shadish, titled “Design-comparable effect sizes in multiple baseline designs: A general modeling framework” has been accepted at Journal of Educational and Behavioral Statistics. The abstract is below. Here’s the article at &lt;a href=&#34;http://doi.org/10.3102/1076998614547577&#34;&gt;the journal website&lt;/a&gt;. &lt;a href=&#34;http://localhost:4321/files/Effect-sizes-in-multiple-baseline-designs-JEBS.pdf&#34;&gt;Postprint&lt;/a&gt; and &lt;a href=&#34;http://localhost:4321/files/Effect-sizes-in-multiple-baseline-designs-Simulation-results.pdf&#34;&gt;supporting materials&lt;/a&gt; are available. An R package that implements the proposed methods is &lt;a href=&#34;http://localhost:4321/getting-started-with-scdhlm/&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In single-case research, the multiple baseline design is a widely used approach for evaluating the effects of interventions on individuals. Multiple baseline designs involve repeated measurement of outcomes over time and the controlled introduction of a treatment at different times for different individuals. This article outlines a general approach for defining effect sizes in multiple baseline designs that are directly comparable to the standardized mean difference from a between-subjects randomized experiment. The target, design-comparable effect size parameter can be estimated using restricted maximum likelihood together with a small-sample correction analogous to Hedges’ g. The approach is demonstrated using hierarchical linear models that include baseline time trends and treatment-by-time interactions. A simulation compares the performance of the proposed estimator to that of an alternative, and an application illustrates the model-fitting process.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing single-case designs: d, G, hierarchical models, Bayesian estimators, generalized additive models, and the hopes and fears of researchers about analyses</title>
      <link>http://localhost:4321/publication/analyzing-scd-hopes-and-fears/</link>
      <pubDate>Fri, 18 Jul 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/analyzing-scd-hopes-and-fears/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ARPobservation now on CRAN</title>
      <link>http://localhost:4321/arpobservation-now-on-cran/</link>
      <pubDate>Sat, 31 May 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/arpobservation-now-on-cran/</guid>
      <description>


&lt;p&gt;Version 1.0 of the &lt;a href=&#34;https://cran.r-project.org/web/packages/ARPobservation/&#34;&gt;ARPobservation package&lt;/a&gt; is now available on the Comprehensive R Archive Network. This makes it &lt;a href=&#34;http://localhost:4321/getting-started-with-ARPobservation&#34;&gt;even easier to install&lt;/a&gt;. Here’s the package description:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ARPobservation: Tools for simulating different methods of observing behavior based on alternating renewal processes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;ARPobservation provides a set of tools for simulating data based on direct observation of behavior. It works by first simulating a behavior stream based on an alternating renewal process, given specified distributions of event durations and interim times. Different procedures for recording data can then be applied to the simulated behavior stream. Currently, functions are provided for the following recording methods: continuous duration recording, event counting, momentary time sampling, partial interval recording, and whole interval recording.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Meta-sandwich with extra mustard</title>
      <link>http://localhost:4321/robust-meta-analysis-3/</link>
      <pubDate>Sat, 26 Apr 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/robust-meta-analysis-3/</guid>
      <description>


&lt;p&gt;In an earlier post about sandwich standard errors for multi-variate meta-analysis, I &lt;a href=&#34;http://localhost:4321/Robust-meta-analysis-1/&#34;&gt;mentioned&lt;/a&gt; that Beth Tipton has recently proposed small-sample corrections for the covariance estimators and t-tests, based on the bias-reduced linearization approach of &lt;a href=&#34;http://www.amstat.org/sections/SRMS/Proceedings/y2001/Proceed/00264.pdf&#34;&gt;McCaffrey, Bell, and Botts (2001)&lt;/a&gt;.
You can find her forthcoming paper on the adjustments &lt;a href=&#34;http://dx.doi.org/10.1037/met0000011&#34;&gt;here&lt;/a&gt;.
My understanding is that these small-sample corrections are important because the uncorrected sandwich estimators can lead to under-statement of uncertainty and inflated type I error rates when a given meta-regression coefficient is estimated from only a small or moderately sized sample of independent studies (or clusters of studies).
Moreover, it can be difficult to determine exactly when you have a large enough sample to trust the uncorrected sandwiches.&lt;/p&gt;
&lt;p&gt;I wanted to try out these small-sample corrected sandwich estimators for a meta-analyses project that I’m working on. Beth and one of her students have written an R package called &lt;a href=&#34;http://cran.r-project.org/web/packages/robumeta/index.html&#34;&gt;robumeta&lt;/a&gt; that implements the sandwich covariance estimator and small-sample corrections as described in her paper.
However, for my project I want to use the &lt;a href=&#34;http://www.metafor-project.org/&#34;&gt;metafor package&lt;/a&gt;, which doesn’t provide these methods.
I’ve therefore created a set of functions that implement the sandwich covariance estimators and small-sample corrections for models estimated using the &lt;code&gt;rma.mv&lt;/code&gt; function in &lt;code&gt;metafor&lt;/code&gt;.
Here is &lt;a href=&#34;https://gist.github.com/jepusto/11302318&#34;&gt;the complete code&lt;/a&gt;. Sorry, there’s no further documentation at the moment (beyond the rest of this post).&lt;/p&gt;
&lt;div id=&#34;consistency-with-robumeta&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Consistency with robumeta&lt;/h3&gt;
&lt;p&gt;In order to check that the functions are correct, I compared the results generated by &lt;code&gt;robumeta&lt;/code&gt; with the results from &lt;code&gt;metafor&lt;/code&gt; plus my functions. Here’s one example (I looked at a few others as well). First, the robumeta results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(robumeta)
data(hierdat)

robu_hier &amp;lt;- robu(effectsize ~ males + binge,
            data = hierdat, modelweights = &amp;quot;HIER&amp;quot;,
            studynum = studyid,
            var.eff.size = var, small = TRUE)
robu_hier&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Hierarchical Effects Model with Small-Sample Corrections 
## 
## Model: effectsize ~ males + binge 
## 
## Number of clusters = 15 
## Number of outcomes = 68 (min = 1 , mean = 4.53 , median = 2 , max = 29 )
## Omega.sq = 0.1146972 
## Tau.sq = 0.06797866 
## 
##                Estimate  StdErr t-value  dfs P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1 X.Intercept.  -0.0989 0.32140  -0.308 1.79 0.79045  -1.6511   1.4533    
## 2        males   0.0020 0.00441   0.454 1.88 0.69689  -0.0182   0.0222    
## 3        binge   0.6799 0.12156   5.594 4.18 0.00439   0.3482   1.0117 ***
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---
## Note: If df &amp;lt; 4, do not trust the results&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To maintain consistency, I first need to calculate the approximate weights used in &lt;code&gt;robumeta&lt;/code&gt; and then fit the model in &lt;code&gt;metafor&lt;/code&gt; using these fixed weights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::source_gist(id = &amp;quot;11302318&amp;quot;, filename = &amp;quot;metafor-BRL.R&amp;quot;)

hierdat$var_HTJ &amp;lt;- hierdat$var + as.numeric(robu_hier$mod_info$omega.sq) + as.numeric(robu_hier$mod_info$tau.sq)

meta_hier &amp;lt;- rma.mv(yi = effectsize ~ males + binge, 
                V = var_HTJ, 
                data = hierdat, method = &amp;quot;FE&amp;quot;)
meta_hier$cluster &amp;lt;- hierdat$studyid

RobustResults(meta_hier)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate  Std. Error    t value       df    Pr(&amp;gt;|t|)
## intrcpt -0.098869582 0.321400179 -0.3076214 1.788350 0.790446059
## males    0.002002043 0.004410552  0.4539212 1.879142 0.696887075
## binge    0.679929801 0.121556887  5.5935111 4.182783 0.004385654&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The estimated covariance matrices match:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(sandwich(meta_hier, meat.=meatBRL), 
          robu_hier$VR.r, 
          check.attributes=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can also be verified that the p-values based on the Satterthwaite degrees of freedom agree.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-with-metafor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use with metafor&lt;/h3&gt;
&lt;p&gt;Of course, the point of writing functions that work with &lt;code&gt;rma.mv&lt;/code&gt; objects is not to replicate &lt;code&gt;robumeta&lt;/code&gt; results, but to take advantage of &lt;code&gt;metafor&lt;/code&gt;’s flexibility. Rather than estimate the model with &lt;code&gt;robumeta&lt;/code&gt;, typically one would estimate the variance components in &lt;code&gt;metafor&lt;/code&gt; and then calculate the sandwich covariance estimates and small-sample corrections. For instance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta_REML &amp;lt;- rma.mv(yi = effectsize ~ males + binge, 
                V = var, random = list(~ 1 | esid, ~ 1 | studyid), 
                data = hierdat,
                method = &amp;quot;REML&amp;quot;)
meta_REML&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 68; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2.1  0.1566  0.3957     68     no     esid 
## sigma^2.2  0.0000  0.0000     15     no  studyid 
## 
## Test for Residual Heterogeneity:
## QE(df = 65) = 297.0172, p-val &amp;lt; .0001
## 
## Test of Moderators (coefficients 2:3):
## QM(df = 2) = 27.2659, p-val &amp;lt; .0001
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb   ci.ub 
## intrcpt   -0.1118  0.2474  -0.4520  0.6513  -0.5966  0.3730      
## males      0.0022  0.0034   0.6467  0.5178  -0.0044  0.0088      
## binge      0.6744  0.1313   5.1349  &amp;lt;.0001   0.4170  0.9319  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults(meta_REML)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate  Std. Error    t value       df    Pr(&amp;gt;|t|)
## intrcpt -0.111796564 0.318156355 -0.3513888 1.794988 0.762200367
## males    0.002173683 0.004380026  0.4962718 1.882842 0.671549040
## binge    0.674435042 0.121660936  5.5435628 4.167780 0.004585142&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One advantage here is that it’s possible to compare the model-based standard errors to the robust ones. In this instance, the two are fairly similar. However, the degrees of freedom estimated in the robust results indicate that the model-based standard errors (based on normal approximations) may be much too narrow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;differences-between-robumeta-and-my-implementation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Differences between robumeta and my implementation&lt;/h3&gt;
&lt;p&gt;There are two important differences between the approach implemented in &lt;code&gt;robumeta&lt;/code&gt; and the approach based on &lt;code&gt;metafor&lt;/code&gt; and the code that I’ve provided. The first is that &lt;code&gt;robumeta&lt;/code&gt; uses moment estimators for the variance components, whereas &lt;code&gt;metafor&lt;/code&gt; uses restricted- or full maximum likelihood. The estimated between-study heterogeneity (and for the hierarchical effects model, the within-study heterogeneity as well) will therefore differ to some degree.&lt;/p&gt;
&lt;p&gt;The second, and perhaps more crucial, distinction has to do with the choice of weights. Weights are used for two purposes: to estimate the fixed effects and to calculate the small-sample correction. The &lt;code&gt;robumeta&lt;/code&gt; package uses diagonal weights for both purposes. Using diagonal weights in calculating the fixed effects means that the resulting point estimates will be equivalent to those from a weighted ordinary least squares regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;WOLS &amp;lt;- lm(effectsize ~ males + binge, data = hierdat, weights = 1 / var_HTJ)
coef(WOLS)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  (Intercept)        males        binge 
## -0.098869582  0.002002043  0.679929801&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(coef(WOLS), as.numeric(robu_hier$b.r), check.attributes = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A subtler point is that &lt;code&gt;robumeta&lt;/code&gt; uses the inverse weights for purposes of calculating the small sample-correction. The small sample correction involves choosing a “working” or “target” covariance matrix towards which to adjust the sandwich estimator. If the working covariance model is correct, then the BRL covariance estimator is exactly unbiased. The working matrix is also used to determine the Satterthwaite degrees of freedom. In &lt;code&gt;robumeta&lt;/code&gt;, the working covariance matrix is taken to be inverse of the weights, which is also a diagonal matrix. Thus, the BRL correction amounts to assuming independence among all of the effect sizes. This may sound somewhat counter-intuitive, but some simulation results (reported in Beth’s paper, referenced above) suggest that the resulting estimators perform well even when the working independence assumption is not correct.&lt;/p&gt;
&lt;p&gt;In contrast to the &lt;code&gt;robumeta&lt;/code&gt; weights, &lt;code&gt;metafor&lt;/code&gt; calculates the fixed effects based on a weighting matrix that is exactly inverse variance for given estimates of the variance components. Typically, the weighting matrix will be block-diagonal but may have off-diagonal entries corresponding to effect sizes drawn from the same study. Furthermore, my implementation of BRL uses the estimated covariance matrix derived from the posited random effects structure; in other words, the working covariance structure is taken to be the same as the model specified in the &lt;code&gt;metafor&lt;/code&gt; call. This seems sensible to me, although I do not have any evidence regarding its performance relative to the alternatives. It is possible that any gains in asymptotic efficiency from using exactly inverse variance weights are outweighed by some sort of instability in small samples. It’s also possible that the performance of the different approaches to weighting might depend on which variance component estimators are used (i.e., MOM vs. REML).&lt;/p&gt;
&lt;p&gt;Neither implementation that I’ve described above is fully general. Following the generalized estimating equation framework, a fully general implementation would allow the user to specify an arbitrary weight matrix in addition to a working covariance structure. The weighting matrix would be used for purposes of estimating the fixed effects. The working covariance model would be estimated (based on MOM or REML or what-not) and then used for purposes of BRL adjustment. Of course, this fully general formulation may well be more complicated than what most analysts would actually need or use (especially for linear mixed models), except perhaps when dealing with complex survey data.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Another meta-sandwich</title>
      <link>http://localhost:4321/robust-meta-analysis-2/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/robust-meta-analysis-2/</guid>
      <description>


&lt;p&gt;In &lt;a href=&#34;http://localhost:4321/Robust-meta-analysis-1/&#34;&gt;a previous post&lt;/a&gt;, I provided some code to do robust variance estimation with &lt;code&gt;metafor&lt;/code&gt; and &lt;code&gt;sandwich&lt;/code&gt;.
Here’s another example, replicating some more of the calculations from &lt;a href=&#34;http://doi.org/10.1002/jrsm.1091&#34;&gt;Tanner-Smith &amp;amp; Tipton (2013)&lt;/a&gt;.
(&lt;a href=&#34;https://gist.github.com/jepusto/11147304&#34;&gt;See here&lt;/a&gt; for the complete code.)&lt;/p&gt;
&lt;p&gt;As a starting point, here are the results produced by the &lt;code&gt;robumeta&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(robumeta)

data(corrdat)
rho &amp;lt;- 0.8

HTJ &amp;lt;- robu(effectsize ~ males + college + binge,
            data = corrdat, 
            modelweights = &amp;quot;CORR&amp;quot;, rho = rho,
            studynum = studyid,
            var.eff.size = var, small = FALSE)
HTJ&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Correlated Effects Model  
## 
## Model: effectsize ~ males + college + binge 
## 
## Number of studies = 39 
## Number of outcomes = 172 (min = 1 , mean = 4.41 , median = 4 , max = 18 )
## Rho = 0.8 
## I.sq = 75.08352 
## Tau.sq = 0.1557714 
## 
##                Estimate  StdErr t-value dfs P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1 X.Intercept.  0.31936 0.27784   1.149  35   0.258  -0.2447  0.88340    
## 2        males -0.00331 0.00376  -0.882  35   0.384  -0.0109  0.00431    
## 3      college  0.41226 0.18685   2.206  35   0.034   0.0329  0.79159  **
## 4        binge  0.13774 0.12586   1.094  35   0.281  -0.1178  0.39326    
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To exactly re-produce the results with &lt;code&gt;metafor&lt;/code&gt;, I’ll need to use the weights proposed by HTJ. In their approach to the correlated effects case, effect size &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; receives weight equal to &lt;span class=&#34;math inline&#34;&gt;\(\left[\left(v_{\cdot j} + \hat\tau^2\right)(1 + (k_j - 1) \rho)\right]^{-1}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(v_{\cdot j}\)&lt;/span&gt; is the average sampling variance of the effect sizes from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt; is an estimate of the between-study variance, &lt;span class=&#34;math inline&#34;&gt;\(k_j\)&lt;/span&gt; is the number of correlated effects in study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is a user-specified value of the intra-study correlation. However, it appears that &lt;code&gt;robumeta&lt;/code&gt; actually uses a slightly different set weights, which are equivalent to taking &lt;span class=&#34;math inline&#34;&gt;\(\rho = 1\)&lt;/span&gt;. I calculate the latter weights, fit the model in &lt;code&gt;metafor&lt;/code&gt;, and output the robust standard errors and &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-tests:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::source_gist(id = &amp;quot;11144005&amp;quot;, filename = &amp;quot;metafor-sandwich.R&amp;quot;)

corrdat &amp;lt;- within(corrdat, {
  var_mean &amp;lt;- tapply(var, studyid, mean)[studyid]
  k &amp;lt;- table(studyid)[studyid]
  var_HTJ &amp;lt;- as.numeric(k * (var_mean + as.numeric(HTJ$mod_info$tau.sq)))
})

meta1 &amp;lt;- rma.mv(effectsize ~ males + college + binge, 
                V = var_HTJ, 
                data = corrdat, method = &amp;quot;FE&amp;quot;)
meta1$cluster &amp;lt;- corrdat$studyid
RobustResults(meta1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##           Estimate Std. Error t value Pr(&amp;gt;|t|)  
## intrcpt  0.3193586  0.2778360  1.1494  0.25816  
## males   -0.0033143  0.0037573 -0.8821  0.38374  
## college  0.4122631  0.1868489  2.2064  0.03401 *
## binge    0.1377393  0.1258637  1.0944  0.28127  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One could specify a similar (though not exactly identical model) in &lt;code&gt;metafor&lt;/code&gt; as follows. In the HTJ approach, &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; represents the total correlation induced by both the within-study sampling error and intra-study correlation in true effects. In contrast, the &lt;code&gt;metafor&lt;/code&gt; approach would take &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; to be correlation due to within-study sampling error alone. I’ll first need to create a block-diagonal covariance matrix given a user-specified value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Matrix)
equicorr &amp;lt;- function(x, rho) {
  corr &amp;lt;- rho + (1 - rho) * diag(nrow = length(x))
  tcrossprod(x) * corr 
} 
covMat &amp;lt;- as.matrix(bdiag(with(corrdat, tapply(var_mean, studyid, equicorr, rho = 0.8, simplify = FALSE))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Passing this block-diagonal covariance matrix to &lt;code&gt;rma.mv&lt;/code&gt;, I now estimate the model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_{ij} = \mathbf{X}_{ij} \beta + \nu_i + e_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Var(\nu_i) = \sigma^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Var(e_{ij}) = v_{ij}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(Cor(e_{ij}, e_{ik}) = \rho\)&lt;/span&gt;. Note that &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; is now estimated via REML.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta2 &amp;lt;- rma.mv(yi = effectsize ~ males + college + binge, 
                V = covMat, random = ~ 1 | studyid, 
                data = corrdat,
                method = &amp;quot;REML&amp;quot;)
c(sigma.sq = meta2$sigma2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  sigma.sq 
## 0.2477825&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between-study heterogeneity estimate is considerably larger than the moment estimate from &lt;code&gt;robumeta&lt;/code&gt;. Together with the difference in weighting, this leads to some changes in the coefficient estimates and their estimated precision:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults(meta2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##           Estimate Std. Error t value Pr(&amp;gt;|t|)   
## intrcpt -0.8907096  0.4148219 -2.1472 0.038783 * 
## males    0.0163074  0.0055805  2.9222 0.006052 **
## college  0.3180139  0.2273396  1.3988 0.170658   
## binge   -0.0984026  0.0897269 -1.0967 0.280265   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is important to keep in mind that the estimate of between-study heterogeneity depends on the posited model for the covariance structure, including the assumed value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. HTJ recommend conducting sensitivity analysis across a range of values for the within-study effect correlation. Re-calculating the value of &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; between 0.0 and 0.9 yields the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sigma2 &amp;lt;- function(rho) {
  covMat &amp;lt;- as.matrix(bdiag(with(corrdat, tapply(var_mean, studyid, equicorr, rho = rho, simplify = FALSE))))
  rma.mv(yi = effectsize ~ males + college + binge, 
                  V = covMat, random = ~ 1 | studyid, 
                  data = corrdat,
                  method = &amp;quot;REML&amp;quot;)$sigma2
}
rho_sens &amp;lt;- seq(0,0.9,0.1)
sigma2_sens &amp;lt;- sapply(rho_sens, sigma2)
cbind(rho = rho_sens, sigma2 = round(sigma2_sens, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       rho sigma2
##  [1,] 0.0 0.2519
##  [2,] 0.1 0.2513
##  [3,] 0.2 0.2507
##  [4,] 0.3 0.2502
##  [5,] 0.4 0.2497
##  [6,] 0.5 0.2492
##  [7,] 0.6 0.2487
##  [8,] 0.7 0.2482
##  [9,] 0.8 0.2478
## [10,] 0.9 0.2474&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between-study heterogeneity is quite insensitive to the assumed value of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The difference between the results based on &lt;code&gt;metafor&lt;/code&gt; versus on &lt;code&gt;robumeta&lt;/code&gt; appears to be due to the subtle difference in the weighting approach: &lt;code&gt;metafor&lt;/code&gt; uses block-diagonal weights that contain off-diagonal terms for effects drawn from a common study, whereas &lt;code&gt;robumeta&lt;/code&gt; uses entirely diagonal weights.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A meta-sandwich</title>
      <link>http://localhost:4321/robust-meta-analysis-1/</link>
      <pubDate>Mon, 21 Apr 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/robust-meta-analysis-1/</guid>
      <description>


&lt;p&gt;A common problem arising in many areas of meta-analysis is how to synthesize a set of effect sizes when the set includes multiple effect size estimates from the same study. It’s often not possible to obtain all of the information you’d need in order to estimate the sampling covariances between those effect sizes, yet without that information, established approaches to modeling dependent effect sizes become inaccurate. &lt;a href=&#34;http://doi.org/10.1002/jrsm.5&#34;&gt;Hedges, Tipton, &amp;amp; Johnson&lt;/a&gt; (2010, HTJ hereafter) proposed the use of cluster-robust standard errors for multi-variate meta-analysis. (These are also called “sandwich” standard errors, which is up there on the list of great and evocative names for statistical procedures.) The great advantage of the sandwich approach is that it permits valid inferences for average effect sizes and meta-regression coefficients even if you don’t have correct covariance estimates (or variance estimates, for that matter).&lt;/p&gt;
&lt;p&gt;I recently heard from &lt;a href=&#34;http://blogs.cuit.columbia.edu/let2119/&#34;&gt;Beth Tipton&lt;/a&gt; (who’s a graduate-school buddy) that she and her student have written an &lt;a href=&#34;http://cran.r-project.org/web/packages/robumeta/index.html&#34;&gt;R package&lt;/a&gt; implementing the HTJ methods, including moment estimators for the between-study variance components. I want to try out the cluster-robust standard errors for a project I’m working on, but I also need to use REML estimators rather than the moment estimators. It turns out, it’s easy enough to do that by writing a couple of short functions. Here’s how.&lt;/p&gt;
&lt;p&gt;First, the &lt;a href=&#34;http://cran.r-project.org/web/packages/metafor/index.html&#34;&gt;metafor package&lt;/a&gt; contains a very rich suite of meta-analytic methods, including for multi-variate meta-analysis. The only thing it lacks is sandwich standard errors. However, the &lt;a href=&#34;http://cran.r-project.org/web/packages/sandwich/index.html&#34;&gt;sandwich package&lt;/a&gt; provides an efficient, well-structured framework for calculating all sorts of robust standard errors. All that’s needed are a few functions to make the packages talk to each other. Each of the functions described below takes as input a fitted multi-variate meta-analysis model, which is represented in R by an object of class &lt;code&gt;rma.mv&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First load up the packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
library(sandwich)
library(lmtest)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I need a &lt;code&gt;bread&lt;/code&gt; method for objects of class &lt;code&gt;rma.mv&lt;/code&gt;, which is a function that returns the &lt;span class=&#34;math inline&#34;&gt;\(p \times p\)&lt;/span&gt; matrix &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle{m \left(\sum_{i=1}^m \mathbf{X}_j&amp;#39; \mathbf{W}_j \mathbf{X}_j\right)^{-1}}\)&lt;/span&gt;. The bread function is straight-forward because it is just a multiple of the model-based covariance matrix, which &lt;code&gt;rma.mv&lt;/code&gt; objects store in the &lt;code&gt;vb&lt;/code&gt; component:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bread.rma.mv &amp;lt;- function(obj) {
  cluster &amp;lt;- findCluster(obj)
  length(unique(cluster)) * obj$vb  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also need an &lt;code&gt;estfun&lt;/code&gt; method for objects of class &lt;code&gt;rma.mv&lt;/code&gt;, which is a function that returns an &lt;span class=&#34;math inline&#34;&gt;\(m \times p\)&lt;/span&gt; matrix where row &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is equal to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{e}_j&amp;#39; \mathbf{W}_j \mathbf{X}_j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,m\)&lt;/span&gt;. The necessary pieces for the &lt;code&gt;estfun&lt;/code&gt; method can also be pulled out of the components of &lt;code&gt;rma.mv&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;estfun.rma.mv &amp;lt;- function(obj) {
  cluster &amp;lt;- droplevels(as.factor(findCluster(obj)))
  res &amp;lt;- residuals(obj)
  WX &amp;lt;- chol2inv(chol(obj$M)) %*% obj$X
  rval &amp;lt;- by(cbind(res, WX), cluster, 
             function(x) colSums(x[,1] * x[,-1, drop = FALSE]))
  rval &amp;lt;- matrix(unlist(rval), length(unique(cluster)), obj$p, byrow=TRUE)
  colnames(rval) &amp;lt;- colnames(obj$X)
  rval
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The remaining question is how to determine which of the components in the model should be used to define independent clusters. This is a little bit tricky because there are several different methods of specifying random effects in the &lt;code&gt;rma.mv&lt;/code&gt; function. One way involves providing a list of formulas, each containing a factor associated with a unique random effect, such as &lt;code&gt;random = list( ~ 1 | classroom, ~ 1 | school)&lt;/code&gt;. If this method of specifying random effects is used, the &lt;code&gt;rma.mv&lt;/code&gt; object will have the component &lt;code&gt;withS&lt;/code&gt; set to &lt;code&gt;TRUE&lt;/code&gt;, and my approach is to simply take the factor with the smallest number of unique levels. This is perhaps a little bit presumptious, because the &lt;code&gt;withS&lt;/code&gt; method could potentially be used to specify arbitrary random effects, where one level is not strictly nested inside another. However, probably the most common use will involve nested factors, so my assumption seems like a good starting point at least.&lt;/p&gt;
&lt;p&gt;Another approach to specifying random effects is to use a formula of the form &lt;code&gt;random = inner | outer&lt;/code&gt;, in which case the &lt;code&gt;rma.mv&lt;/code&gt; object will have the component &lt;code&gt;withG&lt;/code&gt; set to &lt;code&gt;TRUE&lt;/code&gt;. Here, it seems reasonable to use the &lt;code&gt;outer&lt;/code&gt; factor for defining clusters. If both the &lt;code&gt;withS&lt;/code&gt; and &lt;code&gt;withG&lt;/code&gt; methods are used together, I’ll assume that the &lt;code&gt;withS&lt;/code&gt; factors contain the outermost level.&lt;/p&gt;
&lt;p&gt;Finally, if &lt;code&gt;rma.mv&lt;/code&gt; is used to estimate a fixed effects model without any random components, the clustering factor will have to be manually added to the &lt;code&gt;rma.mv&lt;/code&gt; object in a component called &lt;code&gt;cluster&lt;/code&gt;. For example, if you want to cluster on the variable &lt;code&gt;studyID&lt;/code&gt; in the dataframe &lt;code&gt;dat&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rma_fit$cluster &amp;lt;- dat$studyID&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s code that implements these assumptions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;findCluster &amp;lt;- function(obj) {
  if (is.null(obj$cluster)) {
    if (obj$withS) {
      r &amp;lt;- which.min(obj$s.nlevels)
      cluster &amp;lt;- obj$mf.r[[r]][[obj$s.names[r]]]
    } else if (obj$withG) {
      cluster &amp;lt;- obj$mf.r[[1]][[obj$g.names[2]]]
    } else {
        stop(&amp;quot;No clustering variable specified.&amp;quot;)
    }
  } else {
    cluster &amp;lt;- obj$cluster
  }
  cluster
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these three functions, you can then use &lt;code&gt;metafor&lt;/code&gt; to fit a random effects model, &lt;code&gt;sandwich&lt;/code&gt; to calculate the standard errors, and functions like &lt;code&gt;coeftest&lt;/code&gt; from the package &lt;code&gt;lmtest&lt;/code&gt; to run &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-tests. As a little bonus, here’s a function for probably the most common case of how you’d use the sandwich standard errors:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults &amp;lt;- function(obj, adjust = TRUE) {
  cluster &amp;lt;- findCluster(obj)  
  vcov. &amp;lt;- sandwich(obj, adjust = adjust)
  df. &amp;lt;- length(unique(cluster)) - obj$p
  coeftest(obj, vcov. = vcov., df = df.)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://gist.github.com/jepusto/11144005&#34;&gt;See here&lt;/a&gt; for a file containing the full code.&lt;/p&gt;
&lt;div id=&#34;example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://doi.org/10.1002/jrsm.1091&#34;&gt;Tanner-Smith &amp;amp; Tipton (2013)&lt;/a&gt; provide an application of the cluster-robust method to a fictional dataset with 68 effect sizes nested within 15 studies. They call this a “hierarchical” dependence example because each effect size estimate is drawn from an independent sample, but dependence is induced because the experiments were all done in the same lab. For comparison purposes, here are the results produced by &lt;code&gt;robumeta&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(robumeta)
data(hierdat)

HTJ &amp;lt;- robu(effectsize ~ 1,
       data = hierdat, modelweights = &amp;quot;HIER&amp;quot;,
       studynum = studyid,
       var.eff.size = var, small = FALSE)
HTJ&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RVE: Hierarchical Effects Model  
## 
## Model: effectsize ~ 1 
## 
## Number of clusters = 15 
## Number of outcomes = 68 (min = 1 , mean = 4.53 , median = 2 , max = 29 )
## Omega.sq = 0.1560802 
## Tau.sq = 0.06835547 
## 
##                Estimate StdErr t-value dfs  P(|t|&amp;gt;) 95% CI.L 95% CI.U Sig
## 1 X.Intercept.     0.25 0.0598    4.18  14 0.000925    0.122    0.378 ***
## ---
## Signif. codes: &amp;lt; .01 *** &amp;lt; .05 ** &amp;lt; .10 *
## ---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To exactly re-produce the results with &lt;code&gt;metafor&lt;/code&gt;, I’ll need to use the weights proposed by HTJ. In their approach, effect size &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; receives weight equal to &lt;span class=&#34;math inline&#34;&gt;\(\left(v_{ij} + \hat\omega^2 + \hat\tau^2\right)^{-1}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(v_{ij}\)&lt;/span&gt; is the sampling variance of the effect size, &lt;span class=&#34;math inline&#34;&gt;\(\hat\omega^2\)&lt;/span&gt; is an estimate of the between-sample within-study variance, and &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2\)&lt;/span&gt; is an estimate of the between-study variance. After calculating these weights, I fit the model in metafor, calculate the sandwich covariance matrix, and replay the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hierdat$var_HTJ &amp;lt;- hierdat$var + HTJ$mod_info$omega.sq + HTJ$mod_info$tau.sq # calculate weights&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in hierdat$var + HTJ$mod_info$omega.sq: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in hierdat$var + HTJ$mod_info$omega.sq + HTJ$mod_info$tau.sq: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta1 &amp;lt;- rma.mv(yi = effectsize ~ 1, V = var_HTJ, data = hierdat, method = &amp;quot;FE&amp;quot;)
meta1$cluster &amp;lt;- hierdat$studyid # add clustering variable to the fitted model
RobustResults(meta1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##         Estimate Std. Error t value  Pr(&amp;gt;|t|)    
## intrcpt 0.249826   0.059762  4.1803 0.0009253 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The HTJ weights are not the only alternative–one could instead use weights that are exactly inverse variance under the posited model. For effect &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, these weights would be closer to &lt;span class=&#34;math inline&#34;&gt;\(\left(v_{ij} + \hat\omega^2 + k_j \hat\tau^2 \right)^{-1}\)&lt;/span&gt;. For &lt;span class=&#34;math inline&#34;&gt;\(\hat\tau^2 &amp;gt; 0\)&lt;/span&gt;, the inverse-variance weights put proportionately less weight on studies containing many effects. These weights can be calculated in &lt;code&gt;metafor&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta2 &amp;lt;- rma.mv(yi = effectsize ~ 1, V = var, 
                 random = list(~ 1 | esid, ~ 1 | studyid), 
                 sigma2 = c(HTJ$mod_info$omega.sq, HTJ$mod_info$tau.sq),
                 data = hierdat)
RobustResults(meta2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##         Estimate Std. Error t value Pr(&amp;gt;|t|)   
## intrcpt 0.264422   0.086688  3.0503 0.008645 **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Curiously, the robust standard error increases under a weighting scheme that is more efficient if the model is correct.&lt;/p&gt;
&lt;p&gt;Finally, &lt;code&gt;metafor&lt;/code&gt; provides ML and REML estimators for the between-sample and between-study random effects (the HTJ moment estimators are not available though). Here are the results based on REML estimators and the corresponding inverse-variance weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meta3 &amp;lt;- rma.mv(yi = effectsize ~ 1, V = var, 
                 random = list(~ 1 | esid, ~ 1 | studyid), 
                 data = hierdat,
                method = &amp;quot;REML&amp;quot;)
meta3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Multivariate Meta-Analysis Model (k = 68; method: REML)
## 
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed   factor 
## sigma^2.1  0.2263  0.4757     68     no     esid 
## sigma^2.2  0.0000  0.0000     15     no  studyid 
## 
## Test for Heterogeneity:
## Q(df = 67) = 370.1948, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.2501  0.0661  3.7822  0.0002  0.1205  0.3797  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RobustResults(meta3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##         Estimate Std. Error t value  Pr(&amp;gt;|t|)    
## intrcpt 0.250071   0.059796  4.1821 0.0009222 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between-study variance estimate is tiny, particularly when compared to the between-sample within-study estimate. Despite the difference in variance estimates, the average effect size estimate is nearly identical to the estimate based on the HTJ approach.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gist.github.com/jepusto/11143798&#34;&gt;See here&lt;/a&gt; for the full code to reproduce this example.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;notes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;p&gt;It would be straight-forward to add a few more functions that provide robust standard errors for univariate meta-analysis models as well. All that it would take is to write &lt;code&gt;bread&lt;/code&gt; and &lt;code&gt;estfun&lt;/code&gt; methods for the class &lt;code&gt;rma.uni&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Also, Beth &lt;a href=&#34;https://www.sree.org/conferences/2014s/program/downloads/abstracts/1089.pdf&#34;&gt;has recently proposed&lt;/a&gt;
small-sample corrections to the cluster-robust estimators, based on the bias-reduced linearization (BRL) approach of &lt;a href=&#34;http://www.amstat.org/sections/SRMS/Proceedings/y2001/Proceed/00264.pdf&#34;&gt;McCaffrey, Bell, &amp;amp; Botts (2001)&lt;/a&gt;. It seems to me that these small-sample corrections could also be implemented using an approach similar to what I’ve done here, by building out the &lt;code&gt;estfun&lt;/code&gt; method to provide BRL results. It would take a little more thought, but actually it would be worth doing–and treating the general case–because BRL seems like it would be useful for all sorts of models besides multi-variate meta-analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Special Education Pro-Sem</title>
      <link>http://localhost:4321/sped-pro-sem/</link>
      <pubDate>Thu, 10 Apr 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/sped-pro-sem/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://www.edb.utexas.edu/education/departments/sped/about/fac_dir/barnes/&#34;&gt;Dr. Marcia Barnes&lt;/a&gt; from the department of Special Education invited me to visit her pro-seminar this afternoon and talk about some of my work on meta-analytic methods for single-case research. Thanks very much to the students for asking such thoughtful and engaging questions. &lt;a href=&#34;http://localhost:4321/files/Barnes-Pro-Sem-2014-04-10.pdf&#34;&gt;Here are the slides&lt;/a&gt;, which include some additional material that we didn’t get to talk about.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Update: parallel R on the TACC</title>
      <link>http://localhost:4321/parallel-r-on-tacc-update/</link>
      <pubDate>Tue, 08 Apr 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/parallel-r-on-tacc-update/</guid>
      <description>


&lt;p&gt;I have learned from &lt;a href=&#34;https://www.tacc.utexas.edu/staff/yaakoub-el-khamra&#34;&gt;Mr. Yaakoub El Khamra&lt;/a&gt; that he and the good folks at TACC have made some modifications to TACC’s custom MPI implementation and R build in order to correct bugs in Rmpi and snow that were causing crashes. &lt;a href=&#34;http://localhost:4321/parallel-R-on-TACC&#34;&gt;My earlier post&lt;/a&gt; has been updated to reflect the modifications. The main changes are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The version of MVAPICH2 has changed to 2.0b&lt;/li&gt;
&lt;li&gt;Changes to the Rmpi and snow packages necessitate using the latest version of R (Warm Puppy, 3.0.3). This version is available in the &lt;code&gt;Rstats&lt;/code&gt; module.&lt;/li&gt;
&lt;li&gt;For improved reproducibility, I modified the R code so that the simulation driver function uses a seed value.&lt;/li&gt;
&lt;li&gt;I had to switch from &lt;code&gt;maply&lt;/code&gt; to &lt;code&gt;mdply&lt;/code&gt; as a result of (3).&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Four methods of analyzing partial interval recording data, with application to single-case research</title>
      <link>http://localhost:4321/talk/aera-2014-four-methods-for-pir/</link>
      <pubDate>Fri, 04 Apr 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2014-four-methods-for-pir/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Analysis and meta-analysis of single-case designs with a standardized mean difference statistic: A primer and applications</title>
      <link>http://localhost:4321/publication/bc-smd-primer-and-applications/</link>
      <pubDate>Tue, 01 Apr 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/bc-smd-primer-and-applications/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Addressing construct invalidity in partial interval recording data</title>
      <link>http://localhost:4321/talk/tuesap-2014-construct-invalidity-of-pir/</link>
      <pubDate>Fri, 21 Mar 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/tuesap-2014-construct-invalidity-of-pir/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On internal validity in multiple baseline designs</title>
      <link>http://localhost:4321/talk/sree-2014-internal-validity-of-mbd/</link>
      <pubDate>Thu, 06 Mar 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sree-2014-internal-validity-of-mbd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Converting from d to r to z when the design uses extreme groups, dichotomization, or experimental control</title>
      <link>http://localhost:4321/publication/converting-from-d-to-r-to-z/</link>
      <pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/converting-from-d-to-r-to-z/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New article: Measurement-comparable effect sizes for single-case studies of free-operant behavior</title>
      <link>http://localhost:4321/measurement-comparable-effect-sizes/</link>
      <pubDate>Tue, 04 Feb 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/measurement-comparable-effect-sizes/</guid>
      <description>


&lt;p&gt;My article “Measurement-comparable effect sizes for single-case studies of free-operant behavior” has been accepted at &lt;em&gt;Psychological Methods&lt;/em&gt;. &lt;a href=&#34;http://localhost:4321/files/Measurement-comparable-ES.pdf&#34;&gt;Postprint&lt;/a&gt; and &lt;a href=&#34;http://localhost:4321/files/Measuerment-comparable-ES-Appendix.pdf&#34;&gt;supporting materials&lt;/a&gt; are available. Here’s the abstract:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Single-case research comprises a set of designs and methods for evaluating the effects of interventions, practices, or programs on individual cases, through comparison of outcomes measured at different points in time. Although there has long been interest in meta-analytic technique for synthesizing single-case research, there has been little scrutiny of whether proposed effect sizes remain on a directly comparable metric when outcomes are measured using different operational procedures. Much of single-case research focuses on behavioral outcomes in free-operant contexts, which may be measured using a variety of different direct observation procedures. This article describes a suite of effect sizes for quantifying changes in free-operant behavior, motivated by an alternating renewal process model that allows measurement comparability to be established in precise terms. These effect size metrics have the advantage of comporting with how direct observation data are actually collected and summarized. Effect size estimators are proposed that are applicable when the behavior being measured remains stable within a given treatment condition. The methods are illustrated by two examples, including a re-analysis of a systematic review of the effects of choice-making opportunities on problem behavior.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Running R in parallel on the TACC</title>
      <link>http://localhost:4321/parallel-r-on-tacc/</link>
      <pubDate>Fri, 20 Dec 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/parallel-r-on-tacc/</guid>
      <description>


&lt;p&gt;UPDATE (4/8/2014): I have learned from &lt;a href=&#34;https://www.tacc.utexas.edu/staff/yaakoub-el-khamra&#34;&gt;Mr. Yaakoub El Khamra&lt;/a&gt; that he and the good folks at TACC have made some modifications to TACC’s custom MPI implementation and R build in order to correct bugs in Rmpi and snow that were causing crashes. This post &lt;a href=&#34;http://localhost:4321/parallel-R-on-TACC-update&#34;&gt;has been updated&lt;/a&gt; to reflect the modifications.&lt;/p&gt;
&lt;p&gt;I’ve started to use the Texas Advanced Computing Cluster to run statistical simulations in R. It takes a little bit of time to get up and running, but once you do it is an amazing tool. To get started, you’ll need&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;An account on the &lt;a href=&#34;https://www.tacc.utexas.edu/&#34;&gt;TACC&lt;/a&gt; and an allocation of computing time.&lt;/li&gt;
&lt;li&gt;An ssh client like &lt;a href=&#34;http://www.chiark.greenend.org.uk/~sgtatham/putty/&#34;&gt;PUTTY&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Some R code that can be adapted to run in parallel.&lt;/li&gt;
&lt;li&gt;A SLURM script that tells the server (called Stampede) how to run the R.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;the-r-script&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The R script&lt;/h3&gt;
&lt;p&gt;I’ve been running my simulations using a combination of several packages that provide very high-level functionality for parallel computing, namely &lt;code&gt;foreach&lt;/code&gt;, &lt;code&gt;doSNOW&lt;/code&gt;, and the &lt;code&gt;maply&lt;/code&gt; function in &lt;code&gt;plyr&lt;/code&gt;. All of this runs on top of an &lt;code&gt;Rmpi&lt;/code&gt; implementation developed by the folks at TACC (&lt;a href=&#34;https://portal.tacc.utexas.edu/documents/13601/901835/Parallel_R_Final.pdf/&#34;&gt;more details here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;http://localhost:4321/Designing-simulation-studies-using-R/&#34;&gt;an earlier post&lt;/a&gt;, I shared code for running a very simple simulation of the Behrens-Fisher problem. Here’s &lt;a href=&#34;https://gist.github.com/jepusto/8059893&#34;&gt;adapted code&lt;/a&gt; for running the same simulation on Stampede. The main difference is that there are a few extra lines of code to set up a cluster, seed a random number generator, and pass necessary objects (saved in &lt;code&gt;source_func&lt;/code&gt;) to the nodes of the cluster:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Rmpi)
library(snow)
library(foreach)
library(iterators)
library(doSNOW)
library(plyr)

# set up parallel processing
cluster &amp;lt;- getMPIcluster()
registerDoSNOW(cluster)

# export source functions
clusterExport(cluster, source_func)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once it is all set up, running the code is just a matter of turning on the parallel option in &lt;code&gt;mdply&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BFresults &amp;lt;- mdply(parms, .fun = run_sim, .drop=FALSE, .parallel=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I fully admit that my method of passing source functions is rather kludgy. One alternative would be to save all of the source functions in a separate file (say, &lt;code&gt;source_functions.R&lt;/code&gt;), then &lt;code&gt;source&lt;/code&gt; the file at the beginning of the simulation script:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
source(&amp;quot;source_functions.R&amp;quot;)
print(source_func &amp;lt;- ls())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another, more elegant alternative would be to put all of your source functions in a little package (say, &lt;code&gt;BehrensFisher&lt;/code&gt;), install the package, and then pass the package in the &lt;code&gt;maply&lt;/code&gt; call:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BFresults &amp;lt;- mdply(parms, .fun = run_sim, .drop=FALSE, .parallel=TRUE, .paropts = list(.packages=&amp;quot;BehrensFisher&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, developing a package involves a bit more work on the front end.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-slurm-script&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The SLURM script&lt;/h3&gt;
&lt;p&gt;Suppose that you’ve got your R code saved in a file called &lt;code&gt;Behrens_Fisher.R&lt;/code&gt;. Here’s an example of a SLURM script that runs the R script after configuring an Rmpi cluster:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;#!/bin/bash
#SBATCH -J Behrens          # Job name
#SBATCH -o Behrens.o%j      # Name of stdout output file (%j expands to jobId)
#SBATCH -e Behrens.o%j      # Name of stderr output file(%j expands to jobId)
#SBATCH -n 32               # Total number of mpi tasks requested
#SBATCH -p normal           # Submit to the &amp;#39;normal&amp;#39; or &amp;#39;development&amp;#39; queue
#SBATCH -t 0:20:00          # Run time (hh:mm:ss)
#SBATCH -A A-yourproject    # Allocation name to charge job against
#SBATCH --mail-user=you@email.address # specify email address for notifications
#SBATCH --mail-type=begin   # email when job begins
#SBATCH --mail-type=end     # email when job ends

# load R module
module load Rstats           

# call R code from RMPISNOW
ibrun RMPISNOW &amp;lt; Behrens_Fisher.R &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The file should be saved in a plain text file called something like &lt;code&gt;run_BF.slurm&lt;/code&gt;. The file has to use ANSI encoding and Unix-type end-of-line encoding; &lt;a href=&#34;http://notepad-plus-plus.org/&#34;&gt;Notepad++&lt;/a&gt; is a text editor that can create files in this format.&lt;/p&gt;
&lt;p&gt;Note that for full efficiency, the &lt;code&gt;-n&lt;/code&gt; option should be a multiple of 16 because their are 16 cores per compute node. Further details about SBATCH options can be found &lt;a href=&#34;https://portal.tacc.utexas.edu/user-guides/stampede#running-slurm-jobcontrol&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;running-on-stampede&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Running on Stampede&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://portal.tacc.utexas.edu/user-guides/stampede#access&#34;&gt;Follow these directions&lt;/a&gt; to log in to the Stampede server. Here’s the &lt;a href=&#34;https://portal.tacc.utexas.edu/user-guides/stampede&#34;&gt;User Guide&lt;/a&gt; for Stampede. The first thing you’ll need to do is ensure that you’ve got the proper version of MVAPICH loaded. To do that, type&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;module swap intel intel/14.0.1.106
module setdefault&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second line sets this as the default, so you won’t need to do this step again.&lt;/p&gt;
&lt;p&gt;Second, you’ll need to install whatever R packages you’ll need to run your code. To do that, type the following at the &lt;code&gt;login4$&lt;/code&gt; prompt:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;login4$module load Rstats
login4$R&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will start an interactive R session. From the R prompt, use &lt;code&gt;install.packages&lt;/code&gt; to download and install, e.g.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;plyr&amp;quot;,&amp;quot;reshape&amp;quot;,&amp;quot;doSNOW&amp;quot;,&amp;quot;foreach&amp;quot;,&amp;quot;iterators&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The packages will be installed in a local library. Now type &lt;code&gt;q()&lt;/code&gt; to quit R.&lt;/p&gt;
&lt;p&gt;Next, make a new directory for your project:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;login4$mkdir project_name
login4$cd project_name&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Upload your files to the directory (using &lt;a href=&#34;http://the.earth.li/~sgtatham/putty/0.63/htmldoc/Chapter6.html&#34;&gt;psftp&lt;/a&gt;, for instance). Check that your R script is properly configured by viewing it in Vim.&lt;/p&gt;
&lt;p&gt;Finally, submit your job by typing&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;login4$sbatch run_BF.slurm&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or whatever your SLURM script is called. To check the status of the submitted job, type &lt;code&gt;showq -u&lt;/code&gt; followed by your TACC user name (more details &lt;a href=&#34;https://portal.tacc.utexas.edu/user-guides/stampede#running-slurm-jobcontrol-squeue&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further thoughts&lt;/h3&gt;
&lt;p&gt;TACC accounts come with a limited number of computing hours, so you should be careful to write efficient code. Before you even start worrying about running on TACC, you should profile your code and try to find ways to speed up the computations. (Some simple improvements in my Behrens-Fisher code would make it run MUCH faster.) Once you’ve done what you can in terms of efficiency, you should do some small test runs on Stampede. For example, you could try running only a few iterations for each combination of factors, and/or running only some of the combinations rather than the full factorial design. Based on the run-time for these jobs, you’ll then be able to estimate how long the full code would take. If it’s acceptable (and within your allocation), then go ahead and &lt;code&gt;sbatch&lt;/code&gt; the full job. If it’s not, you might reconsider the number of factor levels in your design or the number of iterations you need. I might have more comments about those some other time.&lt;/p&gt;
&lt;p&gt;Comments? Suggestions? Corrections? Drop a comment.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Designing simulation studies using R</title>
      <link>http://localhost:4321/designing-simulation-studies-using-r/</link>
      <pubDate>Fri, 06 Dec 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/designing-simulation-studies-using-r/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;http://localhost:4321/files/Designing-simulation-studies-using-R.pdf&#34;&gt;Here are the slides&lt;/a&gt; from my presentation at this afternoon’s Quant. Methods brown bag. I gave a very quick introduction to using R for conducting simulation studies. I hope it was enough to get people intrigued about the possibilities of using R in their own work.&lt;/p&gt;
&lt;p&gt;The second half of the presentation sketched out a quick-and-dirty simulation of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Behrens%E2%80%93Fisher_problem&#34;&gt;Behrens-Fisher problem&lt;/a&gt;, or more specifically the coverage rates of 95% confidence intervals using Welch’s degrees of freedom approximation, given independent samples with unequal variances. Here is &lt;a href=&#34;https://gist.github.com/jepusto/7686463&#34;&gt;the complete code&lt;/a&gt;. As I mentioned in the talk, there’s lots of room for improvement. The main point that I was trying to illustrate is that simulations have five distinct pieces:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;a data generating model,&lt;/li&gt;
&lt;li&gt;an estimation procedure,&lt;/li&gt;
&lt;li&gt;performance criteria,&lt;/li&gt;
&lt;li&gt;an experimental design (parameter values and sample dimensions), and&lt;/li&gt;
&lt;li&gt;analysis and results.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It is useful to write simulation code that reflects the structure, so that it is easy for you (or other people) to read, revise, extend, or re-run it. And then post it on your blog.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>To what extent does partial interval recording over-estimate prevalence?</title>
      <link>http://localhost:4321/pir-overestimates-prevalence/</link>
      <pubDate>Sat, 26 Oct 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/pir-overestimates-prevalence/</guid>
      <description>


&lt;p&gt;It is well known that the partial interval recording procedure produces an over-estimate of the prevalence of a behavior. Here I will demonstrate how to use the ARPobservation package to study the extent of this bias. First though, I’ll need to define the terms prevalence and incidence and also take a detour through continuous duration recording.&lt;/p&gt;
&lt;div id=&#34;prevalence-and-incidence&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prevalence and incidence&lt;/h2&gt;
&lt;p&gt;First off, what do I mean by prevalence? In an alternating renewal process, &lt;strong&gt;prevalence&lt;/strong&gt; is the long-run proportion of time that the behavior occurs. I’ll call prevalence &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; (“phi”). So far, I’ve described alternating renewal processes in terms of their average event duration (which I’ll call &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; or “mu”) and the average interim time (which I’ll call &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; or “lambda”). Prevalence is related to these quantities mathematically as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \phi = \frac{\mu}{\mu + \lambda}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So given &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, we can figure out &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Another characteristic of behavior that can be determined by the average event duration and average interim time is &lt;strong&gt;incidence&lt;/strong&gt;, or the rate of event occurrence per unit of time. I’ll call incidence &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt; (“zeta”). In an alternating renewal process,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \zeta = \frac{1}{\mu + \lambda}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This makes intuitive sense, because &lt;span class=&#34;math inline&#34;&gt;\(\mu + \lambda\)&lt;/span&gt; is the average time in between the start of each event, so its inverse should be the average number of times that an event starts per unit of time. (Note that though this is quite intuitive, it’s also very difficult to prove mathematically.) Given &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, we can figure out &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt;. Conversely, if we know &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt;, we can solve for &lt;span class=&#34;math inline&#34;&gt;\(\mu = \phi / \zeta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda = (1 - \phi) / \zeta\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;continuous-duration-recording&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Continuous duration recording&lt;/h2&gt;
&lt;p&gt;It can be shown mathematically that, on average, data produced by continuous duration recording (CDR) will be equal to the prevalence of the behavior. In statistical parlance, CDR data produces an &lt;em&gt;unbiased&lt;/em&gt; estimate of prevalence. Since this is a mathematical fact, it’s a good idea to check that the software gives the same result (if it doesn’t, there must be something wrong with the code).&lt;/p&gt;
&lt;p&gt;In order to simulate behavior streams, the software needs values for the average event duration and average interim time. But I want to think in terms of prevalence and incidence, so I’ll first pick a value for incidence. Say that a new behavioral event starts once per minute on average, so incidence (in events per second) would be &lt;span class=&#34;math inline&#34;&gt;\(\zeta = 1 / 60\)&lt;/span&gt;. I’ll then vary prevalence across the range from zero to one. For each value of prevalence, I’ll generate 10 behavior streams (if you’d like to do more, go ahead!).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ARPobservation)
set.seed(8)
zeta &amp;lt;- 1 / 60
phi &amp;lt;- rep(seq(0.01, 0.99, 0.01), each = 10)

# Now solve for mu and lambda
mu &amp;lt;- phi / zeta
lambda &amp;lt;- (1 - phi) / zeta

iterations &amp;lt;- length(phi) # total number of behavior streams to generate&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Two last elements are needed before I can get to the simulating: I need to decide what distributions to use for event durations and interim times, and I need to decide how long the observation session should last. To keep things simple, for the time being I’ll use exponential distributions. I’ll also suppose that we observe for 10 min = 600 s, so that on average we should observe 10 events per session. Now I can simulate a bunch of behavior streams and apply the CDR procedure to them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BS &amp;lt;- r_behavior_stream(n = iterations, mu = mu, lambda = lambda, F_event = F_exp(), F_interim = F_exp(), stream_length = 600)
CDR &amp;lt;- continuous_duration_recording(BS)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check that the CDR procedure is unbiased, I’ll plot the CDR data versus the true value of prevalence, and run a smoothing line through the cloud of data-points:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
qplot(x = phi, y = CDR, geom = &amp;quot;point&amp;quot;) + geom_smooth(method = &amp;quot;loess&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PIR-overestimates-prevalence_files/figure-html/CDR_bias-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The blue line is nearly identical to the line &lt;code&gt;y = x&lt;/code&gt;, meaning that the average of CDR data is equal to prevalence. Good news–the software appears to be working correctly!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;partial-interval-recording&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Partial interval recording&lt;/h2&gt;
&lt;p&gt;Now to partial interval recording (PIR). There are two different ways to think about how PIR data over-estimates prevalence. The conventional statistical approach follows the same logic as above, comparing the average value of PIR data to the true value of prevalence, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;. Using the same simulated data streams as above, with 15 s intervals and 5 s of rest time after each interval…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PIR &amp;lt;- interval_recording(BS, interval_length = 20, rest_length = 5)

qplot(x = phi, y = PIR, geom = &amp;quot;point&amp;quot;, ylim = c(-0.02,1.02)) + 
  geom_smooth(method = &amp;quot;loess&amp;quot;, se = FALSE) + 
  geom_abline(intercept = 0, slope = 1, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PIR-overestimates-prevalence_files/figure-html/PIR_bias-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The blue line indicates the average value of PIR data across the simulations for a given value of prevalence. The dashed line indicates &lt;code&gt;y = x&lt;/code&gt;, so clearly PIR data over-estimates prevalence.&lt;/p&gt;
&lt;p&gt;Previous studies in the Applied Behavior Analysis literature have taken a slightly different approach to thinking about over-estimation. Rather than comparing PIR data to the prevalence parameter &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, PIR data is instead compared to the &lt;em&gt;sample&lt;/em&gt; value of prevalence, which is equivalent to the CDR proportion. Following this logic, I apply the PIR and CDR procedures to the same simulated behavior streams, then plot PIR versus CDR.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obs_data &amp;lt;- reported_observations(BS, data_types = c(&amp;quot;C&amp;quot;,&amp;quot;P&amp;quot;), interval_length = 20, rest_length = 5)

qplot(x = CDR, y = PIR, data = obs_data, geom = &amp;quot;point&amp;quot;, ylim = c(-0.02,1.02)) + 
  geom_smooth(method = &amp;quot;loess&amp;quot;, se = FALSE) + 
  geom_abline(intercept = 0, slope = 1, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PIR-overestimates-prevalence_files/figure-html/PIR_CDR-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The blue fitted line is slightly different than with the other approach, but the general conclusion is the same: PIR data over-estimates prevalence.&lt;/p&gt;
&lt;p&gt;But by how much? That’s actually a tricky question to answer, because the extent of the bias depends on a bunch of factors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the true prevalence &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;,&lt;/li&gt;
&lt;li&gt;the true incidence &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt;,&lt;/li&gt;
&lt;li&gt;the length of the intervals, and&lt;/li&gt;
&lt;li&gt;the distribution of interim times &lt;code&gt;F_lambda&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Curiously enough, the bias doesn’t depend on the distribution of event durations &lt;code&gt;F_mu&lt;/code&gt;.)&lt;/p&gt;
&lt;div id=&#34;interval-length&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Interval length&lt;/h4&gt;
&lt;p&gt;To see that the bias depends on the length of intervals used, I’ll compare 15 s intervals with 5 s rest times versus 25 s intervals with 5 s rest times. For a session of length 600 s, the latter procedure will yield 20 intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PIR_25 &amp;lt;- interval_recording(BS, interval_length = 30, rest_length = 5)
obs_data &amp;lt;- cbind(obs_data, PIR_25)
qplot(x = CDR, y = PIR, data = obs_data, geom = &amp;quot;smooth&amp;quot;, method = &amp;quot;loess&amp;quot;, ylim = c(-0.02,1.02)) + 
  geom_smooth(aes(y = PIR_25), method = &amp;quot;loess&amp;quot;, se = FALSE, col = &amp;quot;red&amp;quot;) + 
  geom_abline(intercept = 0, slope = 1, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;
## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PIR-overestimates-prevalence_files/figure-html/PIR_length-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The red line indicates that the longer interval time leads to a larger degree of over-estimation. (For clarity, I’ve removed the points in the scatter-plot.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interim-time-distribution&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Interim time distribution&lt;/h4&gt;
&lt;p&gt;It isn’t terribly troubling that the bias of PIR data depends on the interval length, because the observer will generally know (and will hopefully report in any write-up of their experiment) the interval length that was used. Much more troubling is the fact that the bias depends on the &lt;em&gt;distribution&lt;/em&gt; of interim times, because this is something that the observer or analyst won’t usually have much information about. To see how this bias works, I’ll compare behavior streams generated using an exponential distribution for the interim times with thos generated using a gamma distribution with shape parameter 3 (this distribution is much less dispersed than the exponential).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BS_exp &amp;lt;- r_behavior_stream(n = iterations, mu = mu, lambda = lambda, F_event = F_exp(), F_interim = F_exp(), stream_length = 600)
obs_exp &amp;lt;- reported_observations(BS_exp, data_types = c(&amp;quot;C&amp;quot;,&amp;quot;P&amp;quot;), interval_length = 20, rest_length = 5)
obs_exp$F_lambda &amp;lt;- &amp;quot;Exponential&amp;quot;

BS_gam &amp;lt;- r_behavior_stream(n = iterations, mu = mu, lambda = lambda, F_event = F_exp(), F_interim = F_gam(shape = 3), stream_length = 600)
obs_gam &amp;lt;- reported_observations(BS_gam, data_types = c(&amp;quot;C&amp;quot;,&amp;quot;P&amp;quot;), interval_length = 20, rest_length = 5)
obs_gam$F_lambda &amp;lt;- &amp;quot;Gamma(3)&amp;quot;

obs_data &amp;lt;- rbind(obs_exp, obs_gam)
qplot(x = C, y = P, color = F_lambda, 
      data = obs_data, geom = &amp;quot;smooth&amp;quot;, method = &amp;quot;loess&amp;quot;, se = FALSE, ylim = c(-0.02, 1.02))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/PIR-overestimates-prevalence_files/figure-html/PIR_interim_dist-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The gamma(3) interim time distribution leads to a slightly larger positive bias.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ARPobservation: Basic use</title>
      <link>http://localhost:4321/arpobservation-basic-use/</link>
      <pubDate>Fri, 25 Oct 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/arpobservation-basic-use/</guid>
      <description>


&lt;p&gt;The ARPobservation package provides a set of tools for simulating data generated by different procedures for direct observation of behavior. This is accomplished in two steps. The first step is to simulate a “behavior stream” itself, which is assumed to follow some type of alternating renewal process. The second step is to apply a procedure or “filter,” which turns the simulated behavior stream into the data recorded by a given observation procedure. Each of these steps is illustrated below.&lt;/p&gt;
&lt;div id=&#34;simulating-behavior-streams&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulating behavior streams&lt;/h2&gt;
&lt;p&gt;Behavior streams are simulated according to an equilibrium alternating renewal process, which involves the following assumptions.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Each instance of a behavior, termed an &lt;em&gt;event&lt;/em&gt;, lasts a random amount of time, drawn from a specified distribution &lt;code&gt;F_mu&lt;/code&gt; with mean &lt;code&gt;mu&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The length of time in between instances of behavior, termed the &lt;em&gt;interim time&lt;/em&gt;, also lasts a random amount of time, drawn from a specified distribution &lt;code&gt;F_lambda&lt;/code&gt; with mean &lt;code&gt;lambda&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All events and interim times are mutually independent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The entire process is in equilibrium.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The function &lt;code&gt;r_behavior_stream&lt;/code&gt; generates random behavior streams. As an initial example, suppose that both the events and the interim times are exponentially distributed, that events last on average 10 seconds, and that the average interim time is 30 seconds. Also suppose that the behavior stream is observed for 300 seconds. The following code will simulate a behavior stream with these parameters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ARPobservation)
set.seed(8)              # for reproducibility

r_behavior_stream(n = 1, mu = 10, lambda = 30, F_event = F_exp(), F_interim = F_exp(), stream_length = 300)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $stream_length
## [1] 300
## 
## $b_streams
## $b_streams[[1]]
## $b_streams[[1]]$start_state
## [1] 0
## 
## $b_streams[[1]]$b_stream
##  [1]  61.46643  67.45959 117.53097 120.56840 175.94950 185.74134 265.04376
##  [8] 269.42231 276.13827 284.70467 286.36179 290.82906
## 
## 
## 
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;behavior_stream&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function returns an object of class &lt;code&gt;behavior_stream&lt;/code&gt;, which isn’t terribly nice to look at. The first characteristic of the object is &lt;code&gt;stream_length&lt;/code&gt;, which just reports back how long the behavior stream is. The second characteristic is &lt;code&gt;b_streams&lt;/code&gt;, a list containing one or more simulated behavior streams. Each behavior stream is also a list. The first element indicate the initial state of the stream, so &lt;code&gt;start_state =&lt;/code&gt;0 means that the behavior was not occuring when observation began. The second element is a vector of transition times. The first entry in the vector indicates that the first event began at time 61.47; the following entry indicates that the first event ended (and the next interim time began) at time 67.46. Similarly, the second event began at time 117.53 and ended at time 120.57.&lt;/p&gt;
&lt;p&gt;The argument &lt;code&gt;n&lt;/code&gt; controls the number of simulated behavior streams returned:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_behavior_stream(n = 3, mu = 10, lambda = 30, F_event = F_exp(), F_interim = F_exp(), stream_length = 300)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $stream_length
## [1] 300
## 
## $b_streams
## $b_streams[[1]]
## $b_streams[[1]]$start_state
## [1] 1
## 
## $b_streams[[1]]$b_stream
##  [1]   8.480116  34.311542  43.069956  49.912461  50.087867  85.046893
##  [7] 103.030351 116.377965 117.101992 140.227289 161.762642 180.640609
## [13] 196.060432 201.493182 212.232970 236.486373 238.432946 276.824019
## 
## 
## $b_streams[[2]]
## $b_streams[[2]]$start_state
## [1] 0
## 
## $b_streams[[2]]$b_stream
##  [1]   6.702804  23.820354  26.087981  33.461543  62.786605  74.705604
##  [7] 163.806646 164.761520 271.270557 283.207882 286.136103 297.587748
## 
## 
## $b_streams[[3]]
## $b_streams[[3]]$start_state
## [1] 0
## 
## $b_streams[[3]]$b_stream
##  [1] 196.4605 203.7452 237.9514 245.2451 246.2089 254.6313 256.6439 258.5644
##  [9] 262.1140 265.3249 283.9702 298.7830
## 
## 
## 
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;behavior_stream&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that now &lt;code&gt;b_streams&lt;/code&gt; is a list with three entries, each of which contains a &lt;code&gt;start_state&lt;/code&gt; and a &lt;code&gt;b_stream&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Most of the time, you won’t need to look at the simulated behavior streams directly. Instead, you’ll just simulate a bunch of streams and store them for later analysis. Let’s store 10 simulated behavior streams in an object called &lt;code&gt;BS10&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BS10 &amp;lt;- r_behavior_stream(n = 10, mu = 10, lambda = 30, F_event = F_exp(), F_interim = F_exp(), stream_length = 300)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;applying-observation-procedures&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Applying observation procedures&lt;/h2&gt;
&lt;p&gt;Several different functions are available to turn the &lt;code&gt;behavior_stream&lt;/code&gt; object into familiar types of behavioral observation data. For example, the &lt;strong&gt;continuous recording procedure&lt;/strong&gt; (CDR) involves summarizing the behavior stream by the overall proportion of observation time during which events occur. This can be accomplished by feeding &lt;code&gt;BS&lt;/code&gt; into the function &lt;code&gt;continuous_duration_recording&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;continuous_duration_recording(BS10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.1680877 0.4426930 0.1290537 0.3506492 0.2372437 0.3568621 0.2897521
##  [8] 0.2570101 0.1704727 0.2968024&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function returns a vector containing one number per simulated behavior stream. As expected all of the numbers are proportions between 0 and 1.&lt;/p&gt;
&lt;p&gt;More interesting is to simulate many more behavior streams, apply CDR, and calculate the mean and variance of the results or plot them in a histogram:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BS_lots &amp;lt;- r_behavior_stream(n = 10000, mu = 10, lambda = 30, F_event = F_exp(), F_interim = F_exp(), stream_length = 300)
CDR &amp;lt;- continuous_duration_recording(BS_lots)
c(mean = mean(CDR), var = var(CDR))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        mean         var 
## 0.250140703 0.009567949&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(CDR)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/ARPobservation-basic-use_files/figure-html/CDR_hist-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another well-known recording procedure is &lt;strong&gt;partial interval recording&lt;/strong&gt; (PIR), which involves dividing the observation session into short intervals, then scoring each interval according to whether or not the behavior occurs at any point during the interval. The function &lt;code&gt;interval_recording&lt;/code&gt; applies partial interval recording (or the closely related procedure of whole interval recording) to a set of simulated behavior streams. Suppose that the observer uses 20 s intervals, back-to-back for 300 s, for a total of 15 intervals. This procedure can be applied to the simulated behavior streams using&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interval_recording(BS10, interval_length = 20, summarize = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
##  [1,]    1    0    1    0    1    1    0    0    0     1
##  [2,]    0    0    0    0    1    1    1    1    1     1
##  [3,]    1    1    1    1    1    1    1    1    1     1
##  [4,]    0    1    1    0    1    1    0    0    1     1
##  [5,]    0    1    0    1    0    1    1    0    1     0
##  [6,]    0    1    0    1    0    1    1    1    0     0
##  [7,]    0    1    0    1    0    1    1    1    0     0
##  [8,]    1    1    0    0    1    1    1    1    0     0
##  [9,]    0    1    0    1    0    1    0    1    0     0
## [10,]    0    0    1    1    0    1    1    1    1     0
## [11,]    1    0    0    1    0    1    1    1    0     1
## [12,]    1    1    1    1    0    1    1    1    1     1
## [13,]    1    1    0    1    0    1    1    1    0     1
## [14,]    1    1    1    1    1    1    1    0    1     0
## [15,]    1    1    1    1    1    1    0    1    0     1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since summarize is set to false, the function returns a 15 by 10 matrix, with one column for each behavior stream. Each column contains one entry for each interval, equal to one if any behavior occured during that interval (and zero otherwise). Typically, PIR data is summarized by calculating the proportion of intervals across the entire observation session. The summary proportion can be calculated automatically by setting the option &lt;code&gt;summarize = TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interval_recording(BS10, interval_length = 20, summarize = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.5333333 0.7333333 0.4666667 0.7333333 0.4666667 1.0000000 0.7333333
##  [8] 0.7333333 0.4666667 0.5333333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colMeans(interval_recording(BS10, interval_length = 20, summarize = FALSE)) # compare to summarized results&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.5333333 0.7333333 0.4666667 0.7333333 0.4666667 1.0000000 0.7333333
##  [8] 0.7333333 0.4666667 0.5333333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sometimes, the PIR procedure is used with a short amount of time in between each interval, which allows the observer to record data or notes. Typical use might involve 15 s intervals of active observation, each followed by 5 s of rest time. This procedure can be applied using the &lt;code&gt;rest_proportion&lt;/code&gt; option. Since 5 s is 25% of the full interval length, the rest proportion is 0.25.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interval_recording(BS10, interval_length = 20, rest_length = 5, summarize = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.4000000 0.7333333 0.4000000 0.6000000 0.4666667 0.8666667 0.5333333
##  [8] 0.6666667 0.4000000 0.5333333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;whole interval recording&lt;/strong&gt; procedure is implemented using &lt;code&gt;interval_recording&lt;/code&gt; with &lt;code&gt;partial = FALSE&lt;/code&gt;. Two other observation procedures are also available: &lt;strong&gt;momentary time recording&lt;/strong&gt; (a.k.a. momentary time sampling), using the function &lt;code&gt;momentary_time_recording&lt;/code&gt;, and &lt;strong&gt;event counting&lt;/strong&gt;, using &lt;code&gt;event_counting&lt;/code&gt;. See the documentation for these functions for usage and examples.&lt;/p&gt;
&lt;p&gt;Finally, a convenience function is available to apply multiple observation procedures to the same set of simulated behavior streams. Suppose that you want to compare the data generated by CDR with the data generated by PIR with 15 s active intervals and 5 s rest times. This can be accomplished using&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reported_observations(BS10, data_types = c(&amp;quot;C&amp;quot;, &amp;quot;P&amp;quot;), interval_length = 20, rest_length = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            C         P
## 1  0.1680877 0.4000000
## 2  0.4426930 0.7333333
## 3  0.1290537 0.4000000
## 4  0.3506492 0.6000000
## 5  0.2372437 0.4666667
## 6  0.3568621 0.8666667
## 7  0.2897521 0.5333333
## 8  0.2570101 0.6666667
## 9  0.1704727 0.4000000
## 10 0.2968024 0.5333333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function returns a data frame with one column for each procedure and one row for each simulated behavior stream. Say that you also want to include data based on momentary time recording, with 20 s in between each moment. Just add an &lt;code&gt;&#34;M&#34;&lt;/code&gt; to the list of data types to include:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reported_observations(BS10, data_types = c(&amp;quot;C&amp;quot;, &amp;quot;M&amp;quot;, &amp;quot;P&amp;quot;), interval_length = 20, rest_length = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            C          M         P
## 1  0.1680877 0.20000000 0.4000000
## 2  0.4426930 0.46666667 0.7333333
## 3  0.1290537 0.06666667 0.4000000
## 4  0.3506492 0.40000000 0.6000000
## 5  0.2372437 0.26666667 0.4666667
## 6  0.3568621 0.40000000 0.8666667
## 7  0.2897521 0.26666667 0.5333333
## 8  0.2570101 0.20000000 0.6666667
## 9  0.1704727 0.06666667 0.4000000
## 10 0.2968024 0.20000000 0.5333333&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Getting started with ARPobservation</title>
      <link>http://localhost:4321/getting-started-with-arpobservation/</link>
      <pubDate>Thu, 24 Oct 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/getting-started-with-arpobservation/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;UPDATED 5/29/2014 after posting the package to CRAN&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here are step-by-step instructions on how to download and install ARPobservation. For the time being, ARPobservation is available as a pre-compiled binary for Windows. For Mac/Linux, you’ll have to download the source from Github.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://cran.us.r-project.org/&#34;&gt;Download&lt;/a&gt; and install R. R is free, open-source software that is used by many data analysts and statisticians. ARPobservation is a contributed package that runs within R, so you’ll need to get the base software first.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;(Optional but recommended) &lt;a href=&#34;http://www.rstudio.com/&#34;&gt;Download&lt;/a&gt; and install RStudio, which is a very nice front-end interface to R.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open R or RStudio and type the following sequence of commands in the console:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;ARPobservation&amp;quot;)
library(ARPobservation)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll only need to do the above once. Once you’ve got the package installed, type the following in order to access the package within an R session: &lt;code&gt;library(ARPobservation)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To open the package documentation, type &lt;code&gt;package?ARPobservation&lt;/code&gt;. To access the documentation for an individual function in this package, just type &lt;code&gt;?&lt;/code&gt; followed by the name of the function. For instance, one of the main functions in the package is called &lt;code&gt;r_behavior_stream&lt;/code&gt;; to access its documentation, type &lt;code&gt;?r_behavior_stream&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reliability of UnGraphed single-case data: An example using the Shogren dataset</title>
      <link>http://localhost:4321/shogren-reliability-analysis/</link>
      <pubDate>Wed, 23 Oct 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/shogren-reliability-analysis/</guid>
      <description>


&lt;p&gt;In one example from my dissertation, I re-analyzed a systematic review by Shogren and colleagues, titled “The effect of choice-making as an intervention for problem behavior” (Shogren, et al., 2004). In order to do the analysis, I retrieved all of the original articles identified by the review, scanned in all of the graphs depicting the data, and used (actually, had an undergraduate use) a computer program called &lt;a href=&#34;http://www.biosoft.com/w/ungraph.htm&#34;&gt;UnGraph&lt;/a&gt; to capture the data-points off of the graphs (see Shadish, et al., 2009 for details on this procedure).&lt;/p&gt;
&lt;p&gt;As it turned out, &lt;a href=&#34;http://www.kuleuven.be/wieiswie/en/person/00006844&#34;&gt;Wim Van Den Noortgate&lt;/a&gt; and &lt;a href=&#34;http://www.kuleuven.be/wieiswie/en/person/00015697&#34;&gt;Patrick Onghena&lt;/a&gt; followed a similar procedure in analyzing the same systematic review (reported in Van Den Noorgate &amp;amp; Onghena, 2008). Wim and Patrick were kind enough to share their data so that I could calculate the reliability of this data extraction procedure, based on the two independent replications. After some initial data-munging, I arrived at a &lt;a href=&#34;%7B%7Bsite.url%7D%7D/data/Shogren_data_merged.csv&#34;&gt;clean, merged dataset&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Shogren &amp;lt;- read.csv(&amp;quot;http://jepusto.com/data/Shogren_data_merged.csv&amp;quot;)
head(Shogren)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Study Case Setting  Measure time choice Phase A B lowIntAxis
## 1 Bambara   Al Dessert Protests    1      0     A 5 5          1
## 2 Bambara   Al Dessert Protests    2      0     A 7 7          1
## 3 Bambara   Al Dessert Protests    3      0     A 4 4          1
## 4 Bambara   Al Dessert Protests    4      1     B 1 1          1
## 5 Bambara   Al Dessert Protests    5      1     B 0 0          1
## 6 Bambara   Al Dessert Protests    6      1     B 1 1          1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variables are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Study - First author of original study included in the meta-analysis;&lt;/li&gt;
&lt;li&gt;Case - Name of individual case;&lt;/li&gt;
&lt;li&gt;Setting - some of the studies used multiple baselines on single individuals across multiple settings;&lt;/li&gt;
&lt;li&gt;Measure - some of the studies used multiple outcome measures on each case;&lt;/li&gt;
&lt;li&gt;time - sequential measurement occasion;&lt;/li&gt;
&lt;li&gt;choice - indicator equal to one if the treatment condition allowed for choice;&lt;/li&gt;
&lt;li&gt;Phase - Factor indicating sequential phases (some of the designs were treatment reversals, such as ABA or ABAB or ABABAB);&lt;/li&gt;
&lt;li&gt;A - Wim’s outcome measurement;&lt;/li&gt;
&lt;li&gt;B - my outcome measurement;&lt;/li&gt;
&lt;li&gt;lowIntAxis - an idicator equal to one if the vertical axis of the graph was labeled with integers, and the axis maximum was &amp;lt;= 20.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The final variable distinguishes graphs that are particularly easy to capture. Wim/Patrick and I used slightly different exclusion criteria, so there are a total of 30 cases across 12 studies included in the merged dataset. To begin, here’s a plot of A versus B by study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
qplot(A, B, geom = &amp;quot;point&amp;quot;, color = Case, data = Shogren) + facet_wrap( ~ Study, scales = &amp;quot;free&amp;quot;) + theme(legend.position=&amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Shogren-reliability-analysis_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly the two measurements are very correlated. You’ll notice that the studies (and sometimes cases within studies) used several different outcome measurement scales, so the overall correlation between A and B (r = 0.999767) isn’t really the best approach. Furthermore, some of the variation in the outcomes is presumably due to differences between phases, and it would be better to calculate a reliability based on the residual variation within phases.&lt;/p&gt;
&lt;p&gt;I accomplish this with a simple hierarchical model, fit separately to the data from each case. Denote the outcome as &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk}\)&lt;/span&gt; for phase &lt;span class=&#34;math inline&#34;&gt;\(i = 1,...,P\)&lt;/span&gt;, measurement occasion &lt;span class=&#34;math inline&#34;&gt;\(j = 1,...,n_i\)&lt;/span&gt;, and replicate &lt;span class=&#34;math inline&#34;&gt;\(k = 1,2\)&lt;/span&gt;. I model these outcomes as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijk} = \beta_i + \epsilon_{ij} + \nu_{ijk}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s fixed, &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij} \sim (0, \tau^2)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\nu_{ijk} \sim (0, \sigma^2)\)&lt;/span&gt;. Reliability is then captured by the intra-class correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho = \tau^2 / (\tau^2 + \sigma^2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;I calculate the reliabilities from each case using restricted maximum likelihood, then apply Fisher’s Z-transform:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reshape)
library(plyr)

Shogren_long &amp;lt;- melt(Shogren, measure.vars = c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;), variable_name = &amp;quot;observer&amp;quot;)

Fisher_Z &amp;lt;- function(x) 0.5 * (log(1 + x) - log(1 - x))

library(nlme)
Z_ICC &amp;lt;- function(x, formula = value ~ Phase){
  fit &amp;lt;- lme(formula, random = ~ 1 | time, data = x)
  tau.sq.ratio &amp;lt;- as.double(coef(fit$modelStruct$reStruct, FALSE))
  rho &amp;lt;- tau.sq.ratio / (tau.sq.ratio + 1)
  Z &amp;lt;- Fisher_Z(rho)
  df &amp;lt;- dim(x)[1] / 2 - length(fit$coefficients$fixed)
  return(c(rho = rho, Z = Z, df = df))
}
ICC &amp;lt;- ddply(Shogren_long, .(Study, Case, Setting, Measure, lowIntAxis), Z_ICC)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It turns out that 5 of 6 cases with lowIntAxis==1 are perfectly correlated. The remainder of my analysis focuses on the cases with lowIntAxis==0. Here’s a histogram of the Z-transformed correlations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(subset(ICC, lowIntAxis==0), hist(Z))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:4321/post/Shogren-reliability-analysis_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With only 2 replicates per measurement occasion, the large-sample variance of the intra-class correlation is equivalent to that of the usual Pearson correlation (see Hedges, Hedberg, &amp;amp; Kuyper, 2013), except that I use &lt;span class=&#34;math inline&#34;&gt;\(N - P\)&lt;/span&gt; in the denominator to account for the fact that separate means are estimated for each of the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; phases: &lt;span class=&#34;math display&#34;&gt;\[Var(\hat\rho) \approx \frac{(1 - \rho^2)^2}{N - P},\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(N = \sum_i n_i\)&lt;/span&gt;. Applying Fisher’s Z transform stabilizes the variance, so that it is appropriate to use inverse variance weights of simply &lt;span class=&#34;math inline&#34;&gt;\(N - P\)&lt;/span&gt;. Turning to a random-effects meta-analysis:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(metafor)
summary(rma_Z &amp;lt;- rma(yi = Z, vi = 1 / df, data = ICC, subset = lowIntAxis==0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Random-Effects Model (k = 27; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc 
## -26.1156   52.2313   56.2313   58.7475   56.7530   
## 
## tau^2 (estimated amount of total heterogeneity): 0.3778 (SE = 0.1198)
## tau (square root of estimated tau^2 value):      0.6146
## I^2 (total heterogeneity / total variability):   88.15%
## H^2 (total variability / sampling variability):  8.44
## 
## Test for Heterogeneity:
## Q(df = 26) = 211.1324, p-val &amp;lt; .0001
## 
## Model Results:
## 
## estimate      se     zval    pval   ci.lb   ci.ub 
##   3.2596  0.1265  25.7670  &amp;lt;.0001  3.0117  3.5075  *** 
## 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The average effect size corresponds to a reliability of 0.9970546 (95% CI: [0.9951684,0.9982051]). The reliabilities are heterogeneous, but because they are all at the extreme of the scale, the heterogeneity has little practical implication: approximating the population of reliabilities by a normal distribution, and based on the RML estimates, 84 percent of reliabilities will be greater than 0.9900. Though one could certainly imagine factors that might explain the variation in reliabilities–the resolution of the image file from which the data were captured, the size of the points used to graph each measurement, the number of outcomes represented on the same graph–it hardly seems worth exploring further because all of the reliabilities are so high. These results are very similar to those reported by Shadish, et al. (2009), who found a median reliability of 0.9993 based on a similar study of 91 single-case graphs.&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Hedges, L. V, Hedberg, E. C., &amp;amp; Kuyper, A. M. (2012). The variance of intraclass correlations in three- and four-level models. Educational and Psychological Measurement. &lt;a href=&#34;doi:10.1177/0013164412445193&#34; class=&#34;uri&#34;&gt;doi:10.1177/0013164412445193&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Shadish, W. R., Brasil, I. C. C., Illingworth, D. A., White, K. D., Galindo, R., Nagler, E. D., &amp;amp; Rindskopf, D. M. (2009). Using UnGraph to extract data from image files: Verification of reliability and validity. Behavior Research Methods, 41(1), 177-83. &lt;a href=&#34;doi:10.3758/BRM.41.1.177&#34; class=&#34;uri&#34;&gt;doi:10.3758/BRM.41.1.177&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Shogren, K. A., Faggella-Luby, M. N., Bae, S. J., &amp;amp; Wehmeyer, M. L. (2004). The effect of choice-making as an intervention for problem behavior. Journal of Positive Behavior Interventions, 6(4), 228-237.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Van den Noortgate, W., &amp;amp; Onghena, P. (2008). A multilevel meta-analysis of single-subject experimental design studies. Evidence-Based Communication Assessment and Intervention, 2(3), 142-151. &lt;a href=&#34;doi:10.1080/17489530802505362&#34; class=&#34;uri&#34;&gt;doi:10.1080/17489530802505362&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Another project idea: Meta-analytic methods for correlational data</title>
      <link>http://localhost:4321/another-project-idea/</link>
      <pubDate>Fri, 13 Sep 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/another-project-idea/</guid>
      <description>


&lt;p&gt;Several different approaches have been proposed for meta-analysis of correlation coefficients. One of the major differences between approaches is the choice of scale: whether effect sizes should be analyzed on the Pearson-r scale or first transformed to the Fisher-z scale. This project will study methods for modeling correlation coefficients on the r scale in the presence of between-study effect heterogeneity. Specific topics include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;refined methods for variance estimation;&lt;/li&gt;
&lt;li&gt;hierarchical modeling to capture differences between distinct operationalizations of the same construct; and&lt;/li&gt;
&lt;li&gt;application to a large correlational meta-analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This project would be appropriate for a Quantitative Methods graduate student with interests in meta-analysis and hierarchical models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A standardized mean difference effect size for multiple baseline designs</title>
      <link>http://localhost:4321/publication/smd-for-mbd/</link>
      <pubDate>Fri, 23 Aug 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/smd-for-mbd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Current projects</title>
      <link>http://localhost:4321/current-projects/</link>
      <pubDate>Tue, 20 Aug 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/current-projects/</guid>
      <description>


&lt;p&gt;Interested in working with me? See below for descriptions of several potential projects. If you have interest and abilities that line up with one of these, feel free to contact me.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Review of methods for direct observation of behavior. Several different methods for recording direct observations of behavior are commonly used in single-case research and other areas of psychology; prominent methods include continuous duration recording, momentary time sampling, and partial interval recording. Textbook advice about appropriate use of different methods is conflicting and often ambiguous, and simulation studies evaluating the operating characteristics of different methods also yield mixed results. The goals of this project are to: find and organize the current guidance about direct observation procedures; understand the basis of that guidance (e.g., simulation studies, heuristic models); and relate the guidance to a unifying statistical framework, by translating claims and conclusions into the terms of a parametric model (known as an alternating renewal process). This project would be appropriate either for a quantitative methods student who is interested in learning about direct observation methods for measuring behavior or for a student from school psychology, counseling psychology, or special education who is familiar with direct observation methods and interested in learning about statistical models for the data they generate.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Applications of meta-analysis for single-case studies of free-operant behavior. I have recently proposed a suite of new effect size metrics for quantifying treatment effects in single-case studies of free-operant behavior. The crux of this line of work is that it is important to use effect size metrics that are comparable across different methods of recording direct observation data. This project will involve: reviewing several published systematic reviews that incorporate evidence from single-case studies, in order to determine what measurement procedures were used to collect data, then re-analyzing the data from one or more of these studies, using the newly proposed effect size metrics and methods. This project would be appropriate for a special education student who is familiar with meta-analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Applications of design-comparable effect size measures for longitudinal studies. Co-authors and I have recently proposed a method of estimating effect sizes from single-case studies (or other types of longitudinal designs) that are in the same metric as Cohen’s d-type effect sizes from conventional between-subjects experiments. The goals of this project are to: develop exemplar code that implements effect size calculations in several major statistical packages (including SPSS, SAS, Stata, and R); review the algorithms available in major statistical packages for estimating the uncertainty of variance components (i.e., information matrices); develop further applications and extensions to the proposed effect sizes. This project would be appropriate for a quantitative methods student who is familiar with estimation of hierarchical linear models in SPSS, SAS, and other major statistical software platforms.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Programming information matrices for hierarchical linear modeling. The Fisher information plays a pivotal role in hierarchical linear models, both as an approximate estimates of parameter uncertainty and as a key component of small-sample hypothesis tests such as those of Kenward and Roger (1997,2009). The goals of this project are to: create an R package for constructing analytic information matrices for HLM models estimated with the well-known nlme package; also add functions for the revised Kenward &amp;amp; Roger hypothesis tests; and evaluate the performance of different information matrices (expected, observed, and average) for calculating degrees-of-freedom adjustments in the context of effect size estimation. This project could be appropriate for a quantitative methods student or a statistics student who has strong programming skills and wants to 1) learn more about the statistical guts of HLM estimation and 2) level-up on their R programming by designing a publishable package.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A discrete-time Markov chain model for partial interval recording data. Partial interval recording is a commonly used method for recording direct observations of human behavior. Data generated by this method is problematic because, as typically analyzed, it yields upwardly biased measures of prevalence (the proportion of time that a behavior occurs). This shortcoming can be addressed by modeling the data using a discrete-time Markov chain and using maximum likelihood methods to estimate parameters corresponding directly to prevalence and incidence (the frequency with which new behaviors occur). The goals of this project are to create an R package implementing maximum likelihood estimation (and possibly other methods) for partial interval recording data and evaluate this estimation approach using asymptotic theory and simulation. This project could be appropriate for an advanced quantitative methods student or statistics student who is interested in learning about Markov chain models and who has strong programming skills.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>A d-statistic for single-case designs that is equivalent to the usual between-groups d-statistics</title>
      <link>http://localhost:4321/publication/between-groups-d-statistic/</link>
      <pubDate>Thu, 18 Jul 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/between-groups-d-statistic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Operationally comparable effect sizes for meta-analysis of single-case research</title>
      <link>http://localhost:4321/publication/operationally-comparable-effect-sizes/</link>
      <pubDate>Sat, 01 Jun 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/operationally-comparable-effect-sizes/</guid>
      <description>&lt;p&gt;This thesis studies quantitative methods for summarizing and synthesizing single-case studies, a class of research designs for evaluating the effects of interventions through repeated measurement of individuals. Despite long-standing interest in meta-analytic synthesis of single-case research, there remains a lack of consensus about appropriate methods, even about the most basic question of what effect size metrics are useful and appropriate. I argue that operational comparability, or invariance to heterogeneous operational procedures, is crucial property for an effect size metric. I then consider two problems with operational comparability that arise in single-case research. The first problem is to find effect sizes that can be applied across studies that use different research designs, such as single-case designs and two-group randomized experiments. The second problem is to find effect sizes that can be applied across studies that use varied operations for measuring the same construct. To address each of these problems, I propose structural models that capture essential features of multiple relevant operations (either design-related operations or measurement-related operations). I then use these structural models to precisely define target effect size parameters and to consider identification issues and estimation strategies.&lt;/p&gt;
&lt;p&gt;Chapter 1 defines operational comparability and situates the concept within the broad methodological concerns of meta-analysis, then reviews relevant features of single-case research and previously proposed effect sizes. Chapter 2 describes an abstract set of modeling criteria for constructing design-comparable effect sizes. Chapters 3 applies the general criteria to the case of standardized mean differences and proposes an effect size estimator based on restricted maximum likelihood. Chapter 4 presents several applications of the proposed models and methods. Chapter 5 proposes measurement-comparability model and defines effect size measures for use in studies of free-operant behavior, one of the most common classes of outcomes in single-case research. Chapter 6 extends the proposed effect size models to incorporate more complex features, including time trends and serial dependence, and studies a method of estimating those models through a combination of marginal quasi-likelihood and Gaussian pseudo-likelihood estimating equations. Chapter 7 collects various further extensions, areas for further research, and concluding thoughts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some Markov models for direct observation of behavior</title>
      <link>http://localhost:4321/talk/nu-stats-2013-markov-models-for-direct-observation/</link>
      <pubDate>Wed, 29 May 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/nu-stats-2013-markov-models-for-direct-observation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect sizes and measurement comparability for meta-analysis of single-case research</title>
      <link>http://localhost:4321/talk/abai-2013-effect-sizes/</link>
      <pubDate>Tue, 28 May 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/abai-2013-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Observation procedures and Markov chain models for estimating the prevalence and incidence of a behavior</title>
      <link>http://localhost:4321/talk/aera-2013-observation-procedures/</link>
      <pubDate>Tue, 30 Apr 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/aera-2013-observation-procedures/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Operationally comparable effect sizes for meta-analysis of single-case research</title>
      <link>http://localhost:4321/talk/sree-2013-operationally-comparable-effect-sizes/</link>
      <pubDate>Thu, 07 Mar 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/sree-2013-operationally-comparable-effect-sizes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Some implications of behavioral observation procedures for meta-analysis of single-case research</title>
      <link>http://localhost:4321/talk/ut-austin-2012-meta-analysis-of-single-case-research/</link>
      <pubDate>Wed, 14 Nov 2012 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/ut-austin-2012-meta-analysis-of-single-case-research/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A standardized mean difference effect size for single case designs</title>
      <link>http://localhost:4321/publication/smd-for-scd/</link>
      <pubDate>Tue, 14 Aug 2012 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/smd-for-scd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Question-order effects in social network name generators</title>
      <link>http://localhost:4321/publication/question-order-effects/</link>
      <pubDate>Thu, 01 Oct 2009 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/publication/question-order-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Question-order effects in social network name generators</title>
      <link>http://localhost:4321/talk/issna-2008-question-order-effects/</link>
      <pubDate>Wed, 23 Jan 2008 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/talk/issna-2008-question-order-effects/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:4321/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/</guid>
      <description>&lt;!DOCTYPE html&gt;

&lt;html&gt;

&lt;head&gt;

&lt;meta charset=&#34;utf-8&#34; /&gt;
&lt;meta name=&#34;generator&#34; content=&#34;pandoc&#34; /&gt;
&lt;meta http-equiv=&#34;X-UA-Compatible&#34; content=&#34;IE=EDGE&#34; /&gt;



&lt;meta name=&#34;date&#34; content=&#34;2023-01-25&#34; /&gt;

&lt;title&gt;Rejection sampler for Efron’s double Poisson distribution&lt;/title&gt;

&lt;script&gt;// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc &lt; 2.8).
document.addEventListener(&#39;DOMContentLoaded&#39;, function(e) {
  var hs = document.querySelectorAll(&#34;div.section[class*=&#39;level&#39;] &gt; :first-child&#34;);
  var i, h, a;
  for (i = 0; i &lt; hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length &gt; 0) h.removeAttribute(a[0].name);
  }
});
&lt;/script&gt;
&lt;script&gt;/*! jQuery v3.6.0 | (c) OpenJS Foundation and other contributors | jquery.org/license */
!function(e,t){&#34;use strict&#34;;&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return t(e)}:t(e)}(&#34;undefined&#34;!=typeof window?window:this,function(C,e){&#34;use strict&#34;;var t=[],r=Object.getPrototypeOf,s=t.slice,g=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},u=t.push,i=t.indexOf,n={},o=n.toString,v=n.hasOwnProperty,a=v.toString,l=a.call(Object),y={},m=function(e){return&#34;function&#34;==typeof e&amp;&amp;&#34;number&#34;!=typeof e.nodeType&amp;&amp;&#34;function&#34;!=typeof e.item},x=function(e){return null!=e&amp;&amp;e===e.window},E=C.document,c={type:!0,src:!0,nonce:!0,noModule:!0};function b(e,t,n){var r,i,o=(n=n||E).createElement(&#34;script&#34;);if(o.text=e,t)for(r in c)(i=t[r]||t.getAttribute&amp;&amp;t.getAttribute(r))&amp;&amp;o.setAttribute(r,i);n.head.appendChild(o).parentNode.removeChild(o)}function w(e){return null==e?e+&#34;&#34;:&#34;object&#34;==typeof e||&#34;function&#34;==typeof e?n[o.call(e)]||&#34;object&#34;:typeof e}var f=&#34;3.6.0&#34;,S=function(e,t){return new S.fn.init(e,t)};function p(e){var t=!!e&amp;&amp;&#34;length&#34;in e&amp;&amp;e.length,n=w(e);return!m(e)&amp;&amp;!x(e)&amp;&amp;(&#34;array&#34;===n||0===t||&#34;number&#34;==typeof t&amp;&amp;0&lt;t&amp;&amp;t-1 in e)}S.fn=S.prototype={jquery:f,constructor:S,length:0,toArray:function(){return s.call(this)},get:function(e){return null==e?s.call(this):e&lt;0?this[e+this.length]:this[e]},pushStack:function(e){var t=S.merge(this.constructor(),e);return t.prevObject=this,t},each:function(e){return S.each(this,e)},map:function(n){return this.pushStack(S.map(this,function(e,t){return n.call(e,t,e)}))},slice:function(){return this.pushStack(s.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},even:function(){return this.pushStack(S.grep(this,function(e,t){return(t+1)%2}))},odd:function(){return this.pushStack(S.grep(this,function(e,t){return t%2}))},eq:function(e){var t=this.length,n=+e+(e&lt;0?t:0);return this.pushStack(0&lt;=n&amp;&amp;n&lt;t?[this[n]]:[])},end:function(){return this.prevObject||this.constructor()},push:u,sort:t.sort,splice:t.splice},S.extend=S.fn.extend=function(){var e,t,n,r,i,o,a=arguments[0]||{},s=1,u=arguments.length,l=!1;for(&#34;boolean&#34;==typeof a&amp;&amp;(l=a,a=arguments[s]||{},s++),&#34;object&#34;==typeof a||m(a)||(a={}),s===u&amp;&amp;(a=this,s--);s&lt;u;s++)if(null!=(e=arguments[s]))for(t in e)r=e[t],&#34;__proto__&#34;!==t&amp;&amp;a!==r&amp;&amp;(l&amp;&amp;r&amp;&amp;(S.isPlainObject(r)||(i=Array.isArray(r)))?(n=a[t],o=i&amp;&amp;!Array.isArray(n)?[]:i||S.isPlainObject(n)?n:{},i=!1,a[t]=S.extend(l,o,r)):void 0!==r&amp;&amp;(a[t]=r));return a},S.extend({expando:&#34;jQuery&#34;+(f+Math.random()).replace(/\D/g,&#34;&#34;),isReady:!0,error:function(e){throw new Error(e)},noop:function(){},isPlainObject:function(e){var t,n;return!(!e||&#34;[object Object]&#34;!==o.call(e))&amp;&amp;(!(t=r(e))||&#34;function&#34;==typeof(n=v.call(t,&#34;constructor&#34;)&amp;&amp;t.constructor)&amp;&amp;a.call(n)===l)},isEmptyObject:function(e){var t;for(t in e)return!1;return!0},globalEval:function(e,t,n){b(e,{nonce:t&amp;&amp;t.nonce},n)},each:function(e,t){var n,r=0;if(p(e)){for(n=e.length;r&lt;n;r++)if(!1===t.call(e[r],r,e[r]))break}else for(r in e)if(!1===t.call(e[r],r,e[r]))break;return e},makeArray:function(e,t){var n=t||[];return null!=e&amp;&amp;(p(Object(e))?S.merge(n,&#34;string&#34;==typeof e?[e]:e):u.call(n,e)),n},inArray:function(e,t,n){return null==t?-1:i.call(t,e,n)},merge:function(e,t){for(var n=+t.length,r=0,i=e.length;r&lt;n;r++)e[i++]=t[r];return e.length=i,e},grep:function(e,t,n){for(var r=[],i=0,o=e.length,a=!n;i&lt;o;i++)!t(e[i],i)!==a&amp;&amp;r.push(e[i]);return r},map:function(e,t,n){var r,i,o=0,a=[];if(p(e))for(r=e.length;o&lt;r;o++)null!=(i=t(e[o],o,n))&amp;&amp;a.push(i);else for(o in e)null!=(i=t(e[o],o,n))&amp;&amp;a.push(i);return g(a)},guid:1,support:y}),&#34;function&#34;==typeof Symbol&amp;&amp;(S.fn[Symbol.iterator]=t[Symbol.iterator]),S.each(&#34;Boolean Number String Function Array Date RegExp Object Error Symbol&#34;.split(&#34; &#34;),function(e,t){n[&#34;[object &#34;+t+&#34;]&#34;]=t.toLowerCase()});var d=function(n){var e,d,b,o,i,h,f,g,w,u,l,T,C,a,E,v,s,c,y,S=&#34;sizzle&#34;+1*new Date,p=n.document,k=0,r=0,m=ue(),x=ue(),A=ue(),N=ue(),j=function(e,t){return e===t&amp;&amp;(l=!0),0},D={}.hasOwnProperty,t=[],q=t.pop,L=t.push,H=t.push,O=t.slice,P=function(e,t){for(var n=0,r=e.length;n&lt;r;n++)if(e[n]===t)return n;return-1},R=&#34;checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped&#34;,M=&#34;[\\x20\\t\\r\\n\\f]&#34;,I=&#34;(?:\\\\[\\da-fA-F]{1,6}&#34;+M+&#34;?|\\\\[^\\r\\n\\f]|[\\w-]|[^\0-\\x7f])+&#34;,W=&#34;\\[&#34;+M+&#34;*(&#34;+I+&#34;)(?:&#34;+M+&#34;*([*^$|!~]?=)&#34;+M+&#34;*(?:&#39;((?:\\\\.|[^\\\\&#39;])*)&#39;|\&#34;((?:\\\\.|[^\\\\\&#34;])*)\&#34;|(&#34;+I+&#34;))|)&#34;+M+&#34;*\\]&#34;,F=&#34;:(&#34;+I+&#34;)(?:\\(((&#39;((?:\\\\.|[^\\\\&#39;])*)&#39;|\&#34;((?:\\\\.|[^\\\\\&#34;])*)\&#34;)|((?:\\\\.|[^\\\\()[\\]]|&#34;+W+&#34;)*)|.*)\\)|)&#34;,B=new RegExp(M+&#34;+&#34;,&#34;g&#34;),$=new RegExp(&#34;^&#34;+M+&#34;+|((?:^|[^\\\\])(?:\\\\.)*)&#34;+M+&#34;+$&#34;,&#34;g&#34;),_=new RegExp(&#34;^&#34;+M+&#34;*,&#34;+M+&#34;*&#34;),z=new RegExp(&#34;^&#34;+M+&#34;*([&gt;+~]|&#34;+M+&#34;)&#34;+M+&#34;*&#34;),U=new RegExp(M+&#34;|&gt;&#34;),X=new RegExp(F),V=new RegExp(&#34;^&#34;+I+&#34;$&#34;),G={ID:new RegExp(&#34;^#(&#34;+I+&#34;)&#34;),CLASS:new RegExp(&#34;^\\.(&#34;+I+&#34;)&#34;),TAG:new RegExp(&#34;^(&#34;+I+&#34;|[*])&#34;),ATTR:new RegExp(&#34;^&#34;+W),PSEUDO:new RegExp(&#34;^&#34;+F),CHILD:new RegExp(&#34;^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(&#34;+M+&#34;*(even|odd|(([+-]|)(\\d*)n|)&#34;+M+&#34;*(?:([+-]|)&#34;+M+&#34;*(\\d+)|))&#34;+M+&#34;*\\)|)&#34;,&#34;i&#34;),bool:new RegExp(&#34;^(?:&#34;+R+&#34;)$&#34;,&#34;i&#34;),needsContext:new RegExp(&#34;^&#34;+M+&#34;*[&gt;+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(&#34;+M+&#34;*((?:-\\d)?\\d*)&#34;+M+&#34;*\\)|)(?=[^-]|$)&#34;,&#34;i&#34;)},Y=/HTML$/i,Q=/^(?:input|select|textarea|button)$/i,J=/^h\d$/i,K=/^[^{]+\{\s*\[native \w/,Z=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,ee=/[+~]/,te=new RegExp(&#34;\\\\[\\da-fA-F]{1,6}&#34;+M+&#34;?|\\\\([^\\r\\n\\f])&#34;,&#34;g&#34;),ne=function(e,t){var n=&#34;0x&#34;+e.slice(1)-65536;return t||(n&lt;0?String.fromCharCode(n+65536):String.fromCharCode(n&gt;&gt;10|55296,1023&amp;n|56320))},re=/([\0-\x1f\x7f]|^-?\d)|^-$|[^\0-\x1f\x7f-\uFFFF\w-]/g,ie=function(e,t){return t?&#34;\0&#34;===e?&#34;\ufffd&#34;:e.slice(0,-1)+&#34;\\&#34;+e.charCodeAt(e.length-1).toString(16)+&#34; &#34;:&#34;\\&#34;+e},oe=function(){T()},ae=be(function(e){return!0===e.disabled&amp;&amp;&#34;fieldset&#34;===e.nodeName.toLowerCase()},{dir:&#34;parentNode&#34;,next:&#34;legend&#34;});try{H.apply(t=O.call(p.childNodes),p.childNodes),t[p.childNodes.length].nodeType}catch(e){H={apply:t.length?function(e,t){L.apply(e,O.call(t))}:function(e,t){var n=e.length,r=0;while(e[n++]=t[r++]);e.length=n-1}}}function se(t,e,n,r){var i,o,a,s,u,l,c,f=e&amp;&amp;e.ownerDocument,p=e?e.nodeType:9;if(n=n||[],&#34;string&#34;!=typeof t||!t||1!==p&amp;&amp;9!==p&amp;&amp;11!==p)return n;if(!r&amp;&amp;(T(e),e=e||C,E)){if(11!==p&amp;&amp;(u=Z.exec(t)))if(i=u[1]){if(9===p){if(!(a=e.getElementById(i)))return n;if(a.id===i)return n.push(a),n}else if(f&amp;&amp;(a=f.getElementById(i))&amp;&amp;y(e,a)&amp;&amp;a.id===i)return n.push(a),n}else{if(u[2])return H.apply(n,e.getElementsByTagName(t)),n;if((i=u[3])&amp;&amp;d.getElementsByClassName&amp;&amp;e.getElementsByClassName)return H.apply(n,e.getElementsByClassName(i)),n}if(d.qsa&amp;&amp;!N[t+&#34; &#34;]&amp;&amp;(!v||!v.test(t))&amp;&amp;(1!==p||&#34;object&#34;!==e.nodeName.toLowerCase())){if(c=t,f=e,1===p&amp;&amp;(U.test(t)||z.test(t))){(f=ee.test(t)&amp;&amp;ye(e.parentNode)||e)===e&amp;&amp;d.scope||((s=e.getAttribute(&#34;id&#34;))?s=s.replace(re,ie):e.setAttribute(&#34;id&#34;,s=S)),o=(l=h(t)).length;while(o--)l[o]=(s?&#34;#&#34;+s:&#34;:scope&#34;)+&#34; &#34;+xe(l[o]);c=l.join(&#34;,&#34;)}try{return H.apply(n,f.querySelectorAll(c)),n}catch(e){N(t,!0)}finally{s===S&amp;&amp;e.removeAttribute(&#34;id&#34;)}}}return g(t.replace($,&#34;$1&#34;),e,n,r)}function ue(){var r=[];return function e(t,n){return r.push(t+&#34; &#34;)&gt;b.cacheLength&amp;&amp;delete e[r.shift()],e[t+&#34; &#34;]=n}}function le(e){return e[S]=!0,e}function ce(e){var t=C.createElement(&#34;fieldset&#34;);try{return!!e(t)}catch(e){return!1}finally{t.parentNode&amp;&amp;t.parentNode.removeChild(t),t=null}}function fe(e,t){var n=e.split(&#34;|&#34;),r=n.length;while(r--)b.attrHandle[n[r]]=t}function pe(e,t){var n=t&amp;&amp;e,r=n&amp;&amp;1===e.nodeType&amp;&amp;1===t.nodeType&amp;&amp;e.sourceIndex-t.sourceIndex;if(r)return r;if(n)while(n=n.nextSibling)if(n===t)return-1;return e?1:-1}function de(t){return function(e){return&#34;input&#34;===e.nodeName.toLowerCase()&amp;&amp;e.type===t}}function he(n){return function(e){var t=e.nodeName.toLowerCase();return(&#34;input&#34;===t||&#34;button&#34;===t)&amp;&amp;e.type===n}}function ge(t){return function(e){return&#34;form&#34;in e?e.parentNode&amp;&amp;!1===e.disabled?&#34;label&#34;in e?&#34;label&#34;in e.parentNode?e.parentNode.disabled===t:e.disabled===t:e.isDisabled===t||e.isDisabled!==!t&amp;&amp;ae(e)===t:e.disabled===t:&#34;label&#34;in e&amp;&amp;e.disabled===t}}function ve(a){return le(function(o){return o=+o,le(function(e,t){var n,r=a([],e.length,o),i=r.length;while(i--)e[n=r[i]]&amp;&amp;(e[n]=!(t[n]=e[n]))})})}function ye(e){return e&amp;&amp;&#34;undefined&#34;!=typeof e.getElementsByTagName&amp;&amp;e}for(e in d=se.support={},i=se.isXML=function(e){var t=e&amp;&amp;e.namespaceURI,n=e&amp;&amp;(e.ownerDocument||e).documentElement;return!Y.test(t||n&amp;&amp;n.nodeName||&#34;HTML&#34;)},T=se.setDocument=function(e){var t,n,r=e?e.ownerDocument||e:p;return r!=C&amp;&amp;9===r.nodeType&amp;&amp;r.documentElement&amp;&amp;(a=(C=r).documentElement,E=!i(C),p!=C&amp;&amp;(n=C.defaultView)&amp;&amp;n.top!==n&amp;&amp;(n.addEventListener?n.addEventListener(&#34;unload&#34;,oe,!1):n.attachEvent&amp;&amp;n.attachEvent(&#34;onunload&#34;,oe)),d.scope=ce(function(e){return a.appendChild(e).appendChild(C.createElement(&#34;div&#34;)),&#34;undefined&#34;!=typeof e.querySelectorAll&amp;&amp;!e.querySelectorAll(&#34;:scope fieldset div&#34;).length}),d.attributes=ce(function(e){return e.className=&#34;i&#34;,!e.getAttribute(&#34;className&#34;)}),d.getElementsByTagName=ce(function(e){return e.appendChild(C.createComment(&#34;&#34;)),!e.getElementsByTagName(&#34;*&#34;).length}),d.getElementsByClassName=K.test(C.getElementsByClassName),d.getById=ce(function(e){return a.appendChild(e).id=S,!C.getElementsByName||!C.getElementsByName(S).length}),d.getById?(b.filter.ID=function(e){var t=e.replace(te,ne);return function(e){return e.getAttribute(&#34;id&#34;)===t}},b.find.ID=function(e,t){if(&#34;undefined&#34;!=typeof t.getElementById&amp;&amp;E){var n=t.getElementById(e);return n?[n]:[]}}):(b.filter.ID=function(e){var n=e.replace(te,ne);return function(e){var t=&#34;undefined&#34;!=typeof e.getAttributeNode&amp;&amp;e.getAttributeNode(&#34;id&#34;);return t&amp;&amp;t.value===n}},b.find.ID=function(e,t){if(&#34;undefined&#34;!=typeof t.getElementById&amp;&amp;E){var n,r,i,o=t.getElementById(e);if(o){if((n=o.getAttributeNode(&#34;id&#34;))&amp;&amp;n.value===e)return[o];i=t.getElementsByName(e),r=0;while(o=i[r++])if((n=o.getAttributeNode(&#34;id&#34;))&amp;&amp;n.value===e)return[o]}return[]}}),b.find.TAG=d.getElementsByTagName?function(e,t){return&#34;undefined&#34;!=typeof t.getElementsByTagName?t.getElementsByTagName(e):d.qsa?t.querySelectorAll(e):void 0}:function(e,t){var n,r=[],i=0,o=t.getElementsByTagName(e);if(&#34;*&#34;===e){while(n=o[i++])1===n.nodeType&amp;&amp;r.push(n);return r}return o},b.find.CLASS=d.getElementsByClassName&amp;&amp;function(e,t){if(&#34;undefined&#34;!=typeof t.getElementsByClassName&amp;&amp;E)return t.getElementsByClassName(e)},s=[],v=[],(d.qsa=K.test(C.querySelectorAll))&amp;&amp;(ce(function(e){var t;a.appendChild(e).innerHTML=&#34;&lt;a id=&#39;&#34;+S+&#34;&#39;&gt;&lt;/a&gt;&lt;select id=&#39;&#34;+S+&#34;-\r\\&#39; msallowcapture=&#39;&#39;&gt;&lt;option selected=&#39;&#39;&gt;&lt;/option&gt;&lt;/select&gt;&#34;,e.querySelectorAll(&#34;[msallowcapture^=&#39;&#39;]&#34;).length&amp;&amp;v.push(&#34;[*^$]=&#34;+M+&#34;*(?:&#39;&#39;|\&#34;\&#34;)&#34;),e.querySelectorAll(&#34;[selected]&#34;).length||v.push(&#34;\\[&#34;+M+&#34;*(?:value|&#34;+R+&#34;)&#34;),e.querySelectorAll(&#34;[id~=&#34;+S+&#34;-]&#34;).length||v.push(&#34;~=&#34;),(t=C.createElement(&#34;input&#34;)).setAttribute(&#34;name&#34;,&#34;&#34;),e.appendChild(t),e.querySelectorAll(&#34;[name=&#39;&#39;]&#34;).length||v.push(&#34;\\[&#34;+M+&#34;*name&#34;+M+&#34;*=&#34;+M+&#34;*(?:&#39;&#39;|\&#34;\&#34;)&#34;),e.querySelectorAll(&#34;:checked&#34;).length||v.push(&#34;:checked&#34;),e.querySelectorAll(&#34;a#&#34;+S+&#34;+*&#34;).length||v.push(&#34;.#.+[+~]&#34;),e.querySelectorAll(&#34;\\\f&#34;),v.push(&#34;[\\r\\n\\f]&#34;)}),ce(function(e){e.innerHTML=&#34;&lt;a href=&#39;&#39; disabled=&#39;disabled&#39;&gt;&lt;/a&gt;&lt;select disabled=&#39;disabled&#39;&gt;&lt;option/&gt;&lt;/select&gt;&#34;;var t=C.createElement(&#34;input&#34;);t.setAttribute(&#34;type&#34;,&#34;hidden&#34;),e.appendChild(t).setAttribute(&#34;name&#34;,&#34;D&#34;),e.querySelectorAll(&#34;[name=d]&#34;).length&amp;&amp;v.push(&#34;name&#34;+M+&#34;*[*^$|!~]?=&#34;),2!==e.querySelectorAll(&#34;:enabled&#34;).length&amp;&amp;v.push(&#34;:enabled&#34;,&#34;:disabled&#34;),a.appendChild(e).disabled=!0,2!==e.querySelectorAll(&#34;:disabled&#34;).length&amp;&amp;v.push(&#34;:enabled&#34;,&#34;:disabled&#34;),e.querySelectorAll(&#34;*,:x&#34;),v.push(&#34;,.*:&#34;)})),(d.matchesSelector=K.test(c=a.matches||a.webkitMatchesSelector||a.mozMatchesSelector||a.oMatchesSelector||a.msMatchesSelector))&amp;&amp;ce(function(e){d.disconnectedMatch=c.call(e,&#34;*&#34;),c.call(e,&#34;[s!=&#39;&#39;]:x&#34;),s.push(&#34;!=&#34;,F)}),v=v.length&amp;&amp;new RegExp(v.join(&#34;|&#34;)),s=s.length&amp;&amp;new RegExp(s.join(&#34;|&#34;)),t=K.test(a.compareDocumentPosition),y=t||K.test(a.contains)?function(e,t){var n=9===e.nodeType?e.documentElement:e,r=t&amp;&amp;t.parentNode;return e===r||!(!r||1!==r.nodeType||!(n.contains?n.contains(r):e.compareDocumentPosition&amp;&amp;16&amp;e.compareDocumentPosition(r)))}:function(e,t){if(t)while(t=t.parentNode)if(t===e)return!0;return!1},j=t?function(e,t){if(e===t)return l=!0,0;var n=!e.compareDocumentPosition-!t.compareDocumentPosition;return n||(1&amp;(n=(e.ownerDocument||e)==(t.ownerDocument||t)?e.compareDocumentPosition(t):1)||!d.sortDetached&amp;&amp;t.compareDocumentPosition(e)===n?e==C||e.ownerDocument==p&amp;&amp;y(p,e)?-1:t==C||t.ownerDocument==p&amp;&amp;y(p,t)?1:u?P(u,e)-P(u,t):0:4&amp;n?-1:1)}:function(e,t){if(e===t)return l=!0,0;var n,r=0,i=e.parentNode,o=t.parentNode,a=[e],s=[t];if(!i||!o)return e==C?-1:t==C?1:i?-1:o?1:u?P(u,e)-P(u,t):0;if(i===o)return pe(e,t);n=e;while(n=n.parentNode)a.unshift(n);n=t;while(n=n.parentNode)s.unshift(n);while(a[r]===s[r])r++;return r?pe(a[r],s[r]):a[r]==p?-1:s[r]==p?1:0}),C},se.matches=function(e,t){return se(e,null,null,t)},se.matchesSelector=function(e,t){if(T(e),d.matchesSelector&amp;&amp;E&amp;&amp;!N[t+&#34; &#34;]&amp;&amp;(!s||!s.test(t))&amp;&amp;(!v||!v.test(t)))try{var n=c.call(e,t);if(n||d.disconnectedMatch||e.document&amp;&amp;11!==e.document.nodeType)return n}catch(e){N(t,!0)}return 0&lt;se(t,C,null,[e]).length},se.contains=function(e,t){return(e.ownerDocument||e)!=C&amp;&amp;T(e),y(e,t)},se.attr=function(e,t){(e.ownerDocument||e)!=C&amp;&amp;T(e);var n=b.attrHandle[t.toLowerCase()],r=n&amp;&amp;D.call(b.attrHandle,t.toLowerCase())?n(e,t,!E):void 0;return void 0!==r?r:d.attributes||!E?e.getAttribute(t):(r=e.getAttributeNode(t))&amp;&amp;r.specified?r.value:null},se.escape=function(e){return(e+&#34;&#34;).replace(re,ie)},se.error=function(e){throw new Error(&#34;Syntax error, unrecognized expression: &#34;+e)},se.uniqueSort=function(e){var t,n=[],r=0,i=0;if(l=!d.detectDuplicates,u=!d.sortStable&amp;&amp;e.slice(0),e.sort(j),l){while(t=e[i++])t===e[i]&amp;&amp;(r=n.push(i));while(r--)e.splice(n[r],1)}return u=null,e},o=se.getText=function(e){var t,n=&#34;&#34;,r=0,i=e.nodeType;if(i){if(1===i||9===i||11===i){if(&#34;string&#34;==typeof e.textContent)return e.textContent;for(e=e.firstChild;e;e=e.nextSibling)n+=o(e)}else if(3===i||4===i)return e.nodeValue}else while(t=e[r++])n+=o(t);return n},(b=se.selectors={cacheLength:50,createPseudo:le,match:G,attrHandle:{},find:{},relative:{&#34;&gt;&#34;:{dir:&#34;parentNode&#34;,first:!0},&#34; &#34;:{dir:&#34;parentNode&#34;},&#34;+&#34;:{dir:&#34;previousSibling&#34;,first:!0},&#34;~&#34;:{dir:&#34;previousSibling&#34;}},preFilter:{ATTR:function(e){return e[1]=e[1].replace(te,ne),e[3]=(e[3]||e[4]||e[5]||&#34;&#34;).replace(te,ne),&#34;~=&#34;===e[2]&amp;&amp;(e[3]=&#34; &#34;+e[3]+&#34; &#34;),e.slice(0,4)},CHILD:function(e){return e[1]=e[1].toLowerCase(),&#34;nth&#34;===e[1].slice(0,3)?(e[3]||se.error(e[0]),e[4]=+(e[4]?e[5]+(e[6]||1):2*(&#34;even&#34;===e[3]||&#34;odd&#34;===e[3])),e[5]=+(e[7]+e[8]||&#34;odd&#34;===e[3])):e[3]&amp;&amp;se.error(e[0]),e},PSEUDO:function(e){var t,n=!e[6]&amp;&amp;e[2];return G.CHILD.test(e[0])?null:(e[3]?e[2]=e[4]||e[5]||&#34;&#34;:n&amp;&amp;X.test(n)&amp;&amp;(t=h(n,!0))&amp;&amp;(t=n.indexOf(&#34;)&#34;,n.length-t)-n.length)&amp;&amp;(e[0]=e[0].slice(0,t),e[2]=n.slice(0,t)),e.slice(0,3))}},filter:{TAG:function(e){var t=e.replace(te,ne).toLowerCase();return&#34;*&#34;===e?function(){return!0}:function(e){return e.nodeName&amp;&amp;e.nodeName.toLowerCase()===t}},CLASS:function(e){var t=m[e+&#34; &#34;];return t||(t=new RegExp(&#34;(^|&#34;+M+&#34;)&#34;+e+&#34;(&#34;+M+&#34;|$)&#34;))&amp;&amp;m(e,function(e){return t.test(&#34;string&#34;==typeof e.className&amp;&amp;e.className||&#34;undefined&#34;!=typeof e.getAttribute&amp;&amp;e.getAttribute(&#34;class&#34;)||&#34;&#34;)})},ATTR:function(n,r,i){return function(e){var t=se.attr(e,n);return null==t?&#34;!=&#34;===r:!r||(t+=&#34;&#34;,&#34;=&#34;===r?t===i:&#34;!=&#34;===r?t!==i:&#34;^=&#34;===r?i&amp;&amp;0===t.indexOf(i):&#34;*=&#34;===r?i&amp;&amp;-1&lt;t.indexOf(i):&#34;$=&#34;===r?i&amp;&amp;t.slice(-i.length)===i:&#34;~=&#34;===r?-1&lt;(&#34; &#34;+t.replace(B,&#34; &#34;)+&#34; &#34;).indexOf(i):&#34;|=&#34;===r&amp;&amp;(t===i||t.slice(0,i.length+1)===i+&#34;-&#34;))}},CHILD:function(h,e,t,g,v){var y=&#34;nth&#34;!==h.slice(0,3),m=&#34;last&#34;!==h.slice(-4),x=&#34;of-type&#34;===e;return 1===g&amp;&amp;0===v?function(e){return!!e.parentNode}:function(e,t,n){var r,i,o,a,s,u,l=y!==m?&#34;nextSibling&#34;:&#34;previousSibling&#34;,c=e.parentNode,f=x&amp;&amp;e.nodeName.toLowerCase(),p=!n&amp;&amp;!x,d=!1;if(c){if(y){while(l){a=e;while(a=a[l])if(x?a.nodeName.toLowerCase()===f:1===a.nodeType)return!1;u=l=&#34;only&#34;===h&amp;&amp;!u&amp;&amp;&#34;nextSibling&#34;}return!0}if(u=[m?c.firstChild:c.lastChild],m&amp;&amp;p){d=(s=(r=(i=(o=(a=c)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===k&amp;&amp;r[1])&amp;&amp;r[2],a=s&amp;&amp;c.childNodes[s];while(a=++s&amp;&amp;a&amp;&amp;a[l]||(d=s=0)||u.pop())if(1===a.nodeType&amp;&amp;++d&amp;&amp;a===e){i[h]=[k,s,d];break}}else if(p&amp;&amp;(d=s=(r=(i=(o=(a=e)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===k&amp;&amp;r[1]),!1===d)while(a=++s&amp;&amp;a&amp;&amp;a[l]||(d=s=0)||u.pop())if((x?a.nodeName.toLowerCase()===f:1===a.nodeType)&amp;&amp;++d&amp;&amp;(p&amp;&amp;((i=(o=a[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]=[k,d]),a===e))break;return(d-=v)===g||d%g==0&amp;&amp;0&lt;=d/g}}},PSEUDO:function(e,o){var t,a=b.pseudos[e]||b.setFilters[e.toLowerCase()]||se.error(&#34;unsupported pseudo: &#34;+e);return a[S]?a(o):1&lt;a.length?(t=[e,e,&#34;&#34;,o],b.setFilters.hasOwnProperty(e.toLowerCase())?le(function(e,t){var n,r=a(e,o),i=r.length;while(i--)e[n=P(e,r[i])]=!(t[n]=r[i])}):function(e){return a(e,0,t)}):a}},pseudos:{not:le(function(e){var r=[],i=[],s=f(e.replace($,&#34;$1&#34;));return s[S]?le(function(e,t,n,r){var i,o=s(e,null,r,[]),a=e.length;while(a--)(i=o[a])&amp;&amp;(e[a]=!(t[a]=i))}):function(e,t,n){return r[0]=e,s(r,null,n,i),r[0]=null,!i.pop()}}),has:le(function(t){return function(e){return 0&lt;se(t,e).length}}),contains:le(function(t){return t=t.replace(te,ne),function(e){return-1&lt;(e.textContent||o(e)).indexOf(t)}}),lang:le(function(n){return V.test(n||&#34;&#34;)||se.error(&#34;unsupported lang: &#34;+n),n=n.replace(te,ne).toLowerCase(),function(e){var t;do{if(t=E?e.lang:e.getAttribute(&#34;xml:lang&#34;)||e.getAttribute(&#34;lang&#34;))return(t=t.toLowerCase())===n||0===t.indexOf(n+&#34;-&#34;)}while((e=e.parentNode)&amp;&amp;1===e.nodeType);return!1}}),target:function(e){var t=n.location&amp;&amp;n.location.hash;return t&amp;&amp;t.slice(1)===e.id},root:function(e){return e===a},focus:function(e){return e===C.activeElement&amp;&amp;(!C.hasFocus||C.hasFocus())&amp;&amp;!!(e.type||e.href||~e.tabIndex)},enabled:ge(!1),disabled:ge(!0),checked:function(e){var t=e.nodeName.toLowerCase();return&#34;input&#34;===t&amp;&amp;!!e.checked||&#34;option&#34;===t&amp;&amp;!!e.selected},selected:function(e){return e.parentNode&amp;&amp;e.parentNode.selectedIndex,!0===e.selected},empty:function(e){for(e=e.firstChild;e;e=e.nextSibling)if(e.nodeType&lt;6)return!1;return!0},parent:function(e){return!b.pseudos.empty(e)},header:function(e){return J.test(e.nodeName)},input:function(e){return Q.test(e.nodeName)},button:function(e){var t=e.nodeName.toLowerCase();return&#34;input&#34;===t&amp;&amp;&#34;button&#34;===e.type||&#34;button&#34;===t},text:function(e){var t;return&#34;input&#34;===e.nodeName.toLowerCase()&amp;&amp;&#34;text&#34;===e.type&amp;&amp;(null==(t=e.getAttribute(&#34;type&#34;))||&#34;text&#34;===t.toLowerCase())},first:ve(function(){return[0]}),last:ve(function(e,t){return[t-1]}),eq:ve(function(e,t,n){return[n&lt;0?n+t:n]}),even:ve(function(e,t){for(var n=0;n&lt;t;n+=2)e.push(n);return e}),odd:ve(function(e,t){for(var n=1;n&lt;t;n+=2)e.push(n);return e}),lt:ve(function(e,t,n){for(var r=n&lt;0?n+t:t&lt;n?t:n;0&lt;=--r;)e.push(r);return e}),gt:ve(function(e,t,n){for(var r=n&lt;0?n+t:n;++r&lt;t;)e.push(r);return e})}}).pseudos.nth=b.pseudos.eq,{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})b.pseudos[e]=de(e);for(e in{submit:!0,reset:!0})b.pseudos[e]=he(e);function me(){}function xe(e){for(var t=0,n=e.length,r=&#34;&#34;;t&lt;n;t++)r+=e[t].value;return r}function be(s,e,t){var u=e.dir,l=e.next,c=l||u,f=t&amp;&amp;&#34;parentNode&#34;===c,p=r++;return e.first?function(e,t,n){while(e=e[u])if(1===e.nodeType||f)return s(e,t,n);return!1}:function(e,t,n){var r,i,o,a=[k,p];if(n){while(e=e[u])if((1===e.nodeType||f)&amp;&amp;s(e,t,n))return!0}else while(e=e[u])if(1===e.nodeType||f)if(i=(o=e[S]||(e[S]={}))[e.uniqueID]||(o[e.uniqueID]={}),l&amp;&amp;l===e.nodeName.toLowerCase())e=e[u]||e;else{if((r=i[c])&amp;&amp;r[0]===k&amp;&amp;r[1]===p)return a[2]=r[2];if((i[c]=a)[2]=s(e,t,n))return!0}return!1}}function we(i){return 1&lt;i.length?function(e,t,n){var r=i.length;while(r--)if(!i[r](e,t,n))return!1;return!0}:i[0]}function Te(e,t,n,r,i){for(var o,a=[],s=0,u=e.length,l=null!=t;s&lt;u;s++)(o=e[s])&amp;&amp;(n&amp;&amp;!n(o,r,i)||(a.push(o),l&amp;&amp;t.push(s)));return a}function Ce(d,h,g,v,y,e){return v&amp;&amp;!v[S]&amp;&amp;(v=Ce(v)),y&amp;&amp;!y[S]&amp;&amp;(y=Ce(y,e)),le(function(e,t,n,r){var i,o,a,s=[],u=[],l=t.length,c=e||function(e,t,n){for(var r=0,i=t.length;r&lt;i;r++)se(e,t[r],n);return n}(h||&#34;*&#34;,n.nodeType?[n]:n,[]),f=!d||!e&amp;&amp;h?c:Te(c,s,d,n,r),p=g?y||(e?d:l||v)?[]:t:f;if(g&amp;&amp;g(f,p,n,r),v){i=Te(p,u),v(i,[],n,r),o=i.length;while(o--)(a=i[o])&amp;&amp;(p[u[o]]=!(f[u[o]]=a))}if(e){if(y||d){if(y){i=[],o=p.length;while(o--)(a=p[o])&amp;&amp;i.push(f[o]=a);y(null,p=[],i,r)}o=p.length;while(o--)(a=p[o])&amp;&amp;-1&lt;(i=y?P(e,a):s[o])&amp;&amp;(e[i]=!(t[i]=a))}}else p=Te(p===t?p.splice(l,p.length):p),y?y(null,t,p,r):H.apply(t,p)})}function Ee(e){for(var i,t,n,r=e.length,o=b.relative[e[0].type],a=o||b.relative[&#34; &#34;],s=o?1:0,u=be(function(e){return e===i},a,!0),l=be(function(e){return-1&lt;P(i,e)},a,!0),c=[function(e,t,n){var r=!o&amp;&amp;(n||t!==w)||((i=t).nodeType?u(e,t,n):l(e,t,n));return i=null,r}];s&lt;r;s++)if(t=b.relative[e[s].type])c=[be(we(c),t)];else{if((t=b.filter[e[s].type].apply(null,e[s].matches))[S]){for(n=++s;n&lt;r;n++)if(b.relative[e[n].type])break;return Ce(1&lt;s&amp;&amp;we(c),1&lt;s&amp;&amp;xe(e.slice(0,s-1).concat({value:&#34; &#34;===e[s-2].type?&#34;*&#34;:&#34;&#34;})).replace($,&#34;$1&#34;),t,s&lt;n&amp;&amp;Ee(e.slice(s,n)),n&lt;r&amp;&amp;Ee(e=e.slice(n)),n&lt;r&amp;&amp;xe(e))}c.push(t)}return we(c)}return me.prototype=b.filters=b.pseudos,b.setFilters=new me,h=se.tokenize=function(e,t){var n,r,i,o,a,s,u,l=x[e+&#34; &#34;];if(l)return t?0:l.slice(0);a=e,s=[],u=b.preFilter;while(a){for(o in n&amp;&amp;!(r=_.exec(a))||(r&amp;&amp;(a=a.slice(r[0].length)||a),s.push(i=[])),n=!1,(r=z.exec(a))&amp;&amp;(n=r.shift(),i.push({value:n,type:r[0].replace($,&#34; &#34;)}),a=a.slice(n.length)),b.filter)!(r=G[o].exec(a))||u[o]&amp;&amp;!(r=u[o](r))||(n=r.shift(),i.push({value:n,type:o,matches:r}),a=a.slice(n.length));if(!n)break}return t?a.length:a?se.error(e):x(e,s).slice(0)},f=se.compile=function(e,t){var n,v,y,m,x,r,i=[],o=[],a=A[e+&#34; &#34;];if(!a){t||(t=h(e)),n=t.length;while(n--)(a=Ee(t[n]))[S]?i.push(a):o.push(a);(a=A(e,(v=o,m=0&lt;(y=i).length,x=0&lt;v.length,r=function(e,t,n,r,i){var o,a,s,u=0,l=&#34;0&#34;,c=e&amp;&amp;[],f=[],p=w,d=e||x&amp;&amp;b.find.TAG(&#34;*&#34;,i),h=k+=null==p?1:Math.random()||.1,g=d.length;for(i&amp;&amp;(w=t==C||t||i);l!==g&amp;&amp;null!=(o=d[l]);l++){if(x&amp;&amp;o){a=0,t||o.ownerDocument==C||(T(o),n=!E);while(s=v[a++])if(s(o,t||C,n)){r.push(o);break}i&amp;&amp;(k=h)}m&amp;&amp;((o=!s&amp;&amp;o)&amp;&amp;u--,e&amp;&amp;c.push(o))}if(u+=l,m&amp;&amp;l!==u){a=0;while(s=y[a++])s(c,f,t,n);if(e){if(0&lt;u)while(l--)c[l]||f[l]||(f[l]=q.call(r));f=Te(f)}H.apply(r,f),i&amp;&amp;!e&amp;&amp;0&lt;f.length&amp;&amp;1&lt;u+y.length&amp;&amp;se.uniqueSort(r)}return i&amp;&amp;(k=h,w=p),c},m?le(r):r))).selector=e}return a},g=se.select=function(e,t,n,r){var i,o,a,s,u,l=&#34;function&#34;==typeof e&amp;&amp;e,c=!r&amp;&amp;h(e=l.selector||e);if(n=n||[],1===c.length){if(2&lt;(o=c[0]=c[0].slice(0)).length&amp;&amp;&#34;ID&#34;===(a=o[0]).type&amp;&amp;9===t.nodeType&amp;&amp;E&amp;&amp;b.relative[o[1].type]){if(!(t=(b.find.ID(a.matches[0].replace(te,ne),t)||[])[0]))return n;l&amp;&amp;(t=t.parentNode),e=e.slice(o.shift().value.length)}i=G.needsContext.test(e)?0:o.length;while(i--){if(a=o[i],b.relative[s=a.type])break;if((u=b.find[s])&amp;&amp;(r=u(a.matches[0].replace(te,ne),ee.test(o[0].type)&amp;&amp;ye(t.parentNode)||t))){if(o.splice(i,1),!(e=r.length&amp;&amp;xe(o)))return H.apply(n,r),n;break}}}return(l||f(e,c))(r,t,!E,n,!t||ee.test(e)&amp;&amp;ye(t.parentNode)||t),n},d.sortStable=S.split(&#34;&#34;).sort(j).join(&#34;&#34;)===S,d.detectDuplicates=!!l,T(),d.sortDetached=ce(function(e){return 1&amp;e.compareDocumentPosition(C.createElement(&#34;fieldset&#34;))}),ce(function(e){return e.innerHTML=&#34;&lt;a href=&#39;#&#39;&gt;&lt;/a&gt;&#34;,&#34;#&#34;===e.firstChild.getAttribute(&#34;href&#34;)})||fe(&#34;type|href|height|width&#34;,function(e,t,n){if(!n)return e.getAttribute(t,&#34;type&#34;===t.toLowerCase()?1:2)}),d.attributes&amp;&amp;ce(function(e){return e.innerHTML=&#34;&lt;input/&gt;&#34;,e.firstChild.setAttribute(&#34;value&#34;,&#34;&#34;),&#34;&#34;===e.firstChild.getAttribute(&#34;value&#34;)})||fe(&#34;value&#34;,function(e,t,n){if(!n&amp;&amp;&#34;input&#34;===e.nodeName.toLowerCase())return e.defaultValue}),ce(function(e){return null==e.getAttribute(&#34;disabled&#34;)})||fe(R,function(e,t,n){var r;if(!n)return!0===e[t]?t.toLowerCase():(r=e.getAttributeNode(t))&amp;&amp;r.specified?r.value:null}),se}(C);S.find=d,S.expr=d.selectors,S.expr[&#34;:&#34;]=S.expr.pseudos,S.uniqueSort=S.unique=d.uniqueSort,S.text=d.getText,S.isXMLDoc=d.isXML,S.contains=d.contains,S.escapeSelector=d.escape;var h=function(e,t,n){var r=[],i=void 0!==n;while((e=e[t])&amp;&amp;9!==e.nodeType)if(1===e.nodeType){if(i&amp;&amp;S(e).is(n))break;r.push(e)}return r},T=function(e,t){for(var n=[];e;e=e.nextSibling)1===e.nodeType&amp;&amp;e!==t&amp;&amp;n.push(e);return n},k=S.expr.match.needsContext;function A(e,t){return e.nodeName&amp;&amp;e.nodeName.toLowerCase()===t.toLowerCase()}var N=/^&lt;([a-z][^\/\0&gt;:\x20\t\r\n\f]*)[\x20\t\r\n\f]*\/?&gt;(?:&lt;\/\1&gt;|)$/i;function j(e,n,r){return m(n)?S.grep(e,function(e,t){return!!n.call(e,t,e)!==r}):n.nodeType?S.grep(e,function(e){return e===n!==r}):&#34;string&#34;!=typeof n?S.grep(e,function(e){return-1&lt;i.call(n,e)!==r}):S.filter(n,e,r)}S.filter=function(e,t,n){var r=t[0];return n&amp;&amp;(e=&#34;:not(&#34;+e+&#34;)&#34;),1===t.length&amp;&amp;1===r.nodeType?S.find.matchesSelector(r,e)?[r]:[]:S.find.matches(e,S.grep(t,function(e){return 1===e.nodeType}))},S.fn.extend({find:function(e){var t,n,r=this.length,i=this;if(&#34;string&#34;!=typeof e)return this.pushStack(S(e).filter(function(){for(t=0;t&lt;r;t++)if(S.contains(i[t],this))return!0}));for(n=this.pushStack([]),t=0;t&lt;r;t++)S.find(e,i[t],n);return 1&lt;r?S.uniqueSort(n):n},filter:function(e){return this.pushStack(j(this,e||[],!1))},not:function(e){return this.pushStack(j(this,e||[],!0))},is:function(e){return!!j(this,&#34;string&#34;==typeof e&amp;&amp;k.test(e)?S(e):e||[],!1).length}});var D,q=/^(?:\s*(&lt;[\w\W]+&gt;)[^&gt;]*|#([\w-]+))$/;(S.fn.init=function(e,t,n){var r,i;if(!e)return this;if(n=n||D,&#34;string&#34;==typeof e){if(!(r=&#34;&lt;&#34;===e[0]&amp;&amp;&#34;&gt;&#34;===e[e.length-1]&amp;&amp;3&lt;=e.length?[null,e,null]:q.exec(e))||!r[1]&amp;&amp;t)return!t||t.jquery?(t||n).find(e):this.constructor(t).find(e);if(r[1]){if(t=t instanceof S?t[0]:t,S.merge(this,S.parseHTML(r[1],t&amp;&amp;t.nodeType?t.ownerDocument||t:E,!0)),N.test(r[1])&amp;&amp;S.isPlainObject(t))for(r in t)m(this[r])?this[r](t[r]):this.attr(r,t[r]);return this}return(i=E.getElementById(r[2]))&amp;&amp;(this[0]=i,this.length=1),this}return e.nodeType?(this[0]=e,this.length=1,this):m(e)?void 0!==n.ready?n.ready(e):e(S):S.makeArray(e,this)}).prototype=S.fn,D=S(E);var L=/^(?:parents|prev(?:Until|All))/,H={children:!0,contents:!0,next:!0,prev:!0};function O(e,t){while((e=e[t])&amp;&amp;1!==e.nodeType);return e}S.fn.extend({has:function(e){var t=S(e,this),n=t.length;return this.filter(function(){for(var e=0;e&lt;n;e++)if(S.contains(this,t[e]))return!0})},closest:function(e,t){var n,r=0,i=this.length,o=[],a=&#34;string&#34;!=typeof e&amp;&amp;S(e);if(!k.test(e))for(;r&lt;i;r++)for(n=this[r];n&amp;&amp;n!==t;n=n.parentNode)if(n.nodeType&lt;11&amp;&amp;(a?-1&lt;a.index(n):1===n.nodeType&amp;&amp;S.find.matchesSelector(n,e))){o.push(n);break}return this.pushStack(1&lt;o.length?S.uniqueSort(o):o)},index:function(e){return e?&#34;string&#34;==typeof e?i.call(S(e),this[0]):i.call(this,e.jquery?e[0]:e):this[0]&amp;&amp;this[0].parentNode?this.first().prevAll().length:-1},add:function(e,t){return this.pushStack(S.uniqueSort(S.merge(this.get(),S(e,t))))},addBack:function(e){return this.add(null==e?this.prevObject:this.prevObject.filter(e))}}),S.each({parent:function(e){var t=e.parentNode;return t&amp;&amp;11!==t.nodeType?t:null},parents:function(e){return h(e,&#34;parentNode&#34;)},parentsUntil:function(e,t,n){return h(e,&#34;parentNode&#34;,n)},next:function(e){return O(e,&#34;nextSibling&#34;)},prev:function(e){return O(e,&#34;previousSibling&#34;)},nextAll:function(e){return h(e,&#34;nextSibling&#34;)},prevAll:function(e){return h(e,&#34;previousSibling&#34;)},nextUntil:function(e,t,n){return h(e,&#34;nextSibling&#34;,n)},prevUntil:function(e,t,n){return h(e,&#34;previousSibling&#34;,n)},siblings:function(e){return T((e.parentNode||{}).firstChild,e)},children:function(e){return T(e.firstChild)},contents:function(e){return null!=e.contentDocument&amp;&amp;r(e.contentDocument)?e.contentDocument:(A(e,&#34;template&#34;)&amp;&amp;(e=e.content||e),S.merge([],e.childNodes))}},function(r,i){S.fn[r]=function(e,t){var n=S.map(this,i,e);return&#34;Until&#34;!==r.slice(-5)&amp;&amp;(t=e),t&amp;&amp;&#34;string&#34;==typeof t&amp;&amp;(n=S.filter(t,n)),1&lt;this.length&amp;&amp;(H[r]||S.uniqueSort(n),L.test(r)&amp;&amp;n.reverse()),this.pushStack(n)}});var P=/[^\x20\t\r\n\f]+/g;function R(e){return e}function M(e){throw e}function I(e,t,n,r){var i;try{e&amp;&amp;m(i=e.promise)?i.call(e).done(t).fail(n):e&amp;&amp;m(i=e.then)?i.call(e,t,n):t.apply(void 0,[e].slice(r))}catch(e){n.apply(void 0,[e])}}S.Callbacks=function(r){var e,n;r=&#34;string&#34;==typeof r?(e=r,n={},S.each(e.match(P)||[],function(e,t){n[t]=!0}),n):S.extend({},r);var i,t,o,a,s=[],u=[],l=-1,c=function(){for(a=a||r.once,o=i=!0;u.length;l=-1){t=u.shift();while(++l&lt;s.length)!1===s[l].apply(t[0],t[1])&amp;&amp;r.stopOnFalse&amp;&amp;(l=s.length,t=!1)}r.memory||(t=!1),i=!1,a&amp;&amp;(s=t?[]:&#34;&#34;)},f={add:function(){return s&amp;&amp;(t&amp;&amp;!i&amp;&amp;(l=s.length-1,u.push(t)),function n(e){S.each(e,function(e,t){m(t)?r.unique&amp;&amp;f.has(t)||s.push(t):t&amp;&amp;t.length&amp;&amp;&#34;string&#34;!==w(t)&amp;&amp;n(t)})}(arguments),t&amp;&amp;!i&amp;&amp;c()),this},remove:function(){return S.each(arguments,function(e,t){var n;while(-1&lt;(n=S.inArray(t,s,n)))s.splice(n,1),n&lt;=l&amp;&amp;l--}),this},has:function(e){return e?-1&lt;S.inArray(e,s):0&lt;s.length},empty:function(){return s&amp;&amp;(s=[]),this},disable:function(){return a=u=[],s=t=&#34;&#34;,this},disabled:function(){return!s},lock:function(){return a=u=[],t||i||(s=t=&#34;&#34;),this},locked:function(){return!!a},fireWith:function(e,t){return a||(t=[e,(t=t||[]).slice?t.slice():t],u.push(t),i||c()),this},fire:function(){return f.fireWith(this,arguments),this},fired:function(){return!!o}};return f},S.extend({Deferred:function(e){var o=[[&#34;notify&#34;,&#34;progress&#34;,S.Callbacks(&#34;memory&#34;),S.Callbacks(&#34;memory&#34;),2],[&#34;resolve&#34;,&#34;done&#34;,S.Callbacks(&#34;once memory&#34;),S.Callbacks(&#34;once memory&#34;),0,&#34;resolved&#34;],[&#34;reject&#34;,&#34;fail&#34;,S.Callbacks(&#34;once memory&#34;),S.Callbacks(&#34;once memory&#34;),1,&#34;rejected&#34;]],i=&#34;pending&#34;,a={state:function(){return i},always:function(){return s.done(arguments).fail(arguments),this},&#34;catch&#34;:function(e){return a.then(null,e)},pipe:function(){var i=arguments;return S.Deferred(function(r){S.each(o,function(e,t){var n=m(i[t[4]])&amp;&amp;i[t[4]];s[t[1]](function(){var e=n&amp;&amp;n.apply(this,arguments);e&amp;&amp;m(e.promise)?e.promise().progress(r.notify).done(r.resolve).fail(r.reject):r[t[0]+&#34;With&#34;](this,n?[e]:arguments)})}),i=null}).promise()},then:function(t,n,r){var u=0;function l(i,o,a,s){return function(){var n=this,r=arguments,e=function(){var e,t;if(!(i&lt;u)){if((e=a.apply(n,r))===o.promise())throw new TypeError(&#34;Thenable self-resolution&#34;);t=e&amp;&amp;(&#34;object&#34;==typeof e||&#34;function&#34;==typeof e)&amp;&amp;e.then,m(t)?s?t.call(e,l(u,o,R,s),l(u,o,M,s)):(u++,t.call(e,l(u,o,R,s),l(u,o,M,s),l(u,o,R,o.notifyWith))):(a!==R&amp;&amp;(n=void 0,r=[e]),(s||o.resolveWith)(n,r))}},t=s?e:function(){try{e()}catch(e){S.Deferred.exceptionHook&amp;&amp;S.Deferred.exceptionHook(e,t.stackTrace),u&lt;=i+1&amp;&amp;(a!==M&amp;&amp;(n=void 0,r=[e]),o.rejectWith(n,r))}};i?t():(S.Deferred.getStackHook&amp;&amp;(t.stackTrace=S.Deferred.getStackHook()),C.setTimeout(t))}}return S.Deferred(function(e){o[0][3].add(l(0,e,m(r)?r:R,e.notifyWith)),o[1][3].add(l(0,e,m(t)?t:R)),o[2][3].add(l(0,e,m(n)?n:M))}).promise()},promise:function(e){return null!=e?S.extend(e,a):a}},s={};return S.each(o,function(e,t){var n=t[2],r=t[5];a[t[1]]=n.add,r&amp;&amp;n.add(function(){i=r},o[3-e][2].disable,o[3-e][3].disable,o[0][2].lock,o[0][3].lock),n.add(t[3].fire),s[t[0]]=function(){return s[t[0]+&#34;With&#34;](this===s?void 0:this,arguments),this},s[t[0]+&#34;With&#34;]=n.fireWith}),a.promise(s),e&amp;&amp;e.call(s,s),s},when:function(e){var n=arguments.length,t=n,r=Array(t),i=s.call(arguments),o=S.Deferred(),a=function(t){return function(e){r[t]=this,i[t]=1&lt;arguments.length?s.call(arguments):e,--n||o.resolveWith(r,i)}};if(n&lt;=1&amp;&amp;(I(e,o.done(a(t)).resolve,o.reject,!n),&#34;pending&#34;===o.state()||m(i[t]&amp;&amp;i[t].then)))return o.then();while(t--)I(i[t],a(t),o.reject);return o.promise()}});var W=/^(Eval|Internal|Range|Reference|Syntax|Type|URI)Error$/;S.Deferred.exceptionHook=function(e,t){C.console&amp;&amp;C.console.warn&amp;&amp;e&amp;&amp;W.test(e.name)&amp;&amp;C.console.warn(&#34;jQuery.Deferred exception: &#34;+e.message,e.stack,t)},S.readyException=function(e){C.setTimeout(function(){throw e})};var F=S.Deferred();function B(){E.removeEventListener(&#34;DOMContentLoaded&#34;,B),C.removeEventListener(&#34;load&#34;,B),S.ready()}S.fn.ready=function(e){return F.then(e)[&#34;catch&#34;](function(e){S.readyException(e)}),this},S.extend({isReady:!1,readyWait:1,ready:function(e){(!0===e?--S.readyWait:S.isReady)||(S.isReady=!0)!==e&amp;&amp;0&lt;--S.readyWait||F.resolveWith(E,[S])}}),S.ready.then=F.then,&#34;complete&#34;===E.readyState||&#34;loading&#34;!==E.readyState&amp;&amp;!E.documentElement.doScroll?C.setTimeout(S.ready):(E.addEventListener(&#34;DOMContentLoaded&#34;,B),C.addEventListener(&#34;load&#34;,B));var $=function(e,t,n,r,i,o,a){var s=0,u=e.length,l=null==n;if(&#34;object&#34;===w(n))for(s in i=!0,n)$(e,t,s,n[s],!0,o,a);else if(void 0!==r&amp;&amp;(i=!0,m(r)||(a=!0),l&amp;&amp;(a?(t.call(e,r),t=null):(l=t,t=function(e,t,n){return l.call(S(e),n)})),t))for(;s&lt;u;s++)t(e[s],n,a?r:r.call(e[s],s,t(e[s],n)));return i?e:l?t.call(e):u?t(e[0],n):o},_=/^-ms-/,z=/-([a-z])/g;function U(e,t){return t.toUpperCase()}function X(e){return e.replace(_,&#34;ms-&#34;).replace(z,U)}var V=function(e){return 1===e.nodeType||9===e.nodeType||!+e.nodeType};function G(){this.expando=S.expando+G.uid++}G.uid=1,G.prototype={cache:function(e){var t=e[this.expando];return t||(t={},V(e)&amp;&amp;(e.nodeType?e[this.expando]=t:Object.defineProperty(e,this.expando,{value:t,configurable:!0}))),t},set:function(e,t,n){var r,i=this.cache(e);if(&#34;string&#34;==typeof t)i[X(t)]=n;else for(r in t)i[X(r)]=t[r];return i},get:function(e,t){return void 0===t?this.cache(e):e[this.expando]&amp;&amp;e[this.expando][X(t)]},access:function(e,t,n){return void 0===t||t&amp;&amp;&#34;string&#34;==typeof t&amp;&amp;void 0===n?this.get(e,t):(this.set(e,t,n),void 0!==n?n:t)},remove:function(e,t){var n,r=e[this.expando];if(void 0!==r){if(void 0!==t){n=(t=Array.isArray(t)?t.map(X):(t=X(t))in r?[t]:t.match(P)||[]).length;while(n--)delete r[t[n]]}(void 0===t||S.isEmptyObject(r))&amp;&amp;(e.nodeType?e[this.expando]=void 0:delete e[this.expando])}},hasData:function(e){var t=e[this.expando];return void 0!==t&amp;&amp;!S.isEmptyObject(t)}};var Y=new G,Q=new G,J=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,K=/[A-Z]/g;function Z(e,t,n){var r,i;if(void 0===n&amp;&amp;1===e.nodeType)if(r=&#34;data-&#34;+t.replace(K,&#34;-$&amp;&#34;).toLowerCase(),&#34;string&#34;==typeof(n=e.getAttribute(r))){try{n=&#34;true&#34;===(i=n)||&#34;false&#34;!==i&amp;&amp;(&#34;null&#34;===i?null:i===+i+&#34;&#34;?+i:J.test(i)?JSON.parse(i):i)}catch(e){}Q.set(e,t,n)}else n=void 0;return n}S.extend({hasData:function(e){return Q.hasData(e)||Y.hasData(e)},data:function(e,t,n){return Q.access(e,t,n)},removeData:function(e,t){Q.remove(e,t)},_data:function(e,t,n){return Y.access(e,t,n)},_removeData:function(e,t){Y.remove(e,t)}}),S.fn.extend({data:function(n,e){var t,r,i,o=this[0],a=o&amp;&amp;o.attributes;if(void 0===n){if(this.length&amp;&amp;(i=Q.get(o),1===o.nodeType&amp;&amp;!Y.get(o,&#34;hasDataAttrs&#34;))){t=a.length;while(t--)a[t]&amp;&amp;0===(r=a[t].name).indexOf(&#34;data-&#34;)&amp;&amp;(r=X(r.slice(5)),Z(o,r,i[r]));Y.set(o,&#34;hasDataAttrs&#34;,!0)}return i}return&#34;object&#34;==typeof n?this.each(function(){Q.set(this,n)}):$(this,function(e){var t;if(o&amp;&amp;void 0===e)return void 0!==(t=Q.get(o,n))?t:void 0!==(t=Z(o,n))?t:void 0;this.each(function(){Q.set(this,n,e)})},null,e,1&lt;arguments.length,null,!0)},removeData:function(e){return this.each(function(){Q.remove(this,e)})}}),S.extend({queue:function(e,t,n){var r;if(e)return t=(t||&#34;fx&#34;)+&#34;queue&#34;,r=Y.get(e,t),n&amp;&amp;(!r||Array.isArray(n)?r=Y.access(e,t,S.makeArray(n)):r.push(n)),r||[]},dequeue:function(e,t){t=t||&#34;fx&#34;;var n=S.queue(e,t),r=n.length,i=n.shift(),o=S._queueHooks(e,t);&#34;inprogress&#34;===i&amp;&amp;(i=n.shift(),r--),i&amp;&amp;(&#34;fx&#34;===t&amp;&amp;n.unshift(&#34;inprogress&#34;),delete o.stop,i.call(e,function(){S.dequeue(e,t)},o)),!r&amp;&amp;o&amp;&amp;o.empty.fire()},_queueHooks:function(e,t){var n=t+&#34;queueHooks&#34;;return Y.get(e,n)||Y.access(e,n,{empty:S.Callbacks(&#34;once memory&#34;).add(function(){Y.remove(e,[t+&#34;queue&#34;,n])})})}}),S.fn.extend({queue:function(t,n){var e=2;return&#34;string&#34;!=typeof t&amp;&amp;(n=t,t=&#34;fx&#34;,e--),arguments.length&lt;e?S.queue(this[0],t):void 0===n?this:this.each(function(){var e=S.queue(this,t,n);S._queueHooks(this,t),&#34;fx&#34;===t&amp;&amp;&#34;inprogress&#34;!==e[0]&amp;&amp;S.dequeue(this,t)})},dequeue:function(e){return this.each(function(){S.dequeue(this,e)})},clearQueue:function(e){return this.queue(e||&#34;fx&#34;,[])},promise:function(e,t){var n,r=1,i=S.Deferred(),o=this,a=this.length,s=function(){--r||i.resolveWith(o,[o])};&#34;string&#34;!=typeof e&amp;&amp;(t=e,e=void 0),e=e||&#34;fx&#34;;while(a--)(n=Y.get(o[a],e+&#34;queueHooks&#34;))&amp;&amp;n.empty&amp;&amp;(r++,n.empty.add(s));return s(),i.promise(t)}});var ee=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,te=new RegExp(&#34;^(?:([+-])=|)(&#34;+ee+&#34;)([a-z%]*)$&#34;,&#34;i&#34;),ne=[&#34;Top&#34;,&#34;Right&#34;,&#34;Bottom&#34;,&#34;Left&#34;],re=E.documentElement,ie=function(e){return S.contains(e.ownerDocument,e)},oe={composed:!0};re.getRootNode&amp;&amp;(ie=function(e){return S.contains(e.ownerDocument,e)||e.getRootNode(oe)===e.ownerDocument});var ae=function(e,t){return&#34;none&#34;===(e=t||e).style.display||&#34;&#34;===e.style.display&amp;&amp;ie(e)&amp;&amp;&#34;none&#34;===S.css(e,&#34;display&#34;)};function se(e,t,n,r){var i,o,a=20,s=r?function(){return r.cur()}:function(){return S.css(e,t,&#34;&#34;)},u=s(),l=n&amp;&amp;n[3]||(S.cssNumber[t]?&#34;&#34;:&#34;px&#34;),c=e.nodeType&amp;&amp;(S.cssNumber[t]||&#34;px&#34;!==l&amp;&amp;+u)&amp;&amp;te.exec(S.css(e,t));if(c&amp;&amp;c[3]!==l){u/=2,l=l||c[3],c=+u||1;while(a--)S.style(e,t,c+l),(1-o)*(1-(o=s()/u||.5))&lt;=0&amp;&amp;(a=0),c/=o;c*=2,S.style(e,t,c+l),n=n||[]}return n&amp;&amp;(c=+c||+u||0,i=n[1]?c+(n[1]+1)*n[2]:+n[2],r&amp;&amp;(r.unit=l,r.start=c,r.end=i)),i}var ue={};function le(e,t){for(var n,r,i,o,a,s,u,l=[],c=0,f=e.length;c&lt;f;c++)(r=e[c]).style&amp;&amp;(n=r.style.display,t?(&#34;none&#34;===n&amp;&amp;(l[c]=Y.get(r,&#34;display&#34;)||null,l[c]||(r.style.display=&#34;&#34;)),&#34;&#34;===r.style.display&amp;&amp;ae(r)&amp;&amp;(l[c]=(u=a=o=void 0,a=(i=r).ownerDocument,s=i.nodeName,(u=ue[s])||(o=a.body.appendChild(a.createElement(s)),u=S.css(o,&#34;display&#34;),o.parentNode.removeChild(o),&#34;none&#34;===u&amp;&amp;(u=&#34;block&#34;),ue[s]=u)))):&#34;none&#34;!==n&amp;&amp;(l[c]=&#34;none&#34;,Y.set(r,&#34;display&#34;,n)));for(c=0;c&lt;f;c++)null!=l[c]&amp;&amp;(e[c].style.display=l[c]);return e}S.fn.extend({show:function(){return le(this,!0)},hide:function(){return le(this)},toggle:function(e){return&#34;boolean&#34;==typeof e?e?this.show():this.hide():this.each(function(){ae(this)?S(this).show():S(this).hide()})}});var ce,fe,pe=/^(?:checkbox|radio)$/i,de=/&lt;([a-z][^\/\0&gt;\x20\t\r\n\f]*)/i,he=/^$|^module$|\/(?:java|ecma)script/i;ce=E.createDocumentFragment().appendChild(E.createElement(&#34;div&#34;)),(fe=E.createElement(&#34;input&#34;)).setAttribute(&#34;type&#34;,&#34;radio&#34;),fe.setAttribute(&#34;checked&#34;,&#34;checked&#34;),fe.setAttribute(&#34;name&#34;,&#34;t&#34;),ce.appendChild(fe),y.checkClone=ce.cloneNode(!0).cloneNode(!0).lastChild.checked,ce.innerHTML=&#34;&lt;textarea&gt;x&lt;/textarea&gt;&#34;,y.noCloneChecked=!!ce.cloneNode(!0).lastChild.defaultValue,ce.innerHTML=&#34;&lt;option&gt;&lt;/option&gt;&#34;,y.option=!!ce.lastChild;var ge={thead:[1,&#34;&lt;table&gt;&#34;,&#34;&lt;/table&gt;&#34;],col:[2,&#34;&lt;table&gt;&lt;colgroup&gt;&#34;,&#34;&lt;/colgroup&gt;&lt;/table&gt;&#34;],tr:[2,&#34;&lt;table&gt;&lt;tbody&gt;&#34;,&#34;&lt;/tbody&gt;&lt;/table&gt;&#34;],td:[3,&#34;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&#34;,&#34;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&#34;],_default:[0,&#34;&#34;,&#34;&#34;]};function ve(e,t){var n;return n=&#34;undefined&#34;!=typeof e.getElementsByTagName?e.getElementsByTagName(t||&#34;*&#34;):&#34;undefined&#34;!=typeof e.querySelectorAll?e.querySelectorAll(t||&#34;*&#34;):[],void 0===t||t&amp;&amp;A(e,t)?S.merge([e],n):n}function ye(e,t){for(var n=0,r=e.length;n&lt;r;n++)Y.set(e[n],&#34;globalEval&#34;,!t||Y.get(t[n],&#34;globalEval&#34;))}ge.tbody=ge.tfoot=ge.colgroup=ge.caption=ge.thead,ge.th=ge.td,y.option||(ge.optgroup=ge.option=[1,&#34;&lt;select multiple=&#39;multiple&#39;&gt;&#34;,&#34;&lt;/select&gt;&#34;]);var me=/&lt;|&amp;#?\w+;/;function xe(e,t,n,r,i){for(var o,a,s,u,l,c,f=t.createDocumentFragment(),p=[],d=0,h=e.length;d&lt;h;d++)if((o=e[d])||0===o)if(&#34;object&#34;===w(o))S.merge(p,o.nodeType?[o]:o);else if(me.test(o)){a=a||f.appendChild(t.createElement(&#34;div&#34;)),s=(de.exec(o)||[&#34;&#34;,&#34;&#34;])[1].toLowerCase(),u=ge[s]||ge._default,a.innerHTML=u[1]+S.htmlPrefilter(o)+u[2],c=u[0];while(c--)a=a.lastChild;S.merge(p,a.childNodes),(a=f.firstChild).textContent=&#34;&#34;}else p.push(t.createTextNode(o));f.textContent=&#34;&#34;,d=0;while(o=p[d++])if(r&amp;&amp;-1&lt;S.inArray(o,r))i&amp;&amp;i.push(o);else if(l=ie(o),a=ve(f.appendChild(o),&#34;script&#34;),l&amp;&amp;ye(a),n){c=0;while(o=a[c++])he.test(o.type||&#34;&#34;)&amp;&amp;n.push(o)}return f}var be=/^([^.]*)(?:\.(.+)|)/;function we(){return!0}function Te(){return!1}function Ce(e,t){return e===function(){try{return E.activeElement}catch(e){}}()==(&#34;focus&#34;===t)}function Ee(e,t,n,r,i,o){var a,s;if(&#34;object&#34;==typeof t){for(s in&#34;string&#34;!=typeof n&amp;&amp;(r=r||n,n=void 0),t)Ee(e,s,n,r,t[s],o);return e}if(null==r&amp;&amp;null==i?(i=n,r=n=void 0):null==i&amp;&amp;(&#34;string&#34;==typeof n?(i=r,r=void 0):(i=r,r=n,n=void 0)),!1===i)i=Te;else if(!i)return e;return 1===o&amp;&amp;(a=i,(i=function(e){return S().off(e),a.apply(this,arguments)}).guid=a.guid||(a.guid=S.guid++)),e.each(function(){S.event.add(this,t,i,r,n)})}function Se(e,i,o){o?(Y.set(e,i,!1),S.event.add(e,i,{namespace:!1,handler:function(e){var t,n,r=Y.get(this,i);if(1&amp;e.isTrigger&amp;&amp;this[i]){if(r.length)(S.event.special[i]||{}).delegateType&amp;&amp;e.stopPropagation();else if(r=s.call(arguments),Y.set(this,i,r),t=o(this,i),this[i](),r!==(n=Y.get(this,i))||t?Y.set(this,i,!1):n={},r!==n)return e.stopImmediatePropagation(),e.preventDefault(),n&amp;&amp;n.value}else r.length&amp;&amp;(Y.set(this,i,{value:S.event.trigger(S.extend(r[0],S.Event.prototype),r.slice(1),this)}),e.stopImmediatePropagation())}})):void 0===Y.get(e,i)&amp;&amp;S.event.add(e,i,we)}S.event={global:{},add:function(t,e,n,r,i){var o,a,s,u,l,c,f,p,d,h,g,v=Y.get(t);if(V(t)){n.handler&amp;&amp;(n=(o=n).handler,i=o.selector),i&amp;&amp;S.find.matchesSelector(re,i),n.guid||(n.guid=S.guid++),(u=v.events)||(u=v.events=Object.create(null)),(a=v.handle)||(a=v.handle=function(e){return&#34;undefined&#34;!=typeof S&amp;&amp;S.event.triggered!==e.type?S.event.dispatch.apply(t,arguments):void 0}),l=(e=(e||&#34;&#34;).match(P)||[&#34;&#34;]).length;while(l--)d=g=(s=be.exec(e[l])||[])[1],h=(s[2]||&#34;&#34;).split(&#34;.&#34;).sort(),d&amp;&amp;(f=S.event.special[d]||{},d=(i?f.delegateType:f.bindType)||d,f=S.event.special[d]||{},c=S.extend({type:d,origType:g,data:r,handler:n,guid:n.guid,selector:i,needsContext:i&amp;&amp;S.expr.match.needsContext.test(i),namespace:h.join(&#34;.&#34;)},o),(p=u[d])||((p=u[d]=[]).delegateCount=0,f.setup&amp;&amp;!1!==f.setup.call(t,r,h,a)||t.addEventListener&amp;&amp;t.addEventListener(d,a)),f.add&amp;&amp;(f.add.call(t,c),c.handler.guid||(c.handler.guid=n.guid)),i?p.splice(p.delegateCount++,0,c):p.push(c),S.event.global[d]=!0)}},remove:function(e,t,n,r,i){var o,a,s,u,l,c,f,p,d,h,g,v=Y.hasData(e)&amp;&amp;Y.get(e);if(v&amp;&amp;(u=v.events)){l=(t=(t||&#34;&#34;).match(P)||[&#34;&#34;]).length;while(l--)if(d=g=(s=be.exec(t[l])||[])[1],h=(s[2]||&#34;&#34;).split(&#34;.&#34;).sort(),d){f=S.event.special[d]||{},p=u[d=(r?f.delegateType:f.bindType)||d]||[],s=s[2]&amp;&amp;new RegExp(&#34;(^|\\.)&#34;+h.join(&#34;\\.(?:.*\\.|)&#34;)+&#34;(\\.|$)&#34;),a=o=p.length;while(o--)c=p[o],!i&amp;&amp;g!==c.origType||n&amp;&amp;n.guid!==c.guid||s&amp;&amp;!s.test(c.namespace)||r&amp;&amp;r!==c.selector&amp;&amp;(&#34;**&#34;!==r||!c.selector)||(p.splice(o,1),c.selector&amp;&amp;p.delegateCount--,f.remove&amp;&amp;f.remove.call(e,c));a&amp;&amp;!p.length&amp;&amp;(f.teardown&amp;&amp;!1!==f.teardown.call(e,h,v.handle)||S.removeEvent(e,d,v.handle),delete u[d])}else for(d in u)S.event.remove(e,d+t[l],n,r,!0);S.isEmptyObject(u)&amp;&amp;Y.remove(e,&#34;handle events&#34;)}},dispatch:function(e){var t,n,r,i,o,a,s=new Array(arguments.length),u=S.event.fix(e),l=(Y.get(this,&#34;events&#34;)||Object.create(null))[u.type]||[],c=S.event.special[u.type]||{};for(s[0]=u,t=1;t&lt;arguments.length;t++)s[t]=arguments[t];if(u.delegateTarget=this,!c.preDispatch||!1!==c.preDispatch.call(this,u)){a=S.event.handlers.call(this,u,l),t=0;while((i=a[t++])&amp;&amp;!u.isPropagationStopped()){u.currentTarget=i.elem,n=0;while((o=i.handlers[n++])&amp;&amp;!u.isImmediatePropagationStopped())u.rnamespace&amp;&amp;!1!==o.namespace&amp;&amp;!u.rnamespace.test(o.namespace)||(u.handleObj=o,u.data=o.data,void 0!==(r=((S.event.special[o.origType]||{}).handle||o.handler).apply(i.elem,s))&amp;&amp;!1===(u.result=r)&amp;&amp;(u.preventDefault(),u.stopPropagation()))}return c.postDispatch&amp;&amp;c.postDispatch.call(this,u),u.result}},handlers:function(e,t){var n,r,i,o,a,s=[],u=t.delegateCount,l=e.target;if(u&amp;&amp;l.nodeType&amp;&amp;!(&#34;click&#34;===e.type&amp;&amp;1&lt;=e.button))for(;l!==this;l=l.parentNode||this)if(1===l.nodeType&amp;&amp;(&#34;click&#34;!==e.type||!0!==l.disabled)){for(o=[],a={},n=0;n&lt;u;n++)void 0===a[i=(r=t[n]).selector+&#34; &#34;]&amp;&amp;(a[i]=r.needsContext?-1&lt;S(i,this).index(l):S.find(i,this,null,[l]).length),a[i]&amp;&amp;o.push(r);o.length&amp;&amp;s.push({elem:l,handlers:o})}return l=this,u&lt;t.length&amp;&amp;s.push({elem:l,handlers:t.slice(u)}),s},addProp:function(t,e){Object.defineProperty(S.Event.prototype,t,{enumerable:!0,configurable:!0,get:m(e)?function(){if(this.originalEvent)return e(this.originalEvent)}:function(){if(this.originalEvent)return this.originalEvent[t]},set:function(e){Object.defineProperty(this,t,{enumerable:!0,configurable:!0,writable:!0,value:e})}})},fix:function(e){return e[S.expando]?e:new S.Event(e)},special:{load:{noBubble:!0},click:{setup:function(e){var t=this||e;return pe.test(t.type)&amp;&amp;t.click&amp;&amp;A(t,&#34;input&#34;)&amp;&amp;Se(t,&#34;click&#34;,we),!1},trigger:function(e){var t=this||e;return pe.test(t.type)&amp;&amp;t.click&amp;&amp;A(t,&#34;input&#34;)&amp;&amp;Se(t,&#34;click&#34;),!0},_default:function(e){var t=e.target;return pe.test(t.type)&amp;&amp;t.click&amp;&amp;A(t,&#34;input&#34;)&amp;&amp;Y.get(t,&#34;click&#34;)||A(t,&#34;a&#34;)}},beforeunload:{postDispatch:function(e){void 0!==e.result&amp;&amp;e.originalEvent&amp;&amp;(e.originalEvent.returnValue=e.result)}}}},S.removeEvent=function(e,t,n){e.removeEventListener&amp;&amp;e.removeEventListener(t,n)},S.Event=function(e,t){if(!(this instanceof S.Event))return new S.Event(e,t);e&amp;&amp;e.type?(this.originalEvent=e,this.type=e.type,this.isDefaultPrevented=e.defaultPrevented||void 0===e.defaultPrevented&amp;&amp;!1===e.returnValue?we:Te,this.target=e.target&amp;&amp;3===e.target.nodeType?e.target.parentNode:e.target,this.currentTarget=e.currentTarget,this.relatedTarget=e.relatedTarget):this.type=e,t&amp;&amp;S.extend(this,t),this.timeStamp=e&amp;&amp;e.timeStamp||Date.now(),this[S.expando]=!0},S.Event.prototype={constructor:S.Event,isDefaultPrevented:Te,isPropagationStopped:Te,isImmediatePropagationStopped:Te,isSimulated:!1,preventDefault:function(){var e=this.originalEvent;this.isDefaultPrevented=we,e&amp;&amp;!this.isSimulated&amp;&amp;e.preventDefault()},stopPropagation:function(){var e=this.originalEvent;this.isPropagationStopped=we,e&amp;&amp;!this.isSimulated&amp;&amp;e.stopPropagation()},stopImmediatePropagation:function(){var e=this.originalEvent;this.isImmediatePropagationStopped=we,e&amp;&amp;!this.isSimulated&amp;&amp;e.stopImmediatePropagation(),this.stopPropagation()}},S.each({altKey:!0,bubbles:!0,cancelable:!0,changedTouches:!0,ctrlKey:!0,detail:!0,eventPhase:!0,metaKey:!0,pageX:!0,pageY:!0,shiftKey:!0,view:!0,&#34;char&#34;:!0,code:!0,charCode:!0,key:!0,keyCode:!0,button:!0,buttons:!0,clientX:!0,clientY:!0,offsetX:!0,offsetY:!0,pointerId:!0,pointerType:!0,screenX:!0,screenY:!0,targetTouches:!0,toElement:!0,touches:!0,which:!0},S.event.addProp),S.each({focus:&#34;focusin&#34;,blur:&#34;focusout&#34;},function(e,t){S.event.special[e]={setup:function(){return Se(this,e,Ce),!1},trigger:function(){return Se(this,e),!0},_default:function(){return!0},delegateType:t}}),S.each({mouseenter:&#34;mouseover&#34;,mouseleave:&#34;mouseout&#34;,pointerenter:&#34;pointerover&#34;,pointerleave:&#34;pointerout&#34;},function(e,i){S.event.special[e]={delegateType:i,bindType:i,handle:function(e){var t,n=e.relatedTarget,r=e.handleObj;return n&amp;&amp;(n===this||S.contains(this,n))||(e.type=r.origType,t=r.handler.apply(this,arguments),e.type=i),t}}}),S.fn.extend({on:function(e,t,n,r){return Ee(this,e,t,n,r)},one:function(e,t,n,r){return Ee(this,e,t,n,r,1)},off:function(e,t,n){var r,i;if(e&amp;&amp;e.preventDefault&amp;&amp;e.handleObj)return r=e.handleObj,S(e.delegateTarget).off(r.namespace?r.origType+&#34;.&#34;+r.namespace:r.origType,r.selector,r.handler),this;if(&#34;object&#34;==typeof e){for(i in e)this.off(i,t,e[i]);return this}return!1!==t&amp;&amp;&#34;function&#34;!=typeof t||(n=t,t=void 0),!1===n&amp;&amp;(n=Te),this.each(function(){S.event.remove(this,e,n,t)})}});var ke=/&lt;script|&lt;style|&lt;link/i,Ae=/checked\s*(?:[^=]|=\s*.checked.)/i,Ne=/^\s*&lt;!(?:\[CDATA\[|--)|(?:\]\]|--)&gt;\s*$/g;function je(e,t){return A(e,&#34;table&#34;)&amp;&amp;A(11!==t.nodeType?t:t.firstChild,&#34;tr&#34;)&amp;&amp;S(e).children(&#34;tbody&#34;)[0]||e}function De(e){return e.type=(null!==e.getAttribute(&#34;type&#34;))+&#34;/&#34;+e.type,e}function qe(e){return&#34;true/&#34;===(e.type||&#34;&#34;).slice(0,5)?e.type=e.type.slice(5):e.removeAttribute(&#34;type&#34;),e}function Le(e,t){var n,r,i,o,a,s;if(1===t.nodeType){if(Y.hasData(e)&amp;&amp;(s=Y.get(e).events))for(i in Y.remove(t,&#34;handle events&#34;),s)for(n=0,r=s[i].length;n&lt;r;n++)S.event.add(t,i,s[i][n]);Q.hasData(e)&amp;&amp;(o=Q.access(e),a=S.extend({},o),Q.set(t,a))}}function He(n,r,i,o){r=g(r);var e,t,a,s,u,l,c=0,f=n.length,p=f-1,d=r[0],h=m(d);if(h||1&lt;f&amp;&amp;&#34;string&#34;==typeof d&amp;&amp;!y.checkClone&amp;&amp;Ae.test(d))return n.each(function(e){var t=n.eq(e);h&amp;&amp;(r[0]=d.call(this,e,t.html())),He(t,r,i,o)});if(f&amp;&amp;(t=(e=xe(r,n[0].ownerDocument,!1,n,o)).firstChild,1===e.childNodes.length&amp;&amp;(e=t),t||o)){for(s=(a=S.map(ve(e,&#34;script&#34;),De)).length;c&lt;f;c++)u=e,c!==p&amp;&amp;(u=S.clone(u,!0,!0),s&amp;&amp;S.merge(a,ve(u,&#34;script&#34;))),i.call(n[c],u,c);if(s)for(l=a[a.length-1].ownerDocument,S.map(a,qe),c=0;c&lt;s;c++)u=a[c],he.test(u.type||&#34;&#34;)&amp;&amp;!Y.access(u,&#34;globalEval&#34;)&amp;&amp;S.contains(l,u)&amp;&amp;(u.src&amp;&amp;&#34;module&#34;!==(u.type||&#34;&#34;).toLowerCase()?S._evalUrl&amp;&amp;!u.noModule&amp;&amp;S._evalUrl(u.src,{nonce:u.nonce||u.getAttribute(&#34;nonce&#34;)},l):b(u.textContent.replace(Ne,&#34;&#34;),u,l))}return n}function Oe(e,t,n){for(var r,i=t?S.filter(t,e):e,o=0;null!=(r=i[o]);o++)n||1!==r.nodeType||S.cleanData(ve(r)),r.parentNode&amp;&amp;(n&amp;&amp;ie(r)&amp;&amp;ye(ve(r,&#34;script&#34;)),r.parentNode.removeChild(r));return e}S.extend({htmlPrefilter:function(e){return e},clone:function(e,t,n){var r,i,o,a,s,u,l,c=e.cloneNode(!0),f=ie(e);if(!(y.noCloneChecked||1!==e.nodeType&amp;&amp;11!==e.nodeType||S.isXMLDoc(e)))for(a=ve(c),r=0,i=(o=ve(e)).length;r&lt;i;r++)s=o[r],u=a[r],void 0,&#34;input&#34;===(l=u.nodeName.toLowerCase())&amp;&amp;pe.test(s.type)?u.checked=s.checked:&#34;input&#34;!==l&amp;&amp;&#34;textarea&#34;!==l||(u.defaultValue=s.defaultValue);if(t)if(n)for(o=o||ve(e),a=a||ve(c),r=0,i=o.length;r&lt;i;r++)Le(o[r],a[r]);else Le(e,c);return 0&lt;(a=ve(c,&#34;script&#34;)).length&amp;&amp;ye(a,!f&amp;&amp;ve(e,&#34;script&#34;)),c},cleanData:function(e){for(var t,n,r,i=S.event.special,o=0;void 0!==(n=e[o]);o++)if(V(n)){if(t=n[Y.expando]){if(t.events)for(r in t.events)i[r]?S.event.remove(n,r):S.removeEvent(n,r,t.handle);n[Y.expando]=void 0}n[Q.expando]&amp;&amp;(n[Q.expando]=void 0)}}}),S.fn.extend({detach:function(e){return Oe(this,e,!0)},remove:function(e){return Oe(this,e)},text:function(e){return $(this,function(e){return void 0===e?S.text(this):this.empty().each(function(){1!==this.nodeType&amp;&amp;11!==this.nodeType&amp;&amp;9!==this.nodeType||(this.textContent=e)})},null,e,arguments.length)},append:function(){return He(this,arguments,function(e){1!==this.nodeType&amp;&amp;11!==this.nodeType&amp;&amp;9!==this.nodeType||je(this,e).appendChild(e)})},prepend:function(){return He(this,arguments,function(e){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var t=je(this,e);t.insertBefore(e,t.firstChild)}})},before:function(){return He(this,arguments,function(e){this.parentNode&amp;&amp;this.parentNode.insertBefore(e,this)})},after:function(){return He(this,arguments,function(e){this.parentNode&amp;&amp;this.parentNode.insertBefore(e,this.nextSibling)})},empty:function(){for(var e,t=0;null!=(e=this[t]);t++)1===e.nodeType&amp;&amp;(S.cleanData(ve(e,!1)),e.textContent=&#34;&#34;);return this},clone:function(e,t){return e=null!=e&amp;&amp;e,t=null==t?e:t,this.map(function(){return S.clone(this,e,t)})},html:function(e){return $(this,function(e){var t=this[0]||{},n=0,r=this.length;if(void 0===e&amp;&amp;1===t.nodeType)return t.innerHTML;if(&#34;string&#34;==typeof e&amp;&amp;!ke.test(e)&amp;&amp;!ge[(de.exec(e)||[&#34;&#34;,&#34;&#34;])[1].toLowerCase()]){e=S.htmlPrefilter(e);try{for(;n&lt;r;n++)1===(t=this[n]||{}).nodeType&amp;&amp;(S.cleanData(ve(t,!1)),t.innerHTML=e);t=0}catch(e){}}t&amp;&amp;this.empty().append(e)},null,e,arguments.length)},replaceWith:function(){var n=[];return He(this,arguments,function(e){var t=this.parentNode;S.inArray(this,n)&lt;0&amp;&amp;(S.cleanData(ve(this)),t&amp;&amp;t.replaceChild(e,this))},n)}}),S.each({appendTo:&#34;append&#34;,prependTo:&#34;prepend&#34;,insertBefore:&#34;before&#34;,insertAfter:&#34;after&#34;,replaceAll:&#34;replaceWith&#34;},function(e,a){S.fn[e]=function(e){for(var t,n=[],r=S(e),i=r.length-1,o=0;o&lt;=i;o++)t=o===i?this:this.clone(!0),S(r[o])[a](t),u.apply(n,t.get());return this.pushStack(n)}});var Pe=new RegExp(&#34;^(&#34;+ee+&#34;)(?!px)[a-z%]+$&#34;,&#34;i&#34;),Re=function(e){var t=e.ownerDocument.defaultView;return t&amp;&amp;t.opener||(t=C),t.getComputedStyle(e)},Me=function(e,t,n){var r,i,o={};for(i in t)o[i]=e.style[i],e.style[i]=t[i];for(i in r=n.call(e),t)e.style[i]=o[i];return r},Ie=new RegExp(ne.join(&#34;|&#34;),&#34;i&#34;);function We(e,t,n){var r,i,o,a,s=e.style;return(n=n||Re(e))&amp;&amp;(&#34;&#34;!==(a=n.getPropertyValue(t)||n[t])||ie(e)||(a=S.style(e,t)),!y.pixelBoxStyles()&amp;&amp;Pe.test(a)&amp;&amp;Ie.test(t)&amp;&amp;(r=s.width,i=s.minWidth,o=s.maxWidth,s.minWidth=s.maxWidth=s.width=a,a=n.width,s.width=r,s.minWidth=i,s.maxWidth=o)),void 0!==a?a+&#34;&#34;:a}function Fe(e,t){return{get:function(){if(!e())return(this.get=t).apply(this,arguments);delete this.get}}}!function(){function e(){if(l){u.style.cssText=&#34;position:absolute;left:-11111px;width:60px;margin-top:1px;padding:0;border:0&#34;,l.style.cssText=&#34;position:relative;display:block;box-sizing:border-box;overflow:scroll;margin:auto;border:1px;padding:1px;width:60%;top:1%&#34;,re.appendChild(u).appendChild(l);var e=C.getComputedStyle(l);n=&#34;1%&#34;!==e.top,s=12===t(e.marginLeft),l.style.right=&#34;60%&#34;,o=36===t(e.right),r=36===t(e.width),l.style.position=&#34;absolute&#34;,i=12===t(l.offsetWidth/3),re.removeChild(u),l=null}}function t(e){return Math.round(parseFloat(e))}var n,r,i,o,a,s,u=E.createElement(&#34;div&#34;),l=E.createElement(&#34;div&#34;);l.style&amp;&amp;(l.style.backgroundClip=&#34;content-box&#34;,l.cloneNode(!0).style.backgroundClip=&#34;&#34;,y.clearCloneStyle=&#34;content-box&#34;===l.style.backgroundClip,S.extend(y,{boxSizingReliable:function(){return e(),r},pixelBoxStyles:function(){return e(),o},pixelPosition:function(){return e(),n},reliableMarginLeft:function(){return e(),s},scrollboxSize:function(){return e(),i},reliableTrDimensions:function(){var e,t,n,r;return null==a&amp;&amp;(e=E.createElement(&#34;table&#34;),t=E.createElement(&#34;tr&#34;),n=E.createElement(&#34;div&#34;),e.style.cssText=&#34;position:absolute;left:-11111px;border-collapse:separate&#34;,t.style.cssText=&#34;border:1px solid&#34;,t.style.height=&#34;1px&#34;,n.style.height=&#34;9px&#34;,n.style.display=&#34;block&#34;,re.appendChild(e).appendChild(t).appendChild(n),r=C.getComputedStyle(t),a=parseInt(r.height,10)+parseInt(r.borderTopWidth,10)+parseInt(r.borderBottomWidth,10)===t.offsetHeight,re.removeChild(e)),a}}))}();var Be=[&#34;Webkit&#34;,&#34;Moz&#34;,&#34;ms&#34;],$e=E.createElement(&#34;div&#34;).style,_e={};function ze(e){var t=S.cssProps[e]||_e[e];return t||(e in $e?e:_e[e]=function(e){var t=e[0].toUpperCase()+e.slice(1),n=Be.length;while(n--)if((e=Be[n]+t)in $e)return e}(e)||e)}var Ue=/^(none|table(?!-c[ea]).+)/,Xe=/^--/,Ve={position:&#34;absolute&#34;,visibility:&#34;hidden&#34;,display:&#34;block&#34;},Ge={letterSpacing:&#34;0&#34;,fontWeight:&#34;400&#34;};function Ye(e,t,n){var r=te.exec(t);return r?Math.max(0,r[2]-(n||0))+(r[3]||&#34;px&#34;):t}function Qe(e,t,n,r,i,o){var a=&#34;width&#34;===t?1:0,s=0,u=0;if(n===(r?&#34;border&#34;:&#34;content&#34;))return 0;for(;a&lt;4;a+=2)&#34;margin&#34;===n&amp;&amp;(u+=S.css(e,n+ne[a],!0,i)),r?(&#34;content&#34;===n&amp;&amp;(u-=S.css(e,&#34;padding&#34;+ne[a],!0,i)),&#34;margin&#34;!==n&amp;&amp;(u-=S.css(e,&#34;border&#34;+ne[a]+&#34;Width&#34;,!0,i))):(u+=S.css(e,&#34;padding&#34;+ne[a],!0,i),&#34;padding&#34;!==n?u+=S.css(e,&#34;border&#34;+ne[a]+&#34;Width&#34;,!0,i):s+=S.css(e,&#34;border&#34;+ne[a]+&#34;Width&#34;,!0,i));return!r&amp;&amp;0&lt;=o&amp;&amp;(u+=Math.max(0,Math.ceil(e[&#34;offset&#34;+t[0].toUpperCase()+t.slice(1)]-o-u-s-.5))||0),u}function Je(e,t,n){var r=Re(e),i=(!y.boxSizingReliable()||n)&amp;&amp;&#34;border-box&#34;===S.css(e,&#34;boxSizing&#34;,!1,r),o=i,a=We(e,t,r),s=&#34;offset&#34;+t[0].toUpperCase()+t.slice(1);if(Pe.test(a)){if(!n)return a;a=&#34;auto&#34;}return(!y.boxSizingReliable()&amp;&amp;i||!y.reliableTrDimensions()&amp;&amp;A(e,&#34;tr&#34;)||&#34;auto&#34;===a||!parseFloat(a)&amp;&amp;&#34;inline&#34;===S.css(e,&#34;display&#34;,!1,r))&amp;&amp;e.getClientRects().length&amp;&amp;(i=&#34;border-box&#34;===S.css(e,&#34;boxSizing&#34;,!1,r),(o=s in e)&amp;&amp;(a=e[s])),(a=parseFloat(a)||0)+Qe(e,t,n||(i?&#34;border&#34;:&#34;content&#34;),o,r,a)+&#34;px&#34;}function Ke(e,t,n,r,i){return new Ke.prototype.init(e,t,n,r,i)}S.extend({cssHooks:{opacity:{get:function(e,t){if(t){var n=We(e,&#34;opacity&#34;);return&#34;&#34;===n?&#34;1&#34;:n}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,gridArea:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnStart:!0,gridRow:!0,gridRowEnd:!0,gridRowStart:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{},style:function(e,t,n,r){if(e&amp;&amp;3!==e.nodeType&amp;&amp;8!==e.nodeType&amp;&amp;e.style){var i,o,a,s=X(t),u=Xe.test(t),l=e.style;if(u||(t=ze(s)),a=S.cssHooks[t]||S.cssHooks[s],void 0===n)return a&amp;&amp;&#34;get&#34;in a&amp;&amp;void 0!==(i=a.get(e,!1,r))?i:l[t];&#34;string&#34;===(o=typeof n)&amp;&amp;(i=te.exec(n))&amp;&amp;i[1]&amp;&amp;(n=se(e,t,i),o=&#34;number&#34;),null!=n&amp;&amp;n==n&amp;&amp;(&#34;number&#34;!==o||u||(n+=i&amp;&amp;i[3]||(S.cssNumber[s]?&#34;&#34;:&#34;px&#34;)),y.clearCloneStyle||&#34;&#34;!==n||0!==t.indexOf(&#34;background&#34;)||(l[t]=&#34;inherit&#34;),a&amp;&amp;&#34;set&#34;in a&amp;&amp;void 0===(n=a.set(e,n,r))||(u?l.setProperty(t,n):l[t]=n))}},css:function(e,t,n,r){var i,o,a,s=X(t);return Xe.test(t)||(t=ze(s)),(a=S.cssHooks[t]||S.cssHooks[s])&amp;&amp;&#34;get&#34;in a&amp;&amp;(i=a.get(e,!0,n)),void 0===i&amp;&amp;(i=We(e,t,r)),&#34;normal&#34;===i&amp;&amp;t in Ge&amp;&amp;(i=Ge[t]),&#34;&#34;===n||n?(o=parseFloat(i),!0===n||isFinite(o)?o||0:i):i}}),S.each([&#34;height&#34;,&#34;width&#34;],function(e,u){S.cssHooks[u]={get:function(e,t,n){if(t)return!Ue.test(S.css(e,&#34;display&#34;))||e.getClientRects().length&amp;&amp;e.getBoundingClientRect().width?Je(e,u,n):Me(e,Ve,function(){return Je(e,u,n)})},set:function(e,t,n){var r,i=Re(e),o=!y.scrollboxSize()&amp;&amp;&#34;absolute&#34;===i.position,a=(o||n)&amp;&amp;&#34;border-box&#34;===S.css(e,&#34;boxSizing&#34;,!1,i),s=n?Qe(e,u,n,a,i):0;return a&amp;&amp;o&amp;&amp;(s-=Math.ceil(e[&#34;offset&#34;+u[0].toUpperCase()+u.slice(1)]-parseFloat(i[u])-Qe(e,u,&#34;border&#34;,!1,i)-.5)),s&amp;&amp;(r=te.exec(t))&amp;&amp;&#34;px&#34;!==(r[3]||&#34;px&#34;)&amp;&amp;(e.style[u]=t,t=S.css(e,u)),Ye(0,t,s)}}}),S.cssHooks.marginLeft=Fe(y.reliableMarginLeft,function(e,t){if(t)return(parseFloat(We(e,&#34;marginLeft&#34;))||e.getBoundingClientRect().left-Me(e,{marginLeft:0},function(){return e.getBoundingClientRect().left}))+&#34;px&#34;}),S.each({margin:&#34;&#34;,padding:&#34;&#34;,border:&#34;Width&#34;},function(i,o){S.cssHooks[i+o]={expand:function(e){for(var t=0,n={},r=&#34;string&#34;==typeof e?e.split(&#34; &#34;):[e];t&lt;4;t++)n[i+ne[t]+o]=r[t]||r[t-2]||r[0];return n}},&#34;margin&#34;!==i&amp;&amp;(S.cssHooks[i+o].set=Ye)}),S.fn.extend({css:function(e,t){return $(this,function(e,t,n){var r,i,o={},a=0;if(Array.isArray(t)){for(r=Re(e),i=t.length;a&lt;i;a++)o[t[a]]=S.css(e,t[a],!1,r);return o}return void 0!==n?S.style(e,t,n):S.css(e,t)},e,t,1&lt;arguments.length)}}),((S.Tween=Ke).prototype={constructor:Ke,init:function(e,t,n,r,i,o){this.elem=e,this.prop=n,this.easing=i||S.easing._default,this.options=t,this.start=this.now=this.cur(),this.end=r,this.unit=o||(S.cssNumber[n]?&#34;&#34;:&#34;px&#34;)},cur:function(){var e=Ke.propHooks[this.prop];return e&amp;&amp;e.get?e.get(this):Ke.propHooks._default.get(this)},run:function(e){var t,n=Ke.propHooks[this.prop];return this.options.duration?this.pos=t=S.easing[this.easing](e,this.options.duration*e,0,1,this.options.duration):this.pos=t=e,this.now=(this.end-this.start)*t+this.start,this.options.step&amp;&amp;this.options.step.call(this.elem,this.now,this),n&amp;&amp;n.set?n.set(this):Ke.propHooks._default.set(this),this}}).init.prototype=Ke.prototype,(Ke.propHooks={_default:{get:function(e){var t;return 1!==e.elem.nodeType||null!=e.elem[e.prop]&amp;&amp;null==e.elem.style[e.prop]?e.elem[e.prop]:(t=S.css(e.elem,e.prop,&#34;&#34;))&amp;&amp;&#34;auto&#34;!==t?t:0},set:function(e){S.fx.step[e.prop]?S.fx.step[e.prop](e):1!==e.elem.nodeType||!S.cssHooks[e.prop]&amp;&amp;null==e.elem.style[ze(e.prop)]?e.elem[e.prop]=e.now:S.style(e.elem,e.prop,e.now+e.unit)}}}).scrollTop=Ke.propHooks.scrollLeft={set:function(e){e.elem.nodeType&amp;&amp;e.elem.parentNode&amp;&amp;(e.elem[e.prop]=e.now)}},S.easing={linear:function(e){return e},swing:function(e){return.5-Math.cos(e*Math.PI)/2},_default:&#34;swing&#34;},S.fx=Ke.prototype.init,S.fx.step={};var Ze,et,tt,nt,rt=/^(?:toggle|show|hide)$/,it=/queueHooks$/;function ot(){et&amp;&amp;(!1===E.hidden&amp;&amp;C.requestAnimationFrame?C.requestAnimationFrame(ot):C.setTimeout(ot,S.fx.interval),S.fx.tick())}function at(){return C.setTimeout(function(){Ze=void 0}),Ze=Date.now()}function st(e,t){var n,r=0,i={height:e};for(t=t?1:0;r&lt;4;r+=2-t)i[&#34;margin&#34;+(n=ne[r])]=i[&#34;padding&#34;+n]=e;return t&amp;&amp;(i.opacity=i.width=e),i}function ut(e,t,n){for(var r,i=(lt.tweeners[t]||[]).concat(lt.tweeners[&#34;*&#34;]),o=0,a=i.length;o&lt;a;o++)if(r=i[o].call(n,t,e))return r}function lt(o,e,t){var n,a,r=0,i=lt.prefilters.length,s=S.Deferred().always(function(){delete u.elem}),u=function(){if(a)return!1;for(var e=Ze||at(),t=Math.max(0,l.startTime+l.duration-e),n=1-(t/l.duration||0),r=0,i=l.tweens.length;r&lt;i;r++)l.tweens[r].run(n);return s.notifyWith(o,[l,n,t]),n&lt;1&amp;&amp;i?t:(i||s.notifyWith(o,[l,1,0]),s.resolveWith(o,[l]),!1)},l=s.promise({elem:o,props:S.extend({},e),opts:S.extend(!0,{specialEasing:{},easing:S.easing._default},t),originalProperties:e,originalOptions:t,startTime:Ze||at(),duration:t.duration,tweens:[],createTween:function(e,t){var n=S.Tween(o,l.opts,e,t,l.opts.specialEasing[e]||l.opts.easing);return l.tweens.push(n),n},stop:function(e){var t=0,n=e?l.tweens.length:0;if(a)return this;for(a=!0;t&lt;n;t++)l.tweens[t].run(1);return e?(s.notifyWith(o,[l,1,0]),s.resolveWith(o,[l,e])):s.rejectWith(o,[l,e]),this}}),c=l.props;for(!function(e,t){var n,r,i,o,a;for(n in e)if(i=t[r=X(n)],o=e[n],Array.isArray(o)&amp;&amp;(i=o[1],o=e[n]=o[0]),n!==r&amp;&amp;(e[r]=o,delete e[n]),(a=S.cssHooks[r])&amp;&amp;&#34;expand&#34;in a)for(n in o=a.expand(o),delete e[r],o)n in e||(e[n]=o[n],t[n]=i);else t[r]=i}(c,l.opts.specialEasing);r&lt;i;r++)if(n=lt.prefilters[r].call(l,o,c,l.opts))return m(n.stop)&amp;&amp;(S._queueHooks(l.elem,l.opts.queue).stop=n.stop.bind(n)),n;return S.map(c,ut,l),m(l.opts.start)&amp;&amp;l.opts.start.call(o,l),l.progress(l.opts.progress).done(l.opts.done,l.opts.complete).fail(l.opts.fail).always(l.opts.always),S.fx.timer(S.extend(u,{elem:o,anim:l,queue:l.opts.queue})),l}S.Animation=S.extend(lt,{tweeners:{&#34;*&#34;:[function(e,t){var n=this.createTween(e,t);return se(n.elem,e,te.exec(t),n),n}]},tweener:function(e,t){m(e)?(t=e,e=[&#34;*&#34;]):e=e.match(P);for(var n,r=0,i=e.length;r&lt;i;r++)n=e[r],lt.tweeners[n]=lt.tweeners[n]||[],lt.tweeners[n].unshift(t)},prefilters:[function(e,t,n){var r,i,o,a,s,u,l,c,f=&#34;width&#34;in t||&#34;height&#34;in t,p=this,d={},h=e.style,g=e.nodeType&amp;&amp;ae(e),v=Y.get(e,&#34;fxshow&#34;);for(r in n.queue||(null==(a=S._queueHooks(e,&#34;fx&#34;)).unqueued&amp;&amp;(a.unqueued=0,s=a.empty.fire,a.empty.fire=function(){a.unqueued||s()}),a.unqueued++,p.always(function(){p.always(function(){a.unqueued--,S.queue(e,&#34;fx&#34;).length||a.empty.fire()})})),t)if(i=t[r],rt.test(i)){if(delete t[r],o=o||&#34;toggle&#34;===i,i===(g?&#34;hide&#34;:&#34;show&#34;)){if(&#34;show&#34;!==i||!v||void 0===v[r])continue;g=!0}d[r]=v&amp;&amp;v[r]||S.style(e,r)}if((u=!S.isEmptyObject(t))||!S.isEmptyObject(d))for(r in f&amp;&amp;1===e.nodeType&amp;&amp;(n.overflow=[h.overflow,h.overflowX,h.overflowY],null==(l=v&amp;&amp;v.display)&amp;&amp;(l=Y.get(e,&#34;display&#34;)),&#34;none&#34;===(c=S.css(e,&#34;display&#34;))&amp;&amp;(l?c=l:(le([e],!0),l=e.style.display||l,c=S.css(e,&#34;display&#34;),le([e]))),(&#34;inline&#34;===c||&#34;inline-block&#34;===c&amp;&amp;null!=l)&amp;&amp;&#34;none&#34;===S.css(e,&#34;float&#34;)&amp;&amp;(u||(p.done(function(){h.display=l}),null==l&amp;&amp;(c=h.display,l=&#34;none&#34;===c?&#34;&#34;:c)),h.display=&#34;inline-block&#34;)),n.overflow&amp;&amp;(h.overflow=&#34;hidden&#34;,p.always(function(){h.overflow=n.overflow[0],h.overflowX=n.overflow[1],h.overflowY=n.overflow[2]})),u=!1,d)u||(v?&#34;hidden&#34;in v&amp;&amp;(g=v.hidden):v=Y.access(e,&#34;fxshow&#34;,{display:l}),o&amp;&amp;(v.hidden=!g),g&amp;&amp;le([e],!0),p.done(function(){for(r in g||le([e]),Y.remove(e,&#34;fxshow&#34;),d)S.style(e,r,d[r])})),u=ut(g?v[r]:0,r,p),r in v||(v[r]=u.start,g&amp;&amp;(u.end=u.start,u.start=0))}],prefilter:function(e,t){t?lt.prefilters.unshift(e):lt.prefilters.push(e)}}),S.speed=function(e,t,n){var r=e&amp;&amp;&#34;object&#34;==typeof e?S.extend({},e):{complete:n||!n&amp;&amp;t||m(e)&amp;&amp;e,duration:e,easing:n&amp;&amp;t||t&amp;&amp;!m(t)&amp;&amp;t};return S.fx.off?r.duration=0:&#34;number&#34;!=typeof r.duration&amp;&amp;(r.duration in S.fx.speeds?r.duration=S.fx.speeds[r.duration]:r.duration=S.fx.speeds._default),null!=r.queue&amp;&amp;!0!==r.queue||(r.queue=&#34;fx&#34;),r.old=r.complete,r.complete=function(){m(r.old)&amp;&amp;r.old.call(this),r.queue&amp;&amp;S.dequeue(this,r.queue)},r},S.fn.extend({fadeTo:function(e,t,n,r){return this.filter(ae).css(&#34;opacity&#34;,0).show().end().animate({opacity:t},e,n,r)},animate:function(t,e,n,r){var i=S.isEmptyObject(t),o=S.speed(e,n,r),a=function(){var e=lt(this,S.extend({},t),o);(i||Y.get(this,&#34;finish&#34;))&amp;&amp;e.stop(!0)};return a.finish=a,i||!1===o.queue?this.each(a):this.queue(o.queue,a)},stop:function(i,e,o){var a=function(e){var t=e.stop;delete e.stop,t(o)};return&#34;string&#34;!=typeof i&amp;&amp;(o=e,e=i,i=void 0),e&amp;&amp;this.queue(i||&#34;fx&#34;,[]),this.each(function(){var e=!0,t=null!=i&amp;&amp;i+&#34;queueHooks&#34;,n=S.timers,r=Y.get(this);if(t)r[t]&amp;&amp;r[t].stop&amp;&amp;a(r[t]);else for(t in r)r[t]&amp;&amp;r[t].stop&amp;&amp;it.test(t)&amp;&amp;a(r[t]);for(t=n.length;t--;)n[t].elem!==this||null!=i&amp;&amp;n[t].queue!==i||(n[t].anim.stop(o),e=!1,n.splice(t,1));!e&amp;&amp;o||S.dequeue(this,i)})},finish:function(a){return!1!==a&amp;&amp;(a=a||&#34;fx&#34;),this.each(function(){var e,t=Y.get(this),n=t[a+&#34;queue&#34;],r=t[a+&#34;queueHooks&#34;],i=S.timers,o=n?n.length:0;for(t.finish=!0,S.queue(this,a,[]),r&amp;&amp;r.stop&amp;&amp;r.stop.call(this,!0),e=i.length;e--;)i[e].elem===this&amp;&amp;i[e].queue===a&amp;&amp;(i[e].anim.stop(!0),i.splice(e,1));for(e=0;e&lt;o;e++)n[e]&amp;&amp;n[e].finish&amp;&amp;n[e].finish.call(this);delete t.finish})}}),S.each([&#34;toggle&#34;,&#34;show&#34;,&#34;hide&#34;],function(e,r){var i=S.fn[r];S.fn[r]=function(e,t,n){return null==e||&#34;boolean&#34;==typeof e?i.apply(this,arguments):this.animate(st(r,!0),e,t,n)}}),S.each({slideDown:st(&#34;show&#34;),slideUp:st(&#34;hide&#34;),slideToggle:st(&#34;toggle&#34;),fadeIn:{opacity:&#34;show&#34;},fadeOut:{opacity:&#34;hide&#34;},fadeToggle:{opacity:&#34;toggle&#34;}},function(e,r){S.fn[e]=function(e,t,n){return this.animate(r,e,t,n)}}),S.timers=[],S.fx.tick=function(){var e,t=0,n=S.timers;for(Ze=Date.now();t&lt;n.length;t++)(e=n[t])()||n[t]!==e||n.splice(t--,1);n.length||S.fx.stop(),Ze=void 0},S.fx.timer=function(e){S.timers.push(e),S.fx.start()},S.fx.interval=13,S.fx.start=function(){et||(et=!0,ot())},S.fx.stop=function(){et=null},S.fx.speeds={slow:600,fast:200,_default:400},S.fn.delay=function(r,e){return r=S.fx&amp;&amp;S.fx.speeds[r]||r,e=e||&#34;fx&#34;,this.queue(e,function(e,t){var n=C.setTimeout(e,r);t.stop=function(){C.clearTimeout(n)}})},tt=E.createElement(&#34;input&#34;),nt=E.createElement(&#34;select&#34;).appendChild(E.createElement(&#34;option&#34;)),tt.type=&#34;checkbox&#34;,y.checkOn=&#34;&#34;!==tt.value,y.optSelected=nt.selected,(tt=E.createElement(&#34;input&#34;)).value=&#34;t&#34;,tt.type=&#34;radio&#34;,y.radioValue=&#34;t&#34;===tt.value;var ct,ft=S.expr.attrHandle;S.fn.extend({attr:function(e,t){return $(this,S.attr,e,t,1&lt;arguments.length)},removeAttr:function(e){return this.each(function(){S.removeAttr(this,e)})}}),S.extend({attr:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&amp;&amp;8!==o&amp;&amp;2!==o)return&#34;undefined&#34;==typeof e.getAttribute?S.prop(e,t,n):(1===o&amp;&amp;S.isXMLDoc(e)||(i=S.attrHooks[t.toLowerCase()]||(S.expr.match.bool.test(t)?ct:void 0)),void 0!==n?null===n?void S.removeAttr(e,t):i&amp;&amp;&#34;set&#34;in i&amp;&amp;void 0!==(r=i.set(e,n,t))?r:(e.setAttribute(t,n+&#34;&#34;),n):i&amp;&amp;&#34;get&#34;in i&amp;&amp;null!==(r=i.get(e,t))?r:null==(r=S.find.attr(e,t))?void 0:r)},attrHooks:{type:{set:function(e,t){if(!y.radioValue&amp;&amp;&#34;radio&#34;===t&amp;&amp;A(e,&#34;input&#34;)){var n=e.value;return e.setAttribute(&#34;type&#34;,t),n&amp;&amp;(e.value=n),t}}}},removeAttr:function(e,t){var n,r=0,i=t&amp;&amp;t.match(P);if(i&amp;&amp;1===e.nodeType)while(n=i[r++])e.removeAttribute(n)}}),ct={set:function(e,t,n){return!1===t?S.removeAttr(e,n):e.setAttribute(n,n),n}},S.each(S.expr.match.bool.source.match(/\w+/g),function(e,t){var a=ft[t]||S.find.attr;ft[t]=function(e,t,n){var r,i,o=t.toLowerCase();return n||(i=ft[o],ft[o]=r,r=null!=a(e,t,n)?o:null,ft[o]=i),r}});var pt=/^(?:input|select|textarea|button)$/i,dt=/^(?:a|area)$/i;function ht(e){return(e.match(P)||[]).join(&#34; &#34;)}function gt(e){return e.getAttribute&amp;&amp;e.getAttribute(&#34;class&#34;)||&#34;&#34;}function vt(e){return Array.isArray(e)?e:&#34;string&#34;==typeof e&amp;&amp;e.match(P)||[]}S.fn.extend({prop:function(e,t){return $(this,S.prop,e,t,1&lt;arguments.length)},removeProp:function(e){return this.each(function(){delete this[S.propFix[e]||e]})}}),S.extend({prop:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&amp;&amp;8!==o&amp;&amp;2!==o)return 1===o&amp;&amp;S.isXMLDoc(e)||(t=S.propFix[t]||t,i=S.propHooks[t]),void 0!==n?i&amp;&amp;&#34;set&#34;in i&amp;&amp;void 0!==(r=i.set(e,n,t))?r:e[t]=n:i&amp;&amp;&#34;get&#34;in i&amp;&amp;null!==(r=i.get(e,t))?r:e[t]},propHooks:{tabIndex:{get:function(e){var t=S.find.attr(e,&#34;tabindex&#34;);return t?parseInt(t,10):pt.test(e.nodeName)||dt.test(e.nodeName)&amp;&amp;e.href?0:-1}}},propFix:{&#34;for&#34;:&#34;htmlFor&#34;,&#34;class&#34;:&#34;className&#34;}}),y.optSelected||(S.propHooks.selected={get:function(e){var t=e.parentNode;return t&amp;&amp;t.parentNode&amp;&amp;t.parentNode.selectedIndex,null},set:function(e){var t=e.parentNode;t&amp;&amp;(t.selectedIndex,t.parentNode&amp;&amp;t.parentNode.selectedIndex)}}),S.each([&#34;tabIndex&#34;,&#34;readOnly&#34;,&#34;maxLength&#34;,&#34;cellSpacing&#34;,&#34;cellPadding&#34;,&#34;rowSpan&#34;,&#34;colSpan&#34;,&#34;useMap&#34;,&#34;frameBorder&#34;,&#34;contentEditable&#34;],function(){S.propFix[this.toLowerCase()]=this}),S.fn.extend({addClass:function(t){var e,n,r,i,o,a,s,u=0;if(m(t))return this.each(function(e){S(this).addClass(t.call(this,e,gt(this)))});if((e=vt(t)).length)while(n=this[u++])if(i=gt(n),r=1===n.nodeType&amp;&amp;&#34; &#34;+ht(i)+&#34; &#34;){a=0;while(o=e[a++])r.indexOf(&#34; &#34;+o+&#34; &#34;)&lt;0&amp;&amp;(r+=o+&#34; &#34;);i!==(s=ht(r))&amp;&amp;n.setAttribute(&#34;class&#34;,s)}return this},removeClass:function(t){var e,n,r,i,o,a,s,u=0;if(m(t))return this.each(function(e){S(this).removeClass(t.call(this,e,gt(this)))});if(!arguments.length)return this.attr(&#34;class&#34;,&#34;&#34;);if((e=vt(t)).length)while(n=this[u++])if(i=gt(n),r=1===n.nodeType&amp;&amp;&#34; &#34;+ht(i)+&#34; &#34;){a=0;while(o=e[a++])while(-1&lt;r.indexOf(&#34; &#34;+o+&#34; &#34;))r=r.replace(&#34; &#34;+o+&#34; &#34;,&#34; &#34;);i!==(s=ht(r))&amp;&amp;n.setAttribute(&#34;class&#34;,s)}return this},toggleClass:function(i,t){var o=typeof i,a=&#34;string&#34;===o||Array.isArray(i);return&#34;boolean&#34;==typeof t&amp;&amp;a?t?this.addClass(i):this.removeClass(i):m(i)?this.each(function(e){S(this).toggleClass(i.call(this,e,gt(this),t),t)}):this.each(function(){var e,t,n,r;if(a){t=0,n=S(this),r=vt(i);while(e=r[t++])n.hasClass(e)?n.removeClass(e):n.addClass(e)}else void 0!==i&amp;&amp;&#34;boolean&#34;!==o||((e=gt(this))&amp;&amp;Y.set(this,&#34;__className__&#34;,e),this.setAttribute&amp;&amp;this.setAttribute(&#34;class&#34;,e||!1===i?&#34;&#34;:Y.get(this,&#34;__className__&#34;)||&#34;&#34;))})},hasClass:function(e){var t,n,r=0;t=&#34; &#34;+e+&#34; &#34;;while(n=this[r++])if(1===n.nodeType&amp;&amp;-1&lt;(&#34; &#34;+ht(gt(n))+&#34; &#34;).indexOf(t))return!0;return!1}});var yt=/\r/g;S.fn.extend({val:function(n){var r,e,i,t=this[0];return arguments.length?(i=m(n),this.each(function(e){var t;1===this.nodeType&amp;&amp;(null==(t=i?n.call(this,e,S(this).val()):n)?t=&#34;&#34;:&#34;number&#34;==typeof t?t+=&#34;&#34;:Array.isArray(t)&amp;&amp;(t=S.map(t,function(e){return null==e?&#34;&#34;:e+&#34;&#34;})),(r=S.valHooks[this.type]||S.valHooks[this.nodeName.toLowerCase()])&amp;&amp;&#34;set&#34;in r&amp;&amp;void 0!==r.set(this,t,&#34;value&#34;)||(this.value=t))})):t?(r=S.valHooks[t.type]||S.valHooks[t.nodeName.toLowerCase()])&amp;&amp;&#34;get&#34;in r&amp;&amp;void 0!==(e=r.get(t,&#34;value&#34;))?e:&#34;string&#34;==typeof(e=t.value)?e.replace(yt,&#34;&#34;):null==e?&#34;&#34;:e:void 0}}),S.extend({valHooks:{option:{get:function(e){var t=S.find.attr(e,&#34;value&#34;);return null!=t?t:ht(S.text(e))}},select:{get:function(e){var t,n,r,i=e.options,o=e.selectedIndex,a=&#34;select-one&#34;===e.type,s=a?null:[],u=a?o+1:i.length;for(r=o&lt;0?u:a?o:0;r&lt;u;r++)if(((n=i[r]).selected||r===o)&amp;&amp;!n.disabled&amp;&amp;(!n.parentNode.disabled||!A(n.parentNode,&#34;optgroup&#34;))){if(t=S(n).val(),a)return t;s.push(t)}return s},set:function(e,t){var n,r,i=e.options,o=S.makeArray(t),a=i.length;while(a--)((r=i[a]).selected=-1&lt;S.inArray(S.valHooks.option.get(r),o))&amp;&amp;(n=!0);return n||(e.selectedIndex=-1),o}}}}),S.each([&#34;radio&#34;,&#34;checkbox&#34;],function(){S.valHooks[this]={set:function(e,t){if(Array.isArray(t))return e.checked=-1&lt;S.inArray(S(e).val(),t)}},y.checkOn||(S.valHooks[this].get=function(e){return null===e.getAttribute(&#34;value&#34;)?&#34;on&#34;:e.value})}),y.focusin=&#34;onfocusin&#34;in C;var mt=/^(?:focusinfocus|focusoutblur)$/,xt=function(e){e.stopPropagation()};S.extend(S.event,{trigger:function(e,t,n,r){var i,o,a,s,u,l,c,f,p=[n||E],d=v.call(e,&#34;type&#34;)?e.type:e,h=v.call(e,&#34;namespace&#34;)?e.namespace.split(&#34;.&#34;):[];if(o=f=a=n=n||E,3!==n.nodeType&amp;&amp;8!==n.nodeType&amp;&amp;!mt.test(d+S.event.triggered)&amp;&amp;(-1&lt;d.indexOf(&#34;.&#34;)&amp;&amp;(d=(h=d.split(&#34;.&#34;)).shift(),h.sort()),u=d.indexOf(&#34;:&#34;)&lt;0&amp;&amp;&#34;on&#34;+d,(e=e[S.expando]?e:new S.Event(d,&#34;object&#34;==typeof e&amp;&amp;e)).isTrigger=r?2:3,e.namespace=h.join(&#34;.&#34;),e.rnamespace=e.namespace?new RegExp(&#34;(^|\\.)&#34;+h.join(&#34;\\.(?:.*\\.|)&#34;)+&#34;(\\.|$)&#34;):null,e.result=void 0,e.target||(e.target=n),t=null==t?[e]:S.makeArray(t,[e]),c=S.event.special[d]||{},r||!c.trigger||!1!==c.trigger.apply(n,t))){if(!r&amp;&amp;!c.noBubble&amp;&amp;!x(n)){for(s=c.delegateType||d,mt.test(s+d)||(o=o.parentNode);o;o=o.parentNode)p.push(o),a=o;a===(n.ownerDocument||E)&amp;&amp;p.push(a.defaultView||a.parentWindow||C)}i=0;while((o=p[i++])&amp;&amp;!e.isPropagationStopped())f=o,e.type=1&lt;i?s:c.bindType||d,(l=(Y.get(o,&#34;events&#34;)||Object.create(null))[e.type]&amp;&amp;Y.get(o,&#34;handle&#34;))&amp;&amp;l.apply(o,t),(l=u&amp;&amp;o[u])&amp;&amp;l.apply&amp;&amp;V(o)&amp;&amp;(e.result=l.apply(o,t),!1===e.result&amp;&amp;e.preventDefault());return e.type=d,r||e.isDefaultPrevented()||c._default&amp;&amp;!1!==c._default.apply(p.pop(),t)||!V(n)||u&amp;&amp;m(n[d])&amp;&amp;!x(n)&amp;&amp;((a=n[u])&amp;&amp;(n[u]=null),S.event.triggered=d,e.isPropagationStopped()&amp;&amp;f.addEventListener(d,xt),n[d](),e.isPropagationStopped()&amp;&amp;f.removeEventListener(d,xt),S.event.triggered=void 0,a&amp;&amp;(n[u]=a)),e.result}},simulate:function(e,t,n){var r=S.extend(new S.Event,n,{type:e,isSimulated:!0});S.event.trigger(r,null,t)}}),S.fn.extend({trigger:function(e,t){return this.each(function(){S.event.trigger(e,t,this)})},triggerHandler:function(e,t){var n=this[0];if(n)return S.event.trigger(e,t,n,!0)}}),y.focusin||S.each({focus:&#34;focusin&#34;,blur:&#34;focusout&#34;},function(n,r){var i=function(e){S.event.simulate(r,e.target,S.event.fix(e))};S.event.special[r]={setup:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r);t||e.addEventListener(n,i,!0),Y.access(e,r,(t||0)+1)},teardown:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r)-1;t?Y.access(e,r,t):(e.removeEventListener(n,i,!0),Y.remove(e,r))}}});var bt=C.location,wt={guid:Date.now()},Tt=/\?/;S.parseXML=function(e){var t,n;if(!e||&#34;string&#34;!=typeof e)return null;try{t=(new C.DOMParser).parseFromString(e,&#34;text/xml&#34;)}catch(e){}return n=t&amp;&amp;t.getElementsByTagName(&#34;parsererror&#34;)[0],t&amp;&amp;!n||S.error(&#34;Invalid XML: &#34;+(n?S.map(n.childNodes,function(e){return e.textContent}).join(&#34;\n&#34;):e)),t};var Ct=/\[\]$/,Et=/\r?\n/g,St=/^(?:submit|button|image|reset|file)$/i,kt=/^(?:input|select|textarea|keygen)/i;function At(n,e,r,i){var t;if(Array.isArray(e))S.each(e,function(e,t){r||Ct.test(n)?i(n,t):At(n+&#34;[&#34;+(&#34;object&#34;==typeof t&amp;&amp;null!=t?e:&#34;&#34;)+&#34;]&#34;,t,r,i)});else if(r||&#34;object&#34;!==w(e))i(n,e);else for(t in e)At(n+&#34;[&#34;+t+&#34;]&#34;,e[t],r,i)}S.param=function(e,t){var n,r=[],i=function(e,t){var n=m(t)?t():t;r[r.length]=encodeURIComponent(e)+&#34;=&#34;+encodeURIComponent(null==n?&#34;&#34;:n)};if(null==e)return&#34;&#34;;if(Array.isArray(e)||e.jquery&amp;&amp;!S.isPlainObject(e))S.each(e,function(){i(this.name,this.value)});else for(n in e)At(n,e[n],t,i);return r.join(&#34;&amp;&#34;)},S.fn.extend({serialize:function(){return S.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var e=S.prop(this,&#34;elements&#34;);return e?S.makeArray(e):this}).filter(function(){var e=this.type;return this.name&amp;&amp;!S(this).is(&#34;:disabled&#34;)&amp;&amp;kt.test(this.nodeName)&amp;&amp;!St.test(e)&amp;&amp;(this.checked||!pe.test(e))}).map(function(e,t){var n=S(this).val();return null==n?null:Array.isArray(n)?S.map(n,function(e){return{name:t.name,value:e.replace(Et,&#34;\r\n&#34;)}}):{name:t.name,value:n.replace(Et,&#34;\r\n&#34;)}}).get()}});var Nt=/%20/g,jt=/#.*$/,Dt=/([?&amp;])_=[^&amp;]*/,qt=/^(.*?):[ \t]*([^\r\n]*)$/gm,Lt=/^(?:GET|HEAD)$/,Ht=/^\/\//,Ot={},Pt={},Rt=&#34;*/&#34;.concat(&#34;*&#34;),Mt=E.createElement(&#34;a&#34;);function It(o){return function(e,t){&#34;string&#34;!=typeof e&amp;&amp;(t=e,e=&#34;*&#34;);var n,r=0,i=e.toLowerCase().match(P)||[];if(m(t))while(n=i[r++])&#34;+&#34;===n[0]?(n=n.slice(1)||&#34;*&#34;,(o[n]=o[n]||[]).unshift(t)):(o[n]=o[n]||[]).push(t)}}function Wt(t,i,o,a){var s={},u=t===Pt;function l(e){var r;return s[e]=!0,S.each(t[e]||[],function(e,t){var n=t(i,o,a);return&#34;string&#34;!=typeof n||u||s[n]?u?!(r=n):void 0:(i.dataTypes.unshift(n),l(n),!1)}),r}return l(i.dataTypes[0])||!s[&#34;*&#34;]&amp;&amp;l(&#34;*&#34;)}function Ft(e,t){var n,r,i=S.ajaxSettings.flatOptions||{};for(n in t)void 0!==t[n]&amp;&amp;((i[n]?e:r||(r={}))[n]=t[n]);return r&amp;&amp;S.extend(!0,e,r),e}Mt.href=bt.href,S.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:bt.href,type:&#34;GET&#34;,isLocal:/^(?:about|app|app-storage|.+-extension|file|res|widget):$/.test(bt.protocol),global:!0,processData:!0,async:!0,contentType:&#34;application/x-www-form-urlencoded; charset=UTF-8&#34;,accepts:{&#34;*&#34;:Rt,text:&#34;text/plain&#34;,html:&#34;text/html&#34;,xml:&#34;application/xml, text/xml&#34;,json:&#34;application/json, text/javascript&#34;},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responseFields:{xml:&#34;responseXML&#34;,text:&#34;responseText&#34;,json:&#34;responseJSON&#34;},converters:{&#34;* text&#34;:String,&#34;text html&#34;:!0,&#34;text json&#34;:JSON.parse,&#34;text xml&#34;:S.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(e,t){return t?Ft(Ft(e,S.ajaxSettings),t):Ft(S.ajaxSettings,e)},ajaxPrefilter:It(Ot),ajaxTransport:It(Pt),ajax:function(e,t){&#34;object&#34;==typeof e&amp;&amp;(t=e,e=void 0),t=t||{};var c,f,p,n,d,r,h,g,i,o,v=S.ajaxSetup({},t),y=v.context||v,m=v.context&amp;&amp;(y.nodeType||y.jquery)?S(y):S.event,x=S.Deferred(),b=S.Callbacks(&#34;once memory&#34;),w=v.statusCode||{},a={},s={},u=&#34;canceled&#34;,T={readyState:0,getResponseHeader:function(e){var t;if(h){if(!n){n={};while(t=qt.exec(p))n[t[1].toLowerCase()+&#34; &#34;]=(n[t[1].toLowerCase()+&#34; &#34;]||[]).concat(t[2])}t=n[e.toLowerCase()+&#34; &#34;]}return null==t?null:t.join(&#34;, &#34;)},getAllResponseHeaders:function(){return h?p:null},setRequestHeader:function(e,t){return null==h&amp;&amp;(e=s[e.toLowerCase()]=s[e.toLowerCase()]||e,a[e]=t),this},overrideMimeType:function(e){return null==h&amp;&amp;(v.mimeType=e),this},statusCode:function(e){var t;if(e)if(h)T.always(e[T.status]);else for(t in e)w[t]=[w[t],e[t]];return this},abort:function(e){var t=e||u;return c&amp;&amp;c.abort(t),l(0,t),this}};if(x.promise(T),v.url=((e||v.url||bt.href)+&#34;&#34;).replace(Ht,bt.protocol+&#34;//&#34;),v.type=t.method||t.type||v.method||v.type,v.dataTypes=(v.dataType||&#34;*&#34;).toLowerCase().match(P)||[&#34;&#34;],null==v.crossDomain){r=E.createElement(&#34;a&#34;);try{r.href=v.url,r.href=r.href,v.crossDomain=Mt.protocol+&#34;//&#34;+Mt.host!=r.protocol+&#34;//&#34;+r.host}catch(e){v.crossDomain=!0}}if(v.data&amp;&amp;v.processData&amp;&amp;&#34;string&#34;!=typeof v.data&amp;&amp;(v.data=S.param(v.data,v.traditional)),Wt(Ot,v,t,T),h)return T;for(i in(g=S.event&amp;&amp;v.global)&amp;&amp;0==S.active++&amp;&amp;S.event.trigger(&#34;ajaxStart&#34;),v.type=v.type.toUpperCase(),v.hasContent=!Lt.test(v.type),f=v.url.replace(jt,&#34;&#34;),v.hasContent?v.data&amp;&amp;v.processData&amp;&amp;0===(v.contentType||&#34;&#34;).indexOf(&#34;application/x-www-form-urlencoded&#34;)&amp;&amp;(v.data=v.data.replace(Nt,&#34;+&#34;)):(o=v.url.slice(f.length),v.data&amp;&amp;(v.processData||&#34;string&#34;==typeof v.data)&amp;&amp;(f+=(Tt.test(f)?&#34;&amp;&#34;:&#34;?&#34;)+v.data,delete v.data),!1===v.cache&amp;&amp;(f=f.replace(Dt,&#34;$1&#34;),o=(Tt.test(f)?&#34;&amp;&#34;:&#34;?&#34;)+&#34;_=&#34;+wt.guid+++o),v.url=f+o),v.ifModified&amp;&amp;(S.lastModified[f]&amp;&amp;T.setRequestHeader(&#34;If-Modified-Since&#34;,S.lastModified[f]),S.etag[f]&amp;&amp;T.setRequestHeader(&#34;If-None-Match&#34;,S.etag[f])),(v.data&amp;&amp;v.hasContent&amp;&amp;!1!==v.contentType||t.contentType)&amp;&amp;T.setRequestHeader(&#34;Content-Type&#34;,v.contentType),T.setRequestHeader(&#34;Accept&#34;,v.dataTypes[0]&amp;&amp;v.accepts[v.dataTypes[0]]?v.accepts[v.dataTypes[0]]+(&#34;*&#34;!==v.dataTypes[0]?&#34;, &#34;+Rt+&#34;; q=0.01&#34;:&#34;&#34;):v.accepts[&#34;*&#34;]),v.headers)T.setRequestHeader(i,v.headers[i]);if(v.beforeSend&amp;&amp;(!1===v.beforeSend.call(y,T,v)||h))return T.abort();if(u=&#34;abort&#34;,b.add(v.complete),T.done(v.success),T.fail(v.error),c=Wt(Pt,v,t,T)){if(T.readyState=1,g&amp;&amp;m.trigger(&#34;ajaxSend&#34;,[T,v]),h)return T;v.async&amp;&amp;0&lt;v.timeout&amp;&amp;(d=C.setTimeout(function(){T.abort(&#34;timeout&#34;)},v.timeout));try{h=!1,c.send(a,l)}catch(e){if(h)throw e;l(-1,e)}}else l(-1,&#34;No Transport&#34;);function l(e,t,n,r){var i,o,a,s,u,l=t;h||(h=!0,d&amp;&amp;C.clearTimeout(d),c=void 0,p=r||&#34;&#34;,T.readyState=0&lt;e?4:0,i=200&lt;=e&amp;&amp;e&lt;300||304===e,n&amp;&amp;(s=function(e,t,n){var r,i,o,a,s=e.contents,u=e.dataTypes;while(&#34;*&#34;===u[0])u.shift(),void 0===r&amp;&amp;(r=e.mimeType||t.getResponseHeader(&#34;Content-Type&#34;));if(r)for(i in s)if(s[i]&amp;&amp;s[i].test(r)){u.unshift(i);break}if(u[0]in n)o=u[0];else{for(i in n){if(!u[0]||e.converters[i+&#34; &#34;+u[0]]){o=i;break}a||(a=i)}o=o||a}if(o)return o!==u[0]&amp;&amp;u.unshift(o),n[o]}(v,T,n)),!i&amp;&amp;-1&lt;S.inArray(&#34;script&#34;,v.dataTypes)&amp;&amp;S.inArray(&#34;json&#34;,v.dataTypes)&lt;0&amp;&amp;(v.converters[&#34;text script&#34;]=function(){}),s=function(e,t,n,r){var i,o,a,s,u,l={},c=e.dataTypes.slice();if(c[1])for(a in e.converters)l[a.toLowerCase()]=e.converters[a];o=c.shift();while(o)if(e.responseFields[o]&amp;&amp;(n[e.responseFields[o]]=t),!u&amp;&amp;r&amp;&amp;e.dataFilter&amp;&amp;(t=e.dataFilter(t,e.dataType)),u=o,o=c.shift())if(&#34;*&#34;===o)o=u;else if(&#34;*&#34;!==u&amp;&amp;u!==o){if(!(a=l[u+&#34; &#34;+o]||l[&#34;* &#34;+o]))for(i in l)if((s=i.split(&#34; &#34;))[1]===o&amp;&amp;(a=l[u+&#34; &#34;+s[0]]||l[&#34;* &#34;+s[0]])){!0===a?a=l[i]:!0!==l[i]&amp;&amp;(o=s[0],c.unshift(s[1]));break}if(!0!==a)if(a&amp;&amp;e[&#34;throws&#34;])t=a(t);else try{t=a(t)}catch(e){return{state:&#34;parsererror&#34;,error:a?e:&#34;No conversion from &#34;+u+&#34; to &#34;+o}}}return{state:&#34;success&#34;,data:t}}(v,s,T,i),i?(v.ifModified&amp;&amp;((u=T.getResponseHeader(&#34;Last-Modified&#34;))&amp;&amp;(S.lastModified[f]=u),(u=T.getResponseHeader(&#34;etag&#34;))&amp;&amp;(S.etag[f]=u)),204===e||&#34;HEAD&#34;===v.type?l=&#34;nocontent&#34;:304===e?l=&#34;notmodified&#34;:(l=s.state,o=s.data,i=!(a=s.error))):(a=l,!e&amp;&amp;l||(l=&#34;error&#34;,e&lt;0&amp;&amp;(e=0))),T.status=e,T.statusText=(t||l)+&#34;&#34;,i?x.resolveWith(y,[o,l,T]):x.rejectWith(y,[T,l,a]),T.statusCode(w),w=void 0,g&amp;&amp;m.trigger(i?&#34;ajaxSuccess&#34;:&#34;ajaxError&#34;,[T,v,i?o:a]),b.fireWith(y,[T,l]),g&amp;&amp;(m.trigger(&#34;ajaxComplete&#34;,[T,v]),--S.active||S.event.trigger(&#34;ajaxStop&#34;)))}return T},getJSON:function(e,t,n){return S.get(e,t,n,&#34;json&#34;)},getScript:function(e,t){return S.get(e,void 0,t,&#34;script&#34;)}}),S.each([&#34;get&#34;,&#34;post&#34;],function(e,i){S[i]=function(e,t,n,r){return m(t)&amp;&amp;(r=r||n,n=t,t=void 0),S.ajax(S.extend({url:e,type:i,dataType:r,data:t,success:n},S.isPlainObject(e)&amp;&amp;e))}}),S.ajaxPrefilter(function(e){var t;for(t in e.headers)&#34;content-type&#34;===t.toLowerCase()&amp;&amp;(e.contentType=e.headers[t]||&#34;&#34;)}),S._evalUrl=function(e,t,n){return S.ajax({url:e,type:&#34;GET&#34;,dataType:&#34;script&#34;,cache:!0,async:!1,global:!1,converters:{&#34;text script&#34;:function(){}},dataFilter:function(e){S.globalEval(e,t,n)}})},S.fn.extend({wrapAll:function(e){var t;return this[0]&amp;&amp;(m(e)&amp;&amp;(e=e.call(this[0])),t=S(e,this[0].ownerDocument).eq(0).clone(!0),this[0].parentNode&amp;&amp;t.insertBefore(this[0]),t.map(function(){var e=this;while(e.firstElementChild)e=e.firstElementChild;return e}).append(this)),this},wrapInner:function(n){return m(n)?this.each(function(e){S(this).wrapInner(n.call(this,e))}):this.each(function(){var e=S(this),t=e.contents();t.length?t.wrapAll(n):e.append(n)})},wrap:function(t){var n=m(t);return this.each(function(e){S(this).wrapAll(n?t.call(this,e):t)})},unwrap:function(e){return this.parent(e).not(&#34;body&#34;).each(function(){S(this).replaceWith(this.childNodes)}),this}}),S.expr.pseudos.hidden=function(e){return!S.expr.pseudos.visible(e)},S.expr.pseudos.visible=function(e){return!!(e.offsetWidth||e.offsetHeight||e.getClientRects().length)},S.ajaxSettings.xhr=function(){try{return new C.XMLHttpRequest}catch(e){}};var Bt={0:200,1223:204},$t=S.ajaxSettings.xhr();y.cors=!!$t&amp;&amp;&#34;withCredentials&#34;in $t,y.ajax=$t=!!$t,S.ajaxTransport(function(i){var o,a;if(y.cors||$t&amp;&amp;!i.crossDomain)return{send:function(e,t){var n,r=i.xhr();if(r.open(i.type,i.url,i.async,i.username,i.password),i.xhrFields)for(n in i.xhrFields)r[n]=i.xhrFields[n];for(n in i.mimeType&amp;&amp;r.overrideMimeType&amp;&amp;r.overrideMimeType(i.mimeType),i.crossDomain||e[&#34;X-Requested-With&#34;]||(e[&#34;X-Requested-With&#34;]=&#34;XMLHttpRequest&#34;),e)r.setRequestHeader(n,e[n]);o=function(e){return function(){o&amp;&amp;(o=a=r.onload=r.onerror=r.onabort=r.ontimeout=r.onreadystatechange=null,&#34;abort&#34;===e?r.abort():&#34;error&#34;===e?&#34;number&#34;!=typeof r.status?t(0,&#34;error&#34;):t(r.status,r.statusText):t(Bt[r.status]||r.status,r.statusText,&#34;text&#34;!==(r.responseType||&#34;text&#34;)||&#34;string&#34;!=typeof r.responseText?{binary:r.response}:{text:r.responseText},r.getAllResponseHeaders()))}},r.onload=o(),a=r.onerror=r.ontimeout=o(&#34;error&#34;),void 0!==r.onabort?r.onabort=a:r.onreadystatechange=function(){4===r.readyState&amp;&amp;C.setTimeout(function(){o&amp;&amp;a()})},o=o(&#34;abort&#34;);try{r.send(i.hasContent&amp;&amp;i.data||null)}catch(e){if(o)throw e}},abort:function(){o&amp;&amp;o()}}}),S.ajaxPrefilter(function(e){e.crossDomain&amp;&amp;(e.contents.script=!1)}),S.ajaxSetup({accepts:{script:&#34;text/javascript, application/javascript, application/ecmascript, application/x-ecmascript&#34;},contents:{script:/\b(?:java|ecma)script\b/},converters:{&#34;text script&#34;:function(e){return S.globalEval(e),e}}}),S.ajaxPrefilter(&#34;script&#34;,function(e){void 0===e.cache&amp;&amp;(e.cache=!1),e.crossDomain&amp;&amp;(e.type=&#34;GET&#34;)}),S.ajaxTransport(&#34;script&#34;,function(n){var r,i;if(n.crossDomain||n.scriptAttrs)return{send:function(e,t){r=S(&#34;&lt;script&gt;&#34;).attr(n.scriptAttrs||{}).prop({charset:n.scriptCharset,src:n.url}).on(&#34;load error&#34;,i=function(e){r.remove(),i=null,e&amp;&amp;t(&#34;error&#34;===e.type?404:200,e.type)}),E.head.appendChild(r[0])},abort:function(){i&amp;&amp;i()}}});var _t,zt=[],Ut=/(=)\?(?=&amp;|$)|\?\?/;S.ajaxSetup({jsonp:&#34;callback&#34;,jsonpCallback:function(){var e=zt.pop()||S.expando+&#34;_&#34;+wt.guid++;return this[e]=!0,e}}),S.ajaxPrefilter(&#34;json jsonp&#34;,function(e,t,n){var r,i,o,a=!1!==e.jsonp&amp;&amp;(Ut.test(e.url)?&#34;url&#34;:&#34;string&#34;==typeof e.data&amp;&amp;0===(e.contentType||&#34;&#34;).indexOf(&#34;application/x-www-form-urlencoded&#34;)&amp;&amp;Ut.test(e.data)&amp;&amp;&#34;data&#34;);if(a||&#34;jsonp&#34;===e.dataTypes[0])return r=e.jsonpCallback=m(e.jsonpCallback)?e.jsonpCallback():e.jsonpCallback,a?e[a]=e[a].replace(Ut,&#34;$1&#34;+r):!1!==e.jsonp&amp;&amp;(e.url+=(Tt.test(e.url)?&#34;&amp;&#34;:&#34;?&#34;)+e.jsonp+&#34;=&#34;+r),e.converters[&#34;script json&#34;]=function(){return o||S.error(r+&#34; was not called&#34;),o[0]},e.dataTypes[0]=&#34;json&#34;,i=C[r],C[r]=function(){o=arguments},n.always(function(){void 0===i?S(C).removeProp(r):C[r]=i,e[r]&amp;&amp;(e.jsonpCallback=t.jsonpCallback,zt.push(r)),o&amp;&amp;m(i)&amp;&amp;i(o[0]),o=i=void 0}),&#34;script&#34;}),y.createHTMLDocument=((_t=E.implementation.createHTMLDocument(&#34;&#34;).body).innerHTML=&#34;&lt;form&gt;&lt;/form&gt;&lt;form&gt;&lt;/form&gt;&#34;,2===_t.childNodes.length),S.parseHTML=function(e,t,n){return&#34;string&#34;!=typeof e?[]:(&#34;boolean&#34;==typeof t&amp;&amp;(n=t,t=!1),t||(y.createHTMLDocument?((r=(t=E.implementation.createHTMLDocument(&#34;&#34;)).createElement(&#34;base&#34;)).href=E.location.href,t.head.appendChild(r)):t=E),o=!n&amp;&amp;[],(i=N.exec(e))?[t.createElement(i[1])]:(i=xe([e],t,o),o&amp;&amp;o.length&amp;&amp;S(o).remove(),S.merge([],i.childNodes)));var r,i,o},S.fn.load=function(e,t,n){var r,i,o,a=this,s=e.indexOf(&#34; &#34;);return-1&lt;s&amp;&amp;(r=ht(e.slice(s)),e=e.slice(0,s)),m(t)?(n=t,t=void 0):t&amp;&amp;&#34;object&#34;==typeof t&amp;&amp;(i=&#34;POST&#34;),0&lt;a.length&amp;&amp;S.ajax({url:e,type:i||&#34;GET&#34;,dataType:&#34;html&#34;,data:t}).done(function(e){o=arguments,a.html(r?S(&#34;&lt;div&gt;&#34;).append(S.parseHTML(e)).find(r):e)}).always(n&amp;&amp;function(e,t){a.each(function(){n.apply(this,o||[e.responseText,t,e])})}),this},S.expr.pseudos.animated=function(t){return S.grep(S.timers,function(e){return t===e.elem}).length},S.offset={setOffset:function(e,t,n){var r,i,o,a,s,u,l=S.css(e,&#34;position&#34;),c=S(e),f={};&#34;static&#34;===l&amp;&amp;(e.style.position=&#34;relative&#34;),s=c.offset(),o=S.css(e,&#34;top&#34;),u=S.css(e,&#34;left&#34;),(&#34;absolute&#34;===l||&#34;fixed&#34;===l)&amp;&amp;-1&lt;(o+u).indexOf(&#34;auto&#34;)?(a=(r=c.position()).top,i=r.left):(a=parseFloat(o)||0,i=parseFloat(u)||0),m(t)&amp;&amp;(t=t.call(e,n,S.extend({},s))),null!=t.top&amp;&amp;(f.top=t.top-s.top+a),null!=t.left&amp;&amp;(f.left=t.left-s.left+i),&#34;using&#34;in t?t.using.call(e,f):c.css(f)}},S.fn.extend({offset:function(t){if(arguments.length)return void 0===t?this:this.each(function(e){S.offset.setOffset(this,t,e)});var e,n,r=this[0];return r?r.getClientRects().length?(e=r.getBoundingClientRect(),n=r.ownerDocument.defaultView,{top:e.top+n.pageYOffset,left:e.left+n.pageXOffset}):{top:0,left:0}:void 0},position:function(){if(this[0]){var e,t,n,r=this[0],i={top:0,left:0};if(&#34;fixed&#34;===S.css(r,&#34;position&#34;))t=r.getBoundingClientRect();else{t=this.offset(),n=r.ownerDocument,e=r.offsetParent||n.documentElement;while(e&amp;&amp;(e===n.body||e===n.documentElement)&amp;&amp;&#34;static&#34;===S.css(e,&#34;position&#34;))e=e.parentNode;e&amp;&amp;e!==r&amp;&amp;1===e.nodeType&amp;&amp;((i=S(e).offset()).top+=S.css(e,&#34;borderTopWidth&#34;,!0),i.left+=S.css(e,&#34;borderLeftWidth&#34;,!0))}return{top:t.top-i.top-S.css(r,&#34;marginTop&#34;,!0),left:t.left-i.left-S.css(r,&#34;marginLeft&#34;,!0)}}},offsetParent:function(){return this.map(function(){var e=this.offsetParent;while(e&amp;&amp;&#34;static&#34;===S.css(e,&#34;position&#34;))e=e.offsetParent;return e||re})}}),S.each({scrollLeft:&#34;pageXOffset&#34;,scrollTop:&#34;pageYOffset&#34;},function(t,i){var o=&#34;pageYOffset&#34;===i;S.fn[t]=function(e){return $(this,function(e,t,n){var r;if(x(e)?r=e:9===e.nodeType&amp;&amp;(r=e.defaultView),void 0===n)return r?r[i]:e[t];r?r.scrollTo(o?r.pageXOffset:n,o?n:r.pageYOffset):e[t]=n},t,e,arguments.length)}}),S.each([&#34;top&#34;,&#34;left&#34;],function(e,n){S.cssHooks[n]=Fe(y.pixelPosition,function(e,t){if(t)return t=We(e,n),Pe.test(t)?S(e).position()[n]+&#34;px&#34;:t})}),S.each({Height:&#34;height&#34;,Width:&#34;width&#34;},function(a,s){S.each({padding:&#34;inner&#34;+a,content:s,&#34;&#34;:&#34;outer&#34;+a},function(r,o){S.fn[o]=function(e,t){var n=arguments.length&amp;&amp;(r||&#34;boolean&#34;!=typeof e),i=r||(!0===e||!0===t?&#34;margin&#34;:&#34;border&#34;);return $(this,function(e,t,n){var r;return x(e)?0===o.indexOf(&#34;outer&#34;)?e[&#34;inner&#34;+a]:e.document.documentElement[&#34;client&#34;+a]:9===e.nodeType?(r=e.documentElement,Math.max(e.body[&#34;scroll&#34;+a],r[&#34;scroll&#34;+a],e.body[&#34;offset&#34;+a],r[&#34;offset&#34;+a],r[&#34;client&#34;+a])):void 0===n?S.css(e,t,i):S.style(e,t,n,i)},s,n?e:void 0,n)}})}),S.each([&#34;ajaxStart&#34;,&#34;ajaxStop&#34;,&#34;ajaxComplete&#34;,&#34;ajaxError&#34;,&#34;ajaxSuccess&#34;,&#34;ajaxSend&#34;],function(e,t){S.fn[t]=function(e){return this.on(t,e)}}),S.fn.extend({bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return 1===arguments.length?this.off(e,&#34;**&#34;):this.off(t,e||&#34;**&#34;,n)},hover:function(e,t){return this.mouseenter(e).mouseleave(t||e)}}),S.each(&#34;blur focus focusin focusout resize scroll click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup contextmenu&#34;.split(&#34; &#34;),function(e,n){S.fn[n]=function(e,t){return 0&lt;arguments.length?this.on(n,null,e,t):this.trigger(n)}});var Xt=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g;S.proxy=function(e,t){var n,r,i;if(&#34;string&#34;==typeof t&amp;&amp;(n=e[t],t=e,e=n),m(e))return r=s.call(arguments,2),(i=function(){return e.apply(t||this,r.concat(s.call(arguments)))}).guid=e.guid=e.guid||S.guid++,i},S.holdReady=function(e){e?S.readyWait++:S.ready(!0)},S.isArray=Array.isArray,S.parseJSON=JSON.parse,S.nodeName=A,S.isFunction=m,S.isWindow=x,S.camelCase=X,S.type=w,S.now=Date.now,S.isNumeric=function(e){var t=S.type(e);return(&#34;number&#34;===t||&#34;string&#34;===t)&amp;&amp;!isNaN(e-parseFloat(e))},S.trim=function(e){return null==e?&#34;&#34;:(e+&#34;&#34;).replace(Xt,&#34;&#34;)},&#34;function&#34;==typeof define&amp;&amp;define.amd&amp;&amp;define(&#34;jquery&#34;,[],function(){return S});var Vt=C.jQuery,Gt=C.$;return S.noConflict=function(e){return C.$===S&amp;&amp;(C.$=Gt),e&amp;&amp;C.jQuery===S&amp;&amp;(C.jQuery=Vt),S},&#34;undefined&#34;==typeof e&amp;&amp;(C.jQuery=C.$=S),S});
&lt;/script&gt;
&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1&#34; /&gt;
&lt;style type=&#34;text/css&#34;&gt;html{font-family:sans-serif;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:700}dfn{font-style:italic}h1{margin:.67em 0;font-size:2em}mark{color:#000;background:#ff0}small{font-size:80%}sub,sup{position:relative;font-size:75%;line-height:0;vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{height:0;-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}button,input,optgroup,select,textarea{margin:0;font:inherit;color:inherit}button{overflow:visible}button,select{text-transform:none}button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}input{line-height:normal}input[type=checkbox],input[type=radio]{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;padding:0}input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto}input[type=search]{-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;-webkit-appearance:textfield}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none}fieldset{padding:.35em .625em .75em;margin:0 2px;border:1px solid silver}legend{padding:0;border:0}textarea{overflow:auto}optgroup{font-weight:700}table{border-spacing:0;border-collapse:collapse}td,th{padding:0}@media print{*,:after,:before{color:#000!important;text-shadow:none!important;background:0 0!important;-webkit-box-shadow:none!important;box-shadow:none!important}a,a:visited{text-decoration:underline}a[href]:after{content:&#34; (&#34; attr(href) &#34;)&#34;}abbr[title]:after{content:&#34; (&#34; attr(title) &#34;)&#34;}a[href^=&#34;javascript:&#34;]:after,a[href^=&#34;#&#34;]:after{content:&#34;&#34;}blockquote,pre{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}img,tr{page-break-inside:avoid}img{max-width:100%!important}h2,h3,p{orphans:3;widows:3}h2,h3{page-break-after:avoid}.navbar{display:none}.btn&gt;.caret,.dropup&gt;.btn&gt;.caret{border-top-color:#000!important}.label{border:1px solid #000}.table{border-collapse:collapse!important}.table td,.table th{background-color:#fff!important}.table-bordered td,.table-bordered th{border:1px solid #ddd!important}}@font-face{font-family:&#39;Glyphicons Halflings&#39;;src:url(data:application/vnd.ms-fontobject;base64,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);src:url(data:application/vnd.ms-fontobject;base64,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) format(&#39;embedded-opentype&#39;),url(data:font/woff;base64,d09GRgABAAAAAFuAAA8AAAAAsVwAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAABGRlRNAAABWAAAABwAAAAcbSqX3EdERUYAAAF0AAAAHwAAACABRAAET1MvMgAAAZQAAABFAAAAYGe5a4ljbWFwAAAB3AAAAsAAAAZy2q3jgWN2dCAAAAScAAAABAAAAAQAKAL4Z2FzcAAABKAAAAAIAAAACP//AANnbHlmAAAEqAAATRcAAJSkfV3Cb2hlYWQAAFHAAAAANAAAADYFTS/YaGhlYQAAUfQAAAAcAAAAJApEBBFobXR4AABSEAAAAU8AAAN00scgYGxvY2EAAFNgAAACJwAAAjBv+5XObWF4cAAAVYgAAAAgAAAAIAFqANhuYW1lAABVqAAAAZ4AAAOisyygm3Bvc3QAAFdIAAAELQAACtG6o+U1d2ViZgAAW3gAAAAGAAAABsMYVFAAAAABAAAAAMw9os8AAAAA0HaBdQAAAADQdnOXeNpjYGRgYOADYgkGEGBiYGRgZBQDkixgHgMABUgASgB42mNgZulmnMDAysDCzMN0gYGBIQpCMy5hMGLaAeQDpRCACYkd6h3ux+DAoPD/P/OB/wJAdSIM1UBhRiQlCgyMADGWCwwAAAB42u2UP2hTQRzHf5ekaVPExv6JjW3fvTQ0sa3QLA5xylBLgyBx0gzSWEUaXbIoBBQyCQGHLqXUqYNdtIIgIg5FHJxEtwqtpbnfaV1E1KFaSvX5vVwGEbW6OPngk8/vvXfv7pt3v4SImojIDw6BViKxRgIVBaZwVdSv+xvXA+Iuzqcog2cOkkvDNE8Lbqs74k64i+5Sf3u8Z2AnIRLbyVCyTflVSEXVoEqrrMqrgiqqsqqqWQ5xlAc5zWOc5TwXucxVnuE5HdQhHdFRHdNJndZZndeFLc/zsKJLQ/WV6BcrCdWkwspVKZVROaw0qUqqoqZZcJhdTnGGxznHBS5xhad5VhNWCuturBTXKZ3RObuS98pb9c57k6ql9rp2v1as5deb1r6s9q1GV2IrHSt73T631424YXzjgPwqt+Rn+VG+lRvyirwsS/KCPCfPytPypDwhj8mjctRZd9acF86y89x55jxxHjkPnXstXfbt/pNjj/nwXW+cHa6/SYvZ7yEwbDYazDcIgoUGzY3h2HtqgUcs1AFPWKgTXrRQF7xkoQhRf7uF9hPFeyzUTTSwY6EoUUJY6AC8bSGMS4Ys1Au3WaiPSGGsMtkdGH2rzJgYHAaYjxIwQqtB1CnYkEZ9BM6ALOpROAfyqI/DBQudgidBETXuqRIooz4DV0AV9UV4GsyivkTEyMMmw1UYGdhkuAYjA5sMGMvIwCbDDRgZeAz1TXgcmDy3YeRhk+cOjCxsMjyAkYFNhscwMrDJ8BQ2886gXoaRhedQvyTSkDZ7uA6HLLQBI5vGntAbGHugTc53cMxC7+E4SKL+ACOzNpk3YWTWJid+iRo5NXIKM3fBItAPW55FdJLY3FeHBDr90606JCIU9Jk+Ms3/Y/8L8jUq3y79bJ/0/+ROoP4v9v/4/mj+i7HBXUd0/elU6IHfHt8Aj9EPGAAoAvgAAAAB//8AAnjaxb0JfBvVtTA+dxaN1hltI1m2ZVuSJVneLVlSHCdy9oTEWchqtrBEJRAgCYEsQNhC2EsbWmpI2dqkQBoSYgKlpaQthVL0yusrpW77aEubfq/ly+ujvJampSTW5Dvnzmi1E+jr//3+Xmbu3Llz77nnbuece865DMu0MAy5jGtiOEZkOp8lTNeUwyLP/DH+rEH41ZTDHAtB5lkOowWMPiwayNiUwwTjE46AI5xwhFrINPXYn/7ENY0dbWHfZAiTZbL8ID/InAd5xz2NpIH4STpDGonHIJNE3OP1KG4ISaSNeBuITAyRLgIxoiEUhFAnmUpEiXSRSGqAQEw0kuyFUIb0k2gnGSApyBFi0il2SI5YLGb5MdFjXCey4mNHzQ7WwLGEdZiPPgYR64we8THZHAt+wnT84D/x8YTpGPgheKH4CMEDVF9xBOIeP3EbQgGH29BGgpGkIxCMTCW9qUTA0Zsir+QUP1mt+P2KusevwIO6Bx/Iaj8/OD5O0VNrZW2EsqZBWbO1skRiEKE0DdlKKaSVO5VAuRpqk8VQJAqY7ydxaK44YJvrO2EWjOoDBoFYzQbDNkON+UbiKoRkywMWWf1j4bEY2iIY1AeMgvmEz/kVo9v4FSc/aMZMrFbjl4zWLL0+Y5FlyzNlEVYDudJohg8gPUP7kcB/mn+G6cd+5PV4Q72dXCgocWJADBgUuDTwiXiGSyZo14HOEQ2lE6k0XDIEusexDzZOMXwt1Dutz+tqmxTvlskNWXXUQIbhaurum9GrePqm9Yaeabjkiqf+bUvzDOvb2Y1E+EX2DnemcTP/zLcuu7xjQXdAtjR0Lo5n4/Hs/GtntMlysHt+29NXbH6se//WbFcyu+r28H0MwzI30DYeYTLMXIA2EG8QlHpAsyS0EfEToR0a3utIxFPJ3kiIHCCrZ66b0e2xEmL1dM9YN/MwS5p01N5jMX/BLKt/1R83l0LyC29M6+iYxo/UNg/EF7c2WyyW5tYl8WnhWg2/hyySbD5UhnDyS7OcU0dnrFw+DfGdI7v4QfYIIzOMq9hFtY55gmvC7jZ2FK7sEdrn6IXBuucYhjsGdQ8z0yEbWkkczjjsE5hNAIZrPx2zOLZDmKNXcXtg7EMqidAEEWg+SJCBBNwxvxJfc/bZa+KKf+xoKZybnq5vaqpPTye7CiF+ZFjxZ8/7Qij0hfOG/cowPA1rT1l4ymWnrKmxxqfErTVrpgwPlz1kC+Oy8NMDz6c+IO38K/x0xkPnLW8Kx6qGAoQdL+TD9V9rb+/ctn//trxz8dUrZrD/zk/ferF0cNt1BzctmX2FZPXt/jnFCQNz4Ah/iKllGiCMs1w5Lkg0kiEwj6VTXCDKsX9rMpnvIj9pcDecXAIXMnqn2dTUbN6w0XQ9ue6FV/nnXCH7S3lPWGltVcLsH75ub3ab7A8M28caNrIeOr3o5Q0yFsYL80xaa0EY/UEczV7icUMY5pnelAkmUAXmHYjvFWFGxuqlSaow3OM+/iYY7/l/hVELF4EjRqNR/bvRbOY+DUGzGR/Oh3EqmE/ugIQQguGt/eMYz/+L0cimjeZfQDI3phXMbMQsqH+CjwVz/hf4idHovgVmB8gLvjbicDcC/NypP536E/9N/puMibExdohBmNwyiaZdJGoigos7GpF222xrfnZhML/7Z+ylaqP63Hr+m7bdUkQ6/2cXqdfmvwixY+s2ksXFeXcE+iX0Z+Iow76DBNgjJ7TOdUK18iPsPflfQD+DPsZG2Aj9VmKMMJ4fYRrhIaxhTDR0Elh2vA6h/AE6xUb29mj3sjmL72petXjejPy+oel60M99tFduCI59N3221xe7apOvxs6aHs7vab1IqY2tv7q2xsHeHGml/cV06u/8S/xTjJ+JYc0bWEX0ukW6YmIbGkJRMdjJ9mYIH5QIdJF4hvRGyK7cC7ctImQRcUET99fGXOoft35GYLMQu+g2smnkgZUrH8AL/9Si217IssJ916nv14ZrJrvdxLkQvrvtBcjgPC0NXOicO8Qf4mcxPqh3hgUw3DDfdvLJXngg7N3dN2zbPJSaed3OfZnMU7dvmznp3C3bruO+Nmue0LFsy7S+6265+fCKFYdvvuW6vmlblnUI8xCXp37CrOZv4B9gauDBlYp7adcUXB5DNCwYImlXOJJKkAdvExXxVvKEYnCo+3eIskP9qrrfIYs71CccBjfXRC52udTHHdaP1A1ui/VvH1otbrLrpNXBsGX5B89QghDyimlvNB2KfkxZ5C9/em3+d1+d//IfFp2+2Oxn/s+9n/79p39S3s8idN6g0yZObwJOgKUpNB3GyU0Ls0PbRzIRq4lcarLKOJBkLRzJQD4j2090XrbA7DW8K3jNF5hlGS5e4V2D17zgss4T20egOJte5iD0bReM9yjTxnQxCRj3c5kFzGJmGbNKmwGw39IJDJcXJZGMkaAB4jyJAKw0jt5IAuIE+A+U3cVAZZrq9zhDyBrU8oosuxcGNTzCKJfla7JjNVmuSb/+tuzN2H+X4vlB+PpdfMXXmuVsNiub1T34SFbjYw5itEvVi0K0Nt9pNJUMI7SLGRhf2xipfCYf8z5OdlGKayOucFeVPeS/dbo3lBrbSMmwUiQN5/ed7g0Ds1s17IuZC5kNzM3MZ6EWCa0DtekdJfAxz+R/OX28sND7yRMTBcf++s8mQCQWHya4qBv/ufeMoWyslPA9DtMxUknxkH/yfTnm2CMYzs+Cq3r7PxY/MXomrvTEsRpfEGHa+WN8E1AHjElb7d06ddA7oK/+5Mdsv9EtPms0jv0Z5kf1FqPxWdFtfFr0kHfgDX0Y+5PRSG7RUj0tQr7rmfX8DH4G5W28kKeJLtmQsQkuwMP1pk16EV4sl7vrMJATfyUWo/GwEco4rh4XFQgaiUX9qxZHrMQqKnz/c2d8b9TysYrAuXpP/Rf/Gr8b1qwwc5a+euLa6S6sneNXToG2XrEJi4R5SGs8Sq2S3d97bsfCRaTdaLwKClRHt37mkudvXbjwVrLhuYeGhh56bvfQkHpk2CwvwClqgWwuBfndC3c8dwmstj81KkagcUgbfPY8Zje0W/82VPWJHmSq6pP8hPWpotc/EexDOK3qU+wngPhOCiO9MJRm8TJefjelrzoKnG2Bn+1NCUmPE4gHFmBN9jrTigRIpsACrc9Gstg58ULkp9467+Gf/eFnD5/31lNrt2967dhrm7bzI+VT5m+fzKhvf2MzpICEm79Bopkn07lt1762adNr127LwVqQLdJ5+lpQDcvHPQtVY5knhYrK6q8/JsiP6EuhGZdFdaNszjvpqvc+PI0CdjN0AXsFOC3ZfALDJwr4q2Xq+GF+GNbsxUg5NLLIEXi8otcDQcUts0D8eQ1iVDRAMBTsYiNdRIxE09EIBJO9A2xqgERTaW86BUFn0OD2xFO97FAgFhF6OoQ7prYt4XwSeUgQHiJyDbeke9IdQntciLQ1FlJMaYcUNvZBg+FB1ubjlnRNvl3o6IEU2w7fdNPhm/hh+FLysUu6++DLHkOkrSHYEjH0tEPe7WdD3uyDgvAgK/m4szFFR7ch0toUgBTdWHr7EpaWru6+6dmbbnqWEbV2EtxAsXiZAPTtGPSbHsotI2leoM8TePEqgSQprs7AGFf8kuOkPdZPXGb55POAW1d/jLST9v5YflasP6v/CO7+GNAPC2BMZWmsOjp2NNbfHwMCJD+LPVL+D/OYlWEEI/9jpPddOFkB5d1GSuKZYggmCCd7JUxD7EXAzxyirYnNDLdDZoFdx14kivkvGc3579Jm36reTTvDgBnaO6vzyQ6chQmlsMoIkIQ2+bBDWBud1Va4pcCn8CPqxlh/fgtG8IPaPH8C5wk6/nZDv69jurV5QhtwE0x2iqOsj9Mx8B9/0EaUdiPfOYYDCi/q9jhWRuupMDEU0+CtX0sDFxv07T/K5niBPqN9+tQjgEc31NGCXFeMcCEuQBIc/BK4CO78u7EPYvl3yaEfK3vcb6qP1R2tI7vUjVDDUdKubsSrNjYKY1qBEa2P50SJoaXiksIoLiCwnxS6EBuBde87botNfdEWwYvF/R0/u5yCqhGeEOR2ynSeyXjt6ka7neyye8kryBSWE52y+RBgogrXPZ8E1yIHoHIFUM+AbJhE7lbMtt8ApL+xmZW7PwbjAO0fAVoXQOuiSP/ksIVdFZ0aulsamKUzwPZ/NYDMJRBPCxsBqLzqHyneXF6Ej9HlIFo7+pg+jUb3unRmGpstGkm6etOuDBGA5wCMefp1gTHcdZlvPBXlOslvYTp1cd8UjYLVd/J5awNrIOKLnIt9MD9qdrKrWCvA6ALm3QV9VrsPm60Q7+RHJHP+2hqfugo/MvI2H/mqr4b9tFnKSRY1Y5Ek80Nm/WIhr1ikKnxGz9TWXrokf9xwujfvcOTtNTWnxd0F37Y2W79tteBqZ4G5qLCuomw+nSr28QESCRVLTyYKILGJOPfcnaIFOsewhRdvv+rWa/Wih0vlbX6Zb75T5C0qNKVFvH1QL/vazSWgC2s6oWXXIuUxQelKiJbowuJDQViatLmLijg9CQBMg8WiPgiw3LEeYRmm5f+XdnvkDnxLLjMLxtvX74C3OlwPQqx4xwIdpPx38LrlDphiyWUWHWKAzzxurS/xTo+P5wGFak62ap1PVFFN4v/y+xuR39WnIO7lsWfwgVsK17wxrs9K8ltIKuhkw7f/6dhK6gQokFKhWX3urrjk/rnI0pgfpGMeuQIUaEM7+GF5q2iMkCaMQwxxOzcvU0eXbsnS9XknXvP7Gtw5dwPXlFu2ecvSHEZgNDsU6x/GdXBYXyOQjzZReSedeEPY6nEv9gJR4oBQJtFO6Kd0fwC6BO4LNHDeBujB6dSNcUQC9zIv2LnAzGk99bUDrdFY+9yGFQtEo0GQPNv6vS2drj4+1jHbv3aJSMUWP+QTZrmbNTjU8wyG/iXNNpskybLcJ3CiTF5Ir+JYzmJwE0mSVhlxbtbmvweB3ulB6Til5UuUZydpgiFVeobhU0WaBqpJ198d+/XeNRTZ9/1OPfG7+2hwzd5W3D+hmyjsRcUg/+Cavb++Vh2ls3L7zT/etOnHNxeerv313vzLVqPai4nJv+K1FC6040/4udw7sAb3laSg0XCkAAs0npBO6VJabS4Elk/U+D4gTXW+j0wnrMlqNamq4tMIYB87tE10i0FR3LZNhJsb7/R561btmes8YBCRkhYNByRtKd55mqTas9FYhJnbRGHuOh3M4QTdgQSqmgRxuzGdSvZGcbMxNQGk5C3ebLjoXIOFM4l+WKHmLTJwRv9E8GWJ6dYvf/FmEyEGr+gyrr1p5zrgkz0Cw2j94Hv8Jdx7dIVegBSNtgsqGsRQEYiIBoXwD0LNvQ5d7s5Z00QzwNhqZA0b+tMG1tQq5nd84uq8R0zPvX35G8uRaze4jcOHzz0w1+Q2BIRvf6J6Kgatnrbiem+CFvAxfkrndzD9MFPP1GWTUHclpASUkCNAQkpCCcCgDSUDAhDZ+CuEkgn8J7i9nMA7pA4lISappxILKfAeSAbIcSDuN2bJcfZILqeO5rLs0MnngSHYRdrHjmaz7JEsEPw51ZqDJDmUIOZIe34WaQeegNsJn1qz8AIpT3yCjyEih/xELkuJ0lEMYTLVCiWpo5oYMleMH6USyYJcD+uOe+kWKpn1Qns34iyYDjkSLvgnZXcgVQNeqINXr48m3iS7cjm8tedyY0f1QvTnHHdsrKby/+SSbPY8/NH6vpl/Esq3Ae4ZU1HC44KFiI9o7CEgab/RqHbj7s5KAg06s39ZP/zxI/mVuF/TbTSy+3Fb8If9/cv7+wt91yy8RfP1QXtW5RzQn7qIiZyuFM5QfJ5E9uVnqT85TanFx0lkP3ukBAMprvsRyi/C8NAJL1xbIIirSvnSj4O5netb4JxmNANHPssHAcHMHsFRgEug816gDBeMbdfiuRcghqYcm0+Xxx/5IAEtN3fqFF3LzAXqwoT0PN0OVTNqxo8sxMkd5Ig6k79Zk7VxxX6gMLOZFQgvpW2RrMW1D0BDihaXQ9wVRoBxPLfpknmkeMtoB/qM9cRc9IqmMD2XUmdZ7GSRKPUZvChf8BoykriM2MnKYbOHX8R7cLdNCxSFFVQqoYswnlWtlFS2mNkhswVpZiQW1J/UKFfipHGlUkM6UKBhMz1istELIHJLMSctu3ugzfaVSOjKvUgc/THK4Sdg2Wscz69leKIkkrwuuWiOe9yGYKQXRumkC3qbRcMwrvhjNXgdZk3RxAUEhuSPvn3nnd++U/3vlVOmrJzCD8JLxV1OHRjrZifbcFDOuRNTGqdgQm1tSNJ2OcQ04YiEXuxtII1ECSQRoQGYioEsgCfchB4ghAtw7FfJre4WZ9hkVi9MtjuWqtdNDlpMrfEG9fOT6q21okg+e4As38MfGquNt7oUws6Ysarj1/efE+yst86YUVNvDdts3Pv5c8m/aP0C+f8/Qb+IMnGq09BgwN01oIOAnAdagI8mBSrqk1gxTDUBOtk2ousEtBH2z4Ir2d3f6k8PXXVlt2qN9RODxRuoJT/v27wm09jRYVc/e++iyx2tyzJb/n3J0htXP87eSsQaf2Ly0s6Zmxela88REy1cf4273mI3iXNJ7KxrZibOm9xm6rl4fqy/t27smU8tOfdW2ucBzg2UfmOIVyLIl3kpYlwphDISTXJXsctmiDtN7fNV6zelgxwnWxsVr83Aj/S5ki1jL/a0GC6+2L6Um+aoddlNFuj+bJ8mH/iaLh8I0/U51NspIEfq0dohwyFXKgm4NggwQ4rRhCOUFtxxo8XnitT4cnGfT93IS8FaT85XE3H5LMY4zIEPL1hw443wz+1UmhTJyJGxZzw+wsKkKZgUiVtKOKMEb2AKHTv61FNc01PQFwKnvsZ/9pPA4RKTASWahmh+8MxwzHxKy74IRn5LGRjsPUUwTu64UYNY38caqd7HKucZ/tHnODtENw/2UfHRMaq1UUPDJQ0OKkWCeet5fYOhII1VRz8+/Elg5j4Gxur3J8o2PJ4rg+2d08T/fwEzSVbyZ9XPro95T477lRKqUSRXQnauHNsISAl27oWi6Fv9z48JMv8r/aMMj8onCP/DuDZOuN+GPPr/+p7bx+7JlbYdppcNhzKU/1Px5aiaGDn/s1iGMaBcleKUo/v9rcxkZj7DBEKOfrayytXNLYiUdBY+pleQXdnscKlQcpzuWluxsieeyuXIK6SdxozitWyGOV3vOHHjguyCQ6fpIYy2JwvrQEF/Qa9Pdf/QqOSqCiE/EE1/XIVKTc2tzWbHnimrEd+Vyz311Ml3P0GVTj7PD5aDnsvCvH36alEaPMePcMegXs7x8igTu4B9v7G9vTHvhCu/kzIdx+BxC0ay9zRSvoS0F2lIxI+X7klU63I40gLQ3w5ep5na+SFnba3z5D64zv+QtM4n4ffG3tq4aNHGRfxgrXPMim+5487abL7xhdseIRn1KDl+7aINixdv0OD+JSPwKf5+xoP6aiTeQIDVlIhMcL1H5R9PYXvprs3fv2bO7MOplCmweuiq2JRZ1zz+9a/v2PH1Hfz9236w+ZrPXvWfAxlj4NLLHpq3c/PQ3uvmvbrjG7fe+o2y/cLdtE6VUlXi0ASb1VLUBVSUWSU4HdvAraTyS8xzM8NxvxFkXV6pUVRiJwcgC5zEeht4rwcp7ki0k41G0qlQhG1Vzlq8alEmnFi58caB5Q9vn988MLhqyVlHvLEWjtQFeupdiocF/tkkOGPW2ibWaBTkeZ/dvPWazXfOnnvL6jkRXpi85sFzZt+55ZptW3bl1cCCHZPD06MhySha7UFzjcjbp8fOecFCirzAG/yVjBX6OFIaadSjQq1nNhyIe8tVbaaSdHlXIWKacMeuZA1uxS95zILhyrxAdsXTL6m7kNQlx2P9uZf2qhufePFFbpI6/OU0WcP99RrCsrwseVot5mtytpf6Y0gm9sdeyKnPQ7onyK4nXlR/rg7H95M1upzu89DH6pgUcikoiihJ6NJKmRxV1x+MJiOA3YwhDRQrWU0u/0rvq0VYXnyCwsLeTJYBq3dAtJDavuzyoVpzZ99Z0+a0uoiFH/xcqgDR7rUFeOrUn6Cywb8ZeNMbhLV5ugP9l0zv9UN5b5mFkjzxUcpPJCn3V402pRxtJd2GrnLdhtVk9ZSZh9W91fCSH5B7ofxPiWL+j3D/uwhBRdyAyozeZwvQzs79soi+BKSnafLviZCcfrpBpLyimfLfTyJtbyruIQKD01tUwJyKEo/ybaxkSNFUMdMkhQoJyRBQFhnUkDQSXhTM+3NmY0EDM7ffLIjqWEGt8lCO6mLia3PukFnghosJD5p5SIho/VDkzQfLE+IrYoJXkD19pdP7OwG/voIUtagiWiZ4PAFTHHlTVhRZ7dYmPar+NJ+8JhmR6DFK5DV1foHoLNO/pHrvZfmWZ15RQlwvoVDKhCWNK3CCch9lfFBuAqUgpFSShmNaPj+i5++WZfKeViJfW5HnUakVL4UCNVkA4+ETfIqx4B5xSaP2L1yn0zn2ltPn4+OqZGmwwEVCaCSqG53ldtL1oLGAhdMLd09MpCCF6tD6ZnAZBY9hDaYsP0jzZ0j5ZjKsF4i1UmLuhbJMCnYJPt5VwFNvmZawXjEvLJqIH8STonZjq7BZ8gKgR20C9MDFqJAX1H64QW2NEup6qgzLP8cvppL/NNTOBTCJABOHeWoXzLhw4Wuy7gaBtjKr9kgKq8ZlRYBS32Lpxc8vIhpNDTfyNXWybMJbn2RyQ5EmWc2QF9wmSZ0KYCE+cPuYO6b15Uotj2Kd4MItLS7gtFbkTdrFND6pvEZqv5Yv7jXAus7Pg7avo7KDot50NX3CPkP+Kps8J9/3mGQIteY/LGPC+L7872SPR2br5fy8MtKBMHedGuM28/MZmPJMrGgi3Gb1S+Si1/L/zrZwO9XH1ce/z7ZQ1WSoY/+pMb5FT4ua0Wm+Jf/298nFmChEQ+Ti71est4mq9VYI6RsymoRJKYidElT2FGnDTZvqtfhGAFTbeqEw68GqtfmbVa/1IFO1/jdWr/8BDRRtQh9XNjubEm4aWVpVonpTGR7PVGc+KJNoBIWF7kYi4gUV3r1U6723i6TxUl3n3/tM27aZfKb7THiHW9VzFSwHJ05VfK6Ar7kaB0XgPPE0BSkSFKsBUpaLihEWoA9wBt8qirh2VSOkZwXEwyrxZ5jyt2rJmSo9gX7cg6jsEUGJU9z9xJPOEM3uQQxKgkh35DNATnVyrmJ3mbCNyIB/yox4wH1bg2DwN7q9kov4pFqny8oSm3RQbGgJ1QQTs6ZMLilOVYJ9v6Wha3HcJ9jddsXp9YhGUXLXt/qMDnvLpPNTXfNa60z5/yjXQOMq+lNmwh5egpYrdfZQZV9rI47xlRkuyTjpzsmCBSWNkAXVoK8sgYWqQJWbo1RLo6QH0YW6pxqfCnRgkd+RiFjUQUQ7poIaYoakgXxwFd9BuuI38H1xBxXSFb/pBDIKQFn7YB3dB36l7sG1FLaKiBdp1KxLvfswap/30lnVESgNnvjbUoT6w9N+Xoio0qcYOIM+heg940YimsucQVvli9NEcft2UZwGQwLuilj1fFr1i3NP94X+PE7Hpvtj6lBJfJ4R6NvWiaL6MgzWHxiN66DExa+dAdAbMYX6HVF8A+7rjEZIXAVbDe7PVI9rmN69JOLV1DOSvRPxWNPZBZf/Nf+Ny65BhYxxxV+77XJ2wfQ389/IQPgajXbwMsuAz/0IaQcXJavKbRqR2IqyZruXjVC2+hdee/5vdnYOedpmVtR3NGXldxSzDSIiBVpkGb9by89UpEPKrSLZmyFDzMab/wXl2CNe7s/qCtTvWgG5kpBmCBlSzDS/r8N4uwBwohRW63JTS1y32f0TQsPfXVGEHQrV8/NCfiOUVirYcBbIeA2+iF68rQIo3B/S628vYESr79ehzS7Q9LEL9UXmik9XVHb1yBO3Ngvt5935+k1efkV51mzzrM0LL3/20avnwMeKuWyOUZg2TasSqZ+KcZQiOn1Iu2Vh497ALUVZiCKt/gh6IvTIj1ZLRjWAkpHKOKovNwp00eqPROiAbiNEKieXwMLcXhVJ1/uzmLP4tfxaHR59cBdJVG1kTAgl9ze9QKUEQ946Hkb+okJ5JRDyf54Axur1D+WS49cLr0tTPEu7UmXrxcSr3XNvumv4yXzInXKH4F7Tc7p17Zt+t/qW2+93k063X7VW6lALxTY7i1nBXMxcxmzQbabxz+tJo+wijYaIGMNS8AoSMgAPt84DdHOoMPfjXhF+kuH1tZvuFQrRCN07xGcXRX9MYxYchDe5BcHj+Z4i+42WyPc8Xofi7bbZJN5nJLJ5qr6IqRtzqNlM17SpFsnkEyTWoABEjz4JXOQvzWYuwdnV5LNGOwTM5v9r4RpQ8ZXsYodks3o31JBlzbYtNotisnm22MxiwGFXam5oN1n0TA/hRvshvTSDwHff4nNzRo9Dum6PaJbMXzDz+x+Fkj4L4bFNBb1asqsgH7Dyh4DvbkPtf5yMDKzEwyoaESMSNS9P9gJVA3/RTlwoMwZvxECFWxIPNw9gi01nOHjP32esZTtmXHnxvZd8ZtakqQ7ekajbXetpNa6ocTVxJtY+uSe69OLz77zh5bDR3xjZMzUz6fxrz1nqrZGcHQHfPVefN+fiK86LeXj+Sc5lPKy+k/vCUI/DaLFYCWHr6nbXuILTIsb5imNKY/rCm28fSMxPhkN1XbNMNZGuqwOBhtTSxWuTk6bw0ZaG86b1hKddePOKuBvmiguYBn4T/yOqOyGRBt7bKUI1GjioBC8aUKwF7Q319UgcmtFGIzCJGBqwQij0ynDsfdFGc3TS3BlNfJ25xmzniMkpXXTPvCaD3ZaZvyzjmZdudBostmhb0ORZNN2sJBeed1HXkrUsywueQH+L0eCPxmsa5ZpgRJSDZ11yDv+jmbd86vxZfc1WcZJ3UkMq1BOOOVtvu/+pB+en186d3GTwWAw2jheaJs09/+LNfZft37DALyrNj1wABMuUKbODyTVnT/KYbJ3Tpq8IrNh92dkxOj5P/YpZx4/ycyiVcDYdn4JbEoKdQi9054iBKsygLW46FRGxAb0NPNCm8BSNCPjoKcj6EAus4SuP3rB+cV99/eTF6294dA8+TK6v74MHVpYNRt/I30e8QGTOOdfGWzzxcy+87a7bLjw37rHw1nPzp0KyyRSeZO+QQhInt3dYgvycjrPOv+T8s1rptaP84VeywdWX2T4ysr0/7TLIs6+x9zib56ye1dM9e/XsZmePY3NDs9zlnNVt4+WgHJbbz3Livg4P9WWgviOMm4kCRT6I8vw0NbUUEnFvOuFKoxQW1gTsvFirsF5pb7qTUCx4i7VmtToveaDxvK9uOaedVvPRpVOnNz0Q6bry7uiSdQ8t7Vy4JQKVS+XPplV2ts4bvCwZu+KzgITtxepaPRzWdpv74muvv6RO0SorX6cu/dqKn/XWnrtp/Zragz13DUCl5myiFW2Ycvb0PtsXnU+tx8pvLFbUspLX68mdegwmOif/NPDONajTGoUh6tU56HBJCTBASVvNUB5VIiKpc9kd7kludodSFz7xQbiOmMk5dOYk56gzL6uaf7N8a6MQOHm0ae6snZpFDfuT3/jdYzjzwkXXIVHoXNuCfQslQZqBZjTsoHMqrkE4jaYdgkGz2ATOgB3cPkSukD01DnV3ttb1wx+6arPqbkcNAHoFPzKUUQ+qL0k97pjbZv1I/egC9zTFbrrlFpNdmea+gIgfWW3wqkcis8ky5FAcRd1If5nNZrl2FFpungc8wpoCl1BpQV/ScS+zjlASyUTVv/AJ46gkJI4bHX4lTnloctxPZE1ckS3+jG2fKIjkQFyzuo8jvYQG1OrGvJPSTu/nSp9PHNTl4z5hK/8gtXVKF6gEKiglgcKiRlCESsQCV5QIlKWKpr34lt/wkSx/JCmP5/cBKQfl/5gd+rOS/+p91/+YCg5CXK2W4M9fu+/6xxX+vnelVuldIDCG0VQTpU9Dw4pRfei+6zWx0MLie0gPbyrkmRU7OwT16JGeyXLHqOLqAfVN1GPlBzWtFNzj0TRTCjogtP1NjIvu5habN5Aoa1k66wGpqriVetJgiGdwDZtKhnN0y4n9sXYnsqGmZfDSR15+5NLBlhoDaedEm7sxmpqRija6ZEEg2EAnTiAC8IrmFbGz1q08P9PSkjl/5bqzYqT9hMmptEXDgTqP3Wiye+sD4Wir4jCeoHbbp5hRfpB7BakUIppIlPCD30dR1GtslDz8OsqbXmejFC/v8wu5X2myq7SJ8Avzv9DFUJySf5uNvq4+Ti7W9D/OZrLChdwxmPNiBRqVjnpK/aGxRCDspVYKAW9AN1JANoo8wP4BJUlGqdgw6m1qPQ2QW3+OfU5/ieLS/NuKpDU3uf8bcAXyBal5jMR2NEAbPAZt0K3hvxHBEDlUxfIGcD+N2gNSNx36nfqlAYow0puatNpRz0e4W2oahKzQHsjf2c16ad/3t2KTtPobnX6D8C8pd0MDP+Kx7wnXqGGlLQcvikMErm6TmfsuxJXbSAxqNjOogJLQBLiKEHAE+JGTS3JoEhTrz8/CB+5YlupJ58aOat8Kv4JvregxwcU5Cp8GFAFm1FyOfto6GS2m1NGTS6CPNKkbsTdCBlnN9onMho55BX8IJZtEQ35lk+htwN5A0V3RCPoD/yXAcv6pAtbZczRUA64JmcUf4q7Q89ZHLeJVZ5D1Ps/t+0iCT3AHVtZC7JDCXfR7OSb/Xja5H3zQbZL1B+ULX1BMTEk3AseSpmnKEK4T9ekMIidUCRQFfcbj7z8gNLvzF7mbhQN8h6ZbRset+nQWdS/ZX3k7WpS8P9sfo0iGS64wV516pOhjI6TZ2dApgI5+LhxywYoWxKUrykKJsIoDsR4mSrCTg0egMPnLW/3Q5Nn8BZEuzqEI7HK3n0+zFmuO3TtWQ5WJoG9YqCD6Gc32SxnbnVPfsxvrFXK2dILl7bLthDp6glhcsfp4bYvbSmj/mQ94uBTw0E73x2jbNRCvC6VL6GCFDwU7eWQDcC5FY5s0slieRDwtAbRsbLXbaXAuu14e2OJw1dc6jQ3ZdY8v7rv2/BWZLqvFWVvvcmwZkK9f5jS4muO9yR5res4kfkRxhV03L1RfPOiPtYi8pd7jNEsOpyTwxpaY/yCZu/Amd5Or9uS3DYaeqVOhH7gZN/8I/wi1fEuLXvyNivibjuKvN+1Nc01HF/3h+ef/sOhox8MPd5SFucPjorQwXT+ytA8EmA5mamHNFDVhBI5pjZbQpugBNkO8MvRub8KVDKST1Wag7D3xlin1ZF7LFP/79nbvCXFOY+PUjrT7/otsPXXZ4exdPzuhZuL5LUXVAn7k7PbhG89uz3b41X01gbjP1xwlu5rrvvf9+pbs6E/Vu7Nk642/PYRaAiUBdrmO6CDTBLPQFA1ur0uXoBR1INDMkypKpoTqnSMx5GiEdTEaSHLs0Alvu/19/5QW9Rv1U1ridT22i+53pzumbs+XFFXYC++CGsTj5JUT/GCgRt3n78i2n71FHG4/u6X++9+raya7os3ZbDmgWfXun44e+u2NZKuGZ0HiF8M4TlMPR+EU6rPKRJ8wOU2RFUFLex3egEsz3YqEAq0cqhAAW19dBZIlVzR61tuIdTnpXH7l+uXrbjPUyep+8cl6aXKWhPHpDcXl9KiTWDNr4mBQc8Tq+NzK/OKSbsfl79o9G20R+brBXYvUg0rLHhtrc4TN81TTOWSZ0gL1ZVlOYH2ery/7XVUjFMbzYpg7UswcqJPQwBd0LKLabJ8IaCr2otcjSkIrGwootKECaUd4XH1+SdazRrfddkBU98t1htvWrbjqSqjaCguxrffM/5zDCpBALUycmajhd+R6ww4SWafuZ5eU+tPid4lgd3gt+b/Y9rQoZNmiXYPXyRHbRs8zX/f4WIFjWZJtUdSD55AP3xtXH+ZipC0EqdBGDA4CoYEU6gRLGPU11QhkLTBiEYPiqOeQgwTCl9aok1Qr5pFf71qEeNxjy/8F0GoqYPv75Yh9j3x4DuJ+uEzHRpAq2lMqb+qfTdiq6kGtzfOWsv0c7lSeMXDHBDe1MT+LUgx0Pg/p87u2UicdIvqQi8DkxhcUwUXCedMpb4NQjwY3npTmgsURJavLwCRyEcN2HfWsDVGfv/u9ZUWUx+PYFueUKwaNvbtu+Xps3eVWbN1GcgVrdMnWJ7WmJz9SD66EBidag0NF1Ukep0t5A7sFCWdhzvYwHv6L/BehXuHqfaBwBEU7hfVLcXvS4VQv+T/vaSIl7cbeMc7ekv9i8S3e1L5xxpvMGcu1EYPbKyCiijjGXcDKckm43PqU2qNWlXusZMiqF82cuVzolUHN9NNR0HZPxFPV9V0wLtvq+k4DqOwVWDlzuQLVdqFiP08cRX7aRlBVfR8cb55bWe5LExnlcsDp1vAP8Q9BucPMk1Ulh4GnN0SAdxcNHv3q9ohx1Ati4S/tkWjIDe3hQdkUGrGRaFBiUdiTSkI41UkMuuQHP+EaSQYlPQTFWJF03BNPpTu5KFAdkWgDukzsZKMG0Q1TAQQglScOaP/dsZ8+fP75D/9Uu5Gs3FY/2SxPld0DHOciXI9gqjcEidXjE+3BLosy0OcX3T7O5g65ROGyzQ2BZs7WbZVnO5ydLe32hMwTQ4wnnKXW6XW5LAa7oaXOIHoUl0FgLQLH2by8wSTWeAx2Y5PDazK3BqZbeJZwXGPaYhX87ZNszoDdaRxotXO1nNlpdvAPFWHDm8PqEE0sZxDEqGzxisFNnuCWetPcGrObN0p23tTZwMuRVodSV8+LTrOV3eRvzjQZiSjaLYS1WEJe0kNsJlZu9LFun7++wW4gRDRbaxw2nrOGm+xOj9cmtbp9ZqeTM1m8UXfQQCSTVSQox6pvtjot/FpHvIUjJovFEoYvHYV9C5Y/xN9OfcalvII37UEhTbTg/AQIaPb4Vz6j5u8/aViycMod/fkDcpu8QZbZoeBi/vbzP3XPsZvOubMtaPHkD9jt6+U2O7vqU/9C9SMvgrXpQNG/E0oJxun+CiElUa0IKQSUwERxOntKSV7ekcuh9VBZBBo3VUcB58ofKBHCwLyf9qFosz9Ibf8dGqwaBMjRig4SGOZ2UkWI7UiO9OfUPdxOYFApUZyfpY7mgEc5rtNGGk2H1lPhAk1Hp/VAMqQEHEUfEYkkUQq1JMdzsX7kklRrTrUi1wMcDjmu1YYfATj7Y+pGpPEBXuoQIj8rR9mgCl4C9yqmF7xnVWxGVniNqtpVmXBvQ6iwni5YQ8a1jYrXtc2J13HvgkvqWxuva1sbr+P2S5ceKGyBwDv2DbrToe1u6BkAJV7xnVLUaq0sJB8pFqcUIPi3yuwxi4JuLr+P30f3OkPQ72aO0xYo3/EsmO3QO5qEF8S0qQH0UsKXv0brnl9+8M7jF174+DsfvPOl1au/RL5/9DsbNnwHL2pHR1NTRxMZhJtHktOOxLxErPF6YlLvpC9YP73x+4ofw+3xVdrHcDE0dQQCmCRgvt9b35xINDf1CDcRSfJ+pYl+Sf8YcurfmXP5F/kj6J82jNsrkWiEuhVlgFfyNkB3S5MUzLhoNiwSCYcxQ7Ui4J0Xh7fmqRbaPa1tzujxkBRlsEHy0/OM4pYLPb7g9O6BQJN6l9zQ0OGyCaZz0vMTbHOzXfQ7a2tsterTcqxeInODoemdktw+1SbVhKwtW9ffe8VKadK0OVuC3bWzyKm5LeddsWTeorWyY9IMtUFutdu5g+Rn533qkocdvLs2HmhU75br/MmWtD8zA3OP2t1ea636jEzqYxJZGAwFiDEd61oTsrRuW3/3pYNi3bS+Rd+GjOfVpAPNd6y64Gsz1GaZleWIPoYL/v9mTeQBENVEguiF1aC4YeXxFETw6QyPfn0m9g8IrMFAvKM1EI11DARnbqibHk/Iojy5rSdgCyZi06y8sS024PeuO4MfwQ5Y9yKRZCqyYaF30vzeHlmUprR21tR0t0yz8KZY66zWuGvxVQB/36kP+K38t2Hu6NQ9SFJfw0AdpqPEK2qTMpf2VCqJwqPoJezTL824b8akoL+x03nhh+oNo5e77psxg9Q5LzebIKD+fsY34f2MtB9fk9v5b8PT6tYrgv4kRPwd0q9z3gdJSJ0653KjCYPwCaR5aUY63eW48O/kdo33yxX9wCiMv2QTrk8eGSI6Ag6moG9t2P/F7GRNlDjl0gw7pJ5aOXXqyqn8SENnXBmbSwUYLyqJjv3UmY1nKr4t80no0faXsaIEiF/BRaIBnItSce4OUif7W6Vm9T9H1X9Vj71BEm+RdmIJQST/ZfVdudUvh9S/qqNvqT98g9SQ3lHibZY0mRVHooyDN/FHmTgzjdozKw28NwQ0hwN6BCoPKaEk3YtKwNhwRLXuk076CGoZNXDQcRwZvreTZY9EZi+d0s4+ztv8iei04JQl6ZbDD2eHV7X4uHuFVfPrOmcs6m6Kr7hssr+1VZFcEZ/PdJkn1hOs8SXS/NFFgqt94PIZzZ3tdaL6Q5vo6piSzdy737pwsX1VyxUrF15iJ4uNkq+rbyg1Z+O8VsNC1UmcvORPRfxtPrfRwL2p/oA1eZp6Z/aGffoewaXcA/xBlKlQLfhQL/oPgBGP3qsA7IQS8qDVNswHKRSheDUvA3Q7MZoRcJMxlEygujn1QdyzfPfq3dEp/bXh5e5YXW2Ngfvza0ZF6UgFL/E0fTq4LBlvTE2qb/KuuzYSXVnjTfM1osvqMHVbm9950quIZlbqaL6YP7jk3kUtA0GnX2nvq53f3WoSsvEdDRnULgo2fN7lNZJgI8/VWi33c3bBZnGY05+dm+3qc7fNmj4YGKLj2nfqFP+g7jdDlxEV5XsJQZP6hYrS1l0VQr4c69Xueixp90gnZPmE5OF22j+SYEWHlZ0K/Hgsh/Ztsbh6h2DNRlvv6jJh9XaJaHCZDiUDKNTMkvb8vsqCyf3ZNdSmO0fa0Y4baJTtpbKzuVzeeSI7fCKr2Z0WypapnXJ4gnoWy3PoUIlIQ1TXdqhQJIXp9Wx5fYdpeWh2TY5D+YVyKd0jw3iumwi/BC3cEy4o83QlZnW79MrCgCjbhWXBlRZVVZZv4rIKpXC01HFlHdHLoeWVl6UVc/J5uGm6CViW5mulYMk+HqNYr0AyUPivLg2oMs2MPqtuhHyRyiwvNJej1Br+fcLyoAyu8D9B7bgmzUqfFobF5nKnK4+t8MPJkI/xHUNWk117jugWF+xazTAALQn6+UE9lhoI5ApGA/iuJOsrlNP28SVVuBVajXmircLel46w2bJS1Q0Ft0KDuikDFL/3pYrid1Q4FvofwRIo4R9h2ftSwc6jHAMqLcCql8YPHtlzGoByNXYN6v8hXnRaOhUvx0sVLCexwupGDR4NOYC7PePa5keIPACnuAdD7dEadRuTIiS6Lb7uskb381My5yjzF8lGCjBRqdwrWJCagfB3yCy7XT1i92hbcZ5Ci1FJkgYMDf6n+jspIsHFjJrTOdzSMuOa9DbDcj/nH9N9bIoGVgzHPWIQuFuYtaMRaq8eCKI0gEF6lPOZjBz3EEvaaxwSUT9U/8JbJZPJJLBLolH1La/RbF9AbC8JJjv/mMnssKjLRBJyqj9QXxNko0Ux/X79epfiXkm6fmKwF/en1HLc6LxloXWKvGa5rVCVL83VuiPcDEX/K5pTXOxHfx6HHB0t2FI0qI2rCZFTrvPWU67zVuS/kTsLnc7IKhFg30e4FOkqNSfH5PtkmUy6Cpiv/36k2sbqCeCFNa+URpoY0sZoYmCgCr3qgZz6s8I0gP1bYiR+D79H56NOz0EVWCTy2/fffvSCCx59W7uRV9995eqrX8GLesOXNm360iZ+T/El3uZqL+FyzSZ8XxpTiI/G0nkT4zznFZ0t4ipMz5v4q9ssqbdKUZt6u82knPCrt6PZwsnn0XySVnyPR1ZXAn72yx48bWJsu7apnI3Hy8bygUK5Js32qcytapqgmn95uexccj205vGgJ+euOeG2SORmKZr/qKzcx9SFctMJdwMUFZDJITs7dnOp1EKZCxg304Cevyfya+vlKqv6aXK1qIj3imL+L6hL+yvUlFfE0VKZ7E8gBY3M/8VoJCFgizH1W6VyC76nH6b7jiibYVxUmVIEspry/LgZIlCeP11Z4zs/AwvVwtGFEut5S1JY4lfyT0N/evOLo+rUEgjcqc9IkGpQbv3iW7Co5b+KgjvpzYdH85PLcc4X21ouwEGl/S4qnUAvoSlXUUhR1eKr2VWFTB+GMl6FsiQsVD1R3urlAAIoSn7JQkmiVVCHSpCwDH/qPepXQ0Db77CJOAImohB+RPWr31ev5g/kE+zTa4lbvZo8xdWPffQu9yJTPCNB66s+zXoJt/0L6hSoCuBIoK8fnBGG87OoRckJpLqyWe4YbpGi50g0+3I3UD85Oa0fzubfoXxPLbW3FDWzigmyJeM0tQkax7PqTy80+UxfUHPlBZIRVNQ+v0xRm8REKPoLmNr0+Uo48v9GFbXPKylqQ2IKm00QddgyWGMROCTxdLB9nCY8P7j2DjlsV/+mfr0C0r/NkeXbbpPlOTBBwT0mVz1zx9S/wJecBF9Wgv3p032iP2v4VSgfgW2G+HUEdEXU6iq4CtpLJfIN9XQG8dwa1VoO8XC2SrPDDyCOQptXgbcPvlAgBfxBoGwftQKeKFrNTASPt3pGGqDt/QRasn2kri+H6L80MJRsmVYJrAKyDItpJUy3/15WYIJqcJ9Q5N/LFJ4c3dc1URpWl9hW6mu50MUIelg4ucTPf15zs5DFo1c0VSp1tKB9jkwIyuM45kb+IP8gHed+6jO3v0KbIknzLy636E8KPTdCuUpB0wLo9JKnAO6pv0vS31EtBha/fJemkgLVVnd8KCk4qBTpQ5m7FbifBKrPJcq0pZAFVG/XbOFz+Tcq2MLrcmV28Nmi/OHskh82bau0k8eWCaPijQPWQ5lUvslwVCfHkXBMIehqUgtDNLeauH1huvZTbYmw+luPjyWoNGEuxRLR7LK5fSyXFUyK7PURQv2v8D3XOt2NJ6liBbmPGOsakw1kbeOs+31Wm5qpH+iJWSzqdPr2O7zc2TmtnrzCig6bBd/vgQmzOlz0STWIlmZEQfupogOZFHUZ7EkUnMn0RrpIMqAgHRJAOjIJ3yGw1I/MAp9q9S3Q/clADNm1wEeO+xbwg5OIYHZLY3ehG5lJk2xhco+6JWybpEVz2wrR6hZyD0QXZbeDVB+onmlimpkWprdAs4WEZDSQppsDlcdCBJJESIYFuAtUnC4GIF2C3Uu2Kv7L1bdz6FxtqxpG4TqQOqOUNAJ2HLvPWA2GgDy4O4vaDrtyl6P+1fAll+SyFcQ28GHqh7fvvf37udylf0fNwhzgz87Y+cf5x9GnF6ygHu18sAbipWeF0YPBgp2GaKeQduxxdEr3SgbH1kvH7tvqSLhedomOvZyts2dw8acu3dY/f+ucuMtCuP/e4zC4XnH3OLZ8ZuxTWxy8dJfU5dhDeKPSlJy5pn/+7u3XrJhmr9C5CuleGflGQocKnlAUaRKp0BAHV0ZwUt9VCqk6zYOgRIuMfePJzdmBdpPJ7/6B23+f+sp9NMDZevovvfYHG5dGPISQq1DojqNckchVrCcCYz/Q0hI0m3NKDRfkgsrnamo+p0CAq1FyvC3a3Nak/s5VX282x9Ufy3E39VAx6o7LpCvO2wK+ch9jNqpJCutcIOooKnYWtDK8gTRVYygRQfwgzKM5+jP2jOZdx3r32Py7rQUPOzAnoRs95NvRAR0qLGU11Taqu1bUYSzMcWjMEir067JQQHfIrLBHsrgv00/Wavd8HRLMEEYFSW3HCSNQehnrHztKqHcDyo4VfZ6gPKCR+gufwA8GegxUEo4A+gd0BASHiH6jYMLIsUdQJTs/C641KN4oCHWolCMLlMfIdtWKScjx7SM5LD9HnfmhrGI0S139UWfUnxgOXdJFW+AMcGjKr6eHAttHF5sUoeArYKDcxMSYcKA/xUDhPiEOEAPafSIUFArN0r24ynI91EPARDXvIDYyvqZaWeroBOUABQA/E+DXC7PWafDLQY2oiwpUEyj4RQtVlUp1GrM7In2p2A7VuiOW6otMiGOo5Mrp05ejVuTy6dNX/k/7mybZQ0nUmfrbx3U4KueDnlHm5wdh8FFeKnoaKKh/TK18StOPhwG9Xo5mqXAxvw/79YQwwDR+nAKQQ4izVXioB84qcppWB7IqjU45z4CE17OvF1Dw+oTFqxtz8dxwtogBnF9MjIl/in+K8s3hM9laIn0TiCbTAXL0T798bPXqx36p3chrv0O+GC9Xaj48Ecv8U8UEeBvUEsDlTepiU5OvlpeNGvpnKF0RvUooWhIjnx6GeBapXCQYTw9DNg6/OC3gZjp76oNTj9Kz6Jqobxb9NDqc08vcKReOpcsQV2K8InXFaXW3aI6Ofr1k48rp7CX7rx+v1UKPsfvzQU0Kc83i2VdILmd2/yX55zT9luN2+Cu4nKfwPcK/CvDVU+pHh8+LaldIf1fA5h3ndT6Fln9/W/9Ce1vndfvJtnPVO2xhm3qbafHVCN1X363UXHq9xuVD8OSD29Z8pZ5cZrern9cAdGW/uib/ud+VK0L9a42r6C90kL8KzxwLQw9NkIQJL0ASU8M+VG0KsUdgdvpgP/6NqqP0/gHZFUfGEijZLHpiIgvV5/Bltrj8Qd7XQd5p4P+7tJo30NMO6VGBwahSPMYiaaBYoLY6uEnciyhhh1Z/vvacG/rjpsvnpzs0B1Id6fmX8119l88XnOxe/uGrzzHcdu7UtY3+2vmXN5zUyj3ZcPl8p1sZSs6/nGXtwrV7Ka0XZdz83fwjjINpZWYw85lL8BRK4nGyIir2RiOsEyipuEcIakpGjWgBjLiHWOgj0Yi34gW1kKPxHt2Na5q+lwg1RdRSpFDNzosb44YJXnAfoEOpZW//6u1lhYA6leevezbI26zNHO811M2dc5HFxpk4i1jPC0s21/BWW5DnPQbn2X1WK43/aM2n18DfSoybbNHijFpamzXI31eRibGUOxSu/lT96YZlq1Yt20DaSBuG6knw2eusHs5EPBfNmVvHKdaQzcDfz9ZsXmLDWGXy2U5OsYSsIn8CS12jQIyD12KKqZrLPy7mSPdICmd6WGHG8NDZkkHuE4h9TU8FpmUO/VjC/EinToFyoNDz2p9XD6g78WgQdPG7Z3R0T/Z5dTM9lsL8Ktek7szl2L+gQwGgwkZHc2g5Su7NvVqwGy2Ua4KSXUwt1X4PaM5paaEu6jQ5zVFyNabxvUksVt2T/4VeamYPlLtffdQsk+2sUTY/zDXl/05W53/Bz9UK3p7LjapZ2ZxOm+UlZXrL3HHGqO8+wVroDaCTTnTxitMxmiAAYQzVJQH+nj3oIHnPaN6Zq6sNSLjBl8tKgVr2mj/9CWi9dnKca8rBQBsd5R1tzVlgrl5pbnPw6kZclCr2CHxMnHohLz+3KRQokzALyeIKFU1TNCiayJdoHvDYe7K6mZLm8S3uJ9dojuaJ62/qN/tjQxnSnhnKPw+LNrLi8ZKyJ3x1YhiI1aNAtP6NzCGzYv3DmaGh/LvQZnt0evgIhTFV0kE/PYxAnOHhCQUZdCWY5JWJwMzlAGl1mpNbDU7yyGnhRMILsYhH3VRAijrPcBU8/Cj1Y9NY6cnGVW0CjTLaz7E3epvaT/LtTV72Rs+0WVVmd0dz/MGTI5F0OsIviaqDlbbO5X6xT3PeXbXHRtf/z+fdka+eKPr8KF7IF4vBsT9MFPuPJMBTBMq9hQxXelQ+bewnf18ap4Ib+mSMrtDU5zqlD8QANa5MBGh/OwOvSDfcV2d66mfEWsbGWmIz6nsyZDWQSmqmxDneYyvjHPmRXHZxeueyRGLZzvRioKnGto9nIPkibAJA16adcOZRQr1iAP3bUyBR7T4RgAWTKxhkCYFwshq+7iV9r0whk50cmRcTg4fy5x4OmmNkHndIA2+YuMbmE9dwGYB4KFTsvnDE6Ah47r/fE3AYI+oXADpkdlENcZ8OZEEf8FFGZNxMs6ZLpG3SUFLL7Q2kcFU/A/Jsw+vWDa/7emewLaoeibaF1B9qUNnuqWK3+UfXYVL1v/omD15xxeDkPnXTOKSVcCbDGtOu0YQNpGAP7U1HU58UrqGu8xIbHtkQ3LVhb7Dx46ET3Ffcm1q0YcOizNmf3bC3VjWfAcpSv3MyTlgJ23FHQgmgvk+gk8pL0mcCDOn08MDAQlf+/SlTZ1z12fnqntOhbOTL9/ZdevbAPN+yby1f/uUtC/ixm8ZBo59LTXEW060hGrTDplNprWd58fwB/b/E27BdS/s7U+rGVCeQ46nzaw9QccnmZerGZZs3Yw9aVHt+Kh6HN4ti6lxIhT/wahnZtWwzlY9QHQ2c79C+dxzvVDKy8GqKWQERO9YAKbpsDUTLdWV5dE8PVPjvj9pqw7ah/PFVtkit7aj6G5xY9mfJrCz1j1e0BcnPol4UjtrCdbahIVtd2HaURujnFJR8CuOuUUfhrGhgKKgjCYNSvCc1WKlEp8wHUaAYynFNyzZn+2MnYv36dbMDBTonl/T/ma5IKAyEGz+4eRnVtaX6tss2o34u8mWorFtuFgm4A6qK/yp/gLEBVat5WnPDdKA574ubuFJ/IUfZ/Y2Nt6mN+ZNNTSTaeI56gKwkXerTe9DDHUw8/H35FY3nNN7GGuBKWhrV9ep+0k1WjNWVaHkW1yA+QHWNu8rtBw2a5YXuE40rs7/GA+j09V3hA98yRnFPOGr8ltGlsFdD/7tRce3LH6Trcneuiy7K7J3khKu+3qUaXPWaX7T6/Kfj9BX2eZq2XAcZT79u1ClJzUtHUqfqSMWBcZS43Ena0cUGLgpkKxB1QM+0Fxz10wgg6r5rltnFpH05pepUq3Y2HfYqeKRntmUFNz+XmcOs1H31U6cC6RTVLfCg7RNBF1UF2/wBgu0fFQtPEU1sSg3VcNsR7dWq3af87tUFn1l3ltXpaJxpNvtcZkH2WmMst3JqRpxUH+WC0E1qOGtP66s1MYv+VLu8/XFXvV/ZbunYYBeVN64ls0ur6NzpV9xzlmQwB5qC4Tq70WC0tk8dWJXeHvkD0h9zJOM0vD86/1NJMaIAolctvlByferCsqOKDKceOfUu1PsmoFCamV5mCrMUOCi6V6FJosMF22AcrKJgQDVhfYh6tepp/lYgvnCEAbJQ1L0rOpajEmRcasMiPfxhgGoVo4rwreQpV6fUJHH2e8fa1s2c13Apl1b89a58ozdoap2sjgLN9uISl7P1DrulyeIkt0zr6JjWocoPOZsaXPb6jtqBblsgsaRre2xHi4nELm0MhG1+x1SXwLpFi53b+aHRYo/IrbZtuWAKu5cSEXfybnnmUCaXGTpQr0xK2O2WWY76f+nAjNVf7nCZHU5XqIkTnpt6VtvsFlPXg1031g/VRdpkkyVpD7jnmax88QwDvg/66NnMRdRXTcGTmQc3cuINwN5IQqi0yzb+YFVHuVqI5s4ADfg5oE4ybDLd28mFSFmYvRoomsWXEdLU2Wl3GJy93ZNb/d5gqmNaqJZSO1l6PVRy0nZIj/45EetjLguh1rLqR+SK0hO6NrsqcNX8zoUdjQYDJ7tb4os6+i+Y0qpY2AWlnLRDWdGFTfGY1gV0zNAtJ7pdo24se0D88AwLY/gZmE9iuP4V5v7CSR/RThaHLh+UeBkXwU6BC7lGOevK65udTv+tS/PfW7qj3ljTcj3b9OkbV85t8xsMj7Ddj7DGpthZKwKPvso/c/1K9aLE12fMWLV1y1D9ua8lyJdWXr/bG+noCFutf/mLILe39ITUV4igr3876fpX5g2zeB52sWnIL4fXHlgeUzOx5QfIvJQyrKQE9wHUqVq+PEaOrz0wVvNbJZVSfsuMzxN4l9PkedFzw9V5Dj+nzpgoT4ZxCxJfC5RWLc74YVHxKlExCYt0JAOMatREhHBSCAtSfod6x6Ls8HCWECLwXZ9nd5Dz1T24JUdWs6fU3++fcnT49Qe+kBs+wdsMZgPXMp3U5S958snPP/EE7bvkOPCuTUDTUQ/UzirLhML9yPahoe1D5Fj5jWsaoveyP00PehdUAHk/seDVWsvDWXXXsyn/4wfpXc2V3/Qxli3jl/5hj/83avSCfpTNxOEKLmTjxOEKuxgNlsQn0xgct724mhynupNW1Ph6o3RYS3/+2TJrzLlkFz+ip3qCHKf6eqW02QJLjBYuuj4sobhCWqa/YHGEHpcnumuWSOhxeaL7sOakNR6vvmo+YcfFA8UFXEPZf9UjyudIOyNwx/i90DdsujS/FX2UAwvWSVK4NxaMhAGw3oowp/uc8CTi7D2rBgZWwb/60faR7SPsEbjkXy4G0XaqhXPwe2cePjxjxuHD6ssQuR1fq6PF0E+o2t1nePTn8TUmxz/A3crMoCc7egESuoTHYc7mYdg6etORoOhR7BBGD+qJopELrl4S6cJNRtEAsLP/OdvnJq0Wo0GolY2Et9VFB2Kf+4bZvVyxfOMz3WdFfSIryj6DwWghre7aQbdiDrkTL3A3vNDuDpk93HqXwam+bWmUJZfNn5ozKV5Pmmq8PF/jVY+2Tlk2M2RzSXKjmbQ4RZcQavEYrN/9rlXwtIQqzxQNMzPPfHYLvuPoO9TbT8bpGw5CQPGd+SyX/Cyf0Vxjd2R9NmsunnXYa8xGHzn+sSfM5J0y0DZEXWWxkXjcR75KBLNLHi7XvX2G8VOrf4Ykg0AMdBESIpo7MgAfyakA6rkqpI6UjNs0px7cMV+D5BF49Tez1VGnYmq0WIijp985m4Sn2gJR9b07riPPFo97OYbUZbxJCpot7H/lpZBicglCPN7WOfJkcHqc3ElWqvvz/1E6bIQrG+tz6WkM1SM9FBTR7FSs8KyBBytSmNEoquJNFN5EQyTiCrnKDx1h58yxCepPHU5nxGoxEQeeOZi2m80DxNxncVhr6BmEfUarxejw+WSiHhWk19bSY7aKR5MsteblJpfTLtjimBouXsm3d3djjYM+wEW0El9dM/ueVRWIsXwe43R7SgbVZqrnqoJ1X/kuF7pcgf8duv4q6vayV5U9zMV91GxO59UUjW8rHV6u799WzKMT7umRCXbYUKM+foaCcwgaoqZUtmodV3p+X7akb4dnU9B9La38RPFUG2SCC90tVA4XwEFhyOpZZrUCsgWYHsczLFBBVGNtstoN1bw0Z+O4fYIbvZVt4EUcJEKOhHeincWqONw+q6w5Go+WGOSR7LhKV+KBqbBPpfUvOf9QqkpDyVhBeyyZQGMsdA5FBUqvFMtUyGq9vjnsAJU4UcrxldP1CCaofyDkSAifoP5QwWx+SyUGxp75BzGAvtG7uQ38LehlyEQMeh0TeE6Bm7tYdXqdkt0uOb3kfYlNwmOdDyacOq/qlFo1v+PTmTi3E/glC9W11b34A22zmLzvb231Q0L2Bgg60OTW4YdstO+YOJnO38TtpH7zy9ymokWyA79qlVSn38HtpFlImFnhu3b4boNWXklOXV0Iwo7lQ1hrZyPFcwtjwFP7iEKSHSSJw509kh8kj6pr+H1jR7km9vcvqN9657vffefkv+fKxge1X+7RdjYUPIESN7gTvRkB/RMYtEkaVkdHApmdBPpnKmz0n1xSWFOyVIuLrinZwpoCRe6kyiVZoHX088F+UX4+WKS4iBTP0IWxGtZgOdMaV4KTayqHQF/VihBwTbgDXTCmKoOBJeNhwJMzEVjtjIFLuU38fPR7hqNG1JS7g/qRCuy3vmQ3W9Vu8qbVbP+SzazGRJH83MzP90Ck2m31mMjP8TiLn5uwD2Ugr2PFvPQjB5BnSJvQxGQZZEB+LopqzGzDbMmbkAPkZVJjeO5FzOSBKCgJze2ZS4Gemc9twrwY6u9H61iUQTcRvtdT9RW3tRxAWwFs2tcuJRnI6xjmBdWjbgFNRHMHiF1uHYBfUR/ut5Ug2jXAaT96+9RH/FToRwIzGbKmVJ1AZQnoabSB1yyIg7ByAridHApPMjyw0OiV6RjSbCuzwLAvFizBliWJua1tsuAgvNPbmljYbpt8lkWam7b3XZiOiKJskMOtmfScnsbPW208knwjuXrXK4Q1iKIgNyYXXDVT9C2Ye/78GQ5BEEXfFdde2RwauOysdJNL5AzCy84ard/nGAVN8alecnFdgu5Gbd5DJTL+hHZK0vApVy3OfU8XTSJg1TlssivsPYUlIqvn66PzrVTymCc4wgF6SDNR0pDf+9Gp+VnsUH5WtpHYsuhOaey8zdwLN47V8MTbm78g687+P3cx6tcAeNpjYGRgYGBk8s0/zBIfz2/zlUGeZQNQhOFCWfF0GP0/8P8c1jusIkAuBwMTSBQAYwQM6HjaY2BkYGAV+d8KJgP/XWG9wwAUQQGLAYqPBl942n1TvUoDQRCe1VM8kWARjNrZGIurBAsRBIuA2vkAFsJiKTYW4guIjT5ARMgTxCLoA1hcb5OgDyGHrY7f7M65e8fpLF++2W/nZ2eTmGfaIJi5I0qGDlZZcD51QzTTJirZPAI9JIwVA+wT8L5nOdMaV0AuMJ+icRHq8of6LSD18fzq8ds7xjpwBnQiSI9V5QVl6NwPvgM15NXn/AtWZyj3W0HjEXitOc/dIdbetPdFTZ+P6t+X7xU0/k6GJtOe1/B3arN0/pmz1J4UZc+D6ExwjD7vioeGd5HvhvU+R+DZcGZ6YBPNfAi0G97iBPwFXqph2cW8+D7kjMfwtinHb6kLb6Wygk3cZytSEoptGrlScdHtLPeri1JKueACMZfU1ViJG1Sq5E43dIt7SZZFl1zuRhb/GOs44xFVDbrJzB5tYs35OmaXTrEmkv0DajnMWQB42mNgYNCCwk0MLxheMPrhgUuY2JiUmOqY2pjWMD1hdmPOY+5hPsLCwWLEksSyiOUOawzrLrYiti/sCuxJ7Kc45DiSOPZxmnG2cG7jvMelweXDNYXrEbcBdxf3KR4OngheLd443g18fHwZfFv4NfiX8T8TEBIIEZggsEpQS7BMcJsQl5CFUI3QAWEp4RLhCyJaIldEbURXiJ4RYxEzE0sQ2yD2TzxIfJkEk4SeRJbENIkNEg8k/klqSGZITpE8InlL8p2UmVSG1A6pb9Jx0ltkjGSmyDySlZF1kc2RnSK7R/aZnJ5cmdwB+ST5SwpuCvsUjRTLFHcoOShNU9qhzKespGyhXKV8SPmBCpOKgUqcyjSVR6omqgmqe9RE1OrUnqkHqO9R/6FholGgsUZzgeYZLTUtL60WbS7tKh0OnQydXTpvdGV0O3S/6Gnopekt0ruhz6fvpl+nv0n/h4GdQYvBJUMhwwTDdYYvjFSM4oxmGd0zVjK2M84w3mYiYZJgssLkkqmO6TzTF2Z2ZjVmd8ylzP3MJ5lfsRCwcLJoszhhyWXpZdlhecZKxirHapbVPesF1ndsJGwCbBbZ/LA1sn1jZ2XXY3fFXsM+z36V/S8HD4cGh2OOTI51ThJOK5zeOUs4OzmXOS9wPuUi4JLgss7lm2uU6zY3NrcSty1u39zN3Mvct7l/8xDzMPLw88jyaPM44ynkaeEZ59niucqLyUvPKwgAn3OqOQAAAQAAARcApwARAAAAAAACAAAAAQABAAAAQAAuAAAAAHjarZK9TgJBEMf/d6CRaAyRhMLqCgsbL4ciglTGRPEjSiSKlnLycXJ86CEniU/hM9jYWPgIFkYfwd6nsDD+d1mBIIUx3mZnfzs3MzszuwDCeIYG8UUwQxmAFgxxPeeuyxrmcaNYxzTuFAewi0fFQSTxqXgM11pC8TgS2oPiCUS1d8Uh8ofiSczpYcVT5LjiCPlY8Qui+ncOr7D02y6/BTCrP/m+b5bdTrPi2I26Z9qNGtbRQBMdXMJBGRW0YOCecxEWYoiTCvxrYBunqHPdoX2bLOyrMKlZg8thDETw5K7Itci1TXlGy0124QRZZLDFU/exhxztMozlosTpMH6ZPge0L+OKGnFKjJ4WRwppHPL0PP3SI2P9jLQwFOu3GRhDfkeyDo//G7IHgzllZQxLdquvrdCyBVvat3seJlYo06gxapUxhU2JWnFygR03sSxnEkvcpf5Y5eibGq315TDp7fKWm8zbUVl71Aqq/ZtNnlkWmLnQtno9ycvXYbA6W2pF3aKfCayyC0Ja7Fr/PW70/HO4YM0OKxFvzf0C1MyPjwAAeNpt1VWUU2cYRuHsgxenQt1d8/3JOUnqAyR1d/cCLQVKO22pu7tQd3d3d3d3d3cXmGzumrWy3pWLs/NdPDMpZaWu1783l1Lpf14MnfzO6FbqVupfGkD30iR60JNe9KYP09CXfvRnAAMZxGCGMG3pW6ZjemZgKDMyEzMzC7MyG7MzB3MyF3MzD/MyH/OzAAuyEAuzCIuyGIuzBGWCRIUqOQU16jRYkqVYmmVYluVYng6GMZwRNGmxAiuyEiuzCquyGquzBmuyFmuzDuuyHuuzARuyERuzCZuyGZuzBVuyFVuzDduyHdszklGMZgd2ZAw7MZZxjGdnJrALu9LJbuzOHkxkT/Zib/ZhX/Zjfw7gQA7iYA7hUA7jcI7gSI7iaI7hWI7jeE7gRE7iZE5hEqdyGqdzBmdyFmdzDudyHudzARdyERdzCZdyGZdzBVdyFVdzDddyHddzAzdyEzdzC7dyG7dzB3dyF3dzD/dyH/fzAA/yEA/zCI/yGI/zBE/yFE/zDM/yHM/zAi/yEi/zCq/yGq/zBm/yFm/zDu/yHu/zAR/yER/zCZ/yGZ/zBV/yFV/zDd/yHd/zAz/yEz/zC7/yG7/zB3/yF3/zD/9mpYwsy7pl3bMeWc+sV9Y765NNk/XN+mX9swHZwGxQNjgb0nPkmInjR0V7Uq/OsaPL5Y7ylE3l8tQNN7kVt+rmbuHW3LrbcDvam1rtzVvdm50TxrU/DBvRtZUY1rV5a3jXFn550Wo/XDNWK3dFmh7X9LimxzU9qulRTY9qelTTo5rlKLt2wk7YiaprL+yFvbAX9pK9ZC/ZS/aSvWQv2Uv2kr1kr2KvYq9ir2KvYq9ir2KvYq9ir2Kvaq9qr2qvaq9qr2qvaq9qr2qvai+3l9vL7eX2cnu5vdxebi+3l9sr7BV2CjuFncJOYaewU9gp7NTs1LyrZq9mr2avZq9mr2avZq9mr26vbq9ur26vbq9ur26vbq9ur26vYa9hr2GvYa9hr2GvYa/R7oXuQ/eh+2j/UU7e3C3cqc/V3fYdof/Qf+g/9B/6D/2H/kP/of/Qf+g/9B/6D/2H/kP/of/Qf+g/9B/6D/2H/kP/of/Qf+g/9B/6D/2H/kP/of/Qf+g/9B/6D92H7kP3ofvQfeg+dB+6D92H7kP3ofvQfRT29B/6D/2H/kP/of/Qf+g/9B/6D/2H/kP/of/Qf+g/9B/6D/2H/kP/of/Qf+g/9B/6D/2H/kP/of/Qf+g/9B/6j6nuG3Ya7U5q/0hN3nCTW3Grbu4Wrs/rP+k/6T/pP+k/6T/pP+k+6T7pPek86TzpPOk86TzpOuk66TrpOuk66TrpOlWmPu/36zrpOuk66TrpOuk66TrpOvl/Pek76TvpO+k76TvpO+k76TvpO+k76TvpO7V9t+qtVs/OaOURU6bo6PgPt6rZbwAAAAABVFDDFwAA) format(&#39;woff&#39;),url(data:font/ttf;base64,AAEAAAAPAIAAAwBwRkZUTW0ql9wAAAD8AAAAHEdERUYBRAAEAAABGAAAACBPUy8yZ7lriQAAATgAAABgY21hcNqt44EAAAGYAAAGcmN2dCAAKAL4AAAIDAAAAARnYXNw//8AAwAACBAAAAAIZ2x5Zn1dwm8AAAgYAACUpGhlYWQFTS/YAACcvAAAADZoaGVhCkQEEQAAnPQAAAAkaG10eNLHIGAAAJ0YAAADdGxvY2Fv+5XOAACgjAAAAjBtYXhwAWoA2AAAorwAAAAgbmFtZbMsoJsAAKLcAAADonBvc3S6o+U1AACmgAAACtF3ZWJmwxhUUAAAsVQAAAAGAAAAAQAAAADMPaLPAAAAANB2gXUAAAAA0HZzlwABAAAADgAAABgAAAAAAAIAAQABARYAAQAEAAAAAgAAAAMEiwGQAAUABAMMAtAAAABaAwwC0AAAAaQAMgK4AAAAAAUAAAAAAAAAAAAAAAIAAAAAAAAAAAAAAFVLV04AQAAg//8DwP8QAAAFFAB7AAAAAQAAAAAAAAAAAAAAIAABAAAABQAAAAMAAAAsAAAACgAAAdwAAQAAAAAEaAADAAEAAAAsAAMACgAAAdwABAGwAAAAaABAAAUAKAAgACsAoAClIAogLyBfIKwgvSISIxsl/CYBJvonCScP4APgCeAZ4CngOeBJ4FngYOBp4HngieCX4QnhGeEp4TnhRuFJ4VnhaeF54YnhleGZ4gbiCeIW4hniIeIn4jniSeJZ4mD4////AAAAIAAqAKAApSAAIC8gXyCsIL0iEiMbJfwmASb6JwknD+AB4AXgEOAg4DDgQOBQ4GDgYuBw4IDgkOEB4RDhIOEw4UDhSOFQ4WDhcOGA4ZDhl+IA4gniEOIY4iHiI+Iw4kDiUOJg+P/////j/9r/Zv9i4Ajf5N+132nfWd4F3P3aHdoZ2SHZE9kOIB0gHCAWIBAgCiAEH/4f+B/3H/Ef6x/lH3wfdh9wH2ofZB9jH10fVx9RH0sfRR9EHt4e3B7WHtUezh7NHsUevx65HrMIFQABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAAAAAACjAAAAAAAAAA1AAAAIAAAACAAAAADAAAAKgAAACsAAAAEAAAAoAAAAKAAAAAGAAAApQAAAKUAAAAHAAAgAAAAIAoAAAAIAAAgLwAAIC8AAAATAAAgXwAAIF8AAAAUAAAgrAAAIKwAAAAVAAAgvQAAIL0AAAAWAAAiEgAAIhIAAAAXAAAjGwAAIxsAAAAYAAAl/AAAJfwAAAAZAAAmAQAAJgEAAAAaAAAm+gAAJvoAAAAbAAAnCQAAJwkAAAAcAAAnDwAAJw8AAAAdAADgAQAA4AMAAAAeAADgBQAA4AkAAAAhAADgEAAA4BkAAAAmAADgIAAA4CkAAAAwAADgMAAA4DkAAAA6AADgQAAA4EkAAABEAADgUAAA4FkAAABOAADgYAAA4GAAAABYAADgYgAA4GkAAABZAADgcAAA4HkAAABhAADggAAA4IkAAABrAADgkAAA4JcAAAB1AADhAQAA4QkAAAB9AADhEAAA4RkAAACGAADhIAAA4SkAAACQAADhMAAA4TkAAACaAADhQAAA4UYAAACkAADhSAAA4UkAAACrAADhUAAA4VkAAACtAADhYAAA4WkAAAC3AADhcAAA4XkAAADBAADhgAAA4YkAAADLAADhkAAA4ZUAAADVAADhlwAA4ZkAAADbAADiAAAA4gYAAADeAADiCQAA4gkAAADlAADiEAAA4hYAAADmAADiGAAA4hkAAADtAADiIQAA4iEAAADvAADiIwAA4icAAADwAADiMAAA4jkAAAD1AADiQAAA4kkAAAD/AADiUAAA4lkAAAEJAADiYAAA4mAAAAETAAD4/wAA+P8AAAEUAAH1EQAB9REAAAEVAAH2qgAB9qoAAAEWAAYCCgAAAAABAAABAAAAAAAAAAAAAAAAAAAAAQACAAAAAAAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAwAAAAAAAAAAAAAAAAAAAAAAAAAEAAUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKAL4AAAAAf//AAIAAgAoAAABaAMgAAMABwAusQEALzyyBwQA7TKxBgXcPLIDAgDtMgCxAwAvPLIFBADtMrIHBgH8PLIBAgDtMjMRIRElMxEjKAFA/ujw8AMg/OAoAtAAAQBkAGQETARMAFsAAAEyFh8BHgEdATc+AR8BFgYPATMyFhcWFRQGDwEOASsBFx4BDwEGJi8BFRQGBwYjIiYvAS4BPQEHDgEvASY2PwEjIiYnJjU0Nj8BPgE7AScuAT8BNhYfATU0Njc2AlgPJgsLCg+eBxYIagcCB57gChECBgMCAQIRCuCeBwIHaggWB54PCikiDyYLCwoPngcWCGoHAgee4AoRAgYDAgECEQrgngcCB2oIFgeeDwopBEwDAgECEQrgngcCB2oIFgeeDwopIg8mCwsKD54HFghqBwIHnuAKEQIGAwIBAhEK4J4HAgdqCBYHng8KKSIPJgsLCg+eBxYIagcCB57gChECBgAAAAABAAAAAARMBEwAIwAAATMyFhURITIWHQEUBiMhERQGKwEiJjURISImPQE0NjMhETQ2AcLIFR0BXhUdHRX+oh0VyBUd/qIVHR0VAV4dBEwdFf6iHRXIFR3+ohUdHRUBXh0VyBUdAV4VHQAAAAABAHAAAARABEwARQAAATMyFgcBBgchMhYPAQ4BKwEVITIWDwEOASsBFRQGKwEiJj0BISImPwE+ATsBNSEiJj8BPgE7ASYnASY2OwEyHwEWMj8BNgM5+goFCP6UBgUBDAoGBngGGAp9ARMKBgZ4BhgKfQ8LlAsP/u0KBgZ4BhgKff7tCgYGeAYYCnYFBv6UCAUK+hkSpAgUCKQSBEwKCP6UBgwMCKAIDGQMCKAIDK4LDw8LrgwIoAgMZAwIoAgMDAYBbAgKEqQICKQSAAABAGQABQSMBK4AOwAAATIXFhcjNC4DIyIOAwchByEGFSEHIR4EMzI+AzUzBgcGIyInLgEnIzczNjcjNzM+ATc2AujycDwGtSM0QDkXEys4MjAPAXtk/tQGAZZk/tQJMDlCNBUWOUA0I64eYmunznYkQgzZZHABBdpkhhQ+H3UErr1oaS1LMCEPCx4uTzJkMjJkSnRCKw8PIjBKK6trdZ4wqndkLzVkV4UljQAAAgB7AAAETASwAD4ARwAAASEyHgUVHAEVFA4FKwEHITIWDwEOASsBFRQGKwEiJj0BISImPwE+ATsBNSEiJj8BPgE7ARE0NhcRMzI2NTQmIwGsAV5DakIwFgwBAQwWMEJqQ7ICASAKBgZ4BhgKigsKlQoP/vUKBgZ4BhgKdf71CgYGeAYYCnUPtstALS1ABLAaJD8yTyokCwsLJCpQMkAlGmQMCKAIDK8LDg8KrwwIoAgMZAwIoAgMAdsKD8j+1EJWVEAAAAEAyAGQBEwCvAAPAAATITIWHQEUBiMhIiY9ATQ2+gMgFR0dFfzgFR0dArwdFcgVHR0VyBUdAAAAAgDIAAAD6ASwACUAQQAAARUUBisBFRQGBx4BHQEzMhYdASE1NDY7ATU0NjcuAT0BIyImPQEXFRQWFx4BFAYHDgEdASE1NCYnLgE0Njc+AT0BA+gdFTJjUVFjMhUd/OAdFTJjUVFjMhUdyEE3HCAgHDdBAZBBNxwgIBw3QQSwlhUdZFuVIyOVW5YdFZaWFR2WW5UjI5VbZB0VlshkPGMYDDI8MgwYYzyWljxjGAwyPDIMGGM8ZAAAAAEAAAAAAAAAAAAAAAAxAAAB//IBLATCBEEAFgAAATIWFzYzMhYVFAYjISImNTQ2NyY1NDYB9261LCwueKqqeP0ST3FVQgLYBEF3YQ6teHmtclBFaw4MGZnXAAAAAgAAAGQEsASvABoAHgAAAB4BDwEBMzIWHQEhNTQ2OwEBJyY+ARYfATc2AyEnAwL2IAkKiAHTHhQe+1AeFB4B1IcKCSAkCm9wCXoBebbDBLMTIxC7/RYlFSoqFSUC6rcQJBQJEJSWEPwecAIWAAAAAAQAAABkBLAETAALABcAIwA3AAATITIWBwEGIicBJjYXARYUBwEGJjURNDYJATYWFREUBicBJjQHARYGIyEiJjcBNjIfARYyPwE2MhkEfgoFCP3MCBQI/cwIBQMBCAgI/vgICgoDjAEICAoKCP74CFwBbAgFCvuCCgUIAWwIFAikCBQIpAgUBEwKCP3JCAgCNwgK2v74CBQI/vgIBQoCJgoF/vABCAgFCv3aCgUIAQgIFID+lAgKCggBbAgIpAgIpAgAAAAD//D/8AS6BLoACQANABAAAAAyHwEWFA8BJzcTAScJAQUTA+AmDpkNDWPWXyL9mdYCZv4f/rNuBLoNmQ4mDlzWYP50/ZrWAmb8anABTwAAAAEAAAAABLAEsAAPAAABETMyFh0BITU0NjsBEQEhArz6FR384B0V+v4MBLACiv3aHRUyMhUdAiYCJgAAAAEADgAIBEwEnAAfAAABJTYWFREUBgcGLgE2NzYXEQURFAYHBi4BNjc2FxE0NgFwAoUnMFNGT4gkV09IQv2oWEFPiCRXT0hCHQP5ow8eIvzBN1EXGSltchkYEAIJm/2iKmAVGilucRoYEQJ/JioAAAACAAn/+AS7BKcAHQApAAAAMh4CFQcXFAcBFgYPAQYiJwEGIycHIi4CND4BBCIOARQeATI+ATQmAZDItoNOAQFOARMXARY7GikT/u13jgUCZLaDTk6DAXKwlFZWlLCUVlYEp06DtmQCBY15/u4aJRg6FBQBEk0BAU6Dtsi2g1tWlLCUVlaUsJQAAQBkAFgErwREABkAAAE+Ah4CFRQOAwcuBDU0PgIeAQKJMHt4dVg2Q3mEqD4+p4V4Qzhadnh5A7VESAUtU3ZAOXmAf7JVVbJ/gHk5QHZTLQVIAAAAAf/TAF4EewSUABgAAAETNjIXEyEyFgcFExYGJyUFBiY3EyUmNjMBl4MHFQeBAaUVBhH+qoIHDxH+qf6qEQ8Hgv6lEQYUAyABYRMT/p8RDPn+bxQLDPb3DAsUAZD7DBEAAv/TAF4EewSUABgAIgAAARM2MhcTITIWBwUTFgYnJQUGJjcTJSY2MwUjFwc3Fyc3IycBl4MHFQeBAaUVBhH+qoIHDxH+qf6qEQ8Hgv6lEQYUAfPwxUrBw0rA6k4DIAFhExP+nxEM+f5vFAsM9vcMCxQBkPsMEWSO4ouM5YzTAAABAAAAAASwBLAAJgAAATIWHQEUBiMVFBYXBR4BHQEUBiMhIiY9ATQ2NyU+AT0BIiY9ATQ2Alh8sD4mDAkBZgkMDwr7ggoPDAkBZgkMJj6wBLCwfPouaEsKFwbmBRcKXQoPDwpdChcF5gYXCktoLvp8sAAAAA0AAAAABLAETAAPABMAIwAnACsALwAzADcARwBLAE8AUwBXAAATITIWFREUBiMhIiY1ETQ2FxUzNSkBIgYVERQWMyEyNjURNCYzFTM1BRUzNSEVMzUFFTM1IRUzNQchIgYVERQWMyEyNjURNCYFFTM1IRUzNQUVMzUhFTM1GQR+Cg8PCvuCCg8PVWQCo/3aCg8PCgImCg8Pc2T8GGQDIGT8GGQDIGTh/doKDw8KAiYKDw/872QDIGT8GGQDIGQETA8K++YKDw8KBBoKD2RkZA8K/qIKDw8KAV4KD2RkyGRkZGTIZGRkZGQPCv6iCg8PCgFeCg9kZGRkZMhkZGRkAAAEAAAAAARMBEwADwAfAC8APwAAEyEyFhURFAYjISImNRE0NikBMhYVERQGIyEiJjURNDYBITIWFREUBiMhIiY1ETQ2KQEyFhURFAYjISImNRE0NjIBkBUdHRX+cBUdHQJtAZAVHR0V/nAVHR39vQGQFR0dFf5wFR0dAm0BkBUdHRX+cBUdHQRMHRX+cBUdHRUBkBUdHRX+cBUdHRUBkBUd/agdFf5wFR0dFQGQFR0dFf5wFR0dFQGQFR0AAAkAAAAABEwETAAPAB8ALwA/AE8AXwBvAH8AjwAAEzMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYhMzIWHQEUBisBIiY9ATQ2ATMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYhMzIWHQEUBisBIiY9ATQ2ATMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYhMzIWHQEUBisBIiY9ATQ2MsgVHR0VyBUdHQGlyBUdHRXIFR0dAaXIFR0dFcgVHR389cgVHR0VyBUdHQGlyBUdHRXIFR0dAaXIFR0dFcgVHR389cgVHR0VyBUdHQGlyBUdHRXIFR0dAaXIFR0dFcgVHR0ETB0VyBUdHRXIFR0dFcgVHR0VyBUdHRXIFR0dFcgVHf5wHRXIFR0dFcgVHR0VyBUdHRXIFR0dFcgVHR0VyBUd/nAdFcgVHR0VyBUdHRXIFR0dFcgVHR0VyBUdHRXIFR0ABgAAAAAEsARMAA8AHwAvAD8ATwBfAAATMzIWHQEUBisBIiY9ATQ2KQEyFh0BFAYjISImPQE0NgEzMhYdARQGKwEiJj0BNDYpATIWHQEUBiMhIiY9ATQ2ATMyFh0BFAYrASImPQE0NikBMhYdARQGIyEiJj0BNDYyyBUdHRXIFR0dAaUCvBUdHRX9RBUdHf6FyBUdHRXIFR0dAaUCvBUdHRX9RBUdHf6FyBUdHRXIFR0dAaUCvBUdHRX9RBUdHQRMHRXIFR0dFcgVHR0VyBUdHRXIFR3+cB0VyBUdHRXIFR0dFcgVHR0VyBUd/nAdFcgVHR0VyBUdHRXIFR0dFcgVHQAAAAABACYALAToBCAAFwAACQE2Mh8BFhQHAQYiJwEmND8BNjIfARYyAdECOwgUB7EICPzxBxUH/oAICLEHFAirBxYB3QI7CAixBxQI/PAICAGACBQHsQgIqwcAAQBuAG4EQgRCACMAAAEXFhQHCQEWFA8BBiInCQEGIi8BJjQ3CQEmND8BNjIXCQE2MgOIsggI/vUBCwgIsggVB/70/vQHFQiyCAgBC/71CAiyCBUHAQwBDAcVBDuzCBUH/vT+9AcVCLIICAEL/vUICLIIFQcBDAEMBxUIsggI/vUBDAcAAwAX/+sExQSZABkAJQBJAAAAMh4CFRQHARYUDwEGIicBBiMiLgI0PgEEIg4BFB4BMj4BNCYFMzIWHQEzMhYdARQGKwEVFAYrASImPQEjIiY9ATQ2OwE1NDYBmcSzgk1OASwICG0HFQj+1HeOYrSBTU2BAW+zmFhYmLOZWFj+vJYKD0sKDw8KSw8KlgoPSwoPDwpLDwSZTYKzYo15/tUIFQhsCAgBK01NgbTEs4JNWJmzmFhYmLOZIw8KSw8KlgoPSwoPDwpLDwqWCg9LCg8AAAMAF//rBMUEmQAZACUANQAAADIeAhUUBwEWFA8BBiInAQYjIi4CND4BBCIOARQeATI+ATQmBSEyFh0BFAYjISImPQE0NgGZxLOCTU4BLAgIbQcVCP7Ud45itIFNTYEBb7OYWFiYs5lYWP5YAV4KDw8K/qIKDw8EmU2Cs2KNef7VCBUIbAgIAStNTYG0xLOCTViZs5hYWJizmYcPCpYKDw8KlgoPAAAAAAIAFwAXBJkEsAAPAC0AAAEzMhYVERQGKwEiJjURNDYFNRYSFRQOAiIuAjU0EjcVDgEVFB4BMj4BNTQmAiZkFR0dFWQVHR0BD6fSW5vW6tabW9KnZ3xyxejFcnwEsB0V/nAVHR0VAZAVHeGmPv7ZuHXWm1tbm9Z1uAEnPqY3yHh0xXJyxXR4yAAEAGQAAASwBLAADwAfAC8APwAAATMyFhURFAYrASImNRE0NgEzMhYVERQGKwEiJjURNDYBMzIWFREUBisBIiY1ETQ2BTMyFh0BFAYrASImPQE0NgQBlgoPDwqWCg8P/t6WCg8PCpYKDw/+3pYKDw8KlgoPD/7elgoPDwqWCg8PBLAPCvuCCg8PCgR+Cg/+cA8K/RIKDw8KAu4KD/7UDwr+PgoPDwoBwgoPyA8K+goPDwr6Cg8AAAAAAgAaABsElgSWAEcATwAAATIfAhYfATcWFwcXFh8CFhUUDwIGDwEXBgcnBwYPAgYjIi8CJi8BByYnNycmLwImNTQ/AjY/ASc2Nxc3Nj8CNhIiBhQWMjY0AlghKSYFMS0Fhj0rUAMZDgGYBQWYAQ8YA1AwOIYFLDIFJisfISkmBTEtBYY8LFADGQ0ClwYGlwINGQNQLzqFBS0xBSYreLJ+frJ+BJYFmAEOGQJQMDmGBSwxBiYrHiIoJgYxLAWGPSxRAxkOApcFBZcCDhkDUTA5hgUtMAYmKiAhKCYGMC0Fhj0sUAIZDgGYBf6ZfrF+frEABwBkAAAEsAUUABMAFwAhACUAKQAtADEAAAEhMhYdASEyFh0BITU0NjMhNTQ2FxUhNQERFAYjISImNREXETMRMxEzETMRMxEzETMRAfQBLCk7ARMKD/u0DwoBEzspASwBLDsp/UQpO2RkZGRkZGRkBRQ7KWQPCktLCg9kKTtkZGT+1PzgKTs7KQMgZP1EArz9RAK8/UQCvP1EArwAAQAMAAAFCATRAB8AABMBNjIXARYGKwERFAYrASImNREhERQGKwEiJjURIyImEgJsCBUHAmAIBQqvDwr6Cg/+1A8K+goPrwoFAmoCYAcH/aAICv3BCg8PCgF3/okKDw8KAj8KAAIAZAAAA+gEsAARABcAAAERFBYzIREUBiMhIiY1ETQ2MwEjIiY9AQJYOykBLB0V/OAVHR0VA1L6FR0EsP5wKTv9dhUdHRUETBUd/nAdFfoAAwAXABcEmQSZAA8AGwAwAAAAMh4CFA4CIi4CND4BBCIOARQeATI+ATQmBTMyFhURMzIWHQEUBisBIiY1ETQ2AePq1ptbW5vW6tabW1ubAb/oxXJyxejFcnL+fDIKD68KDw8K+goPDwSZW5vW6tabW1ub1urWmztyxejFcnLF6MUNDwr+7Q8KMgoPDwoBXgoPAAAAAAL/nAAABRQEsAALAA8AACkBAyMDIQEzAzMDMwEDMwMFFP3mKfIp/eYBr9EVohTQ/p4b4BsBkP5wBLD+1AEs/nD+1AEsAAAAAAIAZAAABLAEsAAVAC8AAAEzMhYVETMyFgcBBiInASY2OwERNDYBMzIWFREUBiMhIiY1ETQ2OwEyFh0BITU0NgImyBUdvxQLDf65DSYN/rkNCxS/HQJUMgoPDwr75goPDwoyCg8DhA8EsB0V/j4XEP5wEBABkBAXAcIVHfzgDwr+ogoPDwoBXgoPDwqvrwoPAAMAFwAXBJkEmQAPABsAMQAAADIeAhQOAiIuAjQ+AQQiDgEUHgEyPgE0JgUzMhYVETMyFgcDBiInAyY2OwERNDYB4+rWm1tbm9bq1ptbW5sBv+jFcnLF6MVycv58lgoPiRUKDd8NJg3fDQoViQ8EmVub1urWm1tbm9bq1ps7csXoxXJyxejFDQ8K/u0XEP7tEBABExAXARMKDwAAAAMAFwAXBJkEmQAPABsAMQAAADIeAhQOAiIuAjQ+AQQiDgEUHgEyPgE0JiUTFgYrAREUBisBIiY1ESMiJjcTNjIB4+rWm1tbm9bq1ptbW5sBv+jFcnLF6MVycv7n3w0KFYkPCpYKD4kVCg3fDSYEmVub1urWm1tbm9bq1ps7csXoxXJyxejFAf7tEBf+7QoPDwoBExcQARMQAAAAAAIAAAAABLAEsAAZADkAABMhMhYXExYVERQGBwYjISImJyY1EzQ3Ez4BBSEiBgcDBhY7ATIWHwEeATsBMjY/AT4BOwEyNicDLgHhAu4KEwO6BwgFDBn7tAweAgYBB7kDEwKX/dQKEgJXAgwKlgoTAiYCEwr6ChMCJgITCpYKDAJXAhIEsA4K/XQYGf5XDB4CBggEDRkBqRkYAowKDsgOC/4+Cw4OCpgKDg4KmAoODgsBwgsOAAMAFwAXBJkEmQAPABsAJwAAADIeAhQOAiIuAjQ+AQQiDgEUHgEyPgE0JgUXFhQPAQYmNRE0NgHj6tabW1ub1urWm1tbmwG/6MVycsXoxXJy/ov9ERH9EBgYBJlbm9bq1ptbW5vW6tabO3LF6MVycsXoxV2+DCQMvgwLFQGQFQsAAQAXABcEmQSwACgAAAE3NhYVERQGIyEiJj8BJiMiDgEUHgEyPgE1MxQOAiIuAjQ+AjMyA7OHBwsPCv6WCwQHhW2BdMVycsXoxXKWW5vW6tabW1ub1nXABCSHBwQL/pYKDwsHhUxyxejFcnLFdHXWm1tbm9bq1ptbAAAAAAIAFwABBJkEsAAaADUAAAE3NhYVERQGIyEiJj8BJiMiDgEVIzQ+AjMyEzMUDgIjIicHBiY1ETQ2MyEyFg8BFjMyPgEDs4cHCw8L/pcLBAeGboF0xXKWW5vWdcDrllub1nXAnIYHCw8LAWgKBQiFboJ0xXIEJIcHBAv+lwsPCweGS3LFdHXWm1v9v3XWm1t2hggFCgFoCw8LB4VMcsUAAAAKAGQAAASwBLAADwAfAC8APwBPAF8AbwB/AI8AnwAAEyEyFhURFAYjISImNRE0NgUhIgYVERQWMyEyNjURNCYFMzIWHQEUBisBIiY9ATQ2MyEyFh0BFAYjISImPQE0NgczMhYdARQGKwEiJj0BNDYzITIWHQEUBiMhIiY9ATQ2BzMyFh0BFAYrASImPQE0NjMhMhYdARQGIyEiJj0BNDYHMzIWHQEUBisBIiY9ATQ2MyEyFh0BFAYjISImPQE0Nn0EGgoPDwr75goPDwPA/K4KDw8KA1IKDw/9CDIKDw8KMgoPD9IBwgoPDwr+PgoPD74yCg8PCjIKDw/SAcIKDw8K/j4KDw++MgoPDwoyCg8P0gHCCg8PCv4+Cg8PvjIKDw8KMgoPD9IBwgoPDwr+PgoPDwSwDwr7ggoPDwoEfgoPyA8K/K4KDw8KA1IKD2QPCjIKDw8KMgoPDwoyCg8PCjIKD8gPCjIKDw8KMgoPDwoyCg8PCjIKD8gPCjIKDw8KMgoPDwoyCg8PCjIKD8gPCjIKDw8KMgoPDwoyCg8PCjIKDwAAAAACAAAAAARMBLAAGQAjAAABNTQmIyEiBh0BIyIGFREUFjMhMjY1ETQmIyE1NDY7ATIWHQEDhHVT/tRSdmQpOzspA4QpOzsp/ageFMgUHgMgyFN1dlLIOyn9qCk7OykCWCk7lhUdHRWWAAIAZAAABEwETAAJADcAABMzMhYVESMRNDYFMhcWFREUBw4DIyIuAScuAiMiBwYjIicmNRE+ATc2HgMXHgIzMjc2fTIKD2QPA8AEBRADIUNAMRwaPyonKSxHHlVLBwgGBQ4WeDsXKC4TOQQpLUUdZ1AHBEwPCvvNBDMKDzACBhH+WwYGO1AkDQ0ODg8PDzkFAwcPAbY3VwMCAwsGFAEODg5XCAAAAwAAAAAEsASXACEAMQBBAAAAMh4CFREUBisBIiY1ETQuASAOARURFAYrASImNRE0PgEDMzIWFREUBisBIiY1ETQ2ITMyFhURFAYrASImNRE0NgHk6N6jYw8KMgoPjeT++uSNDwoyCg9joyqgCAwMCKAIDAwCYKAIDAwIoAgMDASXY6PedP7UCg8PCgEsf9FyctF//tQKDw8KASx03qP9wAwI/jQIDAwIAcwIDAwI/jQIDAwIAcwIDAAAAAACAAAA0wRHA90AFQA5AAABJTYWFREUBiclJisBIiY1ETQ2OwEyBTc2Mh8BFhQPARcWFA8BBiIvAQcGIi8BJjQ/AScmND8BNjIXAUEBAgkMDAn+/hUZ+goPDwr6GQJYeAcUByIHB3h4BwciBxQHeHgHFAciBwd3dwcHIgcUBwMurAYHCv0SCgcGrA4PCgFeCg+EeAcHIgcUB3h4BxQHIgcHd3cHByIHFAd4eAcUByIICAAAAAACAAAA0wNyA90AFQAvAAABJTYWFREUBiclJisBIiY1ETQ2OwEyJTMWFxYVFAcGDwEiLwEuATc2NTQnJjY/ATYBQQECCQwMCf7+FRn6Cg8PCvoZAdIECgZgWgYLAwkHHQcDBkhOBgMIHQcDLqwGBwr9EgoHBqwODwoBXgoPZAEJgaGafwkBAQYXBxMIZ36EaggUBxYFAAAAAAMAAADEBGID7AAbADEASwAAATMWFxYVFAYHBgcjIi8BLgE3NjU0JicmNj8BNgUlNhYVERQGJyUmKwEiJjURNDY7ATIlMxYXFhUUBwYPASIvAS4BNzY1NCcmNj8BNgPHAwsGh0RABwoDCQcqCAIGbzs3BgIJKgf9ggECCQwMCf7+FRn6Cg8PCvoZAdIECgZgWgYLAwkHHQcDBkhOBgMIHQcD7AEJs9lpy1QJAQYiBhQIlrJarEcJFAYhBb6sBgcK/RIKBwasDg8KAV4KD2QBCYGhmn8JAQEGFwcTCGd+hGoIFQYWBQAAAAANAAAAAASwBLAACQAVABkAHQAhACUALQA7AD8AQwBHAEsATwAAATMVIxUhFSMRIQEjFTMVIREjESM1IQURIREhESERBSM1MwUjNTMBMxEhETM1MwEzFSMVIzUjNTM1IzUhBREhEQcjNTMFIzUzASM1MwUhNSEB9GRk/nBkAfQCvMjI/tTIZAJY+7QBLAGQASz84GRkArxkZP1EyP4MyGQB9MhkyGRkyAEs/UQBLGRkZAOEZGT+DGRkAfT+1AEsA4RkZGQCWP4MZMgBLAEsyGT+1AEs/tQBLMhkZGT+DP4MAfRk/tRkZGRkyGTI/tQBLMhkZGT+1GRkZAAAAAAJAAAAAASwBLAAAwAHAAsADwATABcAGwAfACMAADcjETMTIxEzASMRMxMjETMBIxEzASE1IRcjNTMXIzUzBSM1M2RkZMhkZAGQyMjIZGQBLMjI/OD+1AEsyGRkyGRkASzIyMgD6PwYA+j8GAPo/BgD6PwYA+j7UGRkW1tbW1sAAAIAAAAKBKYEsAANABUAAAkBFhQHAQYiJwETNDYzBCYiBhQWMjYB9AKqCAj+MAgUCP1WAQ8KAUM7Uzs7UzsEsP1WCBQI/jAICAKqAdsKD807O1Q7OwAAAAADAAAACgXSBLAADQAZACEAAAkBFhQHAQYiJwETNDYzIQEWFAcBBiIvAQkBBCYiBhQWMjYB9AKqCAj+MAgUCP1WAQ8KAwYCqggI/jAIFAg4Aaj9RP7TO1M7O1M7BLD9VggUCP4wCAgCqgHbCg/9VggUCP4wCAg4AaoCvM07O1Q7OwAAAAABAGQAAASwBLAAJgAAASEyFREUDwEGJjURNCYjISIPAQYWMyEyFhURFAYjISImNRE0PwE2ASwDOUsSQAgKDwr9RBkSQAgFCgK8Cg8PCvyuCg8SixIEsEv8fBkSQAgFCgO2Cg8SQAgKDwr8SgoPDwoDzxkSixIAAAABAMj//wRMBLAACgAAEyEyFhURCQERNDb6AyAVHf4+/j4dBLAdFfuCAbz+QwR/FR0AAAAAAwAAAAAEsASwABUARQBVAAABISIGBwMGHwEeATMhMjY/ATYnAy4BASMiBg8BDgEjISImLwEuASsBIgYVERQWOwEyNj0BNDYzITIWHQEUFjsBMjY1ETQmASEiBg8BBhYzITI2LwEuAQM2/kQLEAFOBw45BhcKAcIKFwY+DgdTARABVpYKFgROBBYK/doKFgROBBYKlgoPDwqWCg8PCgLuCg8PCpYKDw/+sf4MChMCJgILCgJYCgsCJgITBLAPCv7TGBVsCQwMCWwVGAEtCg/+cA0JnAkNDQmcCQ0PCv12Cg8PCpYKDw8KlgoPDwoCigoP/agOCpgKDg4KmAoOAAAAAAQAAABkBLAETAAdACEAKQAxAAABMzIeAh8BMzIWFREUBiMhIiY1ETQ2OwE+BAEVMzUEIgYUFjI2NCQyFhQGIiY0AfTIOF00JAcGlik7Oyn8GCk7OymWAgknM10ByGT+z76Hh76H/u9WPDxWPARMKTs7FRQ7Kf2oKTs7KQJYKTsIG0U1K/7UZGRGh76Hh74IPFY8PFYAAAAAAgA1AAAEsASvACAAIwAACQEWFx4BHwEVITUyNi8BIQYHBh4CMxUhNTY3PgE/AQEDIQMCqQGBFCgSJQkK/l81LBFS/nk6IgsJKjIe/pM4HAwaBwcBj6wBVKIEr/waMioTFQECQkJXLd6RWSIuHAxCQhgcDCUNDQPu/VoByQAAAAADAGQAAAPwBLAAJwAyADsAAAEeBhUUDgMjITU+ATURNC4EJzUFMh4CFRQOAgclMzI2NTQuAisBETMyNjU0JisBAvEFEzUwOyodN1htbDD+DCk7AQYLFyEaAdc5dWM+Hy0tEP6Pi05pESpTPnbYUFJ9Xp8CgQEHGB0zOlIuQ3VONxpZBzMoAzsYFBwLEAkHRwEpSXNDM1s6KwkxYUopOzQb/K5lUFqBAAABAMgAAANvBLAAGQAAARcOAQcDBhYXFSE1NjcTNjQuBCcmJzUDbQJTQgeECSxK/gy6Dq0DAw8MHxUXDQYEsDkTNSj8uTEoBmFhEFIDQBEaExAJCwYHAwI5AAAAAAL/tQAABRQEsAAlAC8AAAEjNC4FKwERFBYfARUhNTI+AzURIyIOBRUjESEFIxEzByczESM3BRQyCAsZEyYYGcgyGRn+cAQOIhoWyBkYJhMZCwgyA+j7m0tLfX1LS30DhBUgFQ4IAwH8rhYZAQJkZAEFCRUOA1IBAwgOFSAVASzI/OCnpwMgpwACACH/tQSPBLAAJQAvAAABIzQuBSsBERQWHwEVITUyPgM1ESMiDgUVIxEhEwc1IRUnNxUhNQRMMggLGRMmGBnIMhkZ/nAEDiIaFsgZGCYTGQsIMgPoQ6f84KenAyADhBUgFQ4IAwH9dhYZAQJkZAEFCRUOAooBAwgOFSAVASz7gn1LS319S0sABAAAAAAEsARMAA8AHwAvAD8AABMhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2EyEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYyAlgVHR0V/agVHR0VA+gVHR0V/BgVHR0VAyAVHR0V/OAVHR0VBEwVHR0V+7QVHR0ETB0VZBUdHRVkFR3+1B0VZBUdHRVkFR3+1B0VZBUdHRVkFR3+1B0VZBUdHRVkFR0ABAAAAAAEsARMAA8AHwAvAD8AABMhMhYdARQGIyEiJj0BNDYDITIWHQEUBiMhIiY9ATQ2EyEyFh0BFAYjISImPQE0NgMhMhYdARQGIyEiJj0BNDb6ArwVHR0V/UQVHR2zBEwVHR0V+7QVHR3dArwVHR0V/UQVHR2zBEwVHR0V+7QVHR0ETB0VZBUdHRVkFR3+1B0VZBUdHRVkFR3+1B0VZBUdHRVkFR3+1B0VZBUdHRVkFR0ABAAAAAAEsARMAA8AHwAvAD8AAAE1NDYzITIWHQEUBiMhIiYBNTQ2MyEyFh0BFAYjISImEzU0NjMhMhYdARQGIyEiJgE1NDYzITIWHQEUBiMhIiYB9B0VAlgVHR0V/agVHf5wHRUD6BUdHRX8GBUdyB0VAyAVHR0V/OAVHf7UHRUETBUdHRX7tBUdA7ZkFR0dFWQVHR3+6WQVHR0VZBUdHf7pZBUdHRVkFR0d/ulkFR0dFWQVHR0AAAQAAAAABLAETAAPAB8ALwA/AAATITIWHQEUBiMhIiY9ATQ2EyEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2MgRMFR0dFfu0FR0dFQRMFR0dFfu0FR0dFQRMFR0dFfu0FR0dFQRMFR0dFfu0FR0dBEwdFWQVHR0VZBUd/tQdFWQVHR0VZBUd/tQdFWQVHR0VZBUd/tQdFWQVHR0VZBUdAAgAAAAABLAETAAPAB8ALwA/AE8AXwBvAH8AABMzMhYdARQGKwEiJj0BNDYpATIWHQEUBiMhIiY9ATQ2ATMyFh0BFAYrASImPQE0NikBMhYdARQGIyEiJj0BNDYBMzIWHQEUBisBIiY9ATQ2KQEyFh0BFAYjISImPQE0NgEzMhYdARQGKwEiJj0BNDYpATIWHQEUBiMhIiY9ATQ2MmQVHR0VZBUdHQFBAyAVHR0V/OAVHR3+6WQVHR0VZBUdHQFBAyAVHR0V/OAVHR3+6WQVHR0VZBUdHQFBAyAVHR0V/OAVHR3+6WQVHR0VZBUdHQFBAyAVHR0V/OAVHR0ETB0VZBUdHRVkFR0dFWQVHR0VZBUd/tQdFWQVHR0VZBUdHRVkFR0dFWQVHf7UHRVkFR0dFWQVHR0VZBUdHRVkFR3+1B0VZBUdHRVkFR0dFWQVHR0VZBUdAAAG/5wAAASwBEwAAwATACMAKgA6AEoAACEjETsCMhYdARQGKwEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2BQc1IzUzNQUhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2AZBkZJZkFR0dFWQVHR0VAfQVHR0V/gwVHR3++qfIyAHCASwVHR0V/tQVHR0VAlgVHR0V/agVHR0ETB0VZBUdHRVkFR3+1B0VZBUdHRVkFR36fUtkS68dFWQVHR0VZBUd/tQdFWQVHR0VZBUdAAAABgAAAAAFFARMAA8AEwAjACoAOgBKAAATMzIWHQEUBisBIiY9ATQ2ASMRMwEhMhYdARQGIyEiJj0BNDYFMxUjFSc3BSEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYyZBUdHRVkFR0dA2dkZPyuAfQVHR0V/gwVHR0EL8jIp6f75gEsFR0dFf7UFR0dFQJYFR0dFf2oFR0dBEwdFWQVHR0VZBUd+7QETP7UHRVkFR0dFWQVHchkS319rx0VZBUdHRVkFR3+1B0VZBUdHRVkFR0AAAAAAgAAAMgEsAPoAA8AEgAAEyEyFhURFAYjISImNRE0NgkCSwLuHywsH/0SHywsBIT+1AEsA+gsH/12HywsHwKKHyz9RAEsASwAAwAAAAAEsARMAA8AFwAfAAATITIWFREUBiMhIiY1ETQ2FxE3BScBExEEMhYUBiImNCwEWBIaGhL7qBIaGkr3ASpKASXs/NJwTk5wTgRMGhL8DBIaGhID9BIaZP0ftoOcAT7+4AH0dE5vT09vAAAAAAIA2wAFBDYEkQAWAB4AAAEyHgEVFAcOAQ8BLgQnJjU0PgIWIgYUFjI2NAKIdcZzRkWyNjYJIV5YbSk8RHOft7eCgreCBJF4ynVzj23pPz4IIWZomEiEdVijeUjDgriBgbgAAAACABcAFwSZBJkADwAXAAAAMh4CFA4CIi4CND4BAREiDgEUHgEB4+rWm1tbm9bq1ptbW5sBS3TFcnLFBJlbm9bq1ptbW5vW6tab/G8DVnLF6MVyAAACAHUAAwPfBQ8AGgA1AAABHgYVFA4DBy4DNTQ+BQMOAhceBBcWNj8BNiYnLgInJjc2IyYCKhVJT1dOPiUzVnB9P1SbfEokP0xXUEm8FykoAwEbITEcExUWAgYCCQkFEikMGiACCAgFD0iPdXdzdYdFR4BeRiYEBTpjl1lFh3ZzeHaQ/f4hS4I6JUEnIw4IBwwQIgoYBwQQQSlZtgsBAAAAAwAAAAAEywRsAAwAKgAvAAABNz4CHgEXHgEPAiUhMhcHISIGFREUFjMhMjY9ATcRFAYjISImNRE0NgkBBzcBA+hsAgYUFR0OFgoFBmz9BQGQMje7/pApOzspAfQpO8i7o/5wpbm5Azj+lqE3AWMD9XMBAgIEDw4WKgsKc8gNuzsp/gwpOzsptsj+tKW5uaUBkKW5/tf+ljKqAWMAAgAAAAAEkwRMABsANgAAASEGByMiBhURFBYzITI2NTcVFAYjISImNRE0NgUBFhQHAQYmJzUmDgMHPgY3NT4BAV4BaaQ0wyk7OykB9Ck7yLml/nClubkCfwFTCAj+rAcLARo5ZFRYGgouOUlARioTAQsETJI2Oyn+DCk7OymZZ6W5uaUBkKW5G/7TBxUH/s4GBAnLAQINFjAhO2JBNB0UBwHSCgUAAAAAAgAAAAAEnQRMAB0ANQAAASEyFwchIgYVERQWMyEyNj0BNxUUBiMhIiY1ETQ2CQE2Mh8BFhQHAQYiLwEmND8BNjIfARYyAV4BXjxDsv6jKTs7KQH0KTvIuaX+cKW5uQHKAYsHFQdlBwf97QcVB/gHB2UHFQdvCBQETBexOyn+DCk7OylFyNulubmlAZCluf4zAYsHB2UHFQf97AcH+AcVB2UHB28HAAAAAQAKAAoEpgSmADsAAAkBNjIXARYGKwEVMzU0NhcBFhQHAQYmPQEjFTMyFgcBBiInASY2OwE1IxUUBicBJjQ3ATYWHQEzNSMiJgE+AQgIFAgBBAcFCqrICggBCAgI/vgICsiqCgUH/vwIFAj++AgFCq/ICgj++AgIAQgICsivCgUDlgEICAj++AgKyK0KBAf+/AcVB/73BwQKrcgKCP74CAgBCAgKyK0KBAcBCQcVBwEEBwQKrcgKAAEAyAAAA4QETAAZAAATMzIWFREBNhYVERQGJwERFAYrASImNRE0NvpkFR0B0A8VFQ/+MB0VZBUdHQRMHRX+SgHFDggV/BgVCA4Bxf5KFR0dFQPoFR0AAAABAAAAAASwBEwAIwAAEzMyFhURATYWFREBNhYVERQGJwERFAYnAREUBisBIiY1ETQ2MmQVHQHQDxUB0A8VFQ/+MBUP/jAdFWQVHR0ETB0V/koBxQ4IFf5KAcUOCBX8GBUIDgHF/koVCA4Bxf5KFR0dFQPoFR0AAAABAJ0AGQSwBDMAFQAAAREUBicBERQGJwEmNDcBNhYVEQE2FgSwFQ/+MBUP/hQPDwHsDxUB0A8VBBr8GBUIDgHF/koVCA4B4A4qDgHgDggV/koBxQ4IAAAAAQDIABYEMwQ2AAsAABMBFhQHAQYmNRE0NvMDLhIS/NISGRkEMv4OCx4L/g4LDhUD6BUOAAIAyABkA4QD6AAPAB8AABMzMhYVERQGKwEiJjURNDYhMzIWFREUBisBIiY1ETQ2+sgVHR0VyBUdHQGlyBUdHRXIFR0dA+gdFfzgFR0dFQMgFR0dFfzgFR0dFQMgFR0AAAEAyABkBEwD6AAPAAABERQGIyEiJjURNDYzITIWBEwdFfzgFR0dFQMgFR0DtvzgFR0dFQMgFR0dAAAAAAEAAAAZBBMEMwAVAAABETQ2FwEWFAcBBiY1EQEGJjURNDYXAfQVDwHsDw/+FA8V/jAPFRUPAmQBthUIDv4gDioO/iAOCBUBtv47DggVA+gVCA4AAAH//gACBLMETwAjAAABNzIWFRMUBiMHIiY1AwEGJjUDAQYmNQM0NhcBAzQ2FwEDNDYEGGQUHgUdFWQVHQL+MQ4VAv4yDxUFFQ8B0gIVDwHSAh0ETgEdFfwYFR0BHRUBtf46DwkVAbX+OQ4JFAPoFQkP/j4BthQJDv49AbYVHQAAAQEsAAAD6ARMABkAAAEzMhYVERQGKwEiJjURAQYmNRE0NhcBETQ2A1JkFR0dFWQVHf4wDxUVDwHQHQRMHRX8GBUdHRUBtv47DggVA+gVCA7+OwG2FR0AAAIAZADIBLAESAALABsAAAkBFgYjISImNwE2MgEhMhYdARQGIyEiJj0BNDYCrgH1DwkW++4WCQ8B9Q8q/fcD6BUdHRX8GBUdHQQ5/eQPFhYPAhwP/UgdFWQVHR0VZBUdAAEAiP/8A3UESgAFAAAJAgcJAQN1/qABYMX92AIoA4T+n/6fxgIoAiYAAAAAAQE7//wEKARKAAUAAAkBJwkBNwQo/dnGAWH+n8YCI/3ZxgFhAWHGAAIAFwAXBJkEmQAPADMAAAAyHgIUDgIiLgI0PgEFIyIGHQEjIgYdARQWOwEVFBY7ATI2PQEzMjY9ATQmKwE1NCYB4+rWm1tbm9bq1ptbW5sBfWQVHZYVHR0Vlh0VZBUdlhUdHRWWHQSZW5vW6tabW1ub1urWm7odFZYdFWQVHZYVHR0Vlh0VZBUdlhUdAAAAAAIAFwAXBJkEmQAPAB8AAAAyHgIUDgIiLgI0PgEBISIGHQEUFjMhMjY9ATQmAePq1ptbW5vW6tabW1ubAkX+DBUdHRUB9BUdHQSZW5vW6tabW1ub1urWm/5+HRVkFR0dFWQVHQACABcAFwSZBJkADwAzAAAAMh4CFA4CIi4CND4BBCIPAScmIg8BBhQfAQcGFB8BFjI/ARcWMj8BNjQvATc2NC8BAePq1ptbW5vW6tabW1ubAeUZCXh4CRkJjQkJeHgJCY0JGQl4eAkZCY0JCXh4CQmNBJlbm9bq1ptbW5vW6tabrQl4eAkJjQkZCXh4CRkJjQkJeHgJCY0JGQl4eAkZCY0AAgAXABcEmQSZAA8AJAAAADIeAhQOAiIuAjQ+AQEnJiIPAQYUHwEWMjcBNjQvASYiBwHj6tabW1ub1urWm1tbmwEVVAcVCIsHB/IHFQcBdwcHiwcVBwSZW5vW6tabW1ub1urWm/4xVQcHiwgUCPEICAF3BxUIiwcHAAAAAAMAFwAXBJkEmQAPADsASwAAADIeAhQOAiIuAjQ+AQUiDgMVFDsBFjc+ATMyFhUUBgciDgUHBhY7ATI+AzU0LgMTIyIGHQEUFjsBMjY9ATQmAePq1ptbW5vW6tabW1ubAT8dPEIyIRSDHgUGHR8UFw4TARkOGhITDAIBDQ6tBx4oIxgiM0Q8OpYKDw8KlgoPDwSZW5vW6tabW1ub1urWm5ELHi9PMhkFEBQQFRIXFgcIBw4UHCoZCBEQKDhcNi9IKhsJ/eMPCpYKDw8KlgoPAAADABcAFwSZBJkADwAfAD4AAAAyHgIUDgIiLgI0PgEFIyIGHQEUFjsBMjY9ATQmAyMiBh0BFBY7ARUjIgYdARQWMyEyNj0BNCYrARE0JgHj6tabW1ub1urWm1tbmwGWlgoPDwqWCg8PCvoKDw8KS0sKDw8KAV4KDw8KSw8EmVub1urWm1tbm9bq1ptWDwqWCg8PCpYKD/7UDwoyCg/IDwoyCg8PCjIKDwETCg8AAgAAAAAEsASwAC8AXwAAATMyFh0BHgEXMzIWHQEUBisBDgEHFRQGKwEiJj0BLgEnIyImPQE0NjsBPgE3NTQ2ExUUBisBIiY9AQ4BBzMyFh0BFAYrAR4BFzU0NjsBMhYdAT4BNyMiJj0BNDY7AS4BAg2WCg9nlxvCCg8PCsIbl2cPCpYKD2eXG8IKDw8KwhuXZw+5DwqWCg9EZheoCg8PCqgXZkQPCpYKD0RmF6gKDw8KqBdmBLAPCsIbl2cPCpYKD2eXG8IKDw8KwhuXZw8KlgoPZ5cbwgoP/s2oCg8PCqgXZkQPCpYKD0RmF6gKDw8KqBdmRA8KlgoPRGYAAwAXABcEmQSZAA8AGwA/AAAAMh4CFA4CIi4CND4BBCIOARQeATI+ATQmBxcWFA8BFxYUDwEGIi8BBwYiLwEmND8BJyY0PwE2Mh8BNzYyAePq1ptbW5vW6tabW1ubAb/oxXJyxejFcnKaQAcHfHwHB0AHFQd8fAcVB0AHB3x8BwdABxUHfHwHFQSZW5vW6tabW1ub1urWmztyxejFcnLF6MVaQAcVB3x8BxUHQAcHfHwHB0AHFQd8fAcVB0AHB3x8BwAAAAMAFwAXBJkEmQAPABsAMAAAADIeAhQOAiIuAjQ+AQQiDgEUHgEyPgE0JgcXFhQHAQYiLwEmND8BNjIfATc2MgHj6tabW1ub1urWm1tbmwG/6MVycsXoxXJyg2oHB/7ACBQIyggIagcVB0/FBxUEmVub1urWm1tbm9bq1ps7csXoxXJyxejFfWoHFQf+vwcHywcVB2oICE/FBwAAAAMAFwAXBJkEmQAPABgAIQAAADIeAhQOAiIuAjQ+AQUiDgEVFBcBJhcBFjMyPgE1NAHj6tabW1ub1urWm1tbmwFLdMVyQQJLafX9uGhzdMVyBJlbm9bq1ptbW5vW6tabO3LFdHhpAktB0P24PnLFdHMAAAAAAQAXAFMEsAP5ABUAABMBNhYVESEyFh0BFAYjIREUBicBJjQnAgoQFwImFR0dFf3aFxD99hACRgGrDQoV/t0dFcgVHf7dFQoNAasNJgAAAAABAAAAUwSZA/kAFQAACQEWFAcBBiY1ESEiJj0BNDYzIRE0NgJ/AgoQEP32EBf92hUdHRUCJhcD8f5VDSYN/lUNChUBIx0VyBUdASMVCgAAAAEAtwAABF0EmQAVAAAJARYGIyERFAYrASImNREhIiY3ATYyAqoBqw0KFf7dHRXIFR3+3RUKDQGrDSYEif32EBf92hUdHRUCJhcQAgoQAAAAAQC3ABcEXQSwABUAAAEzMhYVESEyFgcBBiInASY2MyERNDYCJsgVHQEjFQoN/lUNJg3+VQ0KFQEjHQSwHRX92hcQ/fYQEAIKEBcCJhUdAAABAAAAtwSZBF0AFwAACQEWFAcBBiY1EQ4DBz4ENxE0NgJ/AgoQEP32EBdesKWBJAUsW4fHfhcEVf5VDSYN/lUNChUBIwIkRHVNabGdcUYHAQYVCgACAAAAAASwBLAAFQArAAABITIWFREUBi8BBwYiLwEmND8BJyY2ASEiJjURNDYfATc2Mh8BFhQPARcWBgNSASwVHRUOXvkIFAhqBwf5Xg4I/iH+1BUdFQ5e+QgUCGoHB/leDggEsB0V/tQVCA5e+QcHaggUCPleDhX7UB0VASwVCA5e+QcHaggUCPleDhUAAAACAEkASQRnBGcAFQArAAABFxYUDwEXFgYjISImNRE0Nh8BNzYyASEyFhURFAYvAQcGIi8BJjQ/AScmNgP2agcH+V4OCBX+1BUdFQ5e+QgU/QwBLBUdFQ5e+QgUCGoHB/leDggEYGoIFAj5Xg4VHRUBLBUIDl75B/3xHRX+1BUIDl75BwdqCBQI+V4OFQAAAAADABcAFwSZBJkADwAfAC8AAAAyHgIUDgIiLgI0PgEFIyIGFxMeATsBMjY3EzYmAyMiBh0BFBY7ATI2PQE0JgHj6tabW1ub1urWm1tbmwGz0BQYBDoEIxQ2FCMEOgQYMZYKDw8KlgoPDwSZW5vW6tabW1ub1urWm7odFP7SFB0dFAEuFB3+DA8KlgoPDwqWCg8AAAAABQAAAAAEsASwAEkAVQBhAGgAbwAAATIWHwEWHwEWFxY3Nj8BNjc2MzIWHwEWHwIeATsBMhYdARQGKwEiBh0BIREjESE1NCYrASImPQE0NjsBMjY1ND8BNjc+BAUHBhY7ATI2LwEuAQUnJgYPAQYWOwEyNhMhIiY1ESkBERQGIyERAQQJFAUFFhbEFQ8dCAsmxBYXERUXMA0NDgQZCAEPCj0KDw8KMgoP/nDI/nAPCjIKDw8KPQsOCRkFDgIGFRYfAp2mBwQK2woKAzMDEP41sQgQAzMDCgrnCwMe/okKDwGQAlgPCv6JBLAEAgIKDXYNCxUJDRZ2DQoHIREQFRh7LAkLDwoyCg8PCq8BLP7UrwoPDwoyCg8GBQQwgBkUAwgWEQ55ogcKDgqVCgSqnQcECo8KDgr8cg8KAXf+iQoPAZAAAAAAAgAAAAwErwSmACsASQAAATYWFQYCDgQuAScmByYOAQ8BBiY1NDc+ATc+AScuAT4BNz4GFyYGBw4BDwEOBAcOARY2Nz4CNz4DNz4BBI0IGgItQmxhi2KORDg9EQQRMxuZGhYqCFUYEyADCQIQOjEnUmFch3vAJQgdHyaiPT44XHRZUhcYDhItIRmKcVtGYWtbKRYEBKYDEwiy/t3IlVgxEQgLCwwBAQIbG5kYEyJAJghKFRE8Hzdff4U/M0o1JSMbL0QJGCYvcSEhHjZST2c1ODwEJygeW0AxJUBff1UyFAABAF0AHgRyBM8ATwAAAQ4BHgQXLgc+ATceAwYHDgQHBicmNzY3PgQuAScWDgMmJy4BJyY+BDcGHgM3PgEuAicmPgMCjScfCic4R0IgBBsKGAoQAwEJEg5gikggBhANPkpTPhZINx8SBgsNJysiCRZOQQoVNU1bYC9QZwICBAUWITsoCAYdJzIYHw8YIiYHDyJJYlkEz0OAZVxEOSQMBzgXOB42IzElKRIqg5Gnl0o3Z0c6IAYWCwYNAwQFIDhHXGF1OWiqb0sdBxUknF0XNTQ8PEUiNWNROBYJDS5AQVUhVZloUSkAAAAAA//cAGoE1ARGABsAPwBRAAAAMh4FFA4FIi4FND4EBSYGFxYVFAYiJjU0NzYmBwYHDgEXHgQyPgM3NiYnJgUHDgEXFhcWNj8BNiYnJicuAQIGpJ17bk85HBw6T257naKde25POhwcOU9uewIPDwYIGbD4sBcIBw5GWg0ECxYyWl+DiINfWjIWCwQMWv3/Iw8JCSU4EC0OIw4DDywtCyIERi1JXGJcSSpJXGJcSS0tSVxiXEkqSVxiXEncDwYTOT58sLB8OzcTBg9FcxAxEiRGXkQxMEVeRSQSMRF1HiQPLxJEMA0EDyIPJQ8sSRIEAAAABP/cAAAE1ASwABQAJwA7AEwAACEjNy4ENTQ+BTMyFzczEzceARUUDgMHNz4BNzYmJyYlBgcOARceBBc3LgE1NDc2JhcHDgEXFhcWNj8CJyYnLgECUJQfW6l2WSwcOU9ue51SPUEglCYvbIknUGqYUi5NdiYLBAw2/VFGWg0ECxIqSExoNSlrjxcIB3wjDwkJJTgQLQ4MFgMsLQsieBRhdHpiGxVJXGJcSS0Pef5StVXWNBpacm5jGq0xiD8SMRFGckVzEDESHjxRQTkNmhKnbjs3EwZwJA8vEkQwDQQPC1YELEkSBAAAAAP/ngAABRIEqwALABgAKAAAJwE2FhcBFgYjISImJSE1NDY7ATIWHQEhAQczMhYPAQ4BKwEiJi8BJjZaAoIUOBQCghUbJfryJRsBCgFZDwqWCg8BWf5DaNAUGAQ6BCMUNhQjBDoEGGQEKh8FIfvgIEdEhEsKDw8KSwLT3x0U/BQdHRT8FB0AAAABAGQAFQSwBLAAKAAAADIWFREBHgEdARQGJyURFh0BFAYvAQcGJj0BNDcRBQYmPQE0NjcBETQCTHxYAWsPFhgR/plkGhPNzRMaZP6ZERgWDwFrBLBYPv6t/rsOMRQpFA0M+f75XRRAFRAJgIAJEBVAFF0BB/kMDRQpFDEOAUUBUz4AAAARAAAAAARMBLAAHQAnACsALwAzADcAOwA/AEMARwBLAE8AUwBXAFsAXwBjAAABMzIWHQEzMhYdASE1NDY7ATU0NjsBMhYdASE1NDYBERQGIyEiJjURFxUzNTMVMzUzFTM1MxUzNTMVMzUFFTM1MxUzNTMVMzUzFTM1MxUzNQUVMzUzFTM1MxUzNTMVMzUzFTM1A1JkFR0yFR37tB0VMh0VZBUdAfQdAQ8dFfwYFR1kZGRkZGRkZGRk/HxkZGRkZGRkZGT8fGRkZGRkZGRkZASwHRUyHRWWlhUdMhUdHRUyMhUd/nD9EhUdHRUC7shkZGRkZGRkZGRkyGRkZGRkZGRkZGTIZGRkZGRkZGRkZAAAAAMAAAAZBXcElwAZACUANwAAARcWFA8BBiY9ASMBISImPQE0NjsBATM1NDYBBycjIiY9ATQ2MyEBFxYUDwEGJj0BIyc3FzM1NDYEb/kPD/kOFZ/9qP7dFR0dFdECWPEV/amNetEVHR0VASMDGvkPD/kOFfG1jXqfFQSN5g4qDuYOCBWW/agdFWQVHQJYlhUI/piNeh0VZBUd/k3mDioO5g4IFZa1jXqWFQgAAAABAAAAAASwBEwAEgAAEyEyFhURFAYjIQERIyImNRE0NmQD6Ck7Oyn9rP7QZCk7OwRMOyn9qCk7/tQBLDspAlgpOwAAAAMAZAAABEwEsAAJABMAPwAAEzMyFh0BITU0NiEzMhYdASE1NDYBERQOBSIuBTURIRUUFRwBHgYyPgYmNTQ9AZbIFR3+1B0C0cgVHf7UHQEPBhgoTGacwJxmTCgYBgEsAwcNFB8nNkI2Jx8TDwUFAQSwHRX6+hUdHRX6+hUd/nD+1ClJalZcPigoPlxWakkpASz6CRIVKyclIRsWEAgJEBccISUnKhURCPoAAAAB//8A1ARMA8IABQAAAQcJAScBBEzG/p/+n8UCJwGbxwFh/p/HAicAAQAAAO4ETQPcAAUAAAkCNwkBBE392v3ZxgFhAWEDFf3ZAifH/p8BYQAAAAAC/1EAZAVfA+gAFAApAAABITIWFREzMhYPAQYiLwEmNjsBESElFxYGKwERIRchIiY1ESMiJj8BNjIBlALqFR2WFQgO5g4qDuYOCBWW/oP+HOYOCBWWAYHX/RIVHZYVCA7mDioD6B0V/dkVDvkPD/kOFQGRuPkOFf5wyB0VAiYVDvkPAAABAAYAAASeBLAAMAAAEzMyFh8BITIWBwMOASMhFyEyFhQGKwEVFAYiJj0BIRUUBiImPQEjIiYvAQMjIiY0NjheERwEJgOAGB4FZAUsIf2HMAIXFR0dFTIdKh3+1B0qHR8SHQYFyTYUHh4EsBYQoiUY/iUVK8gdKh0yFR0dFTIyFR0dFTIUCQoDwR0qHQAAAAACAAAAAASwBEwACwAPAAABFSE1MzQ2MyEyFhUFIREhBLD7UMg7KQEsKTv9RASw+1AD6GRkKTs7Kcj84AACAAAAAAXcBEwADAAQAAATAxEzNDYzITIWFSEVBQEhAcjIyDspASwqOgH0ASz+1PtQASwDIP5wAlgpOzspyGT9RAK8AAEBRQAAA2sErwAbAAABFxYGKwERMzIWDwEGIi8BJjY7AREjIiY/ATYyAnvmDggVlpYVCA7mDioO5g4IFZaWFQgO5g4qBKD5DhX9pxUO+Q8P+Q4VAlkVDvkPAAAAAQABAUQErwNrABsAAAEXFhQPAQYmPQEhFRQGLwEmND8BNhYdASE1NDYDqPkODvkPFf2oFQ/5Dg75DxUCWBUDYOUPKQ/lDwkUl5cUCQ/lDykP5Q8JFZWVFQkAAAAEAAAAAASwBLAACQAZAB0AIQAAAQMuASMhIgYHAwUhIgYdARQWMyEyNj0BNCYFNTMVMzUzFQSRrAUkFP1gFCQFrAQt/BgpOzspA+gpOzv+q2RkZAGQAtwXLSgV/R1kOylkKTs7KWQpO8hkZGRkAAAAA/+cAGQEsARMAAsAIwAxAAAAMhYVERQGIiY1ETQDJSMTFgYjIisBIiYnAj0BNDU0PgE7ASUBFSIuAz0BND4CNwRpKh0dKh1k/V0mLwMRFQUCVBQdBDcCCwzIAqP8GAQOIhoWFR0dCwRMHRX8rhUdHRUDUhX8mcj+7BAIHBUBUQ76AgQQDw36/tT6AQsTKRwyGigUDAEAAAACAEoAAARmBLAALAA1AAABMzIWDwEeARcTFzMyFhQGBw4EIyIuBC8BLgE0NjsBNxM+ATcnJjYDFjMyNw4BIiYCKV4UEgYSU3oPP3YRExwaEggeZGqfTzl0XFU+LwwLEhocExF2Pw96UxIGEyQyNDUxDDdGOASwFRMlE39N/rmtHSkoBwQLHBYSCg4REg4FBAgoKR2tAUdNfhQgExr7vgYGMT09AAEAFAAUBJwEnAAXAAABNwcXBxcHFycHJwcnBzcnNyc3Jxc3FzcDIOBO6rS06k7gLZubLeBO6rS06k7gLZubA7JO4C2bmy3gTuq0tOpO4C2bmy3gTuq0tAADAAAAZASwBLAAIQAtAD0AAAEzMhYdAQchMhYdARQHAw4BKwEiJi8BIyImNRE0PwI+ARcPAREzFzMTNSE3NQEzMhYVERQGKwEiJjURNDYCijIoPBwBSCg8He4QLBf6B0YfHz0tNxSRYA0xG2SWZIjW+v4+Mv12ZBUdHRVkFR0dBLBRLJZ9USxkLR3+qBghMhkZJCcBkCQbxMYcKGTU1f6JZAF3feGv/tQdFf4MFR0dFQH0FR0AAAAAAwAAAAAEsARMACAAMAA8AAABMzIWFxMWHQEUBiMhFh0BFAYrASImLwImNRE0NjsBNgUzMhYVERQGKwEiJjURNDYhByMRHwEzNSchNQMCWPoXLBDuHTwo/rgcPCgyGzENYJEUNy09fP3pZBUdHRVkFR0dAl+IZJZkMjIBwvoETCEY/qgdLWQsUXYHlixRKBzGxBskAZAnJGRkHRX+DBUdHRUB9BUdZP6J1dSv4X0BdwADAAAAZAUOBE8AGwA3AEcAAAElNh8BHgEPASEyFhQGKwEDDgEjISImNRE0NjcXERchEz4BOwEyNiYjISoDLgQnJj8BJwUzMhYVERQGKwEiJjURNDYBZAFrHxZuDQEMVAEuVGxuVGqDBhsP/qoHphwOOmQBJYMGGw/LFRMSFv44AgoCCQMHAwUDAQwRklb9T2QVHR0VZBUdHQNp5hAWcA0mD3lMkE7+rRUoog0CDRElCkj+CVkBUxUoMjIBAgIDBQIZFrdT5B0V/gwVHR0VAfQVHQAAAAP/nABkBLAETwAdADYARgAAAQUeBBURFAYjISImJwMjIiY0NjMhJyY2PwE2BxcWBw4FKgIjIRUzMhYXEyE3ESUFMzIWFREUBisBIiY1ETQ2AdsBbgIIFBANrAf+qg8bBoNqVW1sVAEuVQsBDW4WSpIRDAIDBQMHAwkDCgH+Jd0PHAaCASZq/qoCUGQVHR0VZBUdHQRP5gEFEBEXC/3zDaIoFQFTTpBMeQ8mDXAWrrcWGQIFAwICAWQoFf6tWQH37OQdFf4MFR0dFQH0FR0AAAADAGEAAARMBQ4AGwA3AEcAAAAyFh0BBR4BFREUBiMhIiYvAQMmPwE+AR8BETQXNTQmBhURHAMOBAcGLwEHEyE3ESUuAQMhMhYdARQGIyEiJj0BNDYB3pBOAVMVKKIN/fMRJQoJ5hAWcA0mD3nGMjIBAgIDBQIZFrdT7AH3Wf6tFSiWAfQVHR0V/gwVHR0FDm5UaoMGGw/+qgemHA4OAWsfFm4NAQxUAS5U1ssVExIW/jgCCgIJAwcDBQMBDBGSVv6tZAElgwYb/QsdFWQVHR0VZBUdAAP//QAGA+gFFAAPAC0ASQAAASEyNj0BNCYjISIGHQEUFgEVFAYiJjURBwYmLwEmNxM+BDMhMhYVERQGBwEDFzc2Fx4FHAIVERQWNj0BNDY3JREnAV4B9BUdHRX+DBUdHQEPTpBMeQ8mDXAWEOYBBRARFwsCDQ2iKBX9iexTtxYZAgUDAgIBMjIoFQFTWQRMHRVkFR0dFWQVHfzmalRubFQBLlQMAQ1uFh8BawIIEw8Mpgf+qg8bBgHP/q1WkhEMAQMFAwcDCQIKAv44FhITFcsPGwaDASVkAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgEBJSYGHQEhIgYdARQWMyEVFBY3JTY0AeLs1ptbW5vW7NabW1ubAob+7RAX/u0KDw8KARMXEAETEASaW5vW7NabW1ub1uzWm/453w0KFYkPCpYKD4kVCg3fDSYAAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgENAQYUFwUWNj0BITI2PQE0JiMhNTQmAeLs1ptbW5vW7NabW1ubASX+7RAQARMQFwETCg8PCv7tFwSaW5vW7NabW1ub1uzWm+jfDSYN3w0KFYkPCpYKD4kVCgAAAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgEBAyYiBwMGFjsBERQWOwEyNjURMzI2AeLs1ptbW5vW7NabW1ubAkvfDSYN3w0KFYkPCpYKD4kVCgSaW5vW7NabW1ub1uzWm/5AARMQEP7tEBf+7QoPDwoBExcAAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgEFIyIGFREjIgYXExYyNxM2JisBETQmAeLs1ptbW5vW7NabW1ubAZeWCg+JFQoN3w0mDd8NChWJDwSaW5vW7NabW1ub1uzWm7sPCv7tFxD+7RAQARMQFwETCg8AAAMAGAAYBJgEmAAPAJYApgAAADIeAhQOAiIuAjQ+ASUOAwcGJgcOAQcGFgcOAQcGFgcUFgcyHgEXHgIXHgI3Fg4BFx4CFxQGFBcWNz4CNy4BJy4BJyIOAgcGJyY2NS4BJzYuAQYHBicmNzY3HgIXHgMfAT4CJyY+ATc+AzcmNzIWMjY3LgMnND4CJiceAT8BNi4CJwYHFB4BFS4CJz4BNxYyPgEB5OjVm1xcm9Xo1ZtcXJsBZA8rHDoKDz0PFD8DAxMBAzEFCRwGIgEMFhkHECIvCxU/OR0HFBkDDRQjEwcFaHUeISQDDTAMD0UREi4oLBAzDwQBBikEAQMLGhIXExMLBhAGKBsGBxYVEwYFAgsFAwMNFwQGCQcYFgYQCCARFwkKKiFBCwQCAQMDHzcLDAUdLDgNEiEQEgg/KhADGgMKEgoRBJhcm9Xo1ZtcXJvV6NWbEQwRBwkCAwYFBycPCxcHInIWInYcCUcYChQECA4QBAkuHgQPJioRFRscBAcSCgwCch0kPiAIAQcHEAsBAgsLIxcBMQENCQIPHxkCFBkdHB4QBgEBBwoMGBENBAMMJSAQEhYXDQ4qFBkKEhIDCQsXJxQiBgEOCQwHAQ0DBAUcJAwSCwRnETIoAwEJCwsLJQcKDBEAAAAAAQAAAAIErwSFABYAAAE2FwUXNxYGBw4BJwEGIi8BJjQ3ASY2AvSkjv79kfsGUE08hjv9rA8rD28PDwJYIk8EhVxliuh+WYcrIgsW/awQEG4PKxACV2XJAAYAAABgBLAErAAPABMAIwAnADcAOwAAEyEyFh0BFAYjISImPQE0NgUjFTMFITIWHQEUBiMhIiY9ATQ2BSEVIQUhMhYdARQGIyEiJj0BNDYFIRUhZAPoKTs7KfwYKTs7BBHIyPwYA+gpOzsp/BgpOzsEEf4MAfT8GAPoKTs7KfwYKTs7BBH+1AEsBKw7KWQpOzspZCk7ZGTIOylkKTs7KWQpO2RkyDspZCk7OylkKTtkZAAAAAIAZAAABEwEsAALABEAABMhMhYUBiMhIiY0NgERBxEBIZYDhBUdHRX8fBUdHQI7yP6iA4QEsB0qHR0qHf1E/tTIAfQB9AAAAAMAAABkBLAEsAAXABsAJQAAATMyFh0BITIWFREhNSMVIRE0NjMhNTQ2FxUzNQEVFAYjISImPQEB9MgpOwEsKTv+DMj+DDspASw7KcgB9Dsp/BgpOwSwOylkOyn+cGRkAZApO2QpO2RkZP1EyCk7OynIAAAABAAAAAAEsASwABUAKwBBAFcAABMhMhYPARcWFA8BBiIvAQcGJjURNDYpATIWFREUBi8BBwYiLwEmND8BJyY2ARcWFA8BFxYGIyEiJjURNDYfATc2MgU3NhYVERQGIyEiJj8BJyY0PwE2MhcyASwVCA5exwcHaggUCMdeDhUdAzUBLBUdFQ5exwgUCGoHB8deDgj+L2oHB8deDggV/tQVHRUOXscIFALLXg4VHRX+1BUIDl7HBwdqCBQIBLAVDl7HCBQIagcHx14OCBUBLBUdHRX+1BUIDl7HBwdqCBQIx14OFf0maggUCMdeDhUdFQEsFQgOXscHzl4OCBX+1BUdFQ5exwgUCGoHBwAAAAYAAAAABKgEqAAPABsAIwA7AEMASwAAADIeAhQOAiIuAjQ+AQQiDgEUHgEyPgE0JiQyFhQGIiY0JDIWFAYjIicHFhUUBiImNTQ2PwImNTQEMhYUBiImNCQyFhQGIiY0Advy3Z9fX5/d8t2gXl6gAcbgv29vv+C/b2/+LS0gIC0gAUwtICAWDg83ETNIMykfegEJ/octICAtIAIdLSAgLSAEqF+f3fLdoF5eoN3y3Z9Xb7/gv29vv+C/BiAtISEtICAtIQqRFxwkMzMkIDEFfgEODhekIC0gIC0gIC0gIC0AAf/YAFoEuQS8AFsAACUBNjc2JicmIyIOAwcABw4EFx4BMzI3ATYnLgEjIgcGBwEOASY0NwA3PgEzMhceARcWBgcOBgcGIyImJyY2NwE2NzYzMhceARcWBgcBDgEnLgECIgHVWwgHdl8WGSJBMD8hIP6IDx4eLRMNBQlZN0ozAiQkEAcdEhoYDRr+qw8pHA4BRyIjQS4ODyw9DQ4YIwwod26La1YOOEBGdiIwGkQB/0coW2tQSE5nDxE4Qv4eDyoQEAOtAdZbZWKbEQQUGjIhH/6JDxsdNSg3HT5CMwIkJCcQFBcMGv6uDwEcKQ4BTSIjIQEINykvYyMLKnhuiWZMBxtAOU6+RAH/SBg3ISSGV121Qv4kDwIPDyYAAAACAGQAWASvBEQAGQBEAAABPgIeAhUUDgMHLgQ1ND4CHgEFIg4DIi4DIyIGFRQeAhcWFx4EMj4DNzY3PgQ1NCYCiTB7eHVYNkN5hKg+PqeFeEM4WnZ4eQEjIT8yLSohJyktPyJDbxtBMjMPBw86KzEhDSIzKUAMBAgrKT8dF2oDtURIBS1TdkA5eYB/slVVsn+AeTlAdlMtBUgtJjY1JiY1NiZvTRc4SjQxDwcOPCouGBgwKEALBAkpKkQqMhNPbQACADn/8gR3BL4AFwAuAAAAMh8BFhUUBg8BJi8BNycBFwcvASY0NwEDNxYfARYUBwEGIi8BJjQ/ARYfAQcXAQKru0KNQjgiHR8uEl/3/nvUaRONQkIBGxJpCgmNQkL+5UK6Qo1CQjcdLhJf9wGFBL5CjUJeKmsiHTUuEl/4/nvUahKNQrpCARv+RmkICY1CukL+5UJCjUK7Qjc3LxFf+AGFAAAAAAMAyAAAA+gEsAARABUAHQAAADIeAhURFAYjISImNRE0PgEHESERACIGFBYyNjQCBqqaZDo7Kf2oKTs8Zj4CWP7/Vj09Vj0EsB4uMhX8Ryk7OykDuRUzLar9RAK8/RY9Vj09VgABAAAAAASwBLAAFgAACQEWFAYiLwEBEScBBRMBJyEBJyY0NjIDhgEbDx0qDiT+6dT+zP7oywEz0gEsAQsjDx0qBKH+5g8qHQ8j/vX+1NL+zcsBGAE01AEXJA4qHQAAAAADAScAEQQJBOAAMgBAAEsAAAEVHgQXIy4DJxEXHgQVFAYHFSM1JicuASczHgEXEScuBDU0PgI3NRkBDgMVFB4DFxYXET4ENC4CArwmRVI8LAKfBA0dMydAIjxQNyiym2SWVygZA4sFV0obLkJOMCAyVWg6HSoqFQ4TJhkZCWgWKTEiGBkzNwTgTgUTLD9pQiQuLBsH/s0NBxMtPGQ+i6oMTU8QVyhrVk1iEAFPCA4ZLzlYNkZwSCoGTf4SARIEDh02Jh0rGRQIBgPQ/soCCRYgNEM0JRkAAAABAGQAZgOUBK0ASgAAATIeARUjNC4CIyIGBwYVFB4BFxYXMxUjFgYHBgc+ATM2FjMyNxcOAyMiLgEHDgEPASc+BTc+AScjNTMmJy4CPgE3NgIxVJlemSc8OxolVBQpGxoYBgPxxQgVFS02ImIWIIwiUzUyHzY4HCAXanQmJ1YYFzcEGAcTDBEJMAwk3aYXFQcKAg4tJGEErVCLTig/IhIdFSw5GkowKgkFZDKCHj4yCg8BIh6TExcIASIfBAMaDAuRAxAFDQsRCjePR2QvORQrREFMIVgAAAACABn//wSXBLAADwAfAAABMzIWDwEGIi8BJjY7AREzBRcWBisBESMRIyImPwE2MgGQlhUIDuYOKg7mDggVlsgCF+YOCBWWyJYVCA7mDioBLBYO+g8P+g4WA4QQ+Q4V/HwDhBUO+Q8AAAQAGf//A+gEsAAHABcAGwAlAAABIzUjFSMRIQEzMhYPAQYiLwEmNjsBETMFFTM1EwczFSE1NyM1IQPoZGRkASz9qJYVCA7mDioO5g4IFZbIAZFkY8jI/tTIyAEsArxkZAH0/HwWDvoPD/oOFgOEZMjI/RL6ZJb6ZAAAAAAEABn//wPoBLAADwAZACEAJQAAATMyFg8BBiIvASY2OwERMwUHMxUhNTcjNSERIzUjFSMRIQcVMzUBkJYVCA7mDioO5g4IFZbIAljIyP7UyMgBLGRkZAEsx2QBLBYO+g8P+g4WA4SW+mSW+mT7UGRkAfRkyMgAAAAEABn//wRMBLAADwAVABsAHwAAATMyFg8BBiIvASY2OwERMwEjESM1MxMjNSMRIQcVMzUBkJYVCA7mDioO5g4IFZbIAlhkZMhkZMgBLMdkASwWDvoPD/oOFgOE/gwBkGT7UGQBkGTIyAAAAAAEABn//wRMBLAADwAVABkAHwAAATMyFg8BBiIvASY2OwERMwEjNSMRIQcVMzUDIxEjNTMBkJYVCA7mDioO5g4IFZbIArxkyAEsx2QBZGTIASwWDvoPD/oOFgOE/gxkAZBkyMj7tAGQZAAAAAAFABn//wSwBLAADwATABcAGwAfAAABMzIWDwEGIi8BJjY7AREzBSM1MxMhNSETITUhEyE1IQGQlhUIDuYOKg7mDggVlsgB9MjIZP7UASxk/nABkGT+DAH0ASwWDvoPD/oOFgOEyMj+DMj+DMj+DMgABQAZ//8EsASwAA8AEwAXABsAHwAAATMyFg8BBiIvASY2OwERMwUhNSEDITUhAyE1IQMjNTMBkJYVCA7mDioO5g4IFZbIAyD+DAH0ZP5wAZBk/tQBLGTIyAEsFg76Dw/6DhYDhMjI/gzI/gzI/gzIAAIAAAAABEwETAAPAB8AAAEhMhYVERQGIyEiJjURNDYFISIGFREUFjMhMjY1ETQmAV4BkKK8u6P+cKW5uQJn/gwpOzspAfQpOzsETLuj/nClubmlAZClucg7Kf4MKTs7KQH0KTsAAAAAAwAAAAAETARMAA8AHwArAAABITIWFREUBiMhIiY1ETQ2BSEiBhURFBYzITI2NRE0JgUXFhQPAQYmNRE0NgFeAZClubml/nCju7wCZP4MKTs7KQH0KTs7/m/9ERH9EBgYBEy5pf5wpbm5pQGQo7vIOyn+DCk7OykB9Ck7gr4MJAy+DAsVAZAVCwAAAAADAAAAAARMBEwADwAfACsAAAEhMhYVERQGIyEiJjURNDYFISIGFREUFjMhMjY1ETQmBSEyFg8BBiIvASY2AV4BkKO7uaX+cKW5uQJn/gwpOzspAfQpOzv+FQGQFQsMvgwkDL4MCwRMvKL+cKW5uaUBkKO7yDsp/gwpOzspAfQpO8gYEP0REf0QGAAAAAMAAAAABEwETAAPAB8AKwAAASEyFhURFAYjISImNRE0NgUhIgYVERQWMyEyNjURNCYFFxYGIyEiJj8BNjIBXgGQpbm5pf5wo7u5Amf+DCk7OykB9Ck7O/77vgwLFf5wFQsMvgwkBEy5pf5wo7u8ogGQpbnIOyn+DCk7OykB9Ck7z/0QGBgQ/REAAAAAAgAAAAAFFARMAB8ANQAAASEyFhURFAYjISImPQE0NjMhMjY1ETQmIyEiJj0BNDYHARYUBwEGJj0BIyImPQE0NjsBNTQ2AiYBkKW5uaX+cBUdHRUBwik7Oyn+PhUdHb8BRBAQ/rwQFvoVHR0V+hYETLml/nCluR0VZBUdOykB9Ck7HRVkFR3p/uQOJg7+5A4KFZYdFcgVHZYVCgAAAQDZAAID1wSeACMAAAEXFgcGAgclMhYHIggBBwYrAScmNz4BPwEhIicmNzYANjc2MwMZCQgDA5gCASwYEQ4B/vf+8wQMDgkJCQUCUCcn/tIXCAoQSwENuwUJEASeCQoRC/5TBwEjEv7K/sUFDwgLFQnlbm4TFRRWAS/TBhAAAAACAAAAAAT+BEwAHwA1AAABITIWHQEUBiMhIgYVERQWMyEyFh0BFAYjISImNRE0NgUBFhQHAQYmPQEjIiY9ATQ2OwE1NDYBXgGQFR0dFf4+KTs7KQHCFR0dFf5wpbm5AvEBRBAQ/rwQFvoVHR0V+hYETB0VZBUdOyn+DCk7HRVkFR25pQGQpbnp/uQOJg7+5A4KFZYdFcgVHZYVCgACAAAAAASwBLAAFQAxAAABITIWFREUBi8BAQYiLwEmNDcBJyY2ASMiBhURFBYzITI2PQE3ERQGIyEiJjURNDYzIQLuAZAVHRUObf7IDykPjQ8PAThtDgj+75wpOzspAfQpO8i7o/5wpbm5pQEsBLAdFf5wFQgObf7IDw+NDykPAThtDhX+1Dsp/gwpOzsplMj+1qW5uaUBkKW5AAADAA4ADgSiBKIADwAbACMAAAAyHgIUDgIiLgI0PgEEIg4BFB4BMj4BNCYEMhYUBiImNAHh7tmdXV2d2e7ZnV1dnQHD5sJxccLmwnFx/nugcnKgcgSiXZ3Z7tmdXV2d2e7ZnUdxwubCcXHC5sJzcqBycqAAAAMAAAAABEwEsAAVAB8AIwAAATMyFhURMzIWBwEGIicBJjY7ARE0NgEhMhYdASE1NDYFFTM1AcLIFR31FAoO/oEOJw3+hQ0JFfod/oUD6BUd+7QdA2dkBLAdFf6iFg/+Vg8PAaoPFgFeFR38fB0V+voVHWQyMgAAAAMAAAAABEwErAAVAB8AIwAACQEWBisBFRQGKwEiJj0BIyImNwE+AQEhMhYdASE1NDYFFTM1AkcBeg4KFfQiFsgUGPoUCw4Bfw4n/fkD6BUd+7QdA2dkBJ7+TQ8g+hQeHRX6IQ8BrxAC/H8dFfr6FR1kMjIAAwAAAAAETARLABQAHgAiAAAJATYyHwEWFAcBBiInASY0PwE2MhcDITIWHQEhNTQ2BRUzNQGMAXEHFQeLBwf98wcVB/7cBweLCBUH1APoFR37tB0DZ2QC0wFxBweLCBUH/fMICAEjCBQIiwcH/dIdFfr6FR1kMjIABAAAAAAETASbAAkAGQAjACcAABM3NjIfAQcnJjQFNzYWFQMOASMFIiY/ASc3ASEyFh0BITU0NgUVMzWHjg4qDk3UTQ4CFtIOFQIBHRX9qxUIDtCa1P49A+gVHfu0HQNnZAP/jg4OTdRMDyqa0g4IFf2pFB4BFQ7Qm9T9Oh0V+voVHWQyMgAAAAQAAAAABEwEsAAPABkAIwAnAAABBR4BFRMUBi8BByc3JyY2EwcGIi8BJjQ/AQEhMhYdASE1NDYFFTM1AV4CVxQeARUO0JvUm9IOCMNMDyoOjg4OTf76A+gVHfu0HQNnZASwAgEdFf2rFQgO0JrUmtIOFf1QTQ4Ojg4qDk3+WB0V+voVHWQyMgACAAT/7ASwBK8ABQAIAAAlCQERIQkBFQEEsP4d/sb+cQSs/TMCq2cBFP5xAacDHPz55gO5AAAAAAIAAABkBEwEsAAVABkAAAERFAYrAREhESMiJjURNDY7AREhETMHIzUzBEwdFZb9RJYVHR0V+gH0ZMhkZAPo/K4VHQGQ/nAdFQPoFB7+1AEsyMgAAAMAAABFBN0EsAAWABoALwAAAQcBJyYiDwEhESMiJjURNDY7AREhETMHIzUzARcWFAcBBiIvASY0PwE2Mh8BATYyBEwC/tVfCRkJlf7IlhUdHRX6AfRkyGRkAbBqBwf+XAgUCMoICGoHFQdPASkHFQPolf7VXwkJk/5wHRUD6BQe/tQBLMjI/c5qBxUH/lsHB8sHFQdqCAhPASkHAAMAAAANBQcEsAAWABoAPgAAAREHJy4BBwEhESMiJjURNDY7AREhETMHIzUzARcWFA8BFxYUDwEGIi8BBwYiLwEmND8BJyY0PwE2Mh8BNzYyBExnhg8lEP72/reWFR0dFfoB9GTIZGQB9kYPD4ODDw9GDykPg4MPKQ9GDw+Dgw8PRg8pD4ODDykD6P7zZ4YPAw7+9v5wHRUD6BQe/tQBLMjI/YxGDykPg4MPKQ9GDw+Dgw8PRg8pD4ODDykPRg8Pg4MPAAADAAAAFQSXBLAAFQAZAC8AAAERISIGHQEhESMiJjURNDY7AREhETMHIzUzEzMyFh0BMzIWDwEGIi8BJjY7ATU0NgRM/qIVHf4MlhUdHRX6AfRkyGRklmQVHZYVCA7mDioO5g4IFZYdA+j+1B0Vlv5wHRUD6BQe/tQBLMjI/agdFfoVDuYODuYOFfoVHQAAAAADAAAAAASXBLAAFQAZAC8AAAERJyYiBwEhESMiJjURNDY7AREhETMHIzUzExcWBisBFRQGKwEiJj0BIyImPwE2MgRMpQ4qDv75/m6WFR0dFfoB9GTIZGTr5g4IFZYdFWQVHZYVCA7mDioD6P5wpQ8P/vf+cB0VA+gUHv7UASzIyP2F5Q8V+hQeHhT6FQ/lDwADAAAAyASwBEwACQATABcAABMhMhYdASE1NDYBERQGIyEiJjURExUhNTIETBUd+1AdBJMdFfu0FR1kAZAETB0VlpYVHf7U/doVHR0VAib+1MjIAAAGAAMAfQStBJcADwAZAB0ALQAxADsAAAEXFhQPAQYmPQEhNSE1NDYBIyImPQE0NjsBFyM1MwE3NhYdASEVIRUUBi8BJjQFIzU7AjIWHQEUBisBA6f4Dg74DhX+cAGQFf0vMhUdHRUyyGRk/oL3DhUBkP5wFQ73DwOBZGRkMxQdHRQzBI3mDioO5g4IFZbIlhUI/oUdFWQVHcjI/cvmDggVlsiWFQgO5g4qecgdFWQVHQAAAAACAGQAAASwBLAAFgBRAAABJTYWFREUBisBIiY1ES4ENRE0NiUyFh8BERQOAg8BERQGKwEiJjURLgQ1ETQ+AzMyFh8BETMRPAE+AjMyFh8BETMRND4DA14BFBklHRXIFR0EDiIaFiX+4RYZAgEVHR0LCh0VyBUdBA4iGhYBBwoTDRQZAgNkBQkVDxcZAQFkAQUJFQQxdBIUH/uuFR0dFQGNAQgbHzUeAWcfRJEZDA3+Phw/MSkLC/5BFR0dFQG/BA8uLkAcAcICBxENCxkMDf6iAV4CBxENCxkMDf6iAV4CBxENCwABAGQAAASwBEwAMwAAARUiDgMVERQWHwEVITUyNjURIREUFjMVITUyPgM1ETQmLwE1IRUiBhURIRE0JiM1BLAEDiIaFjIZGf5wSxn+DBlL/nAEDiIaFjIZGQGQSxkB9BlLBEw4AQUKFA78iBYZAQI4OA0lAYr+diUNODgBBQoUDgN4FhkBAjg4DSX+dgGKJQ04AAAABgAAAAAETARMAAwAHAAgACQAKAA0AAABITIWHQEjBTUnITchBSEyFhURFAYjISImNRE0NhcVITUBBTUlBRUhNQUVFAYjIQchJyE3MwKjAXcVHWn+2cj+cGQBd/4lASwpOzsp/tQpOzspASwCvP5wAZD8GAEsArwdFf6JZP6JZAGQyGkD6B0VlmJiyGTIOyn+DCk7OykB9Ck7ZMjI/veFo4XGyMhm+BUdZGTIAAEAEAAQBJ8EnwAmAAATNzYWHwEWBg8BHgEXNz4BHwEeAQ8BBiIuBicuBTcRohEuDosOBhF3ZvyNdxEzE8ATBxGjAw0uMUxPZWZ4O0p3RjITCwED76IRBhPCFDERdo78ZXYRBA6IDi8RogEECBUgNUNjO0qZfHNVQBAAAAACAAAAAASwBEwAIwBBAAAAMh4EHwEVFAYvAS4BPQEmIAcVFAYPAQYmPQE+BRIyHgIfARUBHgEdARQGIyEiJj0BNDY3ATU0PgIB/LimdWQ/LAkJHRTKFB2N/sKNHRTKFB0DDTE7ZnTKcFImFgEBAW0OFR0V+7QVHRUOAW0CFiYETBUhKCgiCgrIFRgDIgMiFZIYGJIVIgMiAxgVyAQNJyQrIP7kExwcCgoy/tEPMhTUFR0dFdQUMg8BLzIEDSEZAAADAAAAAASwBLAADQAdACcAAAEHIScRMxUzNTMVMzUzASEyFhQGKwEXITcjIiY0NgMhMhYdASE1NDYETMj9qMjIyMjIyPyuArwVHR0VDIn8SokMFR0dswRMFR37UB0CvMjIAfTIyMjI/OAdKh1kZB0qHf7UHRUyMhUdAAAAAwBkAAAEsARMAAkAEwAdAAABIyIGFREhETQmASMiBhURIRE0JgEhETQ2OwEyFhUCvGQpOwEsOwFnZCk7ASw7/Rv+1DspZCk7BEw7KfwYA+gpO/7UOyn9RAK8KTv84AGQKTs7KQAAAAAF/5wAAASwBEwADwATAB8AJQApAAATITIWFREUBiMhIiY1ETQ2FxEhEQUjFTMRITUzNSMRIQURByMRMwcRMxHIArx8sLB8/UR8sLAYA4T+DMjI/tTIyAEsAZBkyMhkZARMsHz+DHywsHwB9HywyP1EArzIZP7UZGQBLGT+1GQB9GT+1AEsAAAABf+cAAAEsARMAA8AEwAfACUAKQAAEyEyFhURFAYjISImNRE0NhcRIREBIzUjFSMRMxUzNTMFEQcjETMHETMRyAK8fLCwfP1EfLCwGAOE/gxkZGRkZGQBkGTIyGRkBEywfP4MfLCwfAH0fLDI/UQCvP2oyMgB9MjIZP7UZAH0ZP7UASwABP+cAAAEsARMAA8AEwAbACMAABMhMhYVERQGIyEiJjURNDYXESERBSMRMxUhESEFIxEzFSERIcgCvHywsHz9RHywsBgDhP4MyMj+1AEsAZDIyP7UASwETLB8/gx8sLB8AfR8sMj9RAK8yP7UZAH0ZP7UZAH0AAAABP+cAAAEsARMAA8AEwAWABkAABMhMhYVERQGIyEiJjURNDYXESERAS0BDQERyAK8fLCwfP1EfLCwGAOE/gz+1AEsAZD+1ARMsHz+DHywsHwB9HywyP1EArz+DJaWlpYBLAAAAAX/nAAABLAETAAPABMAFwAgACkAABMhMhYVERQGIyEiJjURNDYXESERAyERIQcjIgYVFBY7AQERMzI2NTQmI8gCvHywsHz9RHywsBgDhGT9RAK8ZIImOTYpgv4Mgik2OSYETLB8/gx8sLB8AfR8sMj9RAK8/agB9GRWQUFUASz+1FRBQVYAAAAF/5wAAASwBEwADwATAB8AJQApAAATITIWFREUBiMhIiY1ETQ2FxEhEQUjFTMRITUzNSMRIQEjESM1MwMjNTPIArx8sLB8/UR8sLAYA4T+DMjI/tTIyAEsAZBkZMjIZGQETLB8/gx8sLB8AfR8sMj9RAK8yGT+1GRkASz+DAGQZP4MZAAG/5wAAASwBEwADwATABkAHwAjACcAABMhMhYVERQGIyEiJjURNDYXESERBTMRIREzASMRIzUzBRUzNQEjNTPIArx8sLB8/UR8sLAYA4T9RMj+1GQCWGRkyP2oZAEsZGQETLB8/gx8sLB8AfR8sMj9RAK8yP5wAfT+DAGQZMjIyP7UZAAF/5wAAASwBEwADwATABwAIgAmAAATITIWFREUBiMhIiY1ETQ2FxEhEQEHIzU3NSM1IQEjESM1MwMjNTPIArx8sLB8/UR8sLAYA4T+DMdkx8gBLAGQZGTIx2RkBEywfP4MfLCwfAH0fLDI/UQCvP5wyDLIlmT+DAGQZP4MZAAAAAMACQAJBKcEpwAPABsAJQAAADIeAhQOAiIuAjQ+AQQiDgEUHgEyPgE0JgchFSEVISc1NyEB4PDbnl5entvw255eXp4BxeTCcXHC5MJxcWz+1AEs/tRkZAEsBKdentvw255eXp7b8NueTHHC5MJxccLkwtDIZGTIZAAAAAAEAAkACQSnBKcADwAbACcAKwAAADIeAhQOAiIuAjQ+AQQiDgEUHgEyPgE0JgcVBxcVIycjFSMRIQcVMzUB4PDbnl5entvw255eXp4BxeTCcXHC5MJxcWwyZGRklmQBLMjIBKdentvw255eXp7b8NueTHHC5MJxccLkwtBkMmQyZGQBkGRkZAAAAv/y/50EwgRBACAANgAAATIWFzYzMhYUBisBNTQmIyEiBh0BIyImNTQ2NyY1ND4BEzMyFhURMzIWDwEGIi8BJjY7ARE0NgH3brUsLC54qqp4gB0V/tQVHd5QcFZBAmKqepYKD4kVCg3fDSYN3w0KFYkPBEF3YQ6t8a36FR0dFfpzT0VrDhMSZKpi/bMPCv7tFxD0EBD0EBcBEwoPAAAAAAL/8v+cBMMEQQAcADMAAAEyFhc2MzIWFxQGBwEmIgcBIyImNTQ2NyY1ND4BExcWBisBERQGKwEiJjURIyImNzY3NjIB9m62LCsueaoBeFr+hg0lDf6DCU9xVkECYqnm3w0KFYkPCpYKD4kVCg3HGBMZBEF3YQ+teGOkHAFoEBD+k3NPRWsOExNkqWP9kuQQF/7tCg8PCgETFxDMGBMAAAABAGQAAARMBG0AGAAAJTUhATMBMwkBMwEzASEVIyIGHQEhNTQmIwK8AZD+8qr+8qr+1P7Uqv7yqv7yAZAyFR0BkB0VZGQBLAEsAU3+s/7U/tRkHRUyMhUdAAAAAAEAeQAABDcEmwAvAAABMhYXHgEVFAYHFhUUBiMiJxUyFh0BITU0NjM1BiMiJjU0Ny4BNTQ2MzIXNCY1NDYCWF6TGll7OzIJaUo3LRUd/tQdFS03SmkELzlpSgUSAqMEm3FZBoNaPWcfHRpKaR77HRUyMhUd+x5pShIUFVg1SmkCAhAFdKMAAAAGACcAFASJBJwAEQAqAEIASgBiAHsAAAEWEgIHDgEiJicmAhI3PgEyFgUiBw4BBwYWHwEWMzI3Njc2Nz4BLwEmJyYXIgcOAQcGFh8BFjMyNz4BNz4BLwEmJyYWJiIGFBYyNjciBw4BBw4BHwEWFxYzMjc+ATc2Ji8BJhciBwYHBgcOAR8BFhcWMzI3PgE3NiYvASYD8m9PT29T2dzZU29PT29T2dzZ/j0EBHmxIgQNDCQDBBcGG0dGYAsNAwkDCwccBAVQdRgEDA0iBAQWBhJROQwMAwkDCwf5Y4xjY4xjVhYGElE6CwwDCQMLBwgEBVB1GAQNDCIEjRcGG0dGYAsNAwkDCwcIBAR5sSIEDQwkAwPyb/7V/tVvU1dXU28BKwErb1NXVxwBIrF5DBYDCQEWYEZHGwMVDCMNBgSRAhh1UA0WAwkBFTpREgMVCyMMBwT6Y2OMY2MVFTpREQQVCyMMBwQCGHVQDRYDCQEkFmBGRxsDFQwjDQYEASKxeQwWAwkBAAAABQBkAAAD6ASwAAwADwAWABwAIgAAASERIzUhFSERNDYzIQEjNQMzByczNTMDISImNREFFRQGKwECvAEstP6s/oQPCgI/ASzIZKLU1KJktP51Cg8DhA8KwwMg/oTIyALzCg/+1Mj84NTUyP4MDwoBi8jDCg8AAAAABQBkAAAD6ASwAAkADAATABoAIQAAASERCQERNDYzIQEjNRMjFSM1IzcDISImPQEpARUUBisBNQK8ASz+ov3aDwoCPwEsyD6iZKLUqv6dCg8BfAIIDwqbAyD9+AFe/doERwoP/tTI/HzIyNT+ZA8KNzcKD1AAAAAAAwAAAAAEsAP0AAgAGQAfAAABIxUzFyERIzcFMzIeAhUhFSEDETM0PgIBMwMhASEEiqJkZP7UotT9EsgbGiEOASz9qMhkDiEaAnPw8PzgASwB9AMgyGQBLNTUBBErJGT+ogHCJCsRBP5w/nAB9AAAAAMAAAAABEwETAAZADIAOQAAATMyFh0BMzIWHQEUBiMhIiY9ATQ2OwE1NDYFNTIWFREUBiMhIic3ARE0NjMVFBYzITI2AQc1IzUzNQKKZBUdMhUdHRX+1BUdHRUyHQFzKTs7Kf2oARP2/ro7KVg+ASw+WP201MjIBEwdFTIdFWQVHR0VZBUdMhUd+pY7KfzgKTsE9gFGAUQpO5Y+WFj95tSiZKIAAwBkAAAEvARMABkANgA9AAABMzIWHQEzMhYdARQGIyEiJj0BNDY7ATU0NgU1MhYVESMRMxQOAiMhIiY1ETQ2MxUUFjMhMjYBBzUjNTM1AcJkFR0yFR0dFf7UFR0dFTIdAXMpO8jIDiEaG/2oKTs7KVg+ASw+WAGc1MjIBEwdFTIdFWQVHR0VZBUdMhUd+pY7Kf4M/tQkKxEEOykDICk7lj5YWP3m1KJkogAAAAP/ogAABRYE1AALABsAHwAACQEWBiMhIiY3ATYyEyMiBhcTHgE7ATI2NxM2JgMVMzUCkgJ9FyAs+wQsIBcCfRZARNAUGAQ6BCMUNhQjBDoEGODIBK37sCY3NyYEUCf+TB0U/tIUHR0UAS4UHf4MZGQAAAAACQAAAAAETARMAA8AHwAvAD8ATwBfAG8AfwCPAAABMzIWHQEUBisBIiY9ATQ2EzMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYBMzIWHQEUBisBIiY9ATQ2ITMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYBMzIWHQEUBisBIiY9ATQ2ITMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYBqfoKDw8K+goPDwr6Cg8PCvoKDw8BmvoKDw8K+goPD/zq+goPDwr6Cg8PAZr6Cg8PCvoKDw8BmvoKDw8K+goPD/zq+goPDwr6Cg8PAZr6Cg8PCvoKDw8BmvoKDw8K+goPDwRMDwqWCg8PCpYKD/7UDwqWCg8PCpYKDw8KlgoPDwqWCg/+1A8KlgoPDwqWCg8PCpYKDw8KlgoPDwqWCg8PCpYKD/7UDwqWCg8PCpYKDw8KlgoPDwqWCg8PCpYKDw8KlgoPAAAAAwAAAAAEsAUUABkAKQAzAAABMxUjFSEyFg8BBgchJi8BJjYzITUjNTM1MwEhMhYUBisBFyE3IyImNDYDITIWHQEhNTQ2ArxkZAFePjEcQiko/PwoKUIcMT4BXmRkyP4+ArwVHR0VDIn8SooNFR0dswRMFR37UB0EsMhkTzeEUzMzU4Q3T2TIZPx8HSodZGQdKh3+1B0VMjIVHQAABAAAAAAEsAUUAAUAGQArADUAAAAyFhUjNAchFhUUByEyFg8BIScmNjMhJjU0AyEyFhQGKwEVBSElNSMiJjQ2AyEyFh0BITU0NgIwUDnCPAE6EgMBSCkHIq/9WrIiCikBSAOvArwVHR0VlgET/EoBE5YVHR2zBEwVHftQHQUUOykpjSUmCBEhFpGRFiERCCb+lR0qHcjIyMgdKh39qB0VMjIVHQAEAAAAAASwBJ0ABwAUACQALgAAADIWFAYiJjQTMzIWFRQXITY1NDYzASEyFhQGKwEXITcjIiY0NgMhMhYdASE1NDYCDZZqapZqty4iKyf+vCcrI/7NArwVHR0VDYr8SokMFR0dswRMFR37UB0EnWqWamqW/us5Okxra0w6Of5yHSodZGQdKh3+1B0VMjIVHQAEAAAAAASwBRQADwAcACwANgAAATIeARUUBiImNTQ3FzcnNhMzMhYVFBchNjU0NjMBITIWFAYrARchNyMiJjQ2AyEyFh0BITU0NgJYL1szb5xvIpBvoyIfLiIrJ/68Jysj/s0CvBUdHRUNivxKiQwVHR2zBEwVHftQHQUUa4s2Tm9vTj5Rj2+jGv4KOTpMa2tMOjn+ch0qHWRkHSod/tQdFTIyFR0AAAADAAAAAASwBRIAEgAiACwAAAEFFSEUHgMXIS4BNTQ+AjcBITIWFAYrARchNyMiJjQ2AyEyFh0BITU0NgJYASz+1CU/P00T/e48PUJtj0r+ogK8FR0dFQ2K/EqJDBUdHbMETBUd+1AdBLChizlmUT9IGVO9VFShdksE/H4dKh1kZB0qHf7UHRUyMhUdAAIAyAAAA+gFFAAPACkAAAAyFh0BHgEdASE1NDY3NTQDITIWFyMVMxUjFTMVIxUzFAYjISImNRE0NgIvUjsuNv5wNi5kAZA2XBqsyMjIyMh1U/5wU3V1BRQ7KU4aXDYyMjZcGk4p/kc2LmRkZGRkU3V1UwGQU3UAAAMAZP//BEwETAAPAC8AMwAAEyEyFhURFAYjISImNRE0NgMhMhYdARQGIyEXFhQGIi8BIQcGIiY0PwEhIiY9ATQ2BQchJ5YDhBUdHRX8fBUdHQQDtgoPDwr+5eANGiUNWP30Vw0mGg3g/t8KDw8BqmQBRGQETB0V/gwVHR0VAfQVHf1EDwoyCg/gDSUbDVhYDRslDeAPCjIKD2RkZAAAAAAEAAAAAASwBEwAGQAjAC0ANwAAEyEyFh0BIzQmKwEiBhUjNCYrASIGFSM1NDYDITIWFREhETQ2ExUUBisBIiY9ASEVFAYrASImPQHIAyBTdWQ7KfopO2Q7KfopO2R1EQPoKTv7UDvxHRVkFR0D6B0VZBUdBEx1U8gpOzspKTs7KchTdf4MOyn+1AEsKTv+DDIVHR0VMjIVHR0VMgADAAEAAASpBKwADQARABsAAAkBFhQPASEBJjQ3ATYyCQMDITIWHQEhNTQ2AeACqh8fg/4f/fsgIAEnH1n+rAFWAS/+q6IDIBUd/HwdBI39VR9ZH4MCBh9ZHwEoH/5u/qoBMAFV/BsdFTIyFR0AAAAAAgCPAAAEIQSwABcALwAAAQMuASMhIgYHAwYWMyEVFBYyNj0BMzI2AyE1NDY7ATU0NjsBETMRMzIWHQEzMhYVBCG9CCcV/nAVJwi9CBMVAnEdKh19FROo/a0dFTIdFTDILxUdMhUdAocB+hMcHBP+BhMclhUdHRWWHP2MMhUdMhUdASz+1B0VMh0VAAAEAAAAAASwBLAADQAQAB8AIgAAASERFAYjIREBNTQ2MyEBIzUBIREUBiMhIiY1ETQ2MyEBIzUDhAEsDwr+if7UDwoBdwEsyP2oASwPCv12Cg8PCgF3ASzIAyD9wQoPAk8BLFQKD/7UyP4M/cEKDw8KA7YKD/7UyAAC/5wAZAUUBEcARgBWAAABMzIeAhcWFxY2NzYnJjc+ARYXFgcOASsBDgEPAQ4BKwEiJj8BBisBIicHDgErASImPwEmLwEuAT0BNDY7ATY3JyY2OwE2BSMiBh0BFBY7ATI2PQE0JgHkw0uOakkMEhEfQwoKGRMKBQ8XDCkCA1Y9Pgc4HCcDIhVkFRgDDDEqwxgpCwMiFWQVGAMaVCyfExwdFXwLLW8QBxXLdAFF+goPDwr6Cg8PBEdBa4pJDgYKISAiJRsQCAYIDCw9P1c3fCbqFB0dFEYOCEAUHR0UnUplNQcmFTIVHVdPXw4TZV8PCjIKDw8KMgoPAAb/nP/mBRQEfgAJACQANAA8AFIAYgAAASU2Fh8BFgYPASUzMhYfASEyFh0BFAYHBQYmJyYjISImPQE0NhcjIgYdARQ7ATI2NTQmJyYEIgYUFjI2NAE3PgEeARceAT8BFxYGDwEGJi8BJjYlBwYfAR4BPwE2Jy4BJy4BAoEBpxMuDiAOAxCL/CtqQ0geZgM3FR0cE/0fFyIJKjr+1D5YWLlQExIqhhALIAsSAYBALS1ALf4PmBIgHhMQHC0aPzANITNQL3wpgigJASlmHyElDR0RPRMFAhQHCxADhPcICxAmDyoNeMgiNtQdFTIVJgeEBBQPQ1g+yD5YrBwVODMQEAtEERzJLUAtLUD+24ITChESEyMgAwWzPUkrRSgJL5cvfRxYGyYrDwkLNRAhFEgJDAQAAAAAAwBkAAAEOQSwAFEAYABvAAABMzIWHQEeARcWDgIPATIeBRUUDgUjFRQGKwEiJj0BIxUUBisBIiY9ASMiJj0BNDY7AREjIiY9ATQ2OwE1NDY7ATIWHQEzNTQ2AxUhMj4CNTc0LgMjARUhMj4CNTc0LgMjAnGWCg9PaAEBIC4uEBEGEjQwOiodFyI2LUAjGg8KlgoPZA8KlgoPrwoPDwpLSwoPDwqvDwqWCg9kD9cBBxwpEwsBAQsTKRz++QFrHCkTCwEBCxMpHASwDwptIW1KLk0tHwYGAw8UKDJOLTtdPCoVCwJLCg8PCktLCg8PCksPCpYKDwJYDwqWCg9LCg8PCktLCg/+1MgVHR0LCgQOIhoW/nDIFR0dCwoEDiIaFgAAAwAEAAIEsASuABcAKQAsAAATITIWFREUBg8BDgEjISImJy4CNRE0NgQiDgQPARchNy4FAyMT1AMMVnokEhIdgVL9xFKCHAgYKHoCIIx9VkcrHQYGnAIwnAIIIClJVSGdwwSuelb+YDO3QkJXd3ZYHFrFMwGgVnqZFyYtLSUMDPPzBQ8sKDEj/sIBBQACAMgAAAOEBRQADwAZAAABMzIWFREUBiMhIiY1ETQ2ARUUBisBIiY9AQHblmesVCn+PilUrAFINhWWFTYFFKxn/gwpVFQpAfRnrPwY4RU2NhXhAAACAMgAAAOEBRQADwAZAAABMxQWMxEUBiMhIiY1ETQ2ARUUBisBIiY9AQHbYLOWVCn+PilUrAFINhWWFTYFFJaz/kIpVFQpAfRnrPwY4RU2NhXhAAACAAAAFAUOBBoAFAAaAAAJASUHFRcVJwc1NzU0Jj4CPwEnCQEFJTUFJQUO/YL+hk5klpZkAQEBBQQvkwKCAVz+ov6iAV4BXgL//uWqPOCWx5SVyJb6BA0GCgYDKEEBG/1ipqaTpaUAAAMAZAH0BLADIAAHAA8AFwAAEjIWFAYiJjQkMhYUBiImNCQyFhQGIiY0vHxYWHxYAeh8WFh8WAHofFhYfFgDIFh8WFh8WFh8WFh8WFh8WFh8AAAAAAMBkAAAArwETAAHAA8AFwAAADIWFAYiJjQSMhYUBiImNBIyFhQGIiY0Aeh8WFh8WFh8WFh8WFh8WFh8WARMWHxYWHz+yFh8WFh8/shYfFhYfAAAAAMAZABkBEwETAAPAB8ALwAAEyEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2fQO2Cg8PCvxKCg8PCgO2Cg8PCvxKCg8PCgO2Cg8PCvxKCg8PBEwPCpYKDw8KlgoP/nAPCpYKDw8KlgoP/nAPCpYKDw8KlgoPAAAABAAAAAAEsASwAA8AHwAvADMAAAEhMhYVERQGIyEiJjURNDYFISIGFREUFjMhMjY1ETQmBSEyFhURFAYjISImNRE0NhcVITUBXgH0ory7o/4Mpbm5Asv9qCk7OykCWCk7O/2xAfQVHR0V/gwVHR1HAZAEsLuj/gylubmlAfSlucg7Kf2oKTs7KQJYKTtkHRX+1BUdHRUBLBUdZMjIAAAAAAEAZABkBLAETAA7AAATITIWFAYrARUzMhYUBisBFTMyFhQGKwEVMzIWFAYjISImNDY7ATUjIiY0NjsBNSMiJjQ2OwE1IyImNDaWA+gVHR0VMjIVHR0VMjIVHR0VMjIVHR0V/BgVHR0VMjIVHR0VMjIVHR0VMjIVHR0ETB0qHcgdKh3IHSodyB0qHR0qHcgdKh3IHSodyB0qHQAAAAYBLAAFA+gEowAHAA0AEwAZAB8AKgAAAR4BBgcuATYBMhYVIiYlFAYjNDYBMhYVIiYlFAYjNDYDFRQGIiY9ARYzMgKKVz8/V1c/P/75fLB8sAK8sHyw/cB8sHywArywfLCwHSodKAMRBKNDsrJCQrKy/sCwfLB8fLB8sP7UsHywfHywfLD+05AVHR0VjgQAAAH/tQDIBJQDgQBCAAABNzYXAR4BBw4BKwEyFRQOBCsBIhE0NyYiBxYVECsBIi4DNTQzIyImJyY2NwE2HwEeAQ4BLwEHIScHBi4BNgLpRRkUASoLCAYFGg8IAQQNGyc/KZK4ChRUFQu4jjBJJxkHAgcPGQYGCAsBKhQaTBQVCiMUM7YDe7YsFCMKFgNuEwYS/tkLHw8OEw0dNkY4MhwBIBgXBAQYF/7gKjxTQyMNEw4PHwoBKBIHEwUjKBYGDMHBDAUWKCMAAAAAAgAAAAAEsASwACUAQwAAASM0LgUrAREUFh8BFSE1Mj4DNREjIg4FFSMRIQEjNC4DKwERFBYXMxUjNTI1ESMiDgMVIzUhBLAyCAsZEyYYGcgyGRn+cAQOIhoWyBkYJhMZCwgyA+j9RBkIChgQEWQZDQzIMmQREBgKCBkB9AOEFSAVDggDAfyuFhkBAmRkAQUJFQ4DUgEDCA4VIBUBLP0SDxMKBQH+VwsNATIyGQGpAQUKEw+WAAAAAAMAAAAABEwErgAdACAAMAAAATUiJy4BLwEBIwEGBw4BDwEVITUiJj8BIRcWBiMVARsBARUUBiMhIiY9ATQ2MyEyFgPoGR4OFgUE/t9F/tQSFQkfCwsBETE7EkUBJT0NISf+7IZ5AbEdFfwYFR0dFQPoFR0BLDIgDiIKCwLr/Q4jFQkTBQUyMisusKYiQTIBhwFW/qr942QVHR0VZBUdHQADAAAAAASwBLAADwBHAEoAABMhMhYVERQGIyEiJjURNDYFIyIHAQYHBgcGHQEUFjMhMjY9ATQmIyInJj8BIRcWBwYjIgYdARQWMyEyNj0BNCYnIicmJyMBJhMjEzIETBUdHRX7tBUdHQJGRg0F/tUREhImDAsJAREIDAwINxAKCj8BCjkLEQwYCAwMCAE5CAwLCBEZGQ8B/uAFDsVnBLAdFfu0FR0dFQRMFR1SDP0PIBMSEAUNMggMDAgyCAwXDhmjmR8YEQwIMggMDAgyBwwBGRskAuwM/gUBCAAABAAAAAAEsASwAAMAEwAjACcAAAEhNSEFITIWFREUBiMhIiY1ETQ2KQEyFhURFAYjISImNRE0NhcRIREEsPtQBLD7ggGQFR0dFf5wFR0dAm0BkBUdHRX+cBUdHUcBLARMZMgdFfx8FR0dFQOEFR0dFf5wFR0dFQGQFR1k/tQBLAAEAAAAAASwBLAADwAfACMAJwAAEyEyFhURFAYjISImNRE0NgEhMhYVERQGIyEiJjURNDYXESEREyE1ITIBkBUdHRX+cBUdHQJtAZAVHR0V/nAVHR1HASzI+1AEsASwHRX8fBUdHRUDhBUd/gwdFf5wFR0dFQGQFR1k/tQBLP2oZAAAAAACAAAAZASwA+gAJwArAAATITIWFREzNTQ2MyEyFh0BMxUjFRQGIyEiJj0BIxEUBiMhIiY1ETQ2AREhETIBkBUdZB0VAZAVHWRkHRX+cBUdZB0V/nAVHR0CnwEsA+gdFf6ilhUdHRWWZJYVHR0Vlv6iFR0dFQMgFR3+1P7UASwAAAQAAAAABLAEsAADABMAFwAnAAAzIxEzFyEyFhURFAYjISImNRE0NhcRIREBITIWFREUBiMhIiY1ETQ2ZGRklgGQFR0dFf5wFR0dRwEs/qIDhBUdHRX8fBUdHQSwZB0V/nAVHR0VAZAVHWT+1AEs/gwdFf5wFR0dFQGQFR0AAAAAAgBkAAAETASwACcAKwAAATMyFhURFAYrARUhMhYVERQGIyEiJjURNDYzITUjIiY1ETQ2OwE1MwcRIRECWJYVHR0VlgHCFR0dFfx8FR0dFQFelhUdHRWWZMgBLARMHRX+cBUdZB0V/nAVHR0VAZAVHWQdFQGQFR1kyP7UASwAAAAEAAAAAASwBLAAAwATABcAJwAAISMRMwUhMhYVERQGIyEiJjURNDYXESERASEyFhURFAYjISImNRE0NgSwZGT9dgGQFR0dFf5wFR0dRwEs/K4DhBUdHRX8fBUdHQSwZB0V/nAVHR0VAZAVHWT+1AEs/gwdFf5wFR0dFQGQFR0AAAEBLAAwA28EgAAPAAAJAQYjIiY1ETQ2MzIXARYUA2H+EhcSDhAQDhIXAe4OAjX+EhcbGQPoGRsX/hIOKgAAAAABAUEAMgOEBH4ACwAACQE2FhURFAYnASY0AU8B7h0qKh3+Eg4CewHuHREp/BgpER0B7g4qAAAAAAEAMgFBBH4DhAALAAATITIWBwEGIicBJjZkA+gpER3+Eg4qDv4SHREDhCod/hIODgHuHSoAAAAAAQAyASwEfgNvAAsAAAkBFgYjISImNwE2MgJ7Ae4dESn8GCkRHQHuDioDYf4SHSoqHQHuDgAAAAACAAgAAASwBCgABgAKAAABFQE1LQE1ASE1IQK8/UwBnf5jBKj84AMgAuW2/r3dwcHd+9jIAAAAAAIAAABkBLAEsAALADEAAAEjFTMVIREzNSM1IQEzND4FOwERFAYPARUhNSIuAzURMzIeBRUzESEEsMjI/tTIyAEs+1AyCAsZEyYYGWQyGRkBkAQOIhoWZBkYJhMZCwgy/OADhGRkASxkZP4MFSAVDggDAf3aFhkBAmRkAQUJFQ4CJgEDCA4VIBUBLAAAAgAAAAAETAPoACUAMQAAASM0LgUrAREUFh8BFSE1Mj4DNREjIg4FFSMRIQEjFTMVIREzNSM1IQMgMggLGRMmGBlkMhkZ/nAEDiIaFmQZGCYTGQsIMgMgASzIyP7UyMgBLAK8FSAVDggDAf3aFhkCAWRkAQUJFQ4CJgEDCA4VIBUBLPzgZGQBLGRkAAABAMgAZgNyBEoAEgAAATMyFgcJARYGKwEiJwEmNDcBNgK9oBAKDP4wAdAMChCgDQr+KQcHAdcKBEoWDP4w/jAMFgkB1wgUCAHXCQAAAQE+AGYD6ARKABIAAAEzMhcBFhQHAQYrASImNwkBJjYBU6ANCgHXBwf+KQoNoBAKDAHQ/jAMCgRKCf4pCBQI/ikJFgwB0AHQDBYAAAEAZgDIBEoDcgASAAAAFh0BFAcBBiInASY9ATQ2FwkBBDQWCf4pCBQI/ikJFgwB0AHQA3cKEKANCv4pBwcB1woNoBAKDP4wAdAAAAABAGYBPgRKA+gAEgAACQEWHQEUBicJAQYmPQE0NwE2MgJqAdcJFgz+MP4wDBYJAdcIFAPh/ikKDaAQCgwB0P4wDAoQoA0KAdcHAAAAAgDZ//kEPQSwAAUAOgAAARQGIzQ2BTMyFh8BNjc+Ah4EBgcOBgcGIiYjIgYiJy4DLwEuAT4EHgEXJyY2A+iwfLD+VmQVJgdPBQsiKFAzRyorDwURAQQSFyozTSwNOkkLDkc3EDlfNyYHBw8GDyUqPjdGMR+TDA0EsHywfLDIHBPCAQIGBwcFDx81S21DBxlLR1xKQhEFBQcHGWt0bCQjP2hJNyATBwMGBcASGAAAAAACAMgAFQOEBLAAFgAaAAATITIWFREUBisBEQcGJjURIyImNRE0NhcVITX6AlgVHR0Vlv8TGpYVHR2rASwEsB0V/nAVHf4MsgkQFQKKHRUBkBUdZGRkAAAAAgDIABkETASwAA4AEgAAEyEyFhURBRElIREjETQ2ARU3NfoC7ic9/UQCWP1EZB8BDWQEsFEs/Ft1A7Z9/BgEARc0/V1kFGQAAQAAAAECTW/DBF9fDzz1AB8EsAAAAADQdnOXAAAAANB2c5f/Uf+cBdwFFAAAAAgAAgAAAAAAAAABAAAFFP+FAAAFFP9R/tQF3AABAAAAAAAAAAAAAAAAAAAAowG4ACgAAAAAAZAAAASwAAAEsABkBLAAAASwAAAEsABwAooAAAUUAAACigAABRQAAAGxAAABRQAAANgAAADYAAAAogAAAQQAAABIAAABBAAAAUUAAASwAGQEsAB7BLAAyASwAMgB9AAABLD/8gSwAAAEsAAABLD/8ASwAAAEsAAOBLAACQSwAGQEsP/TBLD/0wSwAAAEsAAABLAAAASwAAAEsAAABLAAJgSwAG4EsAAXBLAAFwSwABcEsABkBLAAGgSwAGQEsAAMBLAAZASwABcEsP+cBLAAZASwABcEsAAXBLAAAASwABcEsAAXBLAAFwSwAGQEsAAABLAAZASwAAAEsAAABLAAAASwAAAEsAAABLAAAASwAAAEsAAABLAAZASwAMgEsAAABLAAAASwADUEsABkBLAAyASw/7UEsAAhBLAAAASwAAAEsAAABLAAAASwAAAEsP+cBLAAAASwAAAEsAAABLAA2wSwABcEsAB1BLAAAASwAAAEsAAABLAACgSwAMgEsAAABLAAnQSwAMgEsADIBLAAyASwAAAEsP/+BLABLASwAGQEsACIBLABOwSwABcEsAAXBLAAFwSwABcEsAAXBLAAFwSwAAAEsAAXBLAAFwSwABcEsAAXBLAAAASwALcEsAC3BLAAAASwAAAEsABJBLAAFwSwAAAEsAAABLAAXQSw/9wEsP/cBLD/nwSwAGQEsAAABLAAAASwAAAEsABkBLD//wSwAAAEsP9RBLAABgSwAAAEsAAABLABRQSwAAEEsAAABLD/nASwAEoEsAAUBLAAAASwAAAEsAAABLD/nASwAGEEsP/9BLAAFgSwABYEsAAWBLAAFgSwABgEsAAABMQAAASwAGQAAAAAAAD/2ABkADkAyAAAAScAZAAZABkAGQAZABkAGQAZAAAAAAAAAAAAAADZAAAAAAAOAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAMAZABkAAAAEAAAAAAAZP+c/5z/nP+c/5z/nP+c/5wACQAJ//L/8gBkAHkAJwBkAGQAAAAAAGT/ogAAAAAAAAAAAAAAAADIAGQAAAABAI8AAP+c/5wAZAAEAMgAyAAAAGQBkABkAAAAZAEs/7UAAAAAAAAAAAAAAAAAAABkAAABLAFBADIAMgAIAAAAAADIAT4AZgBmANkAyADIAAAAKgAqACoAKgCyAOgA6AFOAU4BTgFOAU4BTgFOAU4BTgFOAU4BTgFOAU4BpAIGAiICfgKGAqwC5ANGA24DjAPEBAgEMgRiBKIE3AVcBboGcgb0ByAHYgfKCB4IYgi+CTYJhAm2Cd4KKApMCpQK4gswC4oLygwIDFgNKg1eDbAODg5oDrQPKA+mD+YQEhBUEJAQqhEqEXYRthIKEjgSfBLAExoTdBPQFCoU1BU8FagVzBYEFjYWYBawFv4XUhemGAIYLhhqGJYYsBjgGP4ZKBloGZQZxBnaGe4aNhpoGrga9hteG7QcMhyUHOIdHB1EHWwdlB28HeYeLh52HsAfYh/SIEYgviEyIXYhuCJAIpYiuCMOIyIjOCN6I8Ij4CQCJDAkXiSWJOIlNCVgJbwmFCZ+JuYnUCe8J/goNChwKKwpoCnMKiYqSiqEKworeiwILGgsuizsLRwtiC30LiguZi6iLtgvDi9GL34vsi/4MD4whDDSMRIxYDGuMegyJDJeMpoy3jMiMz4zaDO2NBg0YDSoNNI1LDWeNeg2PjZ8Ntw3GjdON5I31DgQOEI4hjjIOQo5SjmIOcw6HDpsOpo63jugO9w8GDxQPKI8+D0yPew+Oj6MPtQ/KD9uP6o/+kBIQIBAxkECQX5CGEKoQu5DGENCQ3ZDoEPKRBBEYESuRPZFWkW2RgZGdEa0RvZHNkd2R7ZH9kgWSDJITkhqSIZIzEkSSThJXkmESapKAkouSlIAAQAAARcApwARAAAAAAACAAAAAQABAAAAQAAuAAAAAAAAABAAxgABAAAAAAATABIAAAADAAEECQAAAGoAEgADAAEECQABACgAfAADAAEECQACAA4ApAADAAEECQADAEwAsgADAAEECQAEADgA/gADAAEECQAFAHgBNgADAAEECQAGADYBrgADAAEECQAIABYB5AADAAEECQAJABYB+gADAAEECQALACQCEAADAAEECQAMACQCNAADAAEECQATACQCWAADAAEECQDIABYCfAADAAEECQDJADACkgADAAEECdkDABoCwnd3dy5nbHlwaGljb25zLmNvbQBDAG8AcAB5AHIAaQBnAGgAdAAgAKkAIAAyADAAMQA0ACAAYgB5ACAASgBhAG4AIABLAG8AdgBhAHIAaQBrAC4AIABBAGwAbAAgAHIAaQBnAGgAdABzACAAcgBlAHMAZQByAHYAZQBkAC4ARwBMAFkAUABIAEkAQwBPAE4AUwAgAEgAYQBsAGYAbABpAG4AZwBzAFIAZQBnAHUAbABhAHIAMQAuADAAMAA5ADsAVQBLAFcATgA7AEcATABZAFAASABJAEMATwBOAFMASABhAGwAZgBsAGkAbgBnAHMALQBSAGUAZwB1AGwAYQByAEcATABZAFAASABJAEMATwBOAFMAIABIAGEAbABmAGwAaQBuAGcAcwAgAFIAZQBnAHUAbABhAHIAVgBlAHIAcwBpAG8AbgAgADEALgAwADAAOQA7AFAAUwAgADAAMAAxAC4AMAAwADkAOwBoAG8AdABjAG8AbgB2ACAAMQAuADAALgA3ADAAOwBtAGEAawBlAG8AdABmAC4AbABpAGIAMgAuADUALgA1ADgAMwAyADkARwBMAFkAUABIAEkAQwBPAE4AUwBIAGEAbABmAGwAaQBuAGcAcwAtAFIAZQBnAHUAbABhAHIASgBhAG4AIABLAG8AdgBhAHIAaQBrAEoAYQBuACAASwBvAHYAYQByAGkAawB3AHcAdwAuAGcAbAB5AHAAaABpAGMAbwBuAHMALgBjAG8AbQB3AHcAdwAuAGcAbAB5AHAAaABpAGMAbwBuAHMALgBjAG8AbQB3AHcAdwAuAGcAbAB5AHAAaABpAGMAbwBuAHMALgBjAG8AbQBXAGUAYgBmAG8AbgB0ACAAMQAuADAAVwBlAGQAIABPAGMAdAAgADIAOQAgADAANgA6ADMANgA6ADAANwAgADIAMAAxADQARgBvAG4AdAAgAFMAcQB1AGkAcgByAGUAbAAAAAIAAAAAAAD/tQAyAAAAAAAAAAAAAAAAAAAAAAAAAAABFwAAAQIBAwADAA0ADgEEAJYBBQEGAQcBCAEJAQoBCwEMAQ0BDgEPARABEQESARMA7wEUARUBFgEXARgBGQEaARsBHAEdAR4BHwEgASEBIgEjASQBJQEmAScBKAEpASoBKwEsAS0BLgEvATABMQEyATMBNAE1ATYBNwE4ATkBOgE7ATwBPQE+AT8BQAFBAUIBQwFEAUUBRgFHAUgBSQFKAUsBTAFNAU4BTwFQAVEBUgFTAVQBVQFWAVcBWAFZAVoBWwFcAV0BXgFfAWABYQFiAWMBZAFlAWYBZwFoAWkBagFrAWwBbQFuAW8BcAFxAXIBcwF0AXUBdgF3AXgBeQF6AXsBfAF9AX4BfwGAAYEBggGDAYQBhQGGAYcBiAGJAYoBiwGMAY0BjgGPAZABkQGSAZMBlAGVAZYBlwGYAZkBmgGbAZwBnQGeAZ8BoAGhAaIBowGkAaUBpgGnAagBqQGqAasBrAGtAa4BrwGwAbEBsgGzAbQBtQG2AbcBuAG5AboBuwG8Ab0BvgG/AcABwQHCAcMBxAHFAcYBxwHIAckBygHLAcwBzQHOAc8B0AHRAdIB0wHUAdUB1gHXAdgB2QHaAdsB3AHdAd4B3wHgAeEB4gHjAeQB5QHmAecB6AHpAeoB6wHsAe0B7gHvAfAB8QHyAfMB9AH1AfYB9wH4AfkB+gH7AfwB/QH+Af8CAAIBAgICAwIEAgUCBgIHAggCCQIKAgsCDAINAg4CDwIQAhECEgZnbHlwaDEGZ2x5cGgyB3VuaTAwQTAHdW5pMjAwMAd1bmkyMDAxB3VuaTIwMDIHdW5pMjAwMwd1bmkyMDA0B3VuaTIwMDUHdW5pMjAwNgd1bmkyMDA3B3VuaTIwMDgHdW5pMjAwOQd1bmkyMDBBB3VuaTIwMkYHdW5pMjA1RgRFdXJvB3VuaTIwQkQHdW5pMjMxQgd1bmkyNUZDB3VuaTI2MDEHdW5pMjZGQQd1bmkyNzA5B3VuaTI3MEYHdW5pRTAwMQd1bmlFMDAyB3VuaUUwMDMHdW5pRTAwNQd1bmlFMDA2B3VuaUUwMDcHdW5pRTAwOAd1bmlFMDA5B3VuaUUwMTAHdW5pRTAxMQd1bmlFMDEyB3VuaUUwMTMHdW5pRTAxNAd1bmlFMDE1B3VuaUUwMTYHdW5pRTAxNwd1bmlFMDE4B3VuaUUwMTkHdW5pRTAyMAd1bmlFMDIxB3VuaUUwMjIHdW5pRTAyMwd1bmlFMDI0B3VuaUUwMjUHdW5pRTAyNgd1bmlFMDI3B3VuaUUwMjgHdW5pRTAyOQd1bmlFMDMwB3VuaUUwMzEHdW5pRTAzMgd1bmlFMDMzB3VuaUUwMzQHdW5pRTAzNQd1bmlFMDM2B3VuaUUwMzcHdW5pRTAzOAd1bmlFMDM5B3VuaUUwNDAHdW5pRTA0MQd1bmlFMDQyB3VuaUUwNDMHdW5pRTA0NAd1bmlFMDQ1B3VuaUUwNDYHdW5pRTA0Nwd1bmlFMDQ4B3VuaUUwNDkHdW5pRTA1MAd1bmlFMDUxB3VuaUUwNTIHdW5pRTA1Mwd1bmlFMDU0B3VuaUUwNTUHdW5pRTA1Ngd1bmlFMDU3B3VuaUUwNTgHdW5pRTA1OQd1bmlFMDYwB3VuaUUwNjIHdW5pRTA2Mwd1bmlFMDY0B3VuaUUwNjUHdW5pRTA2Ngd1bmlFMDY3B3VuaUUwNjgHdW5pRTA2OQd1bmlFMDcwB3VuaUUwNzEHdW5pRTA3Mgd1bmlFMDczB3VuaUUwNzQHdW5pRTA3NQd1bmlFMDc2B3VuaUUwNzcHdW5pRTA3OAd1bmlFMDc5B3VuaUUwODAHdW5pRTA4MQd1bmlFMDgyB3VuaUUwODMHdW5pRTA4NAd1bmlFMDg1B3VuaUUwODYHdW5pRTA4Nwd1bmlFMDg4B3VuaUUwODkHdW5pRTA5MAd1bmlFMDkxB3VuaUUwOTIHdW5pRTA5Mwd1bmlFMDk0B3VuaUUwOTUHdW5pRTA5Ngd1bmlFMDk3B3VuaUUxMDEHdW5pRTEwMgd1bmlFMTAzB3VuaUUxMDQHdW5pRTEwNQd1bmlFMTA2B3VuaUUxMDcHdW5pRTEwOAd1bmlFMTA5B3VuaUUxMTAHdW5pRTExMQd1bmlFMTEyB3VuaUUxMTMHdW5pRTExNAd1bmlFMTE1B3VuaUUxMTYHdW5pRTExNwd1bmlFMTE4B3VuaUUxMTkHdW5pRTEyMAd1bmlFMTIxB3VuaUUxMjIHdW5pRTEyMwd1bmlFMTI0B3VuaUUxMjUHdW5pRTEyNgd1bmlFMTI3B3VuaUUxMjgHdW5pRTEyOQd1bmlFMTMwB3VuaUUxMzEHdW5pRTEzMgd1bmlFMTMzB3VuaUUxMzQHdW5pRTEzNQd1bmlFMTM2B3VuaUUxMzcHdW5pRTEzOAd1bmlFMTM5B3VuaUUxNDAHdW5pRTE0MQd1bmlFMTQyB3VuaUUxNDMHdW5pRTE0NAd1bmlFMTQ1B3VuaUUxNDYHdW5pRTE0OAd1bmlFMTQ5B3VuaUUxNTAHdW5pRTE1MQd1bmlFMTUyB3VuaUUxNTMHdW5pRTE1NAd1bmlFMTU1B3VuaUUxNTYHdW5pRTE1Nwd1bmlFMTU4B3VuaUUxNTkHdW5pRTE2MAd1bmlFMTYxB3VuaUUxNjIHdW5pRTE2Mwd1bmlFMTY0B3VuaUUxNjUHdW5pRTE2Ngd1bmlFMTY3B3VuaUUxNjgHdW5pRTE2OQd1bmlFMTcwB3VuaUUxNzEHdW5pRTE3Mgd1bmlFMTczB3VuaUUxNzQHdW5pRTE3NQd1bmlFMTc2B3VuaUUxNzcHdW5pRTE3OAd1bmlFMTc5B3VuaUUxODAHdW5pRTE4MQd1bmlFMTgyB3VuaUUxODMHdW5pRTE4NAd1bmlFMTg1B3VuaUUxODYHdW5pRTE4Nwd1bmlFMTg4B3VuaUUxODkHdW5pRTE5MAd1bmlFMTkxB3VuaUUxOTIHdW5pRTE5Mwd1bmlFMTk0B3VuaUUxOTUHdW5pRTE5Nwd1bmlFMTk4B3VuaUUxOTkHdW5pRTIwMAd1bmlFMjAxB3VuaUUyMDIHdW5pRTIwMwd1bmlFMjA0B3VuaUUyMDUHdW5pRTIwNgd1bmlFMjA5B3VuaUUyMTAHdW5pRTIxMQd1bmlFMjEyB3VuaUUyMTMHdW5pRTIxNAd1bmlFMjE1B3VuaUUyMTYHdW5pRTIxOAd1bmlFMjE5B3VuaUUyMjEHdW5pRTIyMwd1bmlFMjI0B3VuaUUyMjUHdW5pRTIyNgd1bmlFMjI3B3VuaUUyMzAHdW5pRTIzMQd1bmlFMjMyB3VuaUUyMzMHdW5pRTIzNAd1bmlFMjM1B3VuaUUyMzYHdW5pRTIzNwd1bmlFMjM4B3VuaUUyMzkHdW5pRTI0MAd1bmlFMjQxB3VuaUUyNDIHdW5pRTI0Mwd1bmlFMjQ0B3VuaUUyNDUHdW5pRTI0Ngd1bmlFMjQ3B3VuaUUyNDgHdW5pRTI0OQd1bmlFMjUwB3VuaUUyNTEHdW5pRTI1Mgd1bmlFMjUzB3VuaUUyNTQHdW5pRTI1NQd1bmlFMjU2B3VuaUUyNTcHdW5pRTI1OAd1bmlFMjU5B3VuaUUyNjAHdW5pRjhGRgZ1MUY1MTEGdTFGNkFBAAAAAAFUUMMXAAA=) format(&#39;truetype&#39;),url(data:image/svg+xml;base64,<?xml version="1.0" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd" >
<svg xmlns="http://www.w3.org/2000/svg">
<metadata></metadata>
<defs>
<font id="glyphicons_halflingsregular" horiz-adv-x="1200" >
<font-face units-per-em="1200" ascent="960" descent="-240" />
<missing-glyph horiz-adv-x="500" />
<glyph horiz-adv-x="0" />
<glyph horiz-adv-x="400" />
<glyph unicode=" " />
<glyph unicode="*" d="M600 1100q15 0 34 -1.5t30 -3.5l11 -1q10 -2 17.5 -10.5t7.5 -18.5v-224l158 158q7 7 18 8t19 -6l106 -106q7 -8 6 -19t-8 -18l-158 -158h224q10 0 18.5 -7.5t10.5 -17.5q6 -41 6 -75q0 -15 -1.5 -34t-3.5 -30l-1 -11q-2 -10 -10.5 -17.5t-18.5 -7.5h-224l158 -158 q7 -7 8 -18t-6 -19l-106 -106q-8 -7 -19 -6t-18 8l-158 158v-224q0 -10 -7.5 -18.5t-17.5 -10.5q-41 -6 -75 -6q-15 0 -34 1.5t-30 3.5l-11 1q-10 2 -17.5 10.5t-7.5 18.5v224l-158 -158q-7 -7 -18 -8t-19 6l-106 106q-7 8 -6 19t8 18l158 158h-224q-10 0 -18.5 7.5 t-10.5 17.5q-6 41 -6 75q0 15 1.5 34t3.5 30l1 11q2 10 10.5 17.5t18.5 7.5h224l-158 158q-7 7 -8 18t6 19l106 106q8 7 19 6t18 -8l158 -158v224q0 10 7.5 18.5t17.5 10.5q41 6 75 6z" />
<glyph unicode="+" d="M450 1100h200q21 0 35.5 -14.5t14.5 -35.5v-350h350q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-350v-350q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v350h-350q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5 h350v350q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xa0;" />
<glyph unicode="&#xa5;" d="M825 1100h250q10 0 12.5 -5t-5.5 -13l-364 -364q-6 -6 -11 -18h268q10 0 13 -6t-3 -14l-120 -160q-6 -8 -18 -14t-22 -6h-125v-100h275q10 0 13 -6t-3 -14l-120 -160q-6 -8 -18 -14t-22 -6h-125v-174q0 -11 -7.5 -18.5t-18.5 -7.5h-148q-11 0 -18.5 7.5t-7.5 18.5v174 h-275q-10 0 -13 6t3 14l120 160q6 8 18 14t22 6h125v100h-275q-10 0 -13 6t3 14l120 160q6 8 18 14t22 6h118q-5 12 -11 18l-364 364q-8 8 -5.5 13t12.5 5h250q25 0 43 -18l164 -164q8 -8 18 -8t18 8l164 164q18 18 43 18z" />
<glyph unicode="&#x2000;" horiz-adv-x="650" />
<glyph unicode="&#x2001;" horiz-adv-x="1300" />
<glyph unicode="&#x2002;" horiz-adv-x="650" />
<glyph unicode="&#x2003;" horiz-adv-x="1300" />
<glyph unicode="&#x2004;" horiz-adv-x="433" />
<glyph unicode="&#x2005;" horiz-adv-x="325" />
<glyph unicode="&#x2006;" horiz-adv-x="216" />
<glyph unicode="&#x2007;" horiz-adv-x="216" />
<glyph unicode="&#x2008;" horiz-adv-x="162" />
<glyph unicode="&#x2009;" horiz-adv-x="260" />
<glyph unicode="&#x200a;" horiz-adv-x="72" />
<glyph unicode="&#x202f;" horiz-adv-x="260" />
<glyph unicode="&#x205f;" horiz-adv-x="325" />
<glyph unicode="&#x20ac;" d="M744 1198q242 0 354 -189q60 -104 66 -209h-181q0 45 -17.5 82.5t-43.5 61.5t-58 40.5t-60.5 24t-51.5 7.5q-19 0 -40.5 -5.5t-49.5 -20.5t-53 -38t-49 -62.5t-39 -89.5h379l-100 -100h-300q-6 -50 -6 -100h406l-100 -100h-300q9 -74 33 -132t52.5 -91t61.5 -54.5t59 -29 t47 -7.5q22 0 50.5 7.5t60.5 24.5t58 41t43.5 61t17.5 80h174q-30 -171 -128 -278q-107 -117 -274 -117q-206 0 -324 158q-36 48 -69 133t-45 204h-217l100 100h112q1 47 6 100h-218l100 100h134q20 87 51 153.5t62 103.5q117 141 297 141z" />
<glyph unicode="&#x20bd;" d="M428 1200h350q67 0 120 -13t86 -31t57 -49.5t35 -56.5t17 -64.5t6.5 -60.5t0.5 -57v-16.5v-16.5q0 -36 -0.5 -57t-6.5 -61t-17 -65t-35 -57t-57 -50.5t-86 -31.5t-120 -13h-178l-2 -100h288q10 0 13 -6t-3 -14l-120 -160q-6 -8 -18 -14t-22 -6h-138v-175q0 -11 -5.5 -18 t-15.5 -7h-149q-10 0 -17.5 7.5t-7.5 17.5v175h-267q-10 0 -13 6t3 14l120 160q6 8 18 14t22 6h117v100h-267q-10 0 -13 6t3 14l120 160q6 8 18 14t22 6h117v475q0 10 7.5 17.5t17.5 7.5zM600 1000v-300h203q64 0 86.5 33t22.5 119q0 84 -22.5 116t-86.5 32h-203z" />
<glyph unicode="&#x2212;" d="M250 700h800q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#x231b;" d="M1000 1200v-150q0 -21 -14.5 -35.5t-35.5 -14.5h-50v-100q0 -91 -49.5 -165.5t-130.5 -109.5q81 -35 130.5 -109.5t49.5 -165.5v-150h50q21 0 35.5 -14.5t14.5 -35.5v-150h-800v150q0 21 14.5 35.5t35.5 14.5h50v150q0 91 49.5 165.5t130.5 109.5q-81 35 -130.5 109.5 t-49.5 165.5v100h-50q-21 0 -35.5 14.5t-14.5 35.5v150h800zM400 1000v-100q0 -60 32.5 -109.5t87.5 -73.5q28 -12 44 -37t16 -55t-16 -55t-44 -37q-55 -24 -87.5 -73.5t-32.5 -109.5v-150h400v150q0 60 -32.5 109.5t-87.5 73.5q-28 12 -44 37t-16 55t16 55t44 37 q55 24 87.5 73.5t32.5 109.5v100h-400z" />
<glyph unicode="&#x25fc;" horiz-adv-x="500" d="M0 0z" />
<glyph unicode="&#x2601;" d="M503 1089q110 0 200.5 -59.5t134.5 -156.5q44 14 90 14q120 0 205 -86.5t85 -206.5q0 -121 -85 -207.5t-205 -86.5h-750q-79 0 -135.5 57t-56.5 137q0 69 42.5 122.5t108.5 67.5q-2 12 -2 37q0 153 108 260.5t260 107.5z" />
<glyph unicode="&#x26fa;" d="M774 1193.5q16 -9.5 20.5 -27t-5.5 -33.5l-136 -187l467 -746h30q20 0 35 -18.5t15 -39.5v-42h-1200v42q0 21 15 39.5t35 18.5h30l468 746l-135 183q-10 16 -5.5 34t20.5 28t34 5.5t28 -20.5l111 -148l112 150q9 16 27 20.5t34 -5zM600 200h377l-182 112l-195 534v-646z " />
<glyph unicode="&#x2709;" d="M25 1100h1150q10 0 12.5 -5t-5.5 -13l-564 -567q-8 -8 -18 -8t-18 8l-564 567q-8 8 -5.5 13t12.5 5zM18 882l264 -264q8 -8 8 -18t-8 -18l-264 -264q-8 -8 -13 -5.5t-5 12.5v550q0 10 5 12.5t13 -5.5zM918 618l264 264q8 8 13 5.5t5 -12.5v-550q0 -10 -5 -12.5t-13 5.5 l-264 264q-8 8 -8 18t8 18zM818 482l364 -364q8 -8 5.5 -13t-12.5 -5h-1150q-10 0 -12.5 5t5.5 13l364 364q8 8 18 8t18 -8l164 -164q8 -8 18 -8t18 8l164 164q8 8 18 8t18 -8z" />
<glyph unicode="&#x270f;" d="M1011 1210q19 0 33 -13l153 -153q13 -14 13 -33t-13 -33l-99 -92l-214 214l95 96q13 14 32 14zM1013 800l-615 -614l-214 214l614 614zM317 96l-333 -112l110 335z" />
<glyph unicode="&#xe001;" d="M700 650v-550h250q21 0 35.5 -14.5t14.5 -35.5v-50h-800v50q0 21 14.5 35.5t35.5 14.5h250v550l-500 550h1200z" />
<glyph unicode="&#xe002;" d="M368 1017l645 163q39 15 63 0t24 -49v-831q0 -55 -41.5 -95.5t-111.5 -63.5q-79 -25 -147 -4.5t-86 75t25.5 111.5t122.5 82q72 24 138 8v521l-600 -155v-606q0 -42 -44 -90t-109 -69q-79 -26 -147 -5.5t-86 75.5t25.5 111.5t122.5 82.5q72 24 138 7v639q0 38 14.5 59 t53.5 34z" />
<glyph unicode="&#xe003;" d="M500 1191q100 0 191 -39t156.5 -104.5t104.5 -156.5t39 -191l-1 -2l1 -5q0 -141 -78 -262l275 -274q23 -26 22.5 -44.5t-22.5 -42.5l-59 -58q-26 -20 -46.5 -20t-39.5 20l-275 274q-119 -77 -261 -77l-5 1l-2 -1q-100 0 -191 39t-156.5 104.5t-104.5 156.5t-39 191 t39 191t104.5 156.5t156.5 104.5t191 39zM500 1022q-88 0 -162 -43t-117 -117t-43 -162t43 -162t117 -117t162 -43t162 43t117 117t43 162t-43 162t-117 117t-162 43z" />
<glyph unicode="&#xe005;" d="M649 949q48 68 109.5 104t121.5 38.5t118.5 -20t102.5 -64t71 -100.5t27 -123q0 -57 -33.5 -117.5t-94 -124.5t-126.5 -127.5t-150 -152.5t-146 -174q-62 85 -145.5 174t-150 152.5t-126.5 127.5t-93.5 124.5t-33.5 117.5q0 64 28 123t73 100.5t104 64t119 20 t120.5 -38.5t104.5 -104z" />
<glyph unicode="&#xe006;" d="M407 800l131 353q7 19 17.5 19t17.5 -19l129 -353h421q21 0 24 -8.5t-14 -20.5l-342 -249l130 -401q7 -20 -0.5 -25.5t-24.5 6.5l-343 246l-342 -247q-17 -12 -24.5 -6.5t-0.5 25.5l130 400l-347 251q-17 12 -14 20.5t23 8.5h429z" />
<glyph unicode="&#xe007;" d="M407 800l131 353q7 19 17.5 19t17.5 -19l129 -353h421q21 0 24 -8.5t-14 -20.5l-342 -249l130 -401q7 -20 -0.5 -25.5t-24.5 6.5l-343 246l-342 -247q-17 -12 -24.5 -6.5t-0.5 25.5l130 400l-347 251q-17 12 -14 20.5t23 8.5h429zM477 700h-240l197 -142l-74 -226 l193 139l195 -140l-74 229l192 140h-234l-78 211z" />
<glyph unicode="&#xe008;" d="M600 1200q124 0 212 -88t88 -212v-250q0 -46 -31 -98t-69 -52v-75q0 -10 6 -21.5t15 -17.5l358 -230q9 -5 15 -16.5t6 -21.5v-93q0 -10 -7.5 -17.5t-17.5 -7.5h-1150q-10 0 -17.5 7.5t-7.5 17.5v93q0 10 6 21.5t15 16.5l358 230q9 6 15 17.5t6 21.5v75q-38 0 -69 52 t-31 98v250q0 124 88 212t212 88z" />
<glyph unicode="&#xe009;" d="M25 1100h1150q10 0 17.5 -7.5t7.5 -17.5v-1050q0 -10 -7.5 -17.5t-17.5 -7.5h-1150q-10 0 -17.5 7.5t-7.5 17.5v1050q0 10 7.5 17.5t17.5 7.5zM100 1000v-100h100v100h-100zM875 1000h-550q-10 0 -17.5 -7.5t-7.5 -17.5v-350q0 -10 7.5 -17.5t17.5 -7.5h550 q10 0 17.5 7.5t7.5 17.5v350q0 10 -7.5 17.5t-17.5 7.5zM1000 1000v-100h100v100h-100zM100 800v-100h100v100h-100zM1000 800v-100h100v100h-100zM100 600v-100h100v100h-100zM1000 600v-100h100v100h-100zM875 500h-550q-10 0 -17.5 -7.5t-7.5 -17.5v-350q0 -10 7.5 -17.5 t17.5 -7.5h550q10 0 17.5 7.5t7.5 17.5v350q0 10 -7.5 17.5t-17.5 7.5zM100 400v-100h100v100h-100zM1000 400v-100h100v100h-100zM100 200v-100h100v100h-100zM1000 200v-100h100v100h-100z" />
<glyph unicode="&#xe010;" d="M50 1100h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5zM650 1100h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v400 q0 21 14.5 35.5t35.5 14.5zM50 500h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5zM650 500h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400 q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe011;" d="M50 1100h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM450 1100h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200 q0 21 14.5 35.5t35.5 14.5zM850 1100h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM50 700h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200 q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM450 700h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM850 700h200q21 0 35.5 -14.5t14.5 -35.5v-200 q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM50 300h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM450 300h200 q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM850 300h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5 t35.5 14.5z" />
<glyph unicode="&#xe012;" d="M50 1100h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM450 1100h700q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-700q-21 0 -35.5 14.5t-14.5 35.5v200 q0 21 14.5 35.5t35.5 14.5zM50 700h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM450 700h700q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-700 q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM50 300h200q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5zM450 300h700q21 0 35.5 -14.5t14.5 -35.5v-200 q0 -21 -14.5 -35.5t-35.5 -14.5h-700q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe013;" d="M465 477l571 571q8 8 18 8t17 -8l177 -177q8 -7 8 -17t-8 -18l-783 -784q-7 -8 -17.5 -8t-17.5 8l-384 384q-8 8 -8 18t8 17l177 177q7 8 17 8t18 -8l171 -171q7 -7 18 -7t18 7z" />
<glyph unicode="&#xe014;" d="M904 1083l178 -179q8 -8 8 -18.5t-8 -17.5l-267 -268l267 -268q8 -7 8 -17.5t-8 -18.5l-178 -178q-8 -8 -18.5 -8t-17.5 8l-268 267l-268 -267q-7 -8 -17.5 -8t-18.5 8l-178 178q-8 8 -8 18.5t8 17.5l267 268l-267 268q-8 7 -8 17.5t8 18.5l178 178q8 8 18.5 8t17.5 -8 l268 -267l268 268q7 7 17.5 7t18.5 -7z" />
<glyph unicode="&#xe015;" d="M507 1177q98 0 187.5 -38.5t154.5 -103.5t103.5 -154.5t38.5 -187.5q0 -141 -78 -262l300 -299q8 -8 8 -18.5t-8 -18.5l-109 -108q-7 -8 -17.5 -8t-18.5 8l-300 299q-119 -77 -261 -77q-98 0 -188 38.5t-154.5 103t-103 154.5t-38.5 188t38.5 187.5t103 154.5 t154.5 103.5t188 38.5zM506.5 1023q-89.5 0 -165.5 -44t-120 -120.5t-44 -166t44 -165.5t120 -120t165.5 -44t166 44t120.5 120t44 165.5t-44 166t-120.5 120.5t-166 44zM425 900h150q10 0 17.5 -7.5t7.5 -17.5v-75h75q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5 t-17.5 -7.5h-75v-75q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v75h-75q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5h75v75q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe016;" d="M507 1177q98 0 187.5 -38.5t154.5 -103.5t103.5 -154.5t38.5 -187.5q0 -141 -78 -262l300 -299q8 -8 8 -18.5t-8 -18.5l-109 -108q-7 -8 -17.5 -8t-18.5 8l-300 299q-119 -77 -261 -77q-98 0 -188 38.5t-154.5 103t-103 154.5t-38.5 188t38.5 187.5t103 154.5 t154.5 103.5t188 38.5zM506.5 1023q-89.5 0 -165.5 -44t-120 -120.5t-44 -166t44 -165.5t120 -120t165.5 -44t166 44t120.5 120t44 165.5t-44 166t-120.5 120.5t-166 44zM325 800h350q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-350q-10 0 -17.5 7.5 t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe017;" d="M550 1200h100q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5zM800 975v166q167 -62 272 -209.5t105 -331.5q0 -117 -45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5 t-184.5 123t-123 184.5t-45.5 224q0 184 105 331.5t272 209.5v-166q-103 -55 -165 -155t-62 -220q0 -116 57 -214.5t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5q0 120 -62 220t-165 155z" />
<glyph unicode="&#xe018;" d="M1025 1200h150q10 0 17.5 -7.5t7.5 -17.5v-1150q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v1150q0 10 7.5 17.5t17.5 7.5zM725 800h150q10 0 17.5 -7.5t7.5 -17.5v-750q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v750 q0 10 7.5 17.5t17.5 7.5zM425 500h150q10 0 17.5 -7.5t7.5 -17.5v-450q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v450q0 10 7.5 17.5t17.5 7.5zM125 300h150q10 0 17.5 -7.5t7.5 -17.5v-250q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5 v250q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe019;" d="M600 1174q33 0 74 -5l38 -152l5 -1q49 -14 94 -39l5 -2l134 80q61 -48 104 -105l-80 -134l3 -5q25 -44 39 -93l1 -6l152 -38q5 -43 5 -73q0 -34 -5 -74l-152 -38l-1 -6q-15 -49 -39 -93l-3 -5l80 -134q-48 -61 -104 -105l-134 81l-5 -3q-44 -25 -94 -39l-5 -2l-38 -151 q-43 -5 -74 -5q-33 0 -74 5l-38 151l-5 2q-49 14 -94 39l-5 3l-134 -81q-60 48 -104 105l80 134l-3 5q-25 45 -38 93l-2 6l-151 38q-6 42 -6 74q0 33 6 73l151 38l2 6q13 48 38 93l3 5l-80 134q47 61 105 105l133 -80l5 2q45 25 94 39l5 1l38 152q43 5 74 5zM600 815 q-89 0 -152 -63t-63 -151.5t63 -151.5t152 -63t152 63t63 151.5t-63 151.5t-152 63z" />
<glyph unicode="&#xe020;" d="M500 1300h300q41 0 70.5 -29.5t29.5 -70.5v-100h275q10 0 17.5 -7.5t7.5 -17.5v-75h-1100v75q0 10 7.5 17.5t17.5 7.5h275v100q0 41 29.5 70.5t70.5 29.5zM500 1200v-100h300v100h-300zM1100 900v-800q0 -41 -29.5 -70.5t-70.5 -29.5h-700q-41 0 -70.5 29.5t-29.5 70.5 v800h900zM300 800v-700h100v700h-100zM500 800v-700h100v700h-100zM700 800v-700h100v700h-100zM900 800v-700h100v700h-100z" />
<glyph unicode="&#xe021;" d="M18 618l620 608q8 7 18.5 7t17.5 -7l608 -608q8 -8 5.5 -13t-12.5 -5h-175v-575q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v375h-300v-375q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v575h-175q-10 0 -12.5 5t5.5 13z" />
<glyph unicode="&#xe022;" d="M600 1200v-400q0 -41 29.5 -70.5t70.5 -29.5h300v-650q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5v1100q0 21 14.5 35.5t35.5 14.5h450zM1000 800h-250q-21 0 -35.5 14.5t-14.5 35.5v250z" />
<glyph unicode="&#xe023;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 1027q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5 t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5t-57 214.5t-155.5 155.5t-214.5 57zM525 900h50q10 0 17.5 -7.5t7.5 -17.5v-275h175q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v350q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe024;" d="M1300 0h-538l-41 400h-242l-41 -400h-538l431 1200h209l-21 -300h162l-20 300h208zM515 800l-27 -300h224l-27 300h-170z" />
<glyph unicode="&#xe025;" d="M550 1200h200q21 0 35.5 -14.5t14.5 -35.5v-450h191q20 0 25.5 -11.5t-7.5 -27.5l-327 -400q-13 -16 -32 -16t-32 16l-327 400q-13 16 -7.5 27.5t25.5 11.5h191v450q0 21 14.5 35.5t35.5 14.5zM1125 400h50q10 0 17.5 -7.5t7.5 -17.5v-350q0 -10 -7.5 -17.5t-17.5 -7.5 h-1050q-10 0 -17.5 7.5t-7.5 17.5v350q0 10 7.5 17.5t17.5 7.5h50q10 0 17.5 -7.5t7.5 -17.5v-175h900v175q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe026;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 1027q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5 t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5t-57 214.5t-155.5 155.5t-214.5 57zM525 900h150q10 0 17.5 -7.5t7.5 -17.5v-275h137q21 0 26 -11.5t-8 -27.5l-223 -275q-13 -16 -32 -16t-32 16l-223 275q-13 16 -8 27.5t26 11.5h137v275q0 10 7.5 17.5t17.5 7.5z " />
<glyph unicode="&#xe027;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 1027q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5 t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5t-57 214.5t-155.5 155.5t-214.5 57zM632 914l223 -275q13 -16 8 -27.5t-26 -11.5h-137v-275q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v275h-137q-21 0 -26 11.5t8 27.5l223 275q13 16 32 16 t32 -16z" />
<glyph unicode="&#xe028;" d="M225 1200h750q10 0 19.5 -7t12.5 -17l186 -652q7 -24 7 -49v-425q0 -12 -4 -27t-9 -17q-12 -6 -37 -6h-1100q-12 0 -27 4t-17 8q-6 13 -6 38l1 425q0 25 7 49l185 652q3 10 12.5 17t19.5 7zM878 1000h-556q-10 0 -19 -7t-11 -18l-87 -450q-2 -11 4 -18t16 -7h150 q10 0 19.5 -7t11.5 -17l38 -152q2 -10 11.5 -17t19.5 -7h250q10 0 19.5 7t11.5 17l38 152q2 10 11.5 17t19.5 7h150q10 0 16 7t4 18l-87 450q-2 11 -11 18t-19 7z" />
<glyph unicode="&#xe029;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 1027q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5 t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5t-57 214.5t-155.5 155.5t-214.5 57zM540 820l253 -190q17 -12 17 -30t-17 -30l-253 -190q-16 -12 -28 -6.5t-12 26.5v400q0 21 12 26.5t28 -6.5z" />
<glyph unicode="&#xe030;" d="M947 1060l135 135q7 7 12.5 5t5.5 -13v-362q0 -10 -7.5 -17.5t-17.5 -7.5h-362q-11 0 -13 5.5t5 12.5l133 133q-109 76 -238 76q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5h150q0 -117 -45.5 -224 t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5q192 0 347 -117z" />
<glyph unicode="&#xe031;" d="M947 1060l135 135q7 7 12.5 5t5.5 -13v-361q0 -11 -7.5 -18.5t-18.5 -7.5h-361q-11 0 -13 5.5t5 12.5l134 134q-110 75 -239 75q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5h-150q0 117 45.5 224t123 184.5t184.5 123t224 45.5q192 0 347 -117zM1027 600h150 q0 -117 -45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5q-192 0 -348 118l-134 -134q-7 -8 -12.5 -5.5t-5.5 12.5v360q0 11 7.5 18.5t18.5 7.5h360q10 0 12.5 -5.5t-5.5 -12.5l-133 -133q110 -76 240 -76q116 0 214.5 57t155.5 155.5t57 214.5z" />
<glyph unicode="&#xe032;" d="M125 1200h1050q10 0 17.5 -7.5t7.5 -17.5v-1150q0 -10 -7.5 -17.5t-17.5 -7.5h-1050q-10 0 -17.5 7.5t-7.5 17.5v1150q0 10 7.5 17.5t17.5 7.5zM1075 1000h-850q-10 0 -17.5 -7.5t-7.5 -17.5v-850q0 -10 7.5 -17.5t17.5 -7.5h850q10 0 17.5 7.5t7.5 17.5v850 q0 10 -7.5 17.5t-17.5 7.5zM325 900h50q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-50q-10 0 -17.5 7.5t-7.5 17.5v50q0 10 7.5 17.5t17.5 7.5zM525 900h450q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-450q-10 0 -17.5 7.5t-7.5 17.5v50 q0 10 7.5 17.5t17.5 7.5zM325 700h50q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-50q-10 0 -17.5 7.5t-7.5 17.5v50q0 10 7.5 17.5t17.5 7.5zM525 700h450q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-450q-10 0 -17.5 7.5t-7.5 17.5v50 q0 10 7.5 17.5t17.5 7.5zM325 500h50q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-50q-10 0 -17.5 7.5t-7.5 17.5v50q0 10 7.5 17.5t17.5 7.5zM525 500h450q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-450q-10 0 -17.5 7.5t-7.5 17.5v50 q0 10 7.5 17.5t17.5 7.5zM325 300h50q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-50q-10 0 -17.5 7.5t-7.5 17.5v50q0 10 7.5 17.5t17.5 7.5zM525 300h450q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-450q-10 0 -17.5 7.5t-7.5 17.5v50 q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe033;" d="M900 800v200q0 83 -58.5 141.5t-141.5 58.5h-300q-82 0 -141 -59t-59 -141v-200h-100q-41 0 -70.5 -29.5t-29.5 -70.5v-600q0 -41 29.5 -70.5t70.5 -29.5h900q41 0 70.5 29.5t29.5 70.5v600q0 41 -29.5 70.5t-70.5 29.5h-100zM400 800v150q0 21 15 35.5t35 14.5h200 q20 0 35 -14.5t15 -35.5v-150h-300z" />
<glyph unicode="&#xe034;" d="M125 1100h50q10 0 17.5 -7.5t7.5 -17.5v-1075h-100v1075q0 10 7.5 17.5t17.5 7.5zM1075 1052q4 0 9 -2q16 -6 16 -23v-421q0 -6 -3 -12q-33 -59 -66.5 -99t-65.5 -58t-56.5 -24.5t-52.5 -6.5q-26 0 -57.5 6.5t-52.5 13.5t-60 21q-41 15 -63 22.5t-57.5 15t-65.5 7.5 q-85 0 -160 -57q-7 -5 -15 -5q-6 0 -11 3q-14 7 -14 22v438q22 55 82 98.5t119 46.5q23 2 43 0.5t43 -7t32.5 -8.5t38 -13t32.5 -11q41 -14 63.5 -21t57 -14t63.5 -7q103 0 183 87q7 8 18 8z" />
<glyph unicode="&#xe035;" d="M600 1175q116 0 227 -49.5t192.5 -131t131 -192.5t49.5 -227v-300q0 -10 -7.5 -17.5t-17.5 -7.5h-50q-10 0 -17.5 7.5t-7.5 17.5v300q0 127 -70.5 231.5t-184.5 161.5t-245 57t-245 -57t-184.5 -161.5t-70.5 -231.5v-300q0 -10 -7.5 -17.5t-17.5 -7.5h-50 q-10 0 -17.5 7.5t-7.5 17.5v300q0 116 49.5 227t131 192.5t192.5 131t227 49.5zM220 500h160q8 0 14 -6t6 -14v-460q0 -8 -6 -14t-14 -6h-160q-8 0 -14 6t-6 14v460q0 8 6 14t14 6zM820 500h160q8 0 14 -6t6 -14v-460q0 -8 -6 -14t-14 -6h-160q-8 0 -14 6t-6 14v460 q0 8 6 14t14 6z" />
<glyph unicode="&#xe036;" d="M321 814l258 172q9 6 15 2.5t6 -13.5v-750q0 -10 -6 -13.5t-15 2.5l-258 172q-21 14 -46 14h-250q-10 0 -17.5 7.5t-7.5 17.5v350q0 10 7.5 17.5t17.5 7.5h250q25 0 46 14zM900 668l120 120q7 7 17 7t17 -7l34 -34q7 -7 7 -17t-7 -17l-120 -120l120 -120q7 -7 7 -17 t-7 -17l-34 -34q-7 -7 -17 -7t-17 7l-120 119l-120 -119q-7 -7 -17 -7t-17 7l-34 34q-7 7 -7 17t7 17l119 120l-119 120q-7 7 -7 17t7 17l34 34q7 8 17 8t17 -8z" />
<glyph unicode="&#xe037;" d="M321 814l258 172q9 6 15 2.5t6 -13.5v-750q0 -10 -6 -13.5t-15 2.5l-258 172q-21 14 -46 14h-250q-10 0 -17.5 7.5t-7.5 17.5v350q0 10 7.5 17.5t17.5 7.5h250q25 0 46 14zM766 900h4q10 -1 16 -10q96 -129 96 -290q0 -154 -90 -281q-6 -9 -17 -10l-3 -1q-9 0 -16 6 l-29 23q-7 7 -8.5 16.5t4.5 17.5q72 103 72 229q0 132 -78 238q-6 8 -4.5 18t9.5 17l29 22q7 5 15 5z" />
<glyph unicode="&#xe038;" d="M967 1004h3q11 -1 17 -10q135 -179 135 -396q0 -105 -34 -206.5t-98 -185.5q-7 -9 -17 -10h-3q-9 0 -16 6l-42 34q-8 6 -9 16t5 18q111 150 111 328q0 90 -29.5 176t-84.5 157q-6 9 -5 19t10 16l42 33q7 5 15 5zM321 814l258 172q9 6 15 2.5t6 -13.5v-750q0 -10 -6 -13.5 t-15 2.5l-258 172q-21 14 -46 14h-250q-10 0 -17.5 7.5t-7.5 17.5v350q0 10 7.5 17.5t17.5 7.5h250q25 0 46 14zM766 900h4q10 -1 16 -10q96 -129 96 -290q0 -154 -90 -281q-6 -9 -17 -10l-3 -1q-9 0 -16 6l-29 23q-7 7 -8.5 16.5t4.5 17.5q72 103 72 229q0 132 -78 238 q-6 8 -4.5 18.5t9.5 16.5l29 22q7 5 15 5z" />
<glyph unicode="&#xe039;" d="M500 900h100v-100h-100v-100h-400v-100h-100v600h500v-300zM1200 700h-200v-100h200v-200h-300v300h-200v300h-100v200h600v-500zM100 1100v-300h300v300h-300zM800 1100v-300h300v300h-300zM300 900h-100v100h100v-100zM1000 900h-100v100h100v-100zM300 500h200v-500 h-500v500h200v100h100v-100zM800 300h200v-100h-100v-100h-200v100h-100v100h100v200h-200v100h300v-300zM100 400v-300h300v300h-300zM300 200h-100v100h100v-100zM1200 200h-100v100h100v-100zM700 0h-100v100h100v-100zM1200 0h-300v100h300v-100z" />
<glyph unicode="&#xe040;" d="M100 200h-100v1000h100v-1000zM300 200h-100v1000h100v-1000zM700 200h-200v1000h200v-1000zM900 200h-100v1000h100v-1000zM1200 200h-200v1000h200v-1000zM400 0h-300v100h300v-100zM600 0h-100v91h100v-91zM800 0h-100v91h100v-91zM1100 0h-200v91h200v-91z" />
<glyph unicode="&#xe041;" d="M500 1200l682 -682q8 -8 8 -18t-8 -18l-464 -464q-8 -8 -18 -8t-18 8l-682 682l1 475q0 10 7.5 17.5t17.5 7.5h474zM319.5 1024.5q-29.5 29.5 -71 29.5t-71 -29.5t-29.5 -71.5t29.5 -71.5t71 -29.5t71 29.5t29.5 71.5t-29.5 71.5z" />
<glyph unicode="&#xe042;" d="M500 1200l682 -682q8 -8 8 -18t-8 -18l-464 -464q-8 -8 -18 -8t-18 8l-682 682l1 475q0 10 7.5 17.5t17.5 7.5h474zM800 1200l682 -682q8 -8 8 -18t-8 -18l-464 -464q-8 -8 -18 -8t-18 8l-56 56l424 426l-700 700h150zM319.5 1024.5q-29.5 29.5 -71 29.5t-71 -29.5 t-29.5 -71.5t29.5 -71.5t71 -29.5t71 29.5t29.5 71.5t-29.5 71.5z" />
<glyph unicode="&#xe043;" d="M300 1200h825q75 0 75 -75v-900q0 -25 -18 -43l-64 -64q-8 -8 -13 -5.5t-5 12.5v950q0 10 -7.5 17.5t-17.5 7.5h-700q-25 0 -43 -18l-64 -64q-8 -8 -5.5 -13t12.5 -5h700q10 0 17.5 -7.5t7.5 -17.5v-950q0 -10 -7.5 -17.5t-17.5 -7.5h-850q-10 0 -17.5 7.5t-7.5 17.5v975 q0 25 18 43l139 139q18 18 43 18z" />
<glyph unicode="&#xe044;" d="M250 1200h800q21 0 35.5 -14.5t14.5 -35.5v-1150l-450 444l-450 -445v1151q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe045;" d="M822 1200h-444q-11 0 -19 -7.5t-9 -17.5l-78 -301q-7 -24 7 -45l57 -108q6 -9 17.5 -15t21.5 -6h450q10 0 21.5 6t17.5 15l62 108q14 21 7 45l-83 301q-1 10 -9 17.5t-19 7.5zM1175 800h-150q-10 0 -21 -6.5t-15 -15.5l-78 -156q-4 -9 -15 -15.5t-21 -6.5h-550 q-10 0 -21 6.5t-15 15.5l-78 156q-4 9 -15 15.5t-21 6.5h-150q-10 0 -17.5 -7.5t-7.5 -17.5v-650q0 -10 7.5 -17.5t17.5 -7.5h150q10 0 17.5 7.5t7.5 17.5v150q0 10 7.5 17.5t17.5 7.5h750q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 7.5 -17.5t17.5 -7.5h150q10 0 17.5 7.5 t7.5 17.5v650q0 10 -7.5 17.5t-17.5 7.5zM850 200h-500q-10 0 -19.5 -7t-11.5 -17l-38 -152q-2 -10 3.5 -17t15.5 -7h600q10 0 15.5 7t3.5 17l-38 152q-2 10 -11.5 17t-19.5 7z" />
<glyph unicode="&#xe046;" d="M500 1100h200q56 0 102.5 -20.5t72.5 -50t44 -59t25 -50.5l6 -20h150q41 0 70.5 -29.5t29.5 -70.5v-600q0 -41 -29.5 -70.5t-70.5 -29.5h-1000q-41 0 -70.5 29.5t-29.5 70.5v600q0 41 29.5 70.5t70.5 29.5h150q2 8 6.5 21.5t24 48t45 61t72 48t102.5 21.5zM900 800v-100 h100v100h-100zM600 730q-95 0 -162.5 -67.5t-67.5 -162.5t67.5 -162.5t162.5 -67.5t162.5 67.5t67.5 162.5t-67.5 162.5t-162.5 67.5zM600 603q43 0 73 -30t30 -73t-30 -73t-73 -30t-73 30t-30 73t30 73t73 30z" />
<glyph unicode="&#xe047;" d="M681 1199l385 -998q20 -50 60 -92q18 -19 36.5 -29.5t27.5 -11.5l10 -2v-66h-417v66q53 0 75 43.5t5 88.5l-82 222h-391q-58 -145 -92 -234q-11 -34 -6.5 -57t25.5 -37t46 -20t55 -6v-66h-365v66q56 24 84 52q12 12 25 30.5t20 31.5l7 13l399 1006h93zM416 521h340 l-162 457z" />
<glyph unicode="&#xe048;" d="M753 641q5 -1 14.5 -4.5t36 -15.5t50.5 -26.5t53.5 -40t50.5 -54.5t35.5 -70t14.5 -87q0 -67 -27.5 -125.5t-71.5 -97.5t-98.5 -66.5t-108.5 -40.5t-102 -13h-500v89q41 7 70.5 32.5t29.5 65.5v827q0 24 -0.5 34t-3.5 24t-8.5 19.5t-17 13.5t-28 12.5t-42.5 11.5v71 l471 -1q57 0 115.5 -20.5t108 -57t80.5 -94t31 -124.5q0 -51 -15.5 -96.5t-38 -74.5t-45 -50.5t-38.5 -30.5zM400 700h139q78 0 130.5 48.5t52.5 122.5q0 41 -8.5 70.5t-29.5 55.5t-62.5 39.5t-103.5 13.5h-118v-350zM400 200h216q80 0 121 50.5t41 130.5q0 90 -62.5 154.5 t-156.5 64.5h-159v-400z" />
<glyph unicode="&#xe049;" d="M877 1200l2 -57q-83 -19 -116 -45.5t-40 -66.5l-132 -839q-9 -49 13 -69t96 -26v-97h-500v97q186 16 200 98l173 832q3 17 3 30t-1.5 22.5t-9 17.5t-13.5 12.5t-21.5 10t-26 8.5t-33.5 10q-13 3 -19 5v57h425z" />
<glyph unicode="&#xe050;" d="M1300 900h-50q0 21 -4 37t-9.5 26.5t-18 17.5t-22 11t-28.5 5.5t-31 2t-37 0.5h-200v-850q0 -22 25 -34.5t50 -13.5l25 -2v-100h-400v100q4 0 11 0.5t24 3t30 7t24 15t11 24.5v850h-200q-25 0 -37 -0.5t-31 -2t-28.5 -5.5t-22 -11t-18 -17.5t-9.5 -26.5t-4 -37h-50v300 h1000v-300zM175 1000h-75v-800h75l-125 -167l-125 167h75v800h-75l125 167z" />
<glyph unicode="&#xe051;" d="M1100 900h-50q0 21 -4 37t-9.5 26.5t-18 17.5t-22 11t-28.5 5.5t-31 2t-37 0.5h-200v-650q0 -22 25 -34.5t50 -13.5l25 -2v-100h-400v100q4 0 11 0.5t24 3t30 7t24 15t11 24.5v650h-200q-25 0 -37 -0.5t-31 -2t-28.5 -5.5t-22 -11t-18 -17.5t-9.5 -26.5t-4 -37h-50v300 h1000v-300zM1167 50l-167 -125v75h-800v-75l-167 125l167 125v-75h800v75z" />
<glyph unicode="&#xe052;" d="M50 1100h600q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-600q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 800h1000q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1000q-21 0 -35.5 14.5t-14.5 35.5v100 q0 21 14.5 35.5t35.5 14.5zM50 500h800q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 200h1100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100 q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe053;" d="M250 1100h700q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-700q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 800h1100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5v100 q0 21 14.5 35.5t35.5 14.5zM250 500h700q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-700q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 200h1100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100 q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe054;" d="M500 950v100q0 21 14.5 35.5t35.5 14.5h600q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-600q-21 0 -35.5 14.5t-14.5 35.5zM100 650v100q0 21 14.5 35.5t35.5 14.5h1000q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1000 q-21 0 -35.5 14.5t-14.5 35.5zM300 350v100q0 21 14.5 35.5t35.5 14.5h800q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5zM0 50v100q0 21 14.5 35.5t35.5 14.5h1100q21 0 35.5 -14.5t14.5 -35.5v-100 q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5z" />
<glyph unicode="&#xe055;" d="M50 1100h1100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 800h1100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5v100 q0 21 14.5 35.5t35.5 14.5zM50 500h1100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 200h1100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100 q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe056;" d="M50 1100h100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM350 1100h800q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5v100 q0 21 14.5 35.5t35.5 14.5zM50 800h100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM350 800h800q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-800 q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 500h100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM350 500h800q21 0 35.5 -14.5t14.5 -35.5v-100 q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 200h100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM350 200h800 q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe057;" d="M400 0h-100v1100h100v-1100zM550 1100h100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM550 800h500q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-500 q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM267 550l-167 -125v75h-200v100h200v75zM550 500h300q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-300q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM550 200h600 q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-600q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe058;" d="M50 1100h100q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM900 0h-100v1100h100v-1100zM50 800h500q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-500 q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM1100 600h200v-100h-200v-75l-167 125l167 125v-75zM50 500h300q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-300q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5zM50 200h600 q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-600q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe059;" d="M75 1000h750q31 0 53 -22t22 -53v-650q0 -31 -22 -53t-53 -22h-750q-31 0 -53 22t-22 53v650q0 31 22 53t53 22zM1200 300l-300 300l300 300v-600z" />
<glyph unicode="&#xe060;" d="M44 1100h1112q18 0 31 -13t13 -31v-1012q0 -18 -13 -31t-31 -13h-1112q-18 0 -31 13t-13 31v1012q0 18 13 31t31 13zM100 1000v-737l247 182l298 -131l-74 156l293 318l236 -288v500h-1000zM342 884q56 0 95 -39t39 -94.5t-39 -95t-95 -39.5t-95 39.5t-39 95t39 94.5 t95 39z" />
<glyph unicode="&#xe062;" d="M648 1169q117 0 216 -60t156.5 -161t57.5 -218q0 -115 -70 -258q-69 -109 -158 -225.5t-143 -179.5l-54 -62q-9 8 -25.5 24.5t-63.5 67.5t-91 103t-98.5 128t-95.5 148q-60 132 -60 249q0 88 34 169.5t91.5 142t137 96.5t166.5 36zM652.5 974q-91.5 0 -156.5 -65 t-65 -157t65 -156.5t156.5 -64.5t156.5 64.5t65 156.5t-65 157t-156.5 65z" />
<glyph unicode="&#xe063;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 173v854q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5 t155.5 -155.5t214.5 -57z" />
<glyph unicode="&#xe064;" d="M554 1295q21 -72 57.5 -143.5t76 -130t83 -118t82.5 -117t70 -116t49.5 -126t18.5 -136.5q0 -71 -25.5 -135t-68.5 -111t-99 -82t-118.5 -54t-125.5 -23q-84 5 -161.5 34t-139.5 78.5t-99 125t-37 164.5q0 69 18 136.5t49.5 126.5t69.5 116.5t81.5 117.5t83.5 119 t76.5 131t58.5 143zM344 710q-23 -33 -43.5 -70.5t-40.5 -102.5t-17 -123q1 -37 14.5 -69.5t30 -52t41 -37t38.5 -24.5t33 -15q21 -7 32 -1t13 22l6 34q2 10 -2.5 22t-13.5 19q-5 4 -14 12t-29.5 40.5t-32.5 73.5q-26 89 6 271q2 11 -6 11q-8 1 -15 -10z" />
<glyph unicode="&#xe065;" d="M1000 1013l108 115q2 1 5 2t13 2t20.5 -1t25 -9.5t28.5 -21.5q22 -22 27 -43t0 -32l-6 -10l-108 -115zM350 1100h400q50 0 105 -13l-187 -187h-368q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5v182l200 200v-332 q0 -165 -93.5 -257.5t-256.5 -92.5h-400q-165 0 -257.5 92.5t-92.5 257.5v400q0 165 92.5 257.5t257.5 92.5zM1009 803l-362 -362l-161 -50l55 170l355 355z" />
<glyph unicode="&#xe066;" d="M350 1100h361q-164 -146 -216 -200h-195q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5l200 153v-103q0 -165 -92.5 -257.5t-257.5 -92.5h-400q-165 0 -257.5 92.5t-92.5 257.5v400q0 165 92.5 257.5t257.5 92.5z M824 1073l339 -301q8 -7 8 -17.5t-8 -17.5l-340 -306q-7 -6 -12.5 -4t-6.5 11v203q-26 1 -54.5 0t-78.5 -7.5t-92 -17.5t-86 -35t-70 -57q10 59 33 108t51.5 81.5t65 58.5t68.5 40.5t67 24.5t56 13.5t40 4.5v210q1 10 6.5 12.5t13.5 -4.5z" />
<glyph unicode="&#xe067;" d="M350 1100h350q60 0 127 -23l-178 -177h-349q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5v69l200 200v-219q0 -165 -92.5 -257.5t-257.5 -92.5h-400q-165 0 -257.5 92.5t-92.5 257.5v400q0 165 92.5 257.5t257.5 92.5z M643 639l395 395q7 7 17.5 7t17.5 -7l101 -101q7 -7 7 -17.5t-7 -17.5l-531 -532q-7 -7 -17.5 -7t-17.5 7l-248 248q-7 7 -7 17.5t7 17.5l101 101q7 7 17.5 7t17.5 -7l111 -111q8 -7 18 -7t18 7z" />
<glyph unicode="&#xe068;" d="M318 918l264 264q8 8 18 8t18 -8l260 -264q7 -8 4.5 -13t-12.5 -5h-170v-200h200v173q0 10 5 12t13 -5l264 -260q8 -7 8 -17.5t-8 -17.5l-264 -265q-8 -7 -13 -5t-5 12v173h-200v-200h170q10 0 12.5 -5t-4.5 -13l-260 -264q-8 -8 -18 -8t-18 8l-264 264q-8 8 -5.5 13 t12.5 5h175v200h-200v-173q0 -10 -5 -12t-13 5l-264 265q-8 7 -8 17.5t8 17.5l264 260q8 7 13 5t5 -12v-173h200v200h-175q-10 0 -12.5 5t5.5 13z" />
<glyph unicode="&#xe069;" d="M250 1100h100q21 0 35.5 -14.5t14.5 -35.5v-438l464 453q15 14 25.5 10t10.5 -25v-1000q0 -21 -10.5 -25t-25.5 10l-464 453v-438q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v1000q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe070;" d="M50 1100h100q21 0 35.5 -14.5t14.5 -35.5v-438l464 453q15 14 25.5 10t10.5 -25v-438l464 453q15 14 25.5 10t10.5 -25v-1000q0 -21 -10.5 -25t-25.5 10l-464 453v-438q0 -21 -10.5 -25t-25.5 10l-464 453v-438q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5 t-14.5 35.5v1000q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe071;" d="M1200 1050v-1000q0 -21 -10.5 -25t-25.5 10l-464 453v-438q0 -21 -10.5 -25t-25.5 10l-492 480q-15 14 -15 35t15 35l492 480q15 14 25.5 10t10.5 -25v-438l464 453q15 14 25.5 10t10.5 -25z" />
<glyph unicode="&#xe072;" d="M243 1074l814 -498q18 -11 18 -26t-18 -26l-814 -498q-18 -11 -30.5 -4t-12.5 28v1000q0 21 12.5 28t30.5 -4z" />
<glyph unicode="&#xe073;" d="M250 1000h200q21 0 35.5 -14.5t14.5 -35.5v-800q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v800q0 21 14.5 35.5t35.5 14.5zM650 1000h200q21 0 35.5 -14.5t14.5 -35.5v-800q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v800 q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe074;" d="M1100 950v-800q0 -21 -14.5 -35.5t-35.5 -14.5h-800q-21 0 -35.5 14.5t-14.5 35.5v800q0 21 14.5 35.5t35.5 14.5h800q21 0 35.5 -14.5t14.5 -35.5z" />
<glyph unicode="&#xe075;" d="M500 612v438q0 21 10.5 25t25.5 -10l492 -480q15 -14 15 -35t-15 -35l-492 -480q-15 -14 -25.5 -10t-10.5 25v438l-464 -453q-15 -14 -25.5 -10t-10.5 25v1000q0 21 10.5 25t25.5 -10z" />
<glyph unicode="&#xe076;" d="M1048 1102l100 1q20 0 35 -14.5t15 -35.5l5 -1000q0 -21 -14.5 -35.5t-35.5 -14.5l-100 -1q-21 0 -35.5 14.5t-14.5 35.5l-2 437l-463 -454q-14 -15 -24.5 -10.5t-10.5 25.5l-2 437l-462 -455q-15 -14 -25.5 -9.5t-10.5 24.5l-5 1000q0 21 10.5 25.5t25.5 -10.5l466 -450 l-2 438q0 20 10.5 24.5t25.5 -9.5l466 -451l-2 438q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe077;" d="M850 1100h100q21 0 35.5 -14.5t14.5 -35.5v-1000q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v438l-464 -453q-15 -14 -25.5 -10t-10.5 25v1000q0 21 10.5 25t25.5 -10l464 -453v438q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe078;" d="M686 1081l501 -540q15 -15 10.5 -26t-26.5 -11h-1042q-22 0 -26.5 11t10.5 26l501 540q15 15 36 15t36 -15zM150 400h1000q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1000q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe079;" d="M885 900l-352 -353l352 -353l-197 -198l-552 552l552 550z" />
<glyph unicode="&#xe080;" d="M1064 547l-551 -551l-198 198l353 353l-353 353l198 198z" />
<glyph unicode="&#xe081;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM650 900h-100q-21 0 -35.5 -14.5t-14.5 -35.5v-150h-150 q-21 0 -35.5 -14.5t-14.5 -35.5v-100q0 -21 14.5 -35.5t35.5 -14.5h150v-150q0 -21 14.5 -35.5t35.5 -14.5h100q21 0 35.5 14.5t14.5 35.5v150h150q21 0 35.5 14.5t14.5 35.5v100q0 21 -14.5 35.5t-35.5 14.5h-150v150q0 21 -14.5 35.5t-35.5 14.5z" />
<glyph unicode="&#xe082;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM850 700h-500q-21 0 -35.5 -14.5t-14.5 -35.5v-100q0 -21 14.5 -35.5 t35.5 -14.5h500q21 0 35.5 14.5t14.5 35.5v100q0 21 -14.5 35.5t-35.5 14.5z" />
<glyph unicode="&#xe083;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM741.5 913q-12.5 0 -21.5 -9l-120 -120l-120 120q-9 9 -21.5 9 t-21.5 -9l-141 -141q-9 -9 -9 -21.5t9 -21.5l120 -120l-120 -120q-9 -9 -9 -21.5t9 -21.5l141 -141q9 -9 21.5 -9t21.5 9l120 120l120 -120q9 -9 21.5 -9t21.5 9l141 141q9 9 9 21.5t-9 21.5l-120 120l120 120q9 9 9 21.5t-9 21.5l-141 141q-9 9 -21.5 9z" />
<glyph unicode="&#xe084;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM546 623l-84 85q-7 7 -17.5 7t-18.5 -7l-139 -139q-7 -8 -7 -18t7 -18 l242 -241q7 -8 17.5 -8t17.5 8l375 375q7 7 7 17.5t-7 18.5l-139 139q-7 7 -17.5 7t-17.5 -7z" />
<glyph unicode="&#xe085;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM588 941q-29 0 -59 -5.5t-63 -20.5t-58 -38.5t-41.5 -63t-16.5 -89.5 q0 -25 20 -25h131q30 -5 35 11q6 20 20.5 28t45.5 8q20 0 31.5 -10.5t11.5 -28.5q0 -23 -7 -34t-26 -18q-1 0 -13.5 -4t-19.5 -7.5t-20 -10.5t-22 -17t-18.5 -24t-15.5 -35t-8 -46q-1 -8 5.5 -16.5t20.5 -8.5h173q7 0 22 8t35 28t37.5 48t29.5 74t12 100q0 47 -17 83 t-42.5 57t-59.5 34.5t-64 18t-59 4.5zM675 400h-150q-10 0 -17.5 -7.5t-7.5 -17.5v-150q0 -10 7.5 -17.5t17.5 -7.5h150q10 0 17.5 7.5t7.5 17.5v150q0 10 -7.5 17.5t-17.5 7.5z" />
<glyph unicode="&#xe086;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM675 1000h-150q-10 0 -17.5 -7.5t-7.5 -17.5v-150q0 -10 7.5 -17.5 t17.5 -7.5h150q10 0 17.5 7.5t7.5 17.5v150q0 10 -7.5 17.5t-17.5 7.5zM675 700h-250q-10 0 -17.5 -7.5t-7.5 -17.5v-50q0 -10 7.5 -17.5t17.5 -7.5h75v-200h-75q-10 0 -17.5 -7.5t-7.5 -17.5v-50q0 -10 7.5 -17.5t17.5 -7.5h350q10 0 17.5 7.5t7.5 17.5v50q0 10 -7.5 17.5 t-17.5 7.5h-75v275q0 10 -7.5 17.5t-17.5 7.5z" />
<glyph unicode="&#xe087;" d="M525 1200h150q10 0 17.5 -7.5t7.5 -17.5v-194q103 -27 178.5 -102.5t102.5 -178.5h194q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-194q-27 -103 -102.5 -178.5t-178.5 -102.5v-194q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v194 q-103 27 -178.5 102.5t-102.5 178.5h-194q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5h194q27 103 102.5 178.5t178.5 102.5v194q0 10 7.5 17.5t17.5 7.5zM700 893v-168q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v168q-68 -23 -119 -74 t-74 -119h168q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-168q23 -68 74 -119t119 -74v168q0 10 7.5 17.5t17.5 7.5h150q10 0 17.5 -7.5t7.5 -17.5v-168q68 23 119 74t74 119h-168q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5h168 q-23 68 -74 119t-119 74z" />
<glyph unicode="&#xe088;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 1027q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5 t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5t-57 214.5t-155.5 155.5t-214.5 57zM759 823l64 -64q7 -7 7 -17.5t-7 -17.5l-124 -124l124 -124q7 -7 7 -17.5t-7 -17.5l-64 -64q-7 -7 -17.5 -7t-17.5 7l-124 124l-124 -124q-7 -7 -17.5 -7t-17.5 7l-64 64 q-7 7 -7 17.5t7 17.5l124 124l-124 124q-7 7 -7 17.5t7 17.5l64 64q7 7 17.5 7t17.5 -7l124 -124l124 124q7 7 17.5 7t17.5 -7z" />
<glyph unicode="&#xe089;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 1027q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5t57 -214.5 t155.5 -155.5t214.5 -57t214.5 57t155.5 155.5t57 214.5t-57 214.5t-155.5 155.5t-214.5 57zM782 788l106 -106q7 -7 7 -17.5t-7 -17.5l-320 -321q-8 -7 -18 -7t-18 7l-202 203q-8 7 -8 17.5t8 17.5l106 106q7 8 17.5 8t17.5 -8l79 -79l197 197q7 7 17.5 7t17.5 -7z" />
<glyph unicode="&#xe090;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM600 1027q-116 0 -214.5 -57t-155.5 -155.5t-57 -214.5q0 -120 65 -225 l587 587q-105 65 -225 65zM965 819l-584 -584q104 -62 219 -62q116 0 214.5 57t155.5 155.5t57 214.5q0 115 -62 219z" />
<glyph unicode="&#xe091;" d="M39 582l522 427q16 13 27.5 8t11.5 -26v-291h550q21 0 35.5 -14.5t14.5 -35.5v-200q0 -21 -14.5 -35.5t-35.5 -14.5h-550v-291q0 -21 -11.5 -26t-27.5 8l-522 427q-16 13 -16 32t16 32z" />
<glyph unicode="&#xe092;" d="M639 1009l522 -427q16 -13 16 -32t-16 -32l-522 -427q-16 -13 -27.5 -8t-11.5 26v291h-550q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5h550v291q0 21 11.5 26t27.5 -8z" />
<glyph unicode="&#xe093;" d="M682 1161l427 -522q13 -16 8 -27.5t-26 -11.5h-291v-550q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v550h-291q-21 0 -26 11.5t8 27.5l427 522q13 16 32 16t32 -16z" />
<glyph unicode="&#xe094;" d="M550 1200h200q21 0 35.5 -14.5t14.5 -35.5v-550h291q21 0 26 -11.5t-8 -27.5l-427 -522q-13 -16 -32 -16t-32 16l-427 522q-13 16 -8 27.5t26 11.5h291v550q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe095;" d="M639 1109l522 -427q16 -13 16 -32t-16 -32l-522 -427q-16 -13 -27.5 -8t-11.5 26v291q-94 -2 -182 -20t-170.5 -52t-147 -92.5t-100.5 -135.5q5 105 27 193.5t67.5 167t113 135t167 91.5t225.5 42v262q0 21 11.5 26t27.5 -8z" />
<glyph unicode="&#xe096;" d="M850 1200h300q21 0 35.5 -14.5t14.5 -35.5v-300q0 -21 -10.5 -25t-24.5 10l-94 94l-249 -249q-8 -7 -18 -7t-18 7l-106 106q-7 8 -7 18t7 18l249 249l-94 94q-14 14 -10 24.5t25 10.5zM350 0h-300q-21 0 -35.5 14.5t-14.5 35.5v300q0 21 10.5 25t24.5 -10l94 -94l249 249 q8 7 18 7t18 -7l106 -106q7 -8 7 -18t-7 -18l-249 -249l94 -94q14 -14 10 -24.5t-25 -10.5z" />
<glyph unicode="&#xe097;" d="M1014 1120l106 -106q7 -8 7 -18t-7 -18l-249 -249l94 -94q14 -14 10 -24.5t-25 -10.5h-300q-21 0 -35.5 14.5t-14.5 35.5v300q0 21 10.5 25t24.5 -10l94 -94l249 249q8 7 18 7t18 -7zM250 600h300q21 0 35.5 -14.5t14.5 -35.5v-300q0 -21 -10.5 -25t-24.5 10l-94 94 l-249 -249q-8 -7 -18 -7t-18 7l-106 106q-7 8 -7 18t7 18l249 249l-94 94q-14 14 -10 24.5t25 10.5z" />
<glyph unicode="&#xe101;" d="M600 1177q117 0 224 -45.5t184.5 -123t123 -184.5t45.5 -224t-45.5 -224t-123 -184.5t-184.5 -123t-224 -45.5t-224 45.5t-184.5 123t-123 184.5t-45.5 224t45.5 224t123 184.5t184.5 123t224 45.5zM704 900h-208q-20 0 -32 -14.5t-8 -34.5l58 -302q4 -20 21.5 -34.5 t37.5 -14.5h54q20 0 37.5 14.5t21.5 34.5l58 302q4 20 -8 34.5t-32 14.5zM675 400h-150q-10 0 -17.5 -7.5t-7.5 -17.5v-150q0 -10 7.5 -17.5t17.5 -7.5h150q10 0 17.5 7.5t7.5 17.5v150q0 10 -7.5 17.5t-17.5 7.5z" />
<glyph unicode="&#xe102;" d="M260 1200q9 0 19 -2t15 -4l5 -2q22 -10 44 -23l196 -118q21 -13 36 -24q29 -21 37 -12q11 13 49 35l196 118q22 13 45 23q17 7 38 7q23 0 47 -16.5t37 -33.5l13 -16q14 -21 18 -45l25 -123l8 -44q1 -9 8.5 -14.5t17.5 -5.5h61q10 0 17.5 -7.5t7.5 -17.5v-50 q0 -10 -7.5 -17.5t-17.5 -7.5h-50q-10 0 -17.5 -7.5t-7.5 -17.5v-175h-400v300h-200v-300h-400v175q0 10 -7.5 17.5t-17.5 7.5h-50q-10 0 -17.5 7.5t-7.5 17.5v50q0 10 7.5 17.5t17.5 7.5h61q11 0 18 3t7 8q0 4 9 52l25 128q5 25 19 45q2 3 5 7t13.5 15t21.5 19.5t26.5 15.5 t29.5 7zM915 1079l-166 -162q-7 -7 -5 -12t12 -5h219q10 0 15 7t2 17l-51 149q-3 10 -11 12t-15 -6zM463 917l-177 157q-8 7 -16 5t-11 -12l-51 -143q-3 -10 2 -17t15 -7h231q11 0 12.5 5t-5.5 12zM500 0h-375q-10 0 -17.5 7.5t-7.5 17.5v375h400v-400zM1100 400v-375 q0 -10 -7.5 -17.5t-17.5 -7.5h-375v400h400z" />
<glyph unicode="&#xe103;" d="M1165 1190q8 3 21 -6.5t13 -17.5q-2 -178 -24.5 -323.5t-55.5 -245.5t-87 -174.5t-102.5 -118.5t-118 -68.5t-118.5 -33t-120 -4.5t-105 9.5t-90 16.5q-61 12 -78 11q-4 1 -12.5 0t-34 -14.5t-52.5 -40.5l-153 -153q-26 -24 -37 -14.5t-11 43.5q0 64 42 102q8 8 50.5 45 t66.5 58q19 17 35 47t13 61q-9 55 -10 102.5t7 111t37 130t78 129.5q39 51 80 88t89.5 63.5t94.5 45t113.5 36t129 31t157.5 37t182 47.5zM1116 1098q-8 9 -22.5 -3t-45.5 -50q-38 -47 -119 -103.5t-142 -89.5l-62 -33q-56 -30 -102 -57t-104 -68t-102.5 -80.5t-85.5 -91 t-64 -104.5q-24 -56 -31 -86t2 -32t31.5 17.5t55.5 59.5q25 30 94 75.5t125.5 77.5t147.5 81q70 37 118.5 69t102 79.5t99 111t86.5 148.5q22 50 24 60t-6 19z" />
<glyph unicode="&#xe104;" d="M653 1231q-39 -67 -54.5 -131t-10.5 -114.5t24.5 -96.5t47.5 -80t63.5 -62.5t68.5 -46.5t65 -30q-4 7 -17.5 35t-18.5 39.5t-17 39.5t-17 43t-13 42t-9.5 44.5t-2 42t4 43t13.5 39t23 38.5q96 -42 165 -107.5t105 -138t52 -156t13 -159t-19 -149.5q-13 -55 -44 -106.5 t-68 -87t-78.5 -64.5t-72.5 -45t-53 -22q-72 -22 -127 -11q-31 6 -13 19q6 3 17 7q13 5 32.5 21t41 44t38.5 63.5t21.5 81.5t-6.5 94.5t-50 107t-104 115.5q10 -104 -0.5 -189t-37 -140.5t-65 -93t-84 -52t-93.5 -11t-95 24.5q-80 36 -131.5 114t-53.5 171q-2 23 0 49.5 t4.5 52.5t13.5 56t27.5 60t46 64.5t69.5 68.5q-8 -53 -5 -102.5t17.5 -90t34 -68.5t44.5 -39t49 -2q31 13 38.5 36t-4.5 55t-29 64.5t-36 75t-26 75.5q-15 85 2 161.5t53.5 128.5t85.5 92.5t93.5 61t81.5 25.5z" />
<glyph unicode="&#xe105;" d="M600 1094q82 0 160.5 -22.5t140 -59t116.5 -82.5t94.5 -95t68 -95t42.5 -82.5t14 -57.5t-14 -57.5t-43 -82.5t-68.5 -95t-94.5 -95t-116.5 -82.5t-140 -59t-159.5 -22.5t-159.5 22.5t-140 59t-116.5 82.5t-94.5 95t-68.5 95t-43 82.5t-14 57.5t14 57.5t42.5 82.5t68 95 t94.5 95t116.5 82.5t140 59t160.5 22.5zM888 829q-15 15 -18 12t5 -22q25 -57 25 -119q0 -124 -88 -212t-212 -88t-212 88t-88 212q0 59 23 114q8 19 4.5 22t-17.5 -12q-70 -69 -160 -184q-13 -16 -15 -40.5t9 -42.5q22 -36 47 -71t70 -82t92.5 -81t113 -58.5t133.5 -24.5 t133.5 24t113 58.5t92.5 81.5t70 81.5t47 70.5q11 18 9 42.5t-14 41.5q-90 117 -163 189zM448 727l-35 -36q-15 -15 -19.5 -38.5t4.5 -41.5q37 -68 93 -116q16 -13 38.5 -11t36.5 17l35 34q14 15 12.5 33.5t-16.5 33.5q-44 44 -89 117q-11 18 -28 20t-32 -12z" />
<glyph unicode="&#xe106;" d="M592 0h-148l31 120q-91 20 -175.5 68.5t-143.5 106.5t-103.5 119t-66.5 110t-22 76q0 21 14 57.5t42.5 82.5t68 95t94.5 95t116.5 82.5t140 59t160.5 22.5q61 0 126 -15l32 121h148zM944 770l47 181q108 -85 176.5 -192t68.5 -159q0 -26 -19.5 -71t-59.5 -102t-93 -112 t-129 -104.5t-158 -75.5l46 173q77 49 136 117t97 131q11 18 9 42.5t-14 41.5q-54 70 -107 130zM310 824q-70 -69 -160 -184q-13 -16 -15 -40.5t9 -42.5q18 -30 39 -60t57 -70.5t74 -73t90 -61t105 -41.5l41 154q-107 18 -178.5 101.5t-71.5 193.5q0 59 23 114q8 19 4.5 22 t-17.5 -12zM448 727l-35 -36q-15 -15 -19.5 -38.5t4.5 -41.5q37 -68 93 -116q16 -13 38.5 -11t36.5 17l12 11l22 86l-3 4q-44 44 -89 117q-11 18 -28 20t-32 -12z" />
<glyph unicode="&#xe107;" d="M-90 100l642 1066q20 31 48 28.5t48 -35.5l642 -1056q21 -32 7.5 -67.5t-50.5 -35.5h-1294q-37 0 -50.5 34t7.5 66zM155 200h345v75q0 10 7.5 17.5t17.5 7.5h150q10 0 17.5 -7.5t7.5 -17.5v-75h345l-445 723zM496 700h208q20 0 32 -14.5t8 -34.5l-58 -252 q-4 -20 -21.5 -34.5t-37.5 -14.5h-54q-20 0 -37.5 14.5t-21.5 34.5l-58 252q-4 20 8 34.5t32 14.5z" />
<glyph unicode="&#xe108;" d="M650 1200q62 0 106 -44t44 -106v-339l363 -325q15 -14 26 -38.5t11 -44.5v-41q0 -20 -12 -26.5t-29 5.5l-359 249v-263q100 -93 100 -113v-64q0 -21 -13 -29t-32 1l-205 128l-205 -128q-19 -9 -32 -1t-13 29v64q0 20 100 113v263l-359 -249q-17 -12 -29 -5.5t-12 26.5v41 q0 20 11 44.5t26 38.5l363 325v339q0 62 44 106t106 44z" />
<glyph unicode="&#xe109;" d="M850 1200h100q21 0 35.5 -14.5t14.5 -35.5v-50h50q21 0 35.5 -14.5t14.5 -35.5v-150h-1100v150q0 21 14.5 35.5t35.5 14.5h50v50q0 21 14.5 35.5t35.5 14.5h100q21 0 35.5 -14.5t14.5 -35.5v-50h500v50q0 21 14.5 35.5t35.5 14.5zM1100 800v-750q0 -21 -14.5 -35.5 t-35.5 -14.5h-1000q-21 0 -35.5 14.5t-14.5 35.5v750h1100zM100 600v-100h100v100h-100zM300 600v-100h100v100h-100zM500 600v-100h100v100h-100zM700 600v-100h100v100h-100zM900 600v-100h100v100h-100zM100 400v-100h100v100h-100zM300 400v-100h100v100h-100zM500 400 v-100h100v100h-100zM700 400v-100h100v100h-100zM900 400v-100h100v100h-100zM100 200v-100h100v100h-100zM300 200v-100h100v100h-100zM500 200v-100h100v100h-100zM700 200v-100h100v100h-100zM900 200v-100h100v100h-100z" />
<glyph unicode="&#xe110;" d="M1135 1165l249 -230q15 -14 15 -35t-15 -35l-249 -230q-14 -14 -24.5 -10t-10.5 25v150h-159l-600 -600h-291q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5h209l600 600h241v150q0 21 10.5 25t24.5 -10zM522 819l-141 -141l-122 122h-209q-21 0 -35.5 14.5 t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5h291zM1135 565l249 -230q15 -14 15 -35t-15 -35l-249 -230q-14 -14 -24.5 -10t-10.5 25v150h-241l-181 181l141 141l122 -122h159v150q0 21 10.5 25t24.5 -10z" />
<glyph unicode="&#xe111;" d="M100 1100h1000q41 0 70.5 -29.5t29.5 -70.5v-600q0 -41 -29.5 -70.5t-70.5 -29.5h-596l-304 -300v300h-100q-41 0 -70.5 29.5t-29.5 70.5v600q0 41 29.5 70.5t70.5 29.5z" />
<glyph unicode="&#xe112;" d="M150 1200h200q21 0 35.5 -14.5t14.5 -35.5v-250h-300v250q0 21 14.5 35.5t35.5 14.5zM850 1200h200q21 0 35.5 -14.5t14.5 -35.5v-250h-300v250q0 21 14.5 35.5t35.5 14.5zM1100 800v-300q0 -41 -3 -77.5t-15 -89.5t-32 -96t-58 -89t-89 -77t-129 -51t-174 -20t-174 20 t-129 51t-89 77t-58 89t-32 96t-15 89.5t-3 77.5v300h300v-250v-27v-42.5t1.5 -41t5 -38t10 -35t16.5 -30t25.5 -24.5t35 -19t46.5 -12t60 -4t60 4.5t46.5 12.5t35 19.5t25 25.5t17 30.5t10 35t5 38t2 40.5t-0.5 42v25v250h300z" />
<glyph unicode="&#xe113;" d="M1100 411l-198 -199l-353 353l-353 -353l-197 199l551 551z" />
<glyph unicode="&#xe114;" d="M1101 789l-550 -551l-551 551l198 199l353 -353l353 353z" />
<glyph unicode="&#xe115;" d="M404 1000h746q21 0 35.5 -14.5t14.5 -35.5v-551h150q21 0 25 -10.5t-10 -24.5l-230 -249q-14 -15 -35 -15t-35 15l-230 249q-14 14 -10 24.5t25 10.5h150v401h-381zM135 984l230 -249q14 -14 10 -24.5t-25 -10.5h-150v-400h385l215 -200h-750q-21 0 -35.5 14.5 t-14.5 35.5v550h-150q-21 0 -25 10.5t10 24.5l230 249q14 15 35 15t35 -15z" />
<glyph unicode="&#xe116;" d="M56 1200h94q17 0 31 -11t18 -27l38 -162h896q24 0 39 -18.5t10 -42.5l-100 -475q-5 -21 -27 -42.5t-55 -21.5h-633l48 -200h535q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-50v-50q0 -21 -14.5 -35.5t-35.5 -14.5t-35.5 14.5t-14.5 35.5v50h-300v-50 q0 -21 -14.5 -35.5t-35.5 -14.5t-35.5 14.5t-14.5 35.5v50h-31q-18 0 -32.5 10t-20.5 19l-5 10l-201 961h-54q-20 0 -35 14.5t-15 35.5t15 35.5t35 14.5z" />
<glyph unicode="&#xe117;" d="M1200 1000v-100h-1200v100h200q0 41 29.5 70.5t70.5 29.5h300q41 0 70.5 -29.5t29.5 -70.5h500zM0 800h1200v-800h-1200v800z" />
<glyph unicode="&#xe118;" d="M200 800l-200 -400v600h200q0 41 29.5 70.5t70.5 29.5h300q42 0 71 -29.5t29 -70.5h500v-200h-1000zM1500 700l-300 -700h-1200l300 700h1200z" />
<glyph unicode="&#xe119;" d="M635 1184l230 -249q14 -14 10 -24.5t-25 -10.5h-150v-601h150q21 0 25 -10.5t-10 -24.5l-230 -249q-14 -15 -35 -15t-35 15l-230 249q-14 14 -10 24.5t25 10.5h150v601h-150q-21 0 -25 10.5t10 24.5l230 249q14 15 35 15t35 -15z" />
<glyph unicode="&#xe120;" d="M936 864l249 -229q14 -15 14 -35.5t-14 -35.5l-249 -229q-15 -15 -25.5 -10.5t-10.5 24.5v151h-600v-151q0 -20 -10.5 -24.5t-25.5 10.5l-249 229q-14 15 -14 35.5t14 35.5l249 229q15 15 25.5 10.5t10.5 -25.5v-149h600v149q0 21 10.5 25.5t25.5 -10.5z" />
<glyph unicode="&#xe121;" d="M1169 400l-172 732q-5 23 -23 45.5t-38 22.5h-672q-20 0 -38 -20t-23 -41l-172 -739h1138zM1100 300h-1000q-41 0 -70.5 -29.5t-29.5 -70.5v-100q0 -41 29.5 -70.5t70.5 -29.5h1000q41 0 70.5 29.5t29.5 70.5v100q0 41 -29.5 70.5t-70.5 29.5zM800 100v100h100v-100h-100 zM1000 100v100h100v-100h-100z" />
<glyph unicode="&#xe122;" d="M1150 1100q21 0 35.5 -14.5t14.5 -35.5v-850q0 -21 -14.5 -35.5t-35.5 -14.5t-35.5 14.5t-14.5 35.5v850q0 21 14.5 35.5t35.5 14.5zM1000 200l-675 200h-38l47 -276q3 -16 -5.5 -20t-29.5 -4h-7h-84q-20 0 -34.5 14t-18.5 35q-55 337 -55 351v250v6q0 16 1 23.5t6.5 14 t17.5 6.5h200l675 250v-850zM0 750v-250q-4 0 -11 0.5t-24 6t-30 15t-24 30t-11 48.5v50q0 26 10.5 46t25 30t29 16t25.5 7z" />
<glyph unicode="&#xe123;" d="M553 1200h94q20 0 29 -10.5t3 -29.5l-18 -37q83 -19 144 -82.5t76 -140.5l63 -327l118 -173h17q19 0 33 -14.5t14 -35t-13 -40.5t-31 -27q-8 -4 -23 -9.5t-65 -19.5t-103 -25t-132.5 -20t-158.5 -9q-57 0 -115 5t-104 12t-88.5 15.5t-73.5 17.5t-54.5 16t-35.5 12l-11 4 q-18 8 -31 28t-13 40.5t14 35t33 14.5h17l118 173l63 327q15 77 76 140t144 83l-18 32q-6 19 3.5 32t28.5 13zM498 110q50 -6 102 -6q53 0 102 6q-12 -49 -39.5 -79.5t-62.5 -30.5t-63 30.5t-39 79.5z" />
<glyph unicode="&#xe124;" d="M800 946l224 78l-78 -224l234 -45l-180 -155l180 -155l-234 -45l78 -224l-224 78l-45 -234l-155 180l-155 -180l-45 234l-224 -78l78 224l-234 45l180 155l-180 155l234 45l-78 224l224 -78l45 234l155 -180l155 180z" />
<glyph unicode="&#xe125;" d="M650 1200h50q40 0 70 -40.5t30 -84.5v-150l-28 -125h328q40 0 70 -40.5t30 -84.5v-100q0 -45 -29 -74l-238 -344q-16 -24 -38 -40.5t-45 -16.5h-250q-7 0 -42 25t-66 50l-31 25h-61q-45 0 -72.5 18t-27.5 57v400q0 36 20 63l145 196l96 198q13 28 37.5 48t51.5 20z M650 1100l-100 -212l-150 -213v-375h100l136 -100h214l250 375v125h-450l50 225v175h-50zM50 800h100q21 0 35.5 -14.5t14.5 -35.5v-500q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v500q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe126;" d="M600 1100h250q23 0 45 -16.5t38 -40.5l238 -344q29 -29 29 -74v-100q0 -44 -30 -84.5t-70 -40.5h-328q28 -118 28 -125v-150q0 -44 -30 -84.5t-70 -40.5h-50q-27 0 -51.5 20t-37.5 48l-96 198l-145 196q-20 27 -20 63v400q0 39 27.5 57t72.5 18h61q124 100 139 100z M50 1000h100q21 0 35.5 -14.5t14.5 -35.5v-500q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v500q0 21 14.5 35.5t35.5 14.5zM636 1000l-136 -100h-100v-375l150 -213l100 -212h50v175l-50 225h450v125l-250 375h-214z" />
<glyph unicode="&#xe127;" d="M356 873l363 230q31 16 53 -6l110 -112q13 -13 13.5 -32t-11.5 -34l-84 -121h302q84 0 138 -38t54 -110t-55 -111t-139 -39h-106l-131 -339q-6 -21 -19.5 -41t-28.5 -20h-342q-7 0 -90 81t-83 94v525q0 17 14 35.5t28 28.5zM400 792v-503l100 -89h293l131 339 q6 21 19.5 41t28.5 20h203q21 0 30.5 25t0.5 50t-31 25h-456h-7h-6h-5.5t-6 0.5t-5 1.5t-5 2t-4 2.5t-4 4t-2.5 4.5q-12 25 5 47l146 183l-86 83zM50 800h100q21 0 35.5 -14.5t14.5 -35.5v-500q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v500 q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe128;" d="M475 1103l366 -230q2 -1 6 -3.5t14 -10.5t18 -16.5t14.5 -20t6.5 -22.5v-525q0 -13 -86 -94t-93 -81h-342q-15 0 -28.5 20t-19.5 41l-131 339h-106q-85 0 -139.5 39t-54.5 111t54 110t138 38h302l-85 121q-11 15 -10.5 34t13.5 32l110 112q22 22 53 6zM370 945l146 -183 q17 -22 5 -47q-2 -2 -3.5 -4.5t-4 -4t-4 -2.5t-5 -2t-5 -1.5t-6 -0.5h-6h-6.5h-6h-475v-100h221q15 0 29 -20t20 -41l130 -339h294l106 89v503l-342 236zM1050 800h100q21 0 35.5 -14.5t14.5 -35.5v-500q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5 v500q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe129;" d="M550 1294q72 0 111 -55t39 -139v-106l339 -131q21 -6 41 -19.5t20 -28.5v-342q0 -7 -81 -90t-94 -83h-525q-17 0 -35.5 14t-28.5 28l-9 14l-230 363q-16 31 6 53l112 110q13 13 32 13.5t34 -11.5l121 -84v302q0 84 38 138t110 54zM600 972v203q0 21 -25 30.5t-50 0.5 t-25 -31v-456v-7v-6v-5.5t-0.5 -6t-1.5 -5t-2 -5t-2.5 -4t-4 -4t-4.5 -2.5q-25 -12 -47 5l-183 146l-83 -86l236 -339h503l89 100v293l-339 131q-21 6 -41 19.5t-20 28.5zM450 200h500q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-500 q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe130;" d="M350 1100h500q21 0 35.5 14.5t14.5 35.5v100q0 21 -14.5 35.5t-35.5 14.5h-500q-21 0 -35.5 -14.5t-14.5 -35.5v-100q0 -21 14.5 -35.5t35.5 -14.5zM600 306v-106q0 -84 -39 -139t-111 -55t-110 54t-38 138v302l-121 -84q-15 -12 -34 -11.5t-32 13.5l-112 110 q-22 22 -6 53l230 363q1 2 3.5 6t10.5 13.5t16.5 17t20 13.5t22.5 6h525q13 0 94 -83t81 -90v-342q0 -15 -20 -28.5t-41 -19.5zM308 900l-236 -339l83 -86l183 146q22 17 47 5q2 -1 4.5 -2.5t4 -4t2.5 -4t2 -5t1.5 -5t0.5 -6v-5.5v-6v-7v-456q0 -22 25 -31t50 0.5t25 30.5 v203q0 15 20 28.5t41 19.5l339 131v293l-89 100h-503z" />
<glyph unicode="&#xe131;" d="M600 1178q118 0 225 -45.5t184.5 -123t123 -184.5t45.5 -225t-45.5 -225t-123 -184.5t-184.5 -123t-225 -45.5t-225 45.5t-184.5 123t-123 184.5t-45.5 225t45.5 225t123 184.5t184.5 123t225 45.5zM914 632l-275 223q-16 13 -27.5 8t-11.5 -26v-137h-275 q-10 0 -17.5 -7.5t-7.5 -17.5v-150q0 -10 7.5 -17.5t17.5 -7.5h275v-137q0 -21 11.5 -26t27.5 8l275 223q16 13 16 32t-16 32z" />
<glyph unicode="&#xe132;" d="M600 1178q118 0 225 -45.5t184.5 -123t123 -184.5t45.5 -225t-45.5 -225t-123 -184.5t-184.5 -123t-225 -45.5t-225 45.5t-184.5 123t-123 184.5t-45.5 225t45.5 225t123 184.5t184.5 123t225 45.5zM561 855l-275 -223q-16 -13 -16 -32t16 -32l275 -223q16 -13 27.5 -8 t11.5 26v137h275q10 0 17.5 7.5t7.5 17.5v150q0 10 -7.5 17.5t-17.5 7.5h-275v137q0 21 -11.5 26t-27.5 -8z" />
<glyph unicode="&#xe133;" d="M600 1178q118 0 225 -45.5t184.5 -123t123 -184.5t45.5 -225t-45.5 -225t-123 -184.5t-184.5 -123t-225 -45.5t-225 45.5t-184.5 123t-123 184.5t-45.5 225t45.5 225t123 184.5t184.5 123t225 45.5zM855 639l-223 275q-13 16 -32 16t-32 -16l-223 -275q-13 -16 -8 -27.5 t26 -11.5h137v-275q0 -10 7.5 -17.5t17.5 -7.5h150q10 0 17.5 7.5t7.5 17.5v275h137q21 0 26 11.5t-8 27.5z" />
<glyph unicode="&#xe134;" d="M600 1178q118 0 225 -45.5t184.5 -123t123 -184.5t45.5 -225t-45.5 -225t-123 -184.5t-184.5 -123t-225 -45.5t-225 45.5t-184.5 123t-123 184.5t-45.5 225t45.5 225t123 184.5t184.5 123t225 45.5zM675 900h-150q-10 0 -17.5 -7.5t-7.5 -17.5v-275h-137q-21 0 -26 -11.5 t8 -27.5l223 -275q13 -16 32 -16t32 16l223 275q13 16 8 27.5t-26 11.5h-137v275q0 10 -7.5 17.5t-17.5 7.5z" />
<glyph unicode="&#xe135;" d="M600 1176q116 0 222.5 -46t184 -123.5t123.5 -184t46 -222.5t-46 -222.5t-123.5 -184t-184 -123.5t-222.5 -46t-222.5 46t-184 123.5t-123.5 184t-46 222.5t46 222.5t123.5 184t184 123.5t222.5 46zM627 1101q-15 -12 -36.5 -20.5t-35.5 -12t-43 -8t-39 -6.5 q-15 -3 -45.5 0t-45.5 -2q-20 -7 -51.5 -26.5t-34.5 -34.5q-3 -11 6.5 -22.5t8.5 -18.5q-3 -34 -27.5 -91t-29.5 -79q-9 -34 5 -93t8 -87q0 -9 17 -44.5t16 -59.5q12 0 23 -5t23.5 -15t19.5 -14q16 -8 33 -15t40.5 -15t34.5 -12q21 -9 52.5 -32t60 -38t57.5 -11 q7 -15 -3 -34t-22.5 -40t-9.5 -38q13 -21 23 -34.5t27.5 -27.5t36.5 -18q0 -7 -3.5 -16t-3.5 -14t5 -17q104 -2 221 112q30 29 46.5 47t34.5 49t21 63q-13 8 -37 8.5t-36 7.5q-15 7 -49.5 15t-51.5 19q-18 0 -41 -0.5t-43 -1.5t-42 -6.5t-38 -16.5q-51 -35 -66 -12 q-4 1 -3.5 25.5t0.5 25.5q-6 13 -26.5 17.5t-24.5 6.5q1 15 -0.5 30.5t-7 28t-18.5 11.5t-31 -21q-23 -25 -42 4q-19 28 -8 58q6 16 22 22q6 -1 26 -1.5t33.5 -4t19.5 -13.5q7 -12 18 -24t21.5 -20.5t20 -15t15.5 -10.5l5 -3q2 12 7.5 30.5t8 34.5t-0.5 32q-3 18 3.5 29 t18 22.5t15.5 24.5q6 14 10.5 35t8 31t15.5 22.5t34 22.5q-6 18 10 36q8 0 24 -1.5t24.5 -1.5t20 4.5t20.5 15.5q-10 23 -31 42.5t-37.5 29.5t-49 27t-43.5 23q0 1 2 8t3 11.5t1.5 10.5t-1 9.5t-4.5 4.5q31 -13 58.5 -14.5t38.5 2.5l12 5q5 28 -9.5 46t-36.5 24t-50 15 t-41 20q-18 -4 -37 0zM613 994q0 -17 8 -42t17 -45t9 -23q-8 1 -39.5 5.5t-52.5 10t-37 16.5q3 11 16 29.5t16 25.5q10 -10 19 -10t14 6t13.5 14.5t16.5 12.5z" />
<glyph unicode="&#xe136;" d="M756 1157q164 92 306 -9l-259 -138l145 -232l251 126q6 -89 -34 -156.5t-117 -110.5q-60 -34 -127 -39.5t-126 16.5l-596 -596q-15 -16 -36.5 -16t-36.5 16l-111 110q-15 15 -15 36.5t15 37.5l600 599q-34 101 5.5 201.5t135.5 154.5z" />
<glyph unicode="&#xe137;" horiz-adv-x="1220" d="M100 1196h1000q41 0 70.5 -29.5t29.5 -70.5v-100q0 -41 -29.5 -70.5t-70.5 -29.5h-1000q-41 0 -70.5 29.5t-29.5 70.5v100q0 41 29.5 70.5t70.5 29.5zM1100 1096h-200v-100h200v100zM100 796h1000q41 0 70.5 -29.5t29.5 -70.5v-100q0 -41 -29.5 -70.5t-70.5 -29.5h-1000 q-41 0 -70.5 29.5t-29.5 70.5v100q0 41 29.5 70.5t70.5 29.5zM1100 696h-500v-100h500v100zM100 396h1000q41 0 70.5 -29.5t29.5 -70.5v-100q0 -41 -29.5 -70.5t-70.5 -29.5h-1000q-41 0 -70.5 29.5t-29.5 70.5v100q0 41 29.5 70.5t70.5 29.5zM1100 296h-300v-100h300v100z " />
<glyph unicode="&#xe138;" d="M150 1200h900q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-900q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5zM700 500v-300l-200 -200v500l-350 500h900z" />
<glyph unicode="&#xe139;" d="M500 1200h200q41 0 70.5 -29.5t29.5 -70.5v-100h300q41 0 70.5 -29.5t29.5 -70.5v-400h-500v100h-200v-100h-500v400q0 41 29.5 70.5t70.5 29.5h300v100q0 41 29.5 70.5t70.5 29.5zM500 1100v-100h200v100h-200zM1200 400v-200q0 -41 -29.5 -70.5t-70.5 -29.5h-1000 q-41 0 -70.5 29.5t-29.5 70.5v200h1200z" />
<glyph unicode="&#xe140;" d="M50 1200h300q21 0 25 -10.5t-10 -24.5l-94 -94l199 -199q7 -8 7 -18t-7 -18l-106 -106q-8 -7 -18 -7t-18 7l-199 199l-94 -94q-14 -14 -24.5 -10t-10.5 25v300q0 21 14.5 35.5t35.5 14.5zM850 1200h300q21 0 35.5 -14.5t14.5 -35.5v-300q0 -21 -10.5 -25t-24.5 10l-94 94 l-199 -199q-8 -7 -18 -7t-18 7l-106 106q-7 8 -7 18t7 18l199 199l-94 94q-14 14 -10 24.5t25 10.5zM364 470l106 -106q7 -8 7 -18t-7 -18l-199 -199l94 -94q14 -14 10 -24.5t-25 -10.5h-300q-21 0 -35.5 14.5t-14.5 35.5v300q0 21 10.5 25t24.5 -10l94 -94l199 199 q8 7 18 7t18 -7zM1071 271l94 94q14 14 24.5 10t10.5 -25v-300q0 -21 -14.5 -35.5t-35.5 -14.5h-300q-21 0 -25 10.5t10 24.5l94 94l-199 199q-7 8 -7 18t7 18l106 106q8 7 18 7t18 -7z" />
<glyph unicode="&#xe141;" d="M596 1192q121 0 231.5 -47.5t190 -127t127 -190t47.5 -231.5t-47.5 -231.5t-127 -190.5t-190 -127t-231.5 -47t-231.5 47t-190.5 127t-127 190.5t-47 231.5t47 231.5t127 190t190.5 127t231.5 47.5zM596 1010q-112 0 -207.5 -55.5t-151 -151t-55.5 -207.5t55.5 -207.5 t151 -151t207.5 -55.5t207.5 55.5t151 151t55.5 207.5t-55.5 207.5t-151 151t-207.5 55.5zM454.5 905q22.5 0 38.5 -16t16 -38.5t-16 -39t-38.5 -16.5t-38.5 16.5t-16 39t16 38.5t38.5 16zM754.5 905q22.5 0 38.5 -16t16 -38.5t-16 -39t-38 -16.5q-14 0 -29 10l-55 -145 q17 -23 17 -51q0 -36 -25.5 -61.5t-61.5 -25.5t-61.5 25.5t-25.5 61.5q0 32 20.5 56.5t51.5 29.5l122 126l1 1q-9 14 -9 28q0 23 16 39t38.5 16zM345.5 709q22.5 0 38.5 -16t16 -38.5t-16 -38.5t-38.5 -16t-38.5 16t-16 38.5t16 38.5t38.5 16zM854.5 709q22.5 0 38.5 -16 t16 -38.5t-16 -38.5t-38.5 -16t-38.5 16t-16 38.5t16 38.5t38.5 16z" />
<glyph unicode="&#xe142;" d="M546 173l469 470q91 91 99 192q7 98 -52 175.5t-154 94.5q-22 4 -47 4q-34 0 -66.5 -10t-56.5 -23t-55.5 -38t-48 -41.5t-48.5 -47.5q-376 -375 -391 -390q-30 -27 -45 -41.5t-37.5 -41t-32 -46.5t-16 -47.5t-1.5 -56.5q9 -62 53.5 -95t99.5 -33q74 0 125 51l548 548 q36 36 20 75q-7 16 -21.5 26t-32.5 10q-26 0 -50 -23q-13 -12 -39 -38l-341 -338q-15 -15 -35.5 -15.5t-34.5 13.5t-14 34.5t14 34.5q327 333 361 367q35 35 67.5 51.5t78.5 16.5q14 0 29 -1q44 -8 74.5 -35.5t43.5 -68.5q14 -47 2 -96.5t-47 -84.5q-12 -11 -32 -32 t-79.5 -81t-114.5 -115t-124.5 -123.5t-123 -119.5t-96.5 -89t-57 -45q-56 -27 -120 -27q-70 0 -129 32t-93 89q-48 78 -35 173t81 163l511 511q71 72 111 96q91 55 198 55q80 0 152 -33q78 -36 129.5 -103t66.5 -154q17 -93 -11 -183.5t-94 -156.5l-482 -476 q-15 -15 -36 -16t-37 14t-17.5 34t14.5 35z" />
<glyph unicode="&#xe143;" d="M649 949q48 68 109.5 104t121.5 38.5t118.5 -20t102.5 -64t71 -100.5t27 -123q0 -57 -33.5 -117.5t-94 -124.5t-126.5 -127.5t-150 -152.5t-146 -174q-62 85 -145.5 174t-150 152.5t-126.5 127.5t-93.5 124.5t-33.5 117.5q0 64 28 123t73 100.5t104 64t119 20 t120.5 -38.5t104.5 -104zM896 972q-33 0 -64.5 -19t-56.5 -46t-47.5 -53.5t-43.5 -45.5t-37.5 -19t-36 19t-40 45.5t-43 53.5t-54 46t-65.5 19q-67 0 -122.5 -55.5t-55.5 -132.5q0 -23 13.5 -51t46 -65t57.5 -63t76 -75l22 -22q15 -14 44 -44t50.5 -51t46 -44t41 -35t23 -12 t23.5 12t42.5 36t46 44t52.5 52t44 43q4 4 12 13q43 41 63.5 62t52 55t46 55t26 46t11.5 44q0 79 -53 133.5t-120 54.5z" />
<glyph unicode="&#xe144;" d="M776.5 1214q93.5 0 159.5 -66l141 -141q66 -66 66 -160q0 -42 -28 -95.5t-62 -87.5l-29 -29q-31 53 -77 99l-18 18l95 95l-247 248l-389 -389l212 -212l-105 -106l-19 18l-141 141q-66 66 -66 159t66 159l283 283q65 66 158.5 66zM600 706l105 105q10 -8 19 -17l141 -141 q66 -66 66 -159t-66 -159l-283 -283q-66 -66 -159 -66t-159 66l-141 141q-66 66 -66 159.5t66 159.5l55 55q29 -55 75 -102l18 -17l-95 -95l247 -248l389 389z" />
<glyph unicode="&#xe145;" d="M603 1200q85 0 162 -15t127 -38t79 -48t29 -46v-953q0 -41 -29.5 -70.5t-70.5 -29.5h-600q-41 0 -70.5 29.5t-29.5 70.5v953q0 21 30 46.5t81 48t129 37.5t163 15zM300 1000v-700h600v700h-600zM600 254q-43 0 -73.5 -30.5t-30.5 -73.5t30.5 -73.5t73.5 -30.5t73.5 30.5 t30.5 73.5t-30.5 73.5t-73.5 30.5z" />
<glyph unicode="&#xe146;" d="M902 1185l283 -282q15 -15 15 -36t-14.5 -35.5t-35.5 -14.5t-35 15l-36 35l-279 -267v-300l-212 210l-308 -307l-280 -203l203 280l307 308l-210 212h300l267 279l-35 36q-15 14 -15 35t14.5 35.5t35.5 14.5t35 -15z" />
<glyph unicode="&#xe148;" d="M700 1248v-78q38 -5 72.5 -14.5t75.5 -31.5t71 -53.5t52 -84t24 -118.5h-159q-4 36 -10.5 59t-21 45t-40 35.5t-64.5 20.5v-307l64 -13q34 -7 64 -16.5t70 -32t67.5 -52.5t47.5 -80t20 -112q0 -139 -89 -224t-244 -97v-77h-100v79q-150 16 -237 103q-40 40 -52.5 93.5 t-15.5 139.5h139q5 -77 48.5 -126t117.5 -65v335l-27 8q-46 14 -79 26.5t-72 36t-63 52t-40 72.5t-16 98q0 70 25 126t67.5 92t94.5 57t110 27v77h100zM600 754v274q-29 -4 -50 -11t-42 -21.5t-31.5 -41.5t-10.5 -65q0 -29 7 -50.5t16.5 -34t28.5 -22.5t31.5 -14t37.5 -10 q9 -3 13 -4zM700 547v-310q22 2 42.5 6.5t45 15.5t41.5 27t29 42t12 59.5t-12.5 59.5t-38 44.5t-53 31t-66.5 24.5z" />
<glyph unicode="&#xe149;" d="M561 1197q84 0 160.5 -40t123.5 -109.5t47 -147.5h-153q0 40 -19.5 71.5t-49.5 48.5t-59.5 26t-55.5 9q-37 0 -79 -14.5t-62 -35.5q-41 -44 -41 -101q0 -26 13.5 -63t26.5 -61t37 -66q6 -9 9 -14h241v-100h-197q8 -50 -2.5 -115t-31.5 -95q-45 -62 -99 -112 q34 10 83 17.5t71 7.5q32 1 102 -16t104 -17q83 0 136 30l50 -147q-31 -19 -58 -30.5t-55 -15.5t-42 -4.5t-46 -0.5q-23 0 -76 17t-111 32.5t-96 11.5q-39 -3 -82 -16t-67 -25l-23 -11l-55 145q4 3 16 11t15.5 10.5t13 9t15.5 12t14.5 14t17.5 18.5q48 55 54 126.5 t-30 142.5h-221v100h166q-23 47 -44 104q-7 20 -12 41.5t-6 55.5t6 66.5t29.5 70.5t58.5 71q97 88 263 88z" />
<glyph unicode="&#xe150;" d="M400 300h150q21 0 25 -11t-10 -25l-230 -250q-14 -15 -35 -15t-35 15l-230 250q-14 14 -10 25t25 11h150v900h200v-900zM935 1184l230 -249q14 -14 10 -24.5t-25 -10.5h-150v-900h-200v900h-150q-21 0 -25 10.5t10 24.5l230 249q14 15 35 15t35 -15z" />
<glyph unicode="&#xe151;" d="M1000 700h-100v100h-100v-100h-100v500h300v-500zM400 300h150q21 0 25 -11t-10 -25l-230 -250q-14 -15 -35 -15t-35 15l-230 250q-14 14 -10 25t25 11h150v900h200v-900zM801 1100v-200h100v200h-100zM1000 350l-200 -250h200v-100h-300v150l200 250h-200v100h300v-150z " />
<glyph unicode="&#xe152;" d="M400 300h150q21 0 25 -11t-10 -25l-230 -250q-14 -15 -35 -15t-35 15l-230 250q-14 14 -10 25t25 11h150v900h200v-900zM1000 1050l-200 -250h200v-100h-300v150l200 250h-200v100h300v-150zM1000 0h-100v100h-100v-100h-100v500h300v-500zM801 400v-200h100v200h-100z " />
<glyph unicode="&#xe153;" d="M400 300h150q21 0 25 -11t-10 -25l-230 -250q-14 -15 -35 -15t-35 15l-230 250q-14 14 -10 25t25 11h150v900h200v-900zM1000 700h-100v400h-100v100h200v-500zM1100 0h-100v100h-200v400h300v-500zM901 400v-200h100v200h-100z" />
<glyph unicode="&#xe154;" d="M400 300h150q21 0 25 -11t-10 -25l-230 -250q-14 -15 -35 -15t-35 15l-230 250q-14 14 -10 25t25 11h150v900h200v-900zM1100 700h-100v100h-200v400h300v-500zM901 1100v-200h100v200h-100zM1000 0h-100v400h-100v100h200v-500z" />
<glyph unicode="&#xe155;" d="M400 300h150q21 0 25 -11t-10 -25l-230 -250q-14 -15 -35 -15t-35 15l-230 250q-14 14 -10 25t25 11h150v900h200v-900zM900 1000h-200v200h200v-200zM1000 700h-300v200h300v-200zM1100 400h-400v200h400v-200zM1200 100h-500v200h500v-200z" />
<glyph unicode="&#xe156;" d="M400 300h150q21 0 25 -11t-10 -25l-230 -250q-14 -15 -35 -15t-35 15l-230 250q-14 14 -10 25t25 11h150v900h200v-900zM1200 1000h-500v200h500v-200zM1100 700h-400v200h400v-200zM1000 400h-300v200h300v-200zM900 100h-200v200h200v-200z" />
<glyph unicode="&#xe157;" d="M350 1100h400q162 0 256 -93.5t94 -256.5v-400q0 -165 -93.5 -257.5t-256.5 -92.5h-400q-165 0 -257.5 92.5t-92.5 257.5v400q0 165 92.5 257.5t257.5 92.5zM800 900h-500q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5 v500q0 41 -29.5 70.5t-70.5 29.5z" />
<glyph unicode="&#xe158;" d="M350 1100h400q165 0 257.5 -92.5t92.5 -257.5v-400q0 -165 -92.5 -257.5t-257.5 -92.5h-400q-163 0 -256.5 92.5t-93.5 257.5v400q0 163 94 256.5t256 93.5zM800 900h-500q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5 v500q0 41 -29.5 70.5t-70.5 29.5zM440 770l253 -190q17 -12 17 -30t-17 -30l-253 -190q-16 -12 -28 -6.5t-12 26.5v400q0 21 12 26.5t28 -6.5z" />
<glyph unicode="&#xe159;" d="M350 1100h400q163 0 256.5 -94t93.5 -256v-400q0 -165 -92.5 -257.5t-257.5 -92.5h-400q-165 0 -257.5 92.5t-92.5 257.5v400q0 163 92.5 256.5t257.5 93.5zM800 900h-500q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5 v500q0 41 -29.5 70.5t-70.5 29.5zM350 700h400q21 0 26.5 -12t-6.5 -28l-190 -253q-12 -17 -30 -17t-30 17l-190 253q-12 16 -6.5 28t26.5 12z" />
<glyph unicode="&#xe160;" d="M350 1100h400q165 0 257.5 -92.5t92.5 -257.5v-400q0 -163 -92.5 -256.5t-257.5 -93.5h-400q-163 0 -256.5 94t-93.5 256v400q0 165 92.5 257.5t257.5 92.5zM800 900h-500q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5 v500q0 41 -29.5 70.5t-70.5 29.5zM580 693l190 -253q12 -16 6.5 -28t-26.5 -12h-400q-21 0 -26.5 12t6.5 28l190 253q12 17 30 17t30 -17z" />
<glyph unicode="&#xe161;" d="M550 1100h400q165 0 257.5 -92.5t92.5 -257.5v-400q0 -165 -92.5 -257.5t-257.5 -92.5h-400q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5h450q41 0 70.5 29.5t29.5 70.5v500q0 41 -29.5 70.5t-70.5 29.5h-450q-21 0 -35.5 14.5t-14.5 35.5v100 q0 21 14.5 35.5t35.5 14.5zM338 867l324 -284q16 -14 16 -33t-16 -33l-324 -284q-16 -14 -27 -9t-11 26v150h-250q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5h250v150q0 21 11 26t27 -9z" />
<glyph unicode="&#xe162;" d="M793 1182l9 -9q8 -10 5 -27q-3 -11 -79 -225.5t-78 -221.5l300 1q24 0 32.5 -17.5t-5.5 -35.5q-1 0 -133.5 -155t-267 -312.5t-138.5 -162.5q-12 -15 -26 -15h-9l-9 8q-9 11 -4 32q2 9 42 123.5t79 224.5l39 110h-302q-23 0 -31 19q-10 21 6 41q75 86 209.5 237.5 t228 257t98.5 111.5q9 16 25 16h9z" />
<glyph unicode="&#xe163;" d="M350 1100h400q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-450q-41 0 -70.5 -29.5t-29.5 -70.5v-500q0 -41 29.5 -70.5t70.5 -29.5h450q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-165 0 -257.5 92.5t-92.5 257.5v400 q0 165 92.5 257.5t257.5 92.5zM938 867l324 -284q16 -14 16 -33t-16 -33l-324 -284q-16 -14 -27 -9t-11 26v150h-250q-21 0 -35.5 14.5t-14.5 35.5v200q0 21 14.5 35.5t35.5 14.5h250v150q0 21 11 26t27 -9z" />
<glyph unicode="&#xe164;" d="M750 1200h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -10.5 -25t-24.5 10l-109 109l-312 -312q-15 -15 -35.5 -15t-35.5 15l-141 141q-15 15 -15 35.5t15 35.5l312 312l-109 109q-14 14 -10 24.5t25 10.5zM456 900h-156q-41 0 -70.5 -29.5t-29.5 -70.5v-500 q0 -41 29.5 -70.5t70.5 -29.5h500q41 0 70.5 29.5t29.5 70.5v148l200 200v-298q0 -165 -93.5 -257.5t-256.5 -92.5h-400q-165 0 -257.5 92.5t-92.5 257.5v400q0 165 92.5 257.5t257.5 92.5h300z" />
<glyph unicode="&#xe165;" d="M600 1186q119 0 227.5 -46.5t187 -125t125 -187t46.5 -227.5t-46.5 -227.5t-125 -187t-187 -125t-227.5 -46.5t-227.5 46.5t-187 125t-125 187t-46.5 227.5t46.5 227.5t125 187t187 125t227.5 46.5zM600 1022q-115 0 -212 -56.5t-153.5 -153.5t-56.5 -212t56.5 -212 t153.5 -153.5t212 -56.5t212 56.5t153.5 153.5t56.5 212t-56.5 212t-153.5 153.5t-212 56.5zM600 794q80 0 137 -57t57 -137t-57 -137t-137 -57t-137 57t-57 137t57 137t137 57z" />
<glyph unicode="&#xe166;" d="M450 1200h200q21 0 35.5 -14.5t14.5 -35.5v-350h245q20 0 25 -11t-9 -26l-383 -426q-14 -15 -33.5 -15t-32.5 15l-379 426q-13 15 -8.5 26t25.5 11h250v350q0 21 14.5 35.5t35.5 14.5zM50 300h1000q21 0 35.5 -14.5t14.5 -35.5v-250h-1100v250q0 21 14.5 35.5t35.5 14.5z M900 200v-50h100v50h-100z" />
<glyph unicode="&#xe167;" d="M583 1182l378 -435q14 -15 9 -31t-26 -16h-244v-250q0 -20 -17 -35t-39 -15h-200q-20 0 -32 14.5t-12 35.5v250h-250q-20 0 -25.5 16.5t8.5 31.5l383 431q14 16 33.5 17t33.5 -14zM50 300h1000q21 0 35.5 -14.5t14.5 -35.5v-250h-1100v250q0 21 14.5 35.5t35.5 14.5z M900 200v-50h100v50h-100z" />
<glyph unicode="&#xe168;" d="M396 723l369 369q7 7 17.5 7t17.5 -7l139 -139q7 -8 7 -18.5t-7 -17.5l-525 -525q-7 -8 -17.5 -8t-17.5 8l-292 291q-7 8 -7 18t7 18l139 139q8 7 18.5 7t17.5 -7zM50 300h1000q21 0 35.5 -14.5t14.5 -35.5v-250h-1100v250q0 21 14.5 35.5t35.5 14.5zM900 200v-50h100v50 h-100z" />
<glyph unicode="&#xe169;" d="M135 1023l142 142q14 14 35 14t35 -14l77 -77l-212 -212l-77 76q-14 15 -14 36t14 35zM655 855l210 210q14 14 24.5 10t10.5 -25l-2 -599q-1 -20 -15.5 -35t-35.5 -15l-597 -1q-21 0 -25 10.5t10 24.5l208 208l-154 155l212 212zM50 300h1000q21 0 35.5 -14.5t14.5 -35.5 v-250h-1100v250q0 21 14.5 35.5t35.5 14.5zM900 200v-50h100v50h-100z" />
<glyph unicode="&#xe170;" d="M350 1200l599 -2q20 -1 35 -15.5t15 -35.5l1 -597q0 -21 -10.5 -25t-24.5 10l-208 208l-155 -154l-212 212l155 154l-210 210q-14 14 -10 24.5t25 10.5zM524 512l-76 -77q-15 -14 -36 -14t-35 14l-142 142q-14 14 -14 35t14 35l77 77zM50 300h1000q21 0 35.5 -14.5 t14.5 -35.5v-250h-1100v250q0 21 14.5 35.5t35.5 14.5zM900 200v-50h100v50h-100z" />
<glyph unicode="&#xe171;" d="M1200 103l-483 276l-314 -399v423h-399l1196 796v-1096zM483 424v-230l683 953z" />
<glyph unicode="&#xe172;" d="M1100 1000v-850q0 -21 -14.5 -35.5t-35.5 -14.5h-150v400h-700v-400h-150q-21 0 -35.5 14.5t-14.5 35.5v1000q0 20 14.5 35t35.5 15h250v-300h500v300h100zM700 1000h-100v200h100v-200z" />
<glyph unicode="&#xe173;" d="M1100 1000l-2 -149l-299 -299l-95 95q-9 9 -21.5 9t-21.5 -9l-149 -147h-312v-400h-150q-21 0 -35.5 14.5t-14.5 35.5v1000q0 20 14.5 35t35.5 15h250v-300h500v300h100zM700 1000h-100v200h100v-200zM1132 638l106 -106q7 -7 7 -17.5t-7 -17.5l-420 -421q-8 -7 -18 -7 t-18 7l-202 203q-8 7 -8 17.5t8 17.5l106 106q7 8 17.5 8t17.5 -8l79 -79l297 297q7 7 17.5 7t17.5 -7z" />
<glyph unicode="&#xe174;" d="M1100 1000v-269l-103 -103l-134 134q-15 15 -33.5 16.5t-34.5 -12.5l-266 -266h-329v-400h-150q-21 0 -35.5 14.5t-14.5 35.5v1000q0 20 14.5 35t35.5 15h250v-300h500v300h100zM700 1000h-100v200h100v-200zM1202 572l70 -70q15 -15 15 -35.5t-15 -35.5l-131 -131 l131 -131q15 -15 15 -35.5t-15 -35.5l-70 -70q-15 -15 -35.5 -15t-35.5 15l-131 131l-131 -131q-15 -15 -35.5 -15t-35.5 15l-70 70q-15 15 -15 35.5t15 35.5l131 131l-131 131q-15 15 -15 35.5t15 35.5l70 70q15 15 35.5 15t35.5 -15l131 -131l131 131q15 15 35.5 15 t35.5 -15z" />
<glyph unicode="&#xe175;" d="M1100 1000v-300h-350q-21 0 -35.5 -14.5t-14.5 -35.5v-150h-500v-400h-150q-21 0 -35.5 14.5t-14.5 35.5v1000q0 20 14.5 35t35.5 15h250v-300h500v300h100zM700 1000h-100v200h100v-200zM850 600h100q21 0 35.5 -14.5t14.5 -35.5v-250h150q21 0 25 -10.5t-10 -24.5 l-230 -230q-14 -14 -35 -14t-35 14l-230 230q-14 14 -10 24.5t25 10.5h150v250q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe176;" d="M1100 1000v-400l-165 165q-14 15 -35 15t-35 -15l-263 -265h-402v-400h-150q-21 0 -35.5 14.5t-14.5 35.5v1000q0 20 14.5 35t35.5 15h250v-300h500v300h100zM700 1000h-100v200h100v-200zM935 565l230 -229q14 -15 10 -25.5t-25 -10.5h-150v-250q0 -20 -14.5 -35 t-35.5 -15h-100q-21 0 -35.5 15t-14.5 35v250h-150q-21 0 -25 10.5t10 25.5l230 229q14 15 35 15t35 -15z" />
<glyph unicode="&#xe177;" d="M50 1100h1100q21 0 35.5 -14.5t14.5 -35.5v-150h-1200v150q0 21 14.5 35.5t35.5 14.5zM1200 800v-550q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5v550h1200zM100 500v-200h400v200h-400z" />
<glyph unicode="&#xe178;" d="M935 1165l248 -230q14 -14 14 -35t-14 -35l-248 -230q-14 -14 -24.5 -10t-10.5 25v150h-400v200h400v150q0 21 10.5 25t24.5 -10zM200 800h-50q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5h50v-200zM400 800h-100v200h100v-200zM18 435l247 230 q14 14 24.5 10t10.5 -25v-150h400v-200h-400v-150q0 -21 -10.5 -25t-24.5 10l-247 230q-15 14 -15 35t15 35zM900 300h-100v200h100v-200zM1000 500h51q20 0 34.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-34.5 -14.5h-51v200z" />
<glyph unicode="&#xe179;" d="M862 1073l276 116q25 18 43.5 8t18.5 -41v-1106q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v397q-4 1 -11 5t-24 17.5t-30 29t-24 42t-11 56.5v359q0 31 18.5 65t43.5 52zM550 1200q22 0 34.5 -12.5t14.5 -24.5l1 -13v-450q0 -28 -10.5 -59.5 t-25 -56t-29 -45t-25.5 -31.5l-10 -11v-447q0 -21 -14.5 -35.5t-35.5 -14.5h-200q-21 0 -35.5 14.5t-14.5 35.5v447q-4 4 -11 11.5t-24 30.5t-30 46t-24 55t-11 60v450q0 2 0.5 5.5t4 12t8.5 15t14.5 12t22.5 5.5q20 0 32.5 -12.5t14.5 -24.5l3 -13v-350h100v350v5.5t2.5 12 t7 15t15 12t25.5 5.5q23 0 35.5 -12.5t13.5 -24.5l1 -13v-350h100v350q0 2 0.5 5.5t3 12t7 15t15 12t24.5 5.5z" />
<glyph unicode="&#xe180;" d="M1200 1100v-56q-4 0 -11 -0.5t-24 -3t-30 -7.5t-24 -15t-11 -24v-888q0 -22 25 -34.5t50 -13.5l25 -2v-56h-400v56q75 0 87.5 6.5t12.5 43.5v394h-500v-394q0 -37 12.5 -43.5t87.5 -6.5v-56h-400v56q4 0 11 0.5t24 3t30 7.5t24 15t11 24v888q0 22 -25 34.5t-50 13.5 l-25 2v56h400v-56q-75 0 -87.5 -6.5t-12.5 -43.5v-394h500v394q0 37 -12.5 43.5t-87.5 6.5v56h400z" />
<glyph unicode="&#xe181;" d="M675 1000h375q21 0 35.5 -14.5t14.5 -35.5v-150h-105l-295 -98v98l-200 200h-400l100 100h375zM100 900h300q41 0 70.5 -29.5t29.5 -70.5v-500q0 -41 -29.5 -70.5t-70.5 -29.5h-300q-41 0 -70.5 29.5t-29.5 70.5v500q0 41 29.5 70.5t70.5 29.5zM100 800v-200h300v200 h-300zM1100 535l-400 -133v163l400 133v-163zM100 500v-200h300v200h-300zM1100 398v-248q0 -21 -14.5 -35.5t-35.5 -14.5h-375l-100 -100h-375l-100 100h400l200 200h105z" />
<glyph unicode="&#xe182;" d="M17 1007l162 162q17 17 40 14t37 -22l139 -194q14 -20 11 -44.5t-20 -41.5l-119 -118q102 -142 228 -268t267 -227l119 118q17 17 42.5 19t44.5 -12l192 -136q19 -14 22.5 -37.5t-13.5 -40.5l-163 -162q-3 -1 -9.5 -1t-29.5 2t-47.5 6t-62.5 14.5t-77.5 26.5t-90 42.5 t-101.5 60t-111 83t-119 108.5q-74 74 -133.5 150.5t-94.5 138.5t-60 119.5t-34.5 100t-15 74.5t-4.5 48z" />
<glyph unicode="&#xe183;" d="M600 1100q92 0 175 -10.5t141.5 -27t108.5 -36.5t81.5 -40t53.5 -37t31 -27l9 -10v-200q0 -21 -14.5 -33t-34.5 -9l-202 34q-20 3 -34.5 20t-14.5 38v146q-141 24 -300 24t-300 -24v-146q0 -21 -14.5 -38t-34.5 -20l-202 -34q-20 -3 -34.5 9t-14.5 33v200q3 4 9.5 10.5 t31 26t54 37.5t80.5 39.5t109 37.5t141 26.5t175 10.5zM600 795q56 0 97 -9.5t60 -23.5t30 -28t12 -24l1 -10v-50l365 -303q14 -15 24.5 -40t10.5 -45v-212q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5v212q0 20 10.5 45t24.5 40l365 303v50 q0 4 1 10.5t12 23t30 29t60 22.5t97 10z" />
<glyph unicode="&#xe184;" d="M1100 700l-200 -200h-600l-200 200v500h200v-200h200v200h200v-200h200v200h200v-500zM250 400h700q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-12l137 -100h-950l137 100h-12q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5zM50 100h1100q21 0 35.5 -14.5 t14.5 -35.5v-50h-1200v50q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe185;" d="M700 1100h-100q-41 0 -70.5 -29.5t-29.5 -70.5v-1000h300v1000q0 41 -29.5 70.5t-70.5 29.5zM1100 800h-100q-41 0 -70.5 -29.5t-29.5 -70.5v-700h300v700q0 41 -29.5 70.5t-70.5 29.5zM400 0h-300v400q0 41 29.5 70.5t70.5 29.5h100q41 0 70.5 -29.5t29.5 -70.5v-400z " />
<glyph unicode="&#xe186;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM500 700h-200v-100h200v-300h-300v100h200v100h-200v300h300v-100zM900 700v-300l-100 -100h-200v500h200z M700 700v-300h100v300h-100z" />
<glyph unicode="&#xe187;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM500 300h-100v200h-100v-200h-100v500h100v-200h100v200h100v-500zM900 700v-300l-100 -100h-200v500h200z M700 700v-300h100v300h-100z" />
<glyph unicode="&#xe188;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM500 700h-200v-300h200v-100h-300v500h300v-100zM900 700h-200v-300h200v-100h-300v500h300v-100z" />
<glyph unicode="&#xe189;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM500 400l-300 150l300 150v-300zM900 550l-300 -150v300z" />
<glyph unicode="&#xe190;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM900 300h-700v500h700v-500zM800 700h-130q-38 0 -66.5 -43t-28.5 -108t27 -107t68 -42h130v300zM300 700v-300 h130q41 0 68 42t27 107t-28.5 108t-66.5 43h-130z" />
<glyph unicode="&#xe191;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM500 700h-200v-100h200v-300h-300v100h200v100h-200v300h300v-100zM900 300h-100v400h-100v100h200v-500z M700 300h-100v100h100v-100z" />
<glyph unicode="&#xe192;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM300 700h200v-400h-300v500h100v-100zM900 300h-100v400h-100v100h200v-500zM300 600v-200h100v200h-100z M700 300h-100v100h100v-100z" />
<glyph unicode="&#xe193;" d="M200 1100h700q124 0 212 -88t88 -212v-500q0 -124 -88 -212t-212 -88h-700q-124 0 -212 88t-88 212v500q0 124 88 212t212 88zM100 900v-700h900v700h-900zM500 500l-199 -200h-100v50l199 200v150h-200v100h300v-300zM900 300h-100v400h-100v100h200v-500zM701 300h-100 v100h100v-100z" />
<glyph unicode="&#xe194;" d="M600 1191q120 0 229.5 -47t188.5 -126t126 -188.5t47 -229.5t-47 -229.5t-126 -188.5t-188.5 -126t-229.5 -47t-229.5 47t-188.5 126t-126 188.5t-47 229.5t47 229.5t126 188.5t188.5 126t229.5 47zM600 1021q-114 0 -211 -56.5t-153.5 -153.5t-56.5 -211t56.5 -211 t153.5 -153.5t211 -56.5t211 56.5t153.5 153.5t56.5 211t-56.5 211t-153.5 153.5t-211 56.5zM800 700h-300v-200h300v-100h-300l-100 100v200l100 100h300v-100z" />
<glyph unicode="&#xe195;" d="M600 1191q120 0 229.5 -47t188.5 -126t126 -188.5t47 -229.5t-47 -229.5t-126 -188.5t-188.5 -126t-229.5 -47t-229.5 47t-188.5 126t-126 188.5t-47 229.5t47 229.5t126 188.5t188.5 126t229.5 47zM600 1021q-114 0 -211 -56.5t-153.5 -153.5t-56.5 -211t56.5 -211 t153.5 -153.5t211 -56.5t211 56.5t153.5 153.5t56.5 211t-56.5 211t-153.5 153.5t-211 56.5zM800 700v-100l-50 -50l100 -100v-50h-100l-100 100h-150v-100h-100v400h300zM500 700v-100h200v100h-200z" />
<glyph unicode="&#xe197;" d="M503 1089q110 0 200.5 -59.5t134.5 -156.5q44 14 90 14q120 0 205 -86.5t85 -207t-85 -207t-205 -86.5h-128v250q0 21 -14.5 35.5t-35.5 14.5h-300q-21 0 -35.5 -14.5t-14.5 -35.5v-250h-222q-80 0 -136 57.5t-56 136.5q0 69 43 122.5t108 67.5q-2 19 -2 37q0 100 49 185 t134 134t185 49zM525 500h150q10 0 17.5 -7.5t7.5 -17.5v-275h137q21 0 26 -11.5t-8 -27.5l-223 -244q-13 -16 -32 -16t-32 16l-223 244q-13 16 -8 27.5t26 11.5h137v275q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe198;" d="M502 1089q110 0 201 -59.5t135 -156.5q43 15 89 15q121 0 206 -86.5t86 -206.5q0 -99 -60 -181t-150 -110l-378 360q-13 16 -31.5 16t-31.5 -16l-381 -365h-9q-79 0 -135.5 57.5t-56.5 136.5q0 69 43 122.5t108 67.5q-2 19 -2 38q0 100 49 184.5t133.5 134t184.5 49.5z M632 467l223 -228q13 -16 8 -27.5t-26 -11.5h-137v-275q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v275h-137q-21 0 -26 11.5t8 27.5q199 204 223 228q19 19 31.5 19t32.5 -19z" />
<glyph unicode="&#xe199;" d="M700 100v100h400l-270 300h170l-270 300h170l-300 333l-300 -333h170l-270 -300h170l-270 -300h400v-100h-50q-21 0 -35.5 -14.5t-14.5 -35.5v-50h400v50q0 21 -14.5 35.5t-35.5 14.5h-50z" />
<glyph unicode="&#xe200;" d="M600 1179q94 0 167.5 -56.5t99.5 -145.5q89 -6 150.5 -71.5t61.5 -155.5q0 -61 -29.5 -112.5t-79.5 -82.5q9 -29 9 -55q0 -74 -52.5 -126.5t-126.5 -52.5q-55 0 -100 30v-251q21 0 35.5 -14.5t14.5 -35.5v-50h-300v50q0 21 14.5 35.5t35.5 14.5v251q-45 -30 -100 -30 q-74 0 -126.5 52.5t-52.5 126.5q0 18 4 38q-47 21 -75.5 65t-28.5 97q0 74 52.5 126.5t126.5 52.5q5 0 23 -2q0 2 -1 10t-1 13q0 116 81.5 197.5t197.5 81.5z" />
<glyph unicode="&#xe201;" d="M1010 1010q111 -111 150.5 -260.5t0 -299t-150.5 -260.5q-83 -83 -191.5 -126.5t-218.5 -43.5t-218.5 43.5t-191.5 126.5q-111 111 -150.5 260.5t0 299t150.5 260.5q83 83 191.5 126.5t218.5 43.5t218.5 -43.5t191.5 -126.5zM476 1065q-4 0 -8 -1q-121 -34 -209.5 -122.5 t-122.5 -209.5q-4 -12 2.5 -23t18.5 -14l36 -9q3 -1 7 -1q23 0 29 22q27 96 98 166q70 71 166 98q11 3 17.5 13.5t3.5 22.5l-9 35q-3 13 -14 19q-7 4 -15 4zM512 920q-4 0 -9 -2q-80 -24 -138.5 -82.5t-82.5 -138.5q-4 -13 2 -24t19 -14l34 -9q4 -1 8 -1q22 0 28 21 q18 58 58.5 98.5t97.5 58.5q12 3 18 13.5t3 21.5l-9 35q-3 12 -14 19q-7 4 -15 4zM719.5 719.5q-49.5 49.5 -119.5 49.5t-119.5 -49.5t-49.5 -119.5t49.5 -119.5t119.5 -49.5t119.5 49.5t49.5 119.5t-49.5 119.5zM855 551q-22 0 -28 -21q-18 -58 -58.5 -98.5t-98.5 -57.5 q-11 -4 -17 -14.5t-3 -21.5l9 -35q3 -12 14 -19q7 -4 15 -4q4 0 9 2q80 24 138.5 82.5t82.5 138.5q4 13 -2.5 24t-18.5 14l-34 9q-4 1 -8 1zM1000 515q-23 0 -29 -22q-27 -96 -98 -166q-70 -71 -166 -98q-11 -3 -17.5 -13.5t-3.5 -22.5l9 -35q3 -13 14 -19q7 -4 15 -4 q4 0 8 1q121 34 209.5 122.5t122.5 209.5q4 12 -2.5 23t-18.5 14l-36 9q-3 1 -7 1z" />
<glyph unicode="&#xe202;" d="M700 800h300v-380h-180v200h-340v-200h-380v755q0 10 7.5 17.5t17.5 7.5h575v-400zM1000 900h-200v200zM700 300h162l-212 -212l-212 212h162v200h100v-200zM520 0h-395q-10 0 -17.5 7.5t-7.5 17.5v395zM1000 220v-195q0 -10 -7.5 -17.5t-17.5 -7.5h-195z" />
<glyph unicode="&#xe203;" d="M700 800h300v-520l-350 350l-550 -550v1095q0 10 7.5 17.5t17.5 7.5h575v-400zM1000 900h-200v200zM862 200h-162v-200h-100v200h-162l212 212zM480 0h-355q-10 0 -17.5 7.5t-7.5 17.5v55h380v-80zM1000 80v-55q0 -10 -7.5 -17.5t-17.5 -7.5h-155v80h180z" />
<glyph unicode="&#xe204;" d="M1162 800h-162v-200h100l100 -100h-300v300h-162l212 212zM200 800h200q27 0 40 -2t29.5 -10.5t23.5 -30t7 -57.5h300v-100h-600l-200 -350v450h100q0 36 7 57.5t23.5 30t29.5 10.5t40 2zM800 400h240l-240 -400h-800l300 500h500v-100z" />
<glyph unicode="&#xe205;" d="M650 1100h100q21 0 35.5 -14.5t14.5 -35.5v-50h50q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-300q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5h50v50q0 21 14.5 35.5t35.5 14.5zM1000 850v150q41 0 70.5 -29.5t29.5 -70.5v-800 q0 -41 -29.5 -70.5t-70.5 -29.5h-600q-1 0 -20 4l246 246l-326 326v324q0 41 29.5 70.5t70.5 29.5v-150q0 -62 44 -106t106 -44h300q62 0 106 44t44 106zM412 250l-212 -212v162h-200v100h200v162z" />
<glyph unicode="&#xe206;" d="M450 1100h100q21 0 35.5 -14.5t14.5 -35.5v-50h50q21 0 35.5 -14.5t14.5 -35.5v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-300q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5h50v50q0 21 14.5 35.5t35.5 14.5zM800 850v150q41 0 70.5 -29.5t29.5 -70.5v-500 h-200v-300h200q0 -36 -7 -57.5t-23.5 -30t-29.5 -10.5t-40 -2h-600q-41 0 -70.5 29.5t-29.5 70.5v800q0 41 29.5 70.5t70.5 29.5v-150q0 -62 44 -106t106 -44h300q62 0 106 44t44 106zM1212 250l-212 -212v162h-200v100h200v162z" />
<glyph unicode="&#xe209;" d="M658 1197l637 -1104q23 -38 7 -65.5t-60 -27.5h-1276q-44 0 -60 27.5t7 65.5l637 1104q22 39 54 39t54 -39zM704 800h-208q-20 0 -32 -14.5t-8 -34.5l58 -302q4 -20 21.5 -34.5t37.5 -14.5h54q20 0 37.5 14.5t21.5 34.5l58 302q4 20 -8 34.5t-32 14.5zM500 300v-100h200 v100h-200z" />
<glyph unicode="&#xe210;" d="M425 1100h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5zM425 800h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5 t17.5 7.5zM825 800h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5zM25 500h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v150 q0 10 7.5 17.5t17.5 7.5zM425 500h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5zM825 500h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5 v150q0 10 7.5 17.5t17.5 7.5zM25 200h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5zM425 200h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5 t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5zM825 200h250q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-250q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe211;" d="M700 1200h100v-200h-100v-100h350q62 0 86.5 -39.5t-3.5 -94.5l-66 -132q-41 -83 -81 -134h-772q-40 51 -81 134l-66 132q-28 55 -3.5 94.5t86.5 39.5h350v100h-100v200h100v100h200v-100zM250 400h700q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-12l137 -100 h-950l138 100h-13q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5zM50 100h1100q21 0 35.5 -14.5t14.5 -35.5v-50h-1200v50q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe212;" d="M600 1300q40 0 68.5 -29.5t28.5 -70.5h-194q0 41 28.5 70.5t68.5 29.5zM443 1100h314q18 -37 18 -75q0 -8 -3 -25h328q41 0 44.5 -16.5t-30.5 -38.5l-175 -145h-678l-178 145q-34 22 -29 38.5t46 16.5h328q-3 17 -3 25q0 38 18 75zM250 700h700q21 0 35.5 -14.5 t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-150v-200l275 -200h-950l275 200v200h-150q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5zM50 100h1100q21 0 35.5 -14.5t14.5 -35.5v-50h-1200v50q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe213;" d="M600 1181q75 0 128 -53t53 -128t-53 -128t-128 -53t-128 53t-53 128t53 128t128 53zM602 798h46q34 0 55.5 -28.5t21.5 -86.5q0 -76 39 -183h-324q39 107 39 183q0 58 21.5 86.5t56.5 28.5h45zM250 400h700q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-13 l138 -100h-950l137 100h-12q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5zM50 100h1100q21 0 35.5 -14.5t14.5 -35.5v-50h-1200v50q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe214;" d="M600 1300q47 0 92.5 -53.5t71 -123t25.5 -123.5q0 -78 -55.5 -133.5t-133.5 -55.5t-133.5 55.5t-55.5 133.5q0 62 34 143l144 -143l111 111l-163 163q34 26 63 26zM602 798h46q34 0 55.5 -28.5t21.5 -86.5q0 -76 39 -183h-324q39 107 39 183q0 58 21.5 86.5t56.5 28.5h45 zM250 400h700q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-13l138 -100h-950l137 100h-12q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5zM50 100h1100q21 0 35.5 -14.5t14.5 -35.5v-50h-1200v50q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe215;" d="M600 1200l300 -161v-139h-300q0 -57 18.5 -108t50 -91.5t63 -72t70 -67.5t57.5 -61h-530q-60 83 -90.5 177.5t-30.5 178.5t33 164.5t87.5 139.5t126 96.5t145.5 41.5v-98zM250 400h700q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-13l138 -100h-950l137 100 h-12q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5zM50 100h1100q21 0 35.5 -14.5t14.5 -35.5v-50h-1200v50q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe216;" d="M600 1300q41 0 70.5 -29.5t29.5 -70.5v-78q46 -26 73 -72t27 -100v-50h-400v50q0 54 27 100t73 72v78q0 41 29.5 70.5t70.5 29.5zM400 800h400q54 0 100 -27t72 -73h-172v-100h200v-100h-200v-100h200v-100h-200v-100h200q0 -83 -58.5 -141.5t-141.5 -58.5h-400 q-83 0 -141.5 58.5t-58.5 141.5v400q0 83 58.5 141.5t141.5 58.5z" />
<glyph unicode="&#xe218;" d="M150 1100h900q21 0 35.5 -14.5t14.5 -35.5v-500q0 -21 -14.5 -35.5t-35.5 -14.5h-900q-21 0 -35.5 14.5t-14.5 35.5v500q0 21 14.5 35.5t35.5 14.5zM125 400h950q10 0 17.5 -7.5t7.5 -17.5v-50q0 -10 -7.5 -17.5t-17.5 -7.5h-283l224 -224q13 -13 13 -31.5t-13 -32 t-31.5 -13.5t-31.5 13l-88 88h-524l-87 -88q-13 -13 -32 -13t-32 13.5t-13 32t13 31.5l224 224h-289q-10 0 -17.5 7.5t-7.5 17.5v50q0 10 7.5 17.5t17.5 7.5zM541 300l-100 -100h324l-100 100h-124z" />
<glyph unicode="&#xe219;" d="M200 1100h800q83 0 141.5 -58.5t58.5 -141.5v-200h-100q0 41 -29.5 70.5t-70.5 29.5h-250q-41 0 -70.5 -29.5t-29.5 -70.5h-100q0 41 -29.5 70.5t-70.5 29.5h-250q-41 0 -70.5 -29.5t-29.5 -70.5h-100v200q0 83 58.5 141.5t141.5 58.5zM100 600h1000q41 0 70.5 -29.5 t29.5 -70.5v-300h-1200v300q0 41 29.5 70.5t70.5 29.5zM300 100v-50q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v50h200zM1100 100v-50q0 -21 -14.5 -35.5t-35.5 -14.5h-100q-21 0 -35.5 14.5t-14.5 35.5v50h200z" />
<glyph unicode="&#xe221;" d="M480 1165l682 -683q31 -31 31 -75.5t-31 -75.5l-131 -131h-481l-517 518q-32 31 -32 75.5t32 75.5l295 296q31 31 75.5 31t76.5 -31zM108 794l342 -342l303 304l-341 341zM250 100h800q21 0 35.5 -14.5t14.5 -35.5v-50h-900v50q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe223;" d="M1057 647l-189 506q-8 19 -27.5 33t-40.5 14h-400q-21 0 -40.5 -14t-27.5 -33l-189 -506q-8 -19 1.5 -33t30.5 -14h625v-150q0 -21 14.5 -35.5t35.5 -14.5t35.5 14.5t14.5 35.5v150h125q21 0 30.5 14t1.5 33zM897 0h-595v50q0 21 14.5 35.5t35.5 14.5h50v50 q0 21 14.5 35.5t35.5 14.5h48v300h200v-300h47q21 0 35.5 -14.5t14.5 -35.5v-50h50q21 0 35.5 -14.5t14.5 -35.5v-50z" />
<glyph unicode="&#xe224;" d="M900 800h300v-575q0 -10 -7.5 -17.5t-17.5 -7.5h-375v591l-300 300v84q0 10 7.5 17.5t17.5 7.5h375v-400zM1200 900h-200v200zM400 600h300v-575q0 -10 -7.5 -17.5t-17.5 -7.5h-650q-10 0 -17.5 7.5t-7.5 17.5v950q0 10 7.5 17.5t17.5 7.5h375v-400zM700 700h-200v200z " />
<glyph unicode="&#xe225;" d="M484 1095h195q75 0 146 -32.5t124 -86t89.5 -122.5t48.5 -142q18 -14 35 -20q31 -10 64.5 6.5t43.5 48.5q10 34 -15 71q-19 27 -9 43q5 8 12.5 11t19 -1t23.5 -16q41 -44 39 -105q-3 -63 -46 -106.5t-104 -43.5h-62q-7 -55 -35 -117t-56 -100l-39 -234q-3 -20 -20 -34.5 t-38 -14.5h-100q-21 0 -33 14.5t-9 34.5l12 70q-49 -14 -91 -14h-195q-24 0 -65 8l-11 -64q-3 -20 -20 -34.5t-38 -14.5h-100q-21 0 -33 14.5t-9 34.5l26 157q-84 74 -128 175l-159 53q-19 7 -33 26t-14 40v50q0 21 14.5 35.5t35.5 14.5h124q11 87 56 166l-111 95 q-16 14 -12.5 23.5t24.5 9.5h203q116 101 250 101zM675 1000h-250q-10 0 -17.5 -7.5t-7.5 -17.5v-50q0 -10 7.5 -17.5t17.5 -7.5h250q10 0 17.5 7.5t7.5 17.5v50q0 10 -7.5 17.5t-17.5 7.5z" />
<glyph unicode="&#xe226;" d="M641 900l423 247q19 8 42 2.5t37 -21.5l32 -38q14 -15 12.5 -36t-17.5 -34l-139 -120h-390zM50 1100h106q67 0 103 -17t66 -71l102 -212h823q21 0 35.5 -14.5t14.5 -35.5v-50q0 -21 -14 -40t-33 -26l-737 -132q-23 -4 -40 6t-26 25q-42 67 -100 67h-300q-62 0 -106 44 t-44 106v200q0 62 44 106t106 44zM173 928h-80q-19 0 -28 -14t-9 -35v-56q0 -51 42 -51h134q16 0 21.5 8t5.5 24q0 11 -16 45t-27 51q-18 28 -43 28zM550 727q-32 0 -54.5 -22.5t-22.5 -54.5t22.5 -54.5t54.5 -22.5t54.5 22.5t22.5 54.5t-22.5 54.5t-54.5 22.5zM130 389 l152 130q18 19 34 24t31 -3.5t24.5 -17.5t25.5 -28q28 -35 50.5 -51t48.5 -13l63 5l48 -179q13 -61 -3.5 -97.5t-67.5 -79.5l-80 -69q-47 -40 -109 -35.5t-103 51.5l-130 151q-40 47 -35.5 109.5t51.5 102.5zM380 377l-102 -88q-31 -27 2 -65l37 -43q13 -15 27.5 -19.5 t31.5 6.5l61 53q19 16 14 49q-2 20 -12 56t-17 45q-11 12 -19 14t-23 -8z" />
<glyph unicode="&#xe227;" d="M625 1200h150q10 0 17.5 -7.5t7.5 -17.5v-109q79 -33 131 -87.5t53 -128.5q1 -46 -15 -84.5t-39 -61t-46 -38t-39 -21.5l-17 -6q6 0 15 -1.5t35 -9t50 -17.5t53 -30t50 -45t35.5 -64t14.5 -84q0 -59 -11.5 -105.5t-28.5 -76.5t-44 -51t-49.5 -31.5t-54.5 -16t-49.5 -6.5 t-43.5 -1v-75q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v75h-100v-75q0 -10 -7.5 -17.5t-17.5 -7.5h-150q-10 0 -17.5 7.5t-7.5 17.5v75h-175q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5h75v600h-75q-10 0 -17.5 7.5t-7.5 17.5v150 q0 10 7.5 17.5t17.5 7.5h175v75q0 10 7.5 17.5t17.5 7.5h150q10 0 17.5 -7.5t7.5 -17.5v-75h100v75q0 10 7.5 17.5t17.5 7.5zM400 900v-200h263q28 0 48.5 10.5t30 25t15 29t5.5 25.5l1 10q0 4 -0.5 11t-6 24t-15 30t-30 24t-48.5 11h-263zM400 500v-200h363q28 0 48.5 10.5 t30 25t15 29t5.5 25.5l1 10q0 4 -0.5 11t-6 24t-15 30t-30 24t-48.5 11h-363z" />
<glyph unicode="&#xe230;" d="M212 1198h780q86 0 147 -61t61 -147v-416q0 -51 -18 -142.5t-36 -157.5l-18 -66q-29 -87 -93.5 -146.5t-146.5 -59.5h-572q-82 0 -147 59t-93 147q-8 28 -20 73t-32 143.5t-20 149.5v416q0 86 61 147t147 61zM600 1045q-70 0 -132.5 -11.5t-105.5 -30.5t-78.5 -41.5 t-57 -45t-36 -41t-20.5 -30.5l-6 -12l156 -243h560l156 243q-2 5 -6 12.5t-20 29.5t-36.5 42t-57 44.5t-79 42t-105 29.5t-132.5 12zM762 703h-157l195 261z" />
<glyph unicode="&#xe231;" d="M475 1300h150q103 0 189 -86t86 -189v-500q0 -41 -42 -83t-83 -42h-450q-41 0 -83 42t-42 83v500q0 103 86 189t189 86zM700 300v-225q0 -21 -27 -48t-48 -27h-150q-21 0 -48 27t-27 48v225h300z" />
<glyph unicode="&#xe232;" d="M475 1300h96q0 -150 89.5 -239.5t239.5 -89.5v-446q0 -41 -42 -83t-83 -42h-450q-41 0 -83 42t-42 83v500q0 103 86 189t189 86zM700 300v-225q0 -21 -27 -48t-48 -27h-150q-21 0 -48 27t-27 48v225h300z" />
<glyph unicode="&#xe233;" d="M1294 767l-638 -283l-378 170l-78 -60v-224l100 -150v-199l-150 148l-150 -149v200l100 150v250q0 4 -0.5 10.5t0 9.5t1 8t3 8t6.5 6l47 40l-147 65l642 283zM1000 380l-350 -166l-350 166v147l350 -165l350 165v-147z" />
<glyph unicode="&#xe234;" d="M250 800q62 0 106 -44t44 -106t-44 -106t-106 -44t-106 44t-44 106t44 106t106 44zM650 800q62 0 106 -44t44 -106t-44 -106t-106 -44t-106 44t-44 106t44 106t106 44zM1050 800q62 0 106 -44t44 -106t-44 -106t-106 -44t-106 44t-44 106t44 106t106 44z" />
<glyph unicode="&#xe235;" d="M550 1100q62 0 106 -44t44 -106t-44 -106t-106 -44t-106 44t-44 106t44 106t106 44zM550 700q62 0 106 -44t44 -106t-44 -106t-106 -44t-106 44t-44 106t44 106t106 44zM550 300q62 0 106 -44t44 -106t-44 -106t-106 -44t-106 44t-44 106t44 106t106 44z" />
<glyph unicode="&#xe236;" d="M125 1100h950q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-950q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5zM125 700h950q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-950q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5 t17.5 7.5zM125 300h950q10 0 17.5 -7.5t7.5 -17.5v-150q0 -10 -7.5 -17.5t-17.5 -7.5h-950q-10 0 -17.5 7.5t-7.5 17.5v150q0 10 7.5 17.5t17.5 7.5z" />
<glyph unicode="&#xe237;" d="M350 1200h500q162 0 256 -93.5t94 -256.5v-500q0 -165 -93.5 -257.5t-256.5 -92.5h-500q-165 0 -257.5 92.5t-92.5 257.5v500q0 165 92.5 257.5t257.5 92.5zM900 1000h-600q-41 0 -70.5 -29.5t-29.5 -70.5v-600q0 -41 29.5 -70.5t70.5 -29.5h600q41 0 70.5 29.5 t29.5 70.5v600q0 41 -29.5 70.5t-70.5 29.5zM350 900h500q21 0 35.5 -14.5t14.5 -35.5v-300q0 -21 -14.5 -35.5t-35.5 -14.5h-500q-21 0 -35.5 14.5t-14.5 35.5v300q0 21 14.5 35.5t35.5 14.5zM400 800v-200h400v200h-400z" />
<glyph unicode="&#xe238;" d="M150 1100h1000q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-50v-200h50q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-50v-200h50q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5t-35.5 -14.5h-50v-200h50q21 0 35.5 -14.5t14.5 -35.5t-14.5 -35.5 t-35.5 -14.5h-1000q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5h50v200h-50q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5h50v200h-50q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5h50v200h-50q-21 0 -35.5 14.5t-14.5 35.5t14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe239;" d="M650 1187q87 -67 118.5 -156t0 -178t-118.5 -155q-87 66 -118.5 155t0 178t118.5 156zM300 800q124 0 212 -88t88 -212q-124 0 -212 88t-88 212zM1000 800q0 -124 -88 -212t-212 -88q0 124 88 212t212 88zM300 500q124 0 212 -88t88 -212q-124 0 -212 88t-88 212z M1000 500q0 -124 -88 -212t-212 -88q0 124 88 212t212 88zM700 199v-144q0 -21 -14.5 -35.5t-35.5 -14.5t-35.5 14.5t-14.5 35.5v142q40 -4 43 -4q17 0 57 6z" />
<glyph unicode="&#xe240;" d="M745 878l69 19q25 6 45 -12l298 -295q11 -11 15 -26.5t-2 -30.5q-5 -14 -18 -23.5t-28 -9.5h-8q1 0 1 -13q0 -29 -2 -56t-8.5 -62t-20 -63t-33 -53t-51 -39t-72.5 -14h-146q-184 0 -184 288q0 24 10 47q-20 4 -62 4t-63 -4q11 -24 11 -47q0 -288 -184 -288h-142 q-48 0 -84.5 21t-56 51t-32 71.5t-16 75t-3.5 68.5q0 13 2 13h-7q-15 0 -27.5 9.5t-18.5 23.5q-6 15 -2 30.5t15 25.5l298 296q20 18 46 11l76 -19q20 -5 30.5 -22.5t5.5 -37.5t-22.5 -31t-37.5 -5l-51 12l-182 -193h891l-182 193l-44 -12q-20 -5 -37.5 6t-22.5 31t6 37.5 t31 22.5z" />
<glyph unicode="&#xe241;" d="M1200 900h-50q0 21 -4 37t-9.5 26.5t-18 17.5t-22 11t-28.5 5.5t-31 2t-37 0.5h-200v-850q0 -22 25 -34.5t50 -13.5l25 -2v-100h-400v100q4 0 11 0.5t24 3t30 7t24 15t11 24.5v850h-200q-25 0 -37 -0.5t-31 -2t-28.5 -5.5t-22 -11t-18 -17.5t-9.5 -26.5t-4 -37h-50v300 h1000v-300zM500 450h-25q0 15 -4 24.5t-9 14.5t-17 7.5t-20 3t-25 0.5h-100v-425q0 -11 12.5 -17.5t25.5 -7.5h12v-50h-200v50q50 0 50 25v425h-100q-17 0 -25 -0.5t-20 -3t-17 -7.5t-9 -14.5t-4 -24.5h-25v150h500v-150z" />
<glyph unicode="&#xe242;" d="M1000 300v50q-25 0 -55 32q-14 14 -25 31t-16 27l-4 11l-289 747h-69l-300 -754q-18 -35 -39 -56q-9 -9 -24.5 -18.5t-26.5 -14.5l-11 -5v-50h273v50q-49 0 -78.5 21.5t-11.5 67.5l69 176h293l61 -166q13 -34 -3.5 -66.5t-55.5 -32.5v-50h312zM412 691l134 342l121 -342 h-255zM1100 150v-100q0 -21 -14.5 -35.5t-35.5 -14.5h-1000q-21 0 -35.5 14.5t-14.5 35.5v100q0 21 14.5 35.5t35.5 14.5h1000q21 0 35.5 -14.5t14.5 -35.5z" />
<glyph unicode="&#xe243;" d="M50 1200h1100q21 0 35.5 -14.5t14.5 -35.5v-1100q0 -21 -14.5 -35.5t-35.5 -14.5h-1100q-21 0 -35.5 14.5t-14.5 35.5v1100q0 21 14.5 35.5t35.5 14.5zM611 1118h-70q-13 0 -18 -12l-299 -753q-17 -32 -35 -51q-18 -18 -56 -34q-12 -5 -12 -18v-50q0 -8 5.5 -14t14.5 -6 h273q8 0 14 6t6 14v50q0 8 -6 14t-14 6q-55 0 -71 23q-10 14 0 39l63 163h266l57 -153q11 -31 -6 -55q-12 -17 -36 -17q-8 0 -14 -6t-6 -14v-50q0 -8 6 -14t14 -6h313q8 0 14 6t6 14v50q0 7 -5.5 13t-13.5 7q-17 0 -42 25q-25 27 -40 63h-1l-288 748q-5 12 -19 12zM639 611 h-197l103 264z" />
<glyph unicode="&#xe244;" d="M1200 1100h-1200v100h1200v-100zM50 1000h400q21 0 35.5 -14.5t14.5 -35.5v-900q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v900q0 21 14.5 35.5t35.5 14.5zM650 1000h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400 q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5zM700 900v-300h300v300h-300z" />
<glyph unicode="&#xe245;" d="M50 1200h400q21 0 35.5 -14.5t14.5 -35.5v-900q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v900q0 21 14.5 35.5t35.5 14.5zM650 700h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v400 q0 21 14.5 35.5t35.5 14.5zM700 600v-300h300v300h-300zM1200 0h-1200v100h1200v-100z" />
<glyph unicode="&#xe246;" d="M50 1000h400q21 0 35.5 -14.5t14.5 -35.5v-350h100v150q0 21 14.5 35.5t35.5 14.5h400q21 0 35.5 -14.5t14.5 -35.5v-150h100v-100h-100v-150q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v150h-100v-350q0 -21 -14.5 -35.5t-35.5 -14.5h-400 q-21 0 -35.5 14.5t-14.5 35.5v800q0 21 14.5 35.5t35.5 14.5zM700 700v-300h300v300h-300z" />
<glyph unicode="&#xe247;" d="M100 0h-100v1200h100v-1200zM250 1100h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5zM300 1000v-300h300v300h-300zM250 500h900q21 0 35.5 -14.5t14.5 -35.5v-400 q0 -21 -14.5 -35.5t-35.5 -14.5h-900q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe248;" d="M600 1100h150q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-150v-100h450q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-900q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5h350v100h-150q-21 0 -35.5 14.5 t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5h150v100h100v-100zM400 1000v-300h300v300h-300z" />
<glyph unicode="&#xe249;" d="M1200 0h-100v1200h100v-1200zM550 1100h400q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-400q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5zM600 1000v-300h300v300h-300zM50 500h900q21 0 35.5 -14.5t14.5 -35.5v-400 q0 -21 -14.5 -35.5t-35.5 -14.5h-900q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5z" />
<glyph unicode="&#xe250;" d="M865 565l-494 -494q-23 -23 -41 -23q-14 0 -22 13.5t-8 38.5v1000q0 25 8 38.5t22 13.5q18 0 41 -23l494 -494q14 -14 14 -35t-14 -35z" />
<glyph unicode="&#xe251;" d="M335 635l494 494q29 29 50 20.5t21 -49.5v-1000q0 -41 -21 -49.5t-50 20.5l-494 494q-14 14 -14 35t14 35z" />
<glyph unicode="&#xe252;" d="M100 900h1000q41 0 49.5 -21t-20.5 -50l-494 -494q-14 -14 -35 -14t-35 14l-494 494q-29 29 -20.5 50t49.5 21z" />
<glyph unicode="&#xe253;" d="M635 865l494 -494q29 -29 20.5 -50t-49.5 -21h-1000q-41 0 -49.5 21t20.5 50l494 494q14 14 35 14t35 -14z" />
<glyph unicode="&#xe254;" d="M700 741v-182l-692 -323v221l413 193l-413 193v221zM1200 0h-800v200h800v-200z" />
<glyph unicode="&#xe255;" d="M1200 900h-200v-100h200v-100h-300v300h200v100h-200v100h300v-300zM0 700h50q0 21 4 37t9.5 26.5t18 17.5t22 11t28.5 5.5t31 2t37 0.5h100v-550q0 -22 -25 -34.5t-50 -13.5l-25 -2v-100h400v100q-4 0 -11 0.5t-24 3t-30 7t-24 15t-11 24.5v550h100q25 0 37 -0.5t31 -2 t28.5 -5.5t22 -11t18 -17.5t9.5 -26.5t4 -37h50v300h-800v-300z" />
<glyph unicode="&#xe256;" d="M800 700h-50q0 21 -4 37t-9.5 26.5t-18 17.5t-22 11t-28.5 5.5t-31 2t-37 0.5h-100v-550q0 -22 25 -34.5t50 -14.5l25 -1v-100h-400v100q4 0 11 0.5t24 3t30 7t24 15t11 24.5v550h-100q-25 0 -37 -0.5t-31 -2t-28.5 -5.5t-22 -11t-18 -17.5t-9.5 -26.5t-4 -37h-50v300 h800v-300zM1100 200h-200v-100h200v-100h-300v300h200v100h-200v100h300v-300z" />
<glyph unicode="&#xe257;" d="M701 1098h160q16 0 21 -11t-7 -23l-464 -464l464 -464q12 -12 7 -23t-21 -11h-160q-13 0 -23 9l-471 471q-7 8 -7 18t7 18l471 471q10 9 23 9z" />
<glyph unicode="&#xe258;" d="M339 1098h160q13 0 23 -9l471 -471q7 -8 7 -18t-7 -18l-471 -471q-10 -9 -23 -9h-160q-16 0 -21 11t7 23l464 464l-464 464q-12 12 -7 23t21 11z" />
<glyph unicode="&#xe259;" d="M1087 882q11 -5 11 -21v-160q0 -13 -9 -23l-471 -471q-8 -7 -18 -7t-18 7l-471 471q-9 10 -9 23v160q0 16 11 21t23 -7l464 -464l464 464q12 12 23 7z" />
<glyph unicode="&#xe260;" d="M618 993l471 -471q9 -10 9 -23v-160q0 -16 -11 -21t-23 7l-464 464l-464 -464q-12 -12 -23 -7t-11 21v160q0 13 9 23l471 471q8 7 18 7t18 -7z" />
<glyph unicode="&#xf8ff;" d="M1000 1200q0 -124 -88 -212t-212 -88q0 124 88 212t212 88zM450 1000h100q21 0 40 -14t26 -33l79 -194q5 1 16 3q34 6 54 9.5t60 7t65.5 1t61 -10t56.5 -23t42.5 -42t29 -64t5 -92t-19.5 -121.5q-1 -7 -3 -19.5t-11 -50t-20.5 -73t-32.5 -81.5t-46.5 -83t-64 -70 t-82.5 -50q-13 -5 -42 -5t-65.5 2.5t-47.5 2.5q-14 0 -49.5 -3.5t-63 -3.5t-43.5 7q-57 25 -104.5 78.5t-75 111.5t-46.5 112t-26 90l-7 35q-15 63 -18 115t4.5 88.5t26 64t39.5 43.5t52 25.5t58.5 13t62.5 2t59.5 -4.5t55.5 -8l-147 192q-12 18 -5.5 30t27.5 12z" />
<glyph unicode="&#x1f511;" d="M250 1200h600q21 0 35.5 -14.5t14.5 -35.5v-400q0 -21 -14.5 -35.5t-35.5 -14.5h-150v-500l-255 -178q-19 -9 -32 -1t-13 29v650h-150q-21 0 -35.5 14.5t-14.5 35.5v400q0 21 14.5 35.5t35.5 14.5zM400 1100v-100h300v100h-300z" />
<glyph unicode="&#x1f6aa;" d="M250 1200h750q39 0 69.5 -40.5t30.5 -84.5v-933l-700 -117v950l600 125h-700v-1000h-100v1025q0 23 15.5 49t34.5 26zM500 525v-100l100 20v100z" />
</font>
</defs></svg> ) format(&#39;svg&#39;)}.glyphicon{position:relative;top:1px;display:inline-block;font-family:&#39;Glyphicons Halflings&#39;;font-style:normal;font-weight:400;line-height:1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.glyphicon-asterisk:before{content:&#34;\2a&#34;}.glyphicon-plus:before{content:&#34;\2b&#34;}.glyphicon-eur:before,.glyphicon-euro:before{content:&#34;\20ac&#34;}.glyphicon-minus:before{content:&#34;\2212&#34;}.glyphicon-cloud:before{content:&#34;\2601&#34;}.glyphicon-envelope:before{content:&#34;\2709&#34;}.glyphicon-pencil:before{content:&#34;\270f&#34;}.glyphicon-glass:before{content:&#34;\e001&#34;}.glyphicon-music:before{content:&#34;\e002&#34;}.glyphicon-search:before{content:&#34;\e003&#34;}.glyphicon-heart:before{content:&#34;\e005&#34;}.glyphicon-star:before{content:&#34;\e006&#34;}.glyphicon-star-empty:before{content:&#34;\e007&#34;}.glyphicon-user:before{content:&#34;\e008&#34;}.glyphicon-film:before{content:&#34;\e009&#34;}.glyphicon-th-large:before{content:&#34;\e010&#34;}.glyphicon-th:before{content:&#34;\e011&#34;}.glyphicon-th-list:before{content:&#34;\e012&#34;}.glyphicon-ok:before{content:&#34;\e013&#34;}.glyphicon-remove:before{content:&#34;\e014&#34;}.glyphicon-zoom-in:before{content:&#34;\e015&#34;}.glyphicon-zoom-out:before{content:&#34;\e016&#34;}.glyphicon-off:before{content:&#34;\e017&#34;}.glyphicon-signal:before{content:&#34;\e018&#34;}.glyphicon-cog:before{content:&#34;\e019&#34;}.glyphicon-trash:before{content:&#34;\e020&#34;}.glyphicon-home:before{content:&#34;\e021&#34;}.glyphicon-file:before{content:&#34;\e022&#34;}.glyphicon-time:before{content:&#34;\e023&#34;}.glyphicon-road:before{content:&#34;\e024&#34;}.glyphicon-download-alt:before{content:&#34;\e025&#34;}.glyphicon-download:before{content:&#34;\e026&#34;}.glyphicon-upload:before{content:&#34;\e027&#34;}.glyphicon-inbox:before{content:&#34;\e028&#34;}.glyphicon-play-circle:before{content:&#34;\e029&#34;}.glyphicon-repeat:before{content:&#34;\e030&#34;}.glyphicon-refresh:before{content:&#34;\e031&#34;}.glyphicon-list-alt:before{content:&#34;\e032&#34;}.glyphicon-lock:before{content:&#34;\e033&#34;}.glyphicon-flag:before{content:&#34;\e034&#34;}.glyphicon-headphones:before{content:&#34;\e035&#34;}.glyphicon-volume-off:before{content:&#34;\e036&#34;}.glyphicon-volume-down:before{content:&#34;\e037&#34;}.glyphicon-volume-up:before{content:&#34;\e038&#34;}.glyphicon-qrcode:before{content:&#34;\e039&#34;}.glyphicon-barcode:before{content:&#34;\e040&#34;}.glyphicon-tag:before{content:&#34;\e041&#34;}.glyphicon-tags:before{content:&#34;\e042&#34;}.glyphicon-book:before{content:&#34;\e043&#34;}.glyphicon-bookmark:before{content:&#34;\e044&#34;}.glyphicon-print:before{content:&#34;\e045&#34;}.glyphicon-camera:before{content:&#34;\e046&#34;}.glyphicon-font:before{content:&#34;\e047&#34;}.glyphicon-bold:before{content:&#34;\e048&#34;}.glyphicon-italic:before{content:&#34;\e049&#34;}.glyphicon-text-height:before{content:&#34;\e050&#34;}.glyphicon-text-width:before{content:&#34;\e051&#34;}.glyphicon-align-left:before{content:&#34;\e052&#34;}.glyphicon-align-center:before{content:&#34;\e053&#34;}.glyphicon-align-right:before{content:&#34;\e054&#34;}.glyphicon-align-justify:before{content:&#34;\e055&#34;}.glyphicon-list:before{content:&#34;\e056&#34;}.glyphicon-indent-left:before{content:&#34;\e057&#34;}.glyphicon-indent-right:before{content:&#34;\e058&#34;}.glyphicon-facetime-video:before{content:&#34;\e059&#34;}.glyphicon-picture:before{content:&#34;\e060&#34;}.glyphicon-map-marker:before{content:&#34;\e062&#34;}.glyphicon-adjust:before{content:&#34;\e063&#34;}.glyphicon-tint:before{content:&#34;\e064&#34;}.glyphicon-edit:before{content:&#34;\e065&#34;}.glyphicon-share:before{content:&#34;\e066&#34;}.glyphicon-check:before{content:&#34;\e067&#34;}.glyphicon-move:before{content:&#34;\e068&#34;}.glyphicon-step-backward:before{content:&#34;\e069&#34;}.glyphicon-fast-backward:before{content:&#34;\e070&#34;}.glyphicon-backward:before{content:&#34;\e071&#34;}.glyphicon-play:before{content:&#34;\e072&#34;}.glyphicon-pause:before{content:&#34;\e073&#34;}.glyphicon-stop:before{content:&#34;\e074&#34;}.glyphicon-forward:before{content:&#34;\e075&#34;}.glyphicon-fast-forward:before{content:&#34;\e076&#34;}.glyphicon-step-forward:before{content:&#34;\e077&#34;}.glyphicon-eject:before{content:&#34;\e078&#34;}.glyphicon-chevron-left:before{content:&#34;\e079&#34;}.glyphicon-chevron-right:before{content:&#34;\e080&#34;}.glyphicon-plus-sign:before{content:&#34;\e081&#34;}.glyphicon-minus-sign:before{content:&#34;\e082&#34;}.glyphicon-remove-sign:before{content:&#34;\e083&#34;}.glyphicon-ok-sign:before{content:&#34;\e084&#34;}.glyphicon-question-sign:before{content:&#34;\e085&#34;}.glyphicon-info-sign:before{content:&#34;\e086&#34;}.glyphicon-screenshot:before{content:&#34;\e087&#34;}.glyphicon-remove-circle:before{content:&#34;\e088&#34;}.glyphicon-ok-circle:before{content:&#34;\e089&#34;}.glyphicon-ban-circle:before{content:&#34;\e090&#34;}.glyphicon-arrow-left:before{content:&#34;\e091&#34;}.glyphicon-arrow-right:before{content:&#34;\e092&#34;}.glyphicon-arrow-up:before{content:&#34;\e093&#34;}.glyphicon-arrow-down:before{content:&#34;\e094&#34;}.glyphicon-share-alt:before{content:&#34;\e095&#34;}.glyphicon-resize-full:before{content:&#34;\e096&#34;}.glyphicon-resize-small:before{content:&#34;\e097&#34;}.glyphicon-exclamation-sign:before{content:&#34;\e101&#34;}.glyphicon-gift:before{content:&#34;\e102&#34;}.glyphicon-leaf:before{content:&#34;\e103&#34;}.glyphicon-fire:before{content:&#34;\e104&#34;}.glyphicon-eye-open:before{content:&#34;\e105&#34;}.glyphicon-eye-close:before{content:&#34;\e106&#34;}.glyphicon-warning-sign:before{content:&#34;\e107&#34;}.glyphicon-plane:before{content:&#34;\e108&#34;}.glyphicon-calendar:before{content:&#34;\e109&#34;}.glyphicon-random:before{content:&#34;\e110&#34;}.glyphicon-comment:before{content:&#34;\e111&#34;}.glyphicon-magnet:before{content:&#34;\e112&#34;}.glyphicon-chevron-up:before{content:&#34;\e113&#34;}.glyphicon-chevron-down:before{content:&#34;\e114&#34;}.glyphicon-retweet:before{content:&#34;\e115&#34;}.glyphicon-shopping-cart:before{content:&#34;\e116&#34;}.glyphicon-folder-close:before{content:&#34;\e117&#34;}.glyphicon-folder-open:before{content:&#34;\e118&#34;}.glyphicon-resize-vertical:before{content:&#34;\e119&#34;}.glyphicon-resize-horizontal:before{content:&#34;\e120&#34;}.glyphicon-hdd:before{content:&#34;\e121&#34;}.glyphicon-bullhorn:before{content:&#34;\e122&#34;}.glyphicon-bell:before{content:&#34;\e123&#34;}.glyphicon-certificate:before{content:&#34;\e124&#34;}.glyphicon-thumbs-up:before{content:&#34;\e125&#34;}.glyphicon-thumbs-down:before{content:&#34;\e126&#34;}.glyphicon-hand-right:before{content:&#34;\e127&#34;}.glyphicon-hand-left:before{content:&#34;\e128&#34;}.glyphicon-hand-up:before{content:&#34;\e129&#34;}.glyphicon-hand-down:before{content:&#34;\e130&#34;}.glyphicon-circle-arrow-right:before{content:&#34;\e131&#34;}.glyphicon-circle-arrow-left:before{content:&#34;\e132&#34;}.glyphicon-circle-arrow-up:before{content:&#34;\e133&#34;}.glyphicon-circle-arrow-down:before{content:&#34;\e134&#34;}.glyphicon-globe:before{content:&#34;\e135&#34;}.glyphicon-wrench:before{content:&#34;\e136&#34;}.glyphicon-tasks:before{content:&#34;\e137&#34;}.glyphicon-filter:before{content:&#34;\e138&#34;}.glyphicon-briefcase:before{content:&#34;\e139&#34;}.glyphicon-fullscreen:before{content:&#34;\e140&#34;}.glyphicon-dashboard:before{content:&#34;\e141&#34;}.glyphicon-paperclip:before{content:&#34;\e142&#34;}.glyphicon-heart-empty:before{content:&#34;\e143&#34;}.glyphicon-link:before{content:&#34;\e144&#34;}.glyphicon-phone:before{content:&#34;\e145&#34;}.glyphicon-pushpin:before{content:&#34;\e146&#34;}.glyphicon-usd:before{content:&#34;\e148&#34;}.glyphicon-gbp:before{content:&#34;\e149&#34;}.glyphicon-sort:before{content:&#34;\e150&#34;}.glyphicon-sort-by-alphabet:before{content:&#34;\e151&#34;}.glyphicon-sort-by-alphabet-alt:before{content:&#34;\e152&#34;}.glyphicon-sort-by-order:before{content:&#34;\e153&#34;}.glyphicon-sort-by-order-alt:before{content:&#34;\e154&#34;}.glyphicon-sort-by-attributes:before{content:&#34;\e155&#34;}.glyphicon-sort-by-attributes-alt:before{content:&#34;\e156&#34;}.glyphicon-unchecked:before{content:&#34;\e157&#34;}.glyphicon-expand:before{content:&#34;\e158&#34;}.glyphicon-collapse-down:before{content:&#34;\e159&#34;}.glyphicon-collapse-up:before{content:&#34;\e160&#34;}.glyphicon-log-in:before{content:&#34;\e161&#34;}.glyphicon-flash:before{content:&#34;\e162&#34;}.glyphicon-log-out:before{content:&#34;\e163&#34;}.glyphicon-new-window:before{content:&#34;\e164&#34;}.glyphicon-record:before{content:&#34;\e165&#34;}.glyphicon-save:before{content:&#34;\e166&#34;}.glyphicon-open:before{content:&#34;\e167&#34;}.glyphicon-saved:before{content:&#34;\e168&#34;}.glyphicon-import:before{content:&#34;\e169&#34;}.glyphicon-export:before{content:&#34;\e170&#34;}.glyphicon-send:before{content:&#34;\e171&#34;}.glyphicon-floppy-disk:before{content:&#34;\e172&#34;}.glyphicon-floppy-saved:before{content:&#34;\e173&#34;}.glyphicon-floppy-remove:before{content:&#34;\e174&#34;}.glyphicon-floppy-save:before{content:&#34;\e175&#34;}.glyphicon-floppy-open:before{content:&#34;\e176&#34;}.glyphicon-credit-card:before{content:&#34;\e177&#34;}.glyphicon-transfer:before{content:&#34;\e178&#34;}.glyphicon-cutlery:before{content:&#34;\e179&#34;}.glyphicon-header:before{content:&#34;\e180&#34;}.glyphicon-compressed:before{content:&#34;\e181&#34;}.glyphicon-earphone:before{content:&#34;\e182&#34;}.glyphicon-phone-alt:before{content:&#34;\e183&#34;}.glyphicon-tower:before{content:&#34;\e184&#34;}.glyphicon-stats:before{content:&#34;\e185&#34;}.glyphicon-sd-video:before{content:&#34;\e186&#34;}.glyphicon-hd-video:before{content:&#34;\e187&#34;}.glyphicon-subtitles:before{content:&#34;\e188&#34;}.glyphicon-sound-stereo:before{content:&#34;\e189&#34;}.glyphicon-sound-dolby:before{content:&#34;\e190&#34;}.glyphicon-sound-5-1:before{content:&#34;\e191&#34;}.glyphicon-sound-6-1:before{content:&#34;\e192&#34;}.glyphicon-sound-7-1:before{content:&#34;\e193&#34;}.glyphicon-copyright-mark:before{content:&#34;\e194&#34;}.glyphicon-registration-mark:before{content:&#34;\e195&#34;}.glyphicon-cloud-download:before{content:&#34;\e197&#34;}.glyphicon-cloud-upload:before{content:&#34;\e198&#34;}.glyphicon-tree-conifer:before{content:&#34;\e199&#34;}.glyphicon-tree-deciduous:before{content:&#34;\e200&#34;}.glyphicon-cd:before{content:&#34;\e201&#34;}.glyphicon-save-file:before{content:&#34;\e202&#34;}.glyphicon-open-file:before{content:&#34;\e203&#34;}.glyphicon-level-up:before{content:&#34;\e204&#34;}.glyphicon-copy:before{content:&#34;\e205&#34;}.glyphicon-paste:before{content:&#34;\e206&#34;}.glyphicon-alert:before{content:&#34;\e209&#34;}.glyphicon-equalizer:before{content:&#34;\e210&#34;}.glyphicon-king:before{content:&#34;\e211&#34;}.glyphicon-queen:before{content:&#34;\e212&#34;}.glyphicon-pawn:before{content:&#34;\e213&#34;}.glyphicon-bishop:before{content:&#34;\e214&#34;}.glyphicon-knight:before{content:&#34;\e215&#34;}.glyphicon-baby-formula:before{content:&#34;\e216&#34;}.glyphicon-tent:before{content:&#34;\26fa&#34;}.glyphicon-blackboard:before{content:&#34;\e218&#34;}.glyphicon-bed:before{content:&#34;\e219&#34;}.glyphicon-apple:before{content:&#34;\f8ff&#34;}.glyphicon-erase:before{content:&#34;\e221&#34;}.glyphicon-hourglass:before{content:&#34;\231b&#34;}.glyphicon-lamp:before{content:&#34;\e223&#34;}.glyphicon-duplicate:before{content:&#34;\e224&#34;}.glyphicon-piggy-bank:before{content:&#34;\e225&#34;}.glyphicon-scissors:before{content:&#34;\e226&#34;}.glyphicon-bitcoin:before{content:&#34;\e227&#34;}.glyphicon-btc:before{content:&#34;\e227&#34;}.glyphicon-xbt:before{content:&#34;\e227&#34;}.glyphicon-yen:before{content:&#34;\00a5&#34;}.glyphicon-jpy:before{content:&#34;\00a5&#34;}.glyphicon-ruble:before{content:&#34;\20bd&#34;}.glyphicon-rub:before{content:&#34;\20bd&#34;}.glyphicon-scale:before{content:&#34;\e230&#34;}.glyphicon-ice-lolly:before{content:&#34;\e231&#34;}.glyphicon-ice-lolly-tasted:before{content:&#34;\e232&#34;}.glyphicon-education:before{content:&#34;\e233&#34;}.glyphicon-option-horizontal:before{content:&#34;\e234&#34;}.glyphicon-option-vertical:before{content:&#34;\e235&#34;}.glyphicon-menu-hamburger:before{content:&#34;\e236&#34;}.glyphicon-modal-window:before{content:&#34;\e237&#34;}.glyphicon-oil:before{content:&#34;\e238&#34;}.glyphicon-grain:before{content:&#34;\e239&#34;}.glyphicon-sunglasses:before{content:&#34;\e240&#34;}.glyphicon-text-size:before{content:&#34;\e241&#34;}.glyphicon-text-color:before{content:&#34;\e242&#34;}.glyphicon-text-background:before{content:&#34;\e243&#34;}.glyphicon-object-align-top:before{content:&#34;\e244&#34;}.glyphicon-object-align-bottom:before{content:&#34;\e245&#34;}.glyphicon-object-align-horizontal:before{content:&#34;\e246&#34;}.glyphicon-object-align-left:before{content:&#34;\e247&#34;}.glyphicon-object-align-vertical:before{content:&#34;\e248&#34;}.glyphicon-object-align-right:before{content:&#34;\e249&#34;}.glyphicon-triangle-right:before{content:&#34;\e250&#34;}.glyphicon-triangle-left:before{content:&#34;\e251&#34;}.glyphicon-triangle-bottom:before{content:&#34;\e252&#34;}.glyphicon-triangle-top:before{content:&#34;\e253&#34;}.glyphicon-console:before{content:&#34;\e254&#34;}.glyphicon-superscript:before{content:&#34;\e255&#34;}.glyphicon-subscript:before{content:&#34;\e256&#34;}.glyphicon-menu-left:before{content:&#34;\e257&#34;}.glyphicon-menu-right:before{content:&#34;\e258&#34;}.glyphicon-menu-down:before{content:&#34;\e259&#34;}.glyphicon-menu-up:before{content:&#34;\e260&#34;}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}:after,:before{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}html{font-size:10px;-webkit-tap-highlight-color:rgba(0,0,0,0)}body{font-family:&#34;Helvetica Neue&#34;,Helvetica,Arial,sans-serif;font-size:14px;line-height:1.42857143;color:#333;background-color:#fff}button,input,select,textarea{font-family:inherit;font-size:inherit;line-height:inherit}a{color:#337ab7;text-decoration:none}a:focus,a:hover{color:#23527c;text-decoration:underline}a:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}figure{margin:0}img{vertical-align:middle}.carousel-inner&gt;.item&gt;a&gt;img,.carousel-inner&gt;.item&gt;img,.img-responsive,.thumbnail a&gt;img,.thumbnail&gt;img{display:block;max-width:100%;height:auto}.img-rounded{border-radius:6px}.img-thumbnail{display:inline-block;max-width:100%;height:auto;padding:4px;line-height:1.42857143;background-color:#fff;border:1px solid #ddd;border-radius:4px;-webkit-transition:all .2s ease-in-out;-o-transition:all .2s ease-in-out;transition:all .2s ease-in-out}.img-circle{border-radius:50%}hr{margin-top:20px;margin-bottom:20px;border:0;border-top:1px solid #eee}.sr-only{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);border:0}.sr-only-focusable:active,.sr-only-focusable:focus{position:static;width:auto;height:auto;margin:0;overflow:visible;clip:auto}[role=button]{cursor:pointer}.h1,.h2,.h3,.h4,.h5,.h6,h1,h2,h3,h4,h5,h6{font-family:inherit;font-weight:500;line-height:1.1;color:inherit}.h1 .small,.h1 small,.h2 .small,.h2 small,.h3 .small,.h3 small,.h4 .small,.h4 small,.h5 .small,.h5 small,.h6 .small,.h6 small,h1 .small,h1 small,h2 .small,h2 small,h3 .small,h3 small,h4 .small,h4 small,h5 .small,h5 small,h6 .small,h6 small{font-weight:400;line-height:1;color:#777}.h1,.h2,.h3,h1,h2,h3{margin-top:20px;margin-bottom:10px}.h1 .small,.h1 small,.h2 .small,.h2 small,.h3 .small,.h3 small,h1 .small,h1 small,h2 .small,h2 small,h3 .small,h3 small{font-size:65%}.h4,.h5,.h6,h4,h5,h6{margin-top:10px;margin-bottom:10px}.h4 .small,.h4 small,.h5 .small,.h5 small,.h6 .small,.h6 small,h4 .small,h4 small,h5 .small,h5 small,h6 .small,h6 small{font-size:75%}.h1,h1{font-size:36px}.h2,h2{font-size:30px}.h3,h3{font-size:24px}.h4,h4{font-size:18px}.h5,h5{font-size:14px}.h6,h6{font-size:12px}p{margin:0 0 10px}.lead{margin-bottom:20px;font-size:16px;font-weight:300;line-height:1.4}@media (min-width:768px){.lead{font-size:21px}}.small,small{font-size:85%}.mark,mark{padding:.2em;background-color:#fcf8e3}.text-left{text-align:left}.text-right{text-align:right}.text-center{text-align:center}.text-justify{text-align:justify}.text-nowrap{white-space:nowrap}.text-lowercase{text-transform:lowercase}.text-uppercase{text-transform:uppercase}.text-capitalize{text-transform:capitalize}.text-muted{color:#777}.text-primary{color:#337ab7}a.text-primary:focus,a.text-primary:hover{color:#286090}.text-success{color:#3c763d}a.text-success:focus,a.text-success:hover{color:#2b542c}.text-info{color:#31708f}a.text-info:focus,a.text-info:hover{color:#245269}.text-warning{color:#8a6d3b}a.text-warning:focus,a.text-warning:hover{color:#66512c}.text-danger{color:#a94442}a.text-danger:focus,a.text-danger:hover{color:#843534}.bg-primary{color:#fff;background-color:#337ab7}a.bg-primary:focus,a.bg-primary:hover{background-color:#286090}.bg-success{background-color:#dff0d8}a.bg-success:focus,a.bg-success:hover{background-color:#c1e2b3}.bg-info{background-color:#d9edf7}a.bg-info:focus,a.bg-info:hover{background-color:#afd9ee}.bg-warning{background-color:#fcf8e3}a.bg-warning:focus,a.bg-warning:hover{background-color:#f7ecb5}.bg-danger{background-color:#f2dede}a.bg-danger:focus,a.bg-danger:hover{background-color:#e4b9b9}.page-header{padding-bottom:9px;margin:40px 0 20px;border-bottom:1px solid #eee}ol,ul{margin-top:0;margin-bottom:10px}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}.list-unstyled{padding-left:0;list-style:none}.list-inline{padding-left:0;margin-left:-5px;list-style:none}.list-inline&gt;li{display:inline-block;padding-right:5px;padding-left:5px}dl{margin-top:0;margin-bottom:20px}dd,dt{line-height:1.42857143}dt{font-weight:700}dd{margin-left:0}@media (min-width:768px){.dl-horizontal dt{float:left;width:160px;overflow:hidden;clear:left;text-align:right;text-overflow:ellipsis;white-space:nowrap}.dl-horizontal dd{margin-left:180px}}abbr[data-original-title],abbr[title]{cursor:help;border-bottom:1px dotted #777}.initialism{font-size:90%;text-transform:uppercase}blockquote{padding:10px 20px;margin:0 0 20px;font-size:17.5px;border-left:5px solid #eee}blockquote ol:last-child,blockquote p:last-child,blockquote ul:last-child{margin-bottom:0}blockquote .small,blockquote footer,blockquote small{display:block;font-size:80%;line-height:1.42857143;color:#777}blockquote .small:before,blockquote footer:before,blockquote small:before{content:&#39;\2014 \00A0&#39;}.blockquote-reverse,blockquote.pull-right{padding-right:15px;padding-left:0;text-align:right;border-right:5px solid #eee;border-left:0}.blockquote-reverse .small:before,.blockquote-reverse footer:before,.blockquote-reverse small:before,blockquote.pull-right .small:before,blockquote.pull-right footer:before,blockquote.pull-right small:before{content:&#39;&#39;}.blockquote-reverse .small:after,.blockquote-reverse footer:after,.blockquote-reverse small:after,blockquote.pull-right .small:after,blockquote.pull-right footer:after,blockquote.pull-right small:after{content:&#39;\00A0 \2014&#39;}address{margin-bottom:20px;font-style:normal;line-height:1.42857143}code,kbd,pre,samp{font-family:monospace}code{padding:2px 4px;font-size:90%;color:#c7254e;background-color:#f9f2f4;border-radius:4px}kbd{padding:2px 4px;font-size:90%;color:#fff;background-color:#333;border-radius:3px;-webkit-box-shadow:inset 0 -1px 0 rgba(0,0,0,.25);box-shadow:inset 0 -1px 0 rgba(0,0,0,.25)}kbd kbd{padding:0;font-size:100%;font-weight:700;-webkit-box-shadow:none;box-shadow:none}pre{display:block;padding:9.5px;margin:0 0 10px;font-size:13px;line-height:1.42857143;color:#333;word-break:break-all;word-wrap:break-word;background-color:#f5f5f5;border:1px solid #ccc;border-radius:4px}pre code{padding:0;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0}.pre-scrollable{max-height:340px;overflow-y:scroll}.container{padding-right:15px;padding-left:15px;margin-right:auto;margin-left:auto}@media (min-width:768px){.container{width:750px}}@media (min-width:992px){.container{width:970px}}@media (min-width:1200px){.container{width:1170px}}.container-fluid{padding-right:15px;padding-left:15px;margin-right:auto;margin-left:auto}.row{margin-right:-15px;margin-left:-15px}.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9{position:relative;min-height:1px;padding-right:15px;padding-left:15px}.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9{float:left}.col-xs-12{width:100%}.col-xs-11{width:91.66666667%}.col-xs-10{width:83.33333333%}.col-xs-9{width:75%}.col-xs-8{width:66.66666667%}.col-xs-7{width:58.33333333%}.col-xs-6{width:50%}.col-xs-5{width:41.66666667%}.col-xs-4{width:33.33333333%}.col-xs-3{width:25%}.col-xs-2{width:16.66666667%}.col-xs-1{width:8.33333333%}.col-xs-pull-12{right:100%}.col-xs-pull-11{right:91.66666667%}.col-xs-pull-10{right:83.33333333%}.col-xs-pull-9{right:75%}.col-xs-pull-8{right:66.66666667%}.col-xs-pull-7{right:58.33333333%}.col-xs-pull-6{right:50%}.col-xs-pull-5{right:41.66666667%}.col-xs-pull-4{right:33.33333333%}.col-xs-pull-3{right:25%}.col-xs-pull-2{right:16.66666667%}.col-xs-pull-1{right:8.33333333%}.col-xs-pull-0{right:auto}.col-xs-push-12{left:100%}.col-xs-push-11{left:91.66666667%}.col-xs-push-10{left:83.33333333%}.col-xs-push-9{left:75%}.col-xs-push-8{left:66.66666667%}.col-xs-push-7{left:58.33333333%}.col-xs-push-6{left:50%}.col-xs-push-5{left:41.66666667%}.col-xs-push-4{left:33.33333333%}.col-xs-push-3{left:25%}.col-xs-push-2{left:16.66666667%}.col-xs-push-1{left:8.33333333%}.col-xs-push-0{left:auto}.col-xs-offset-12{margin-left:100%}.col-xs-offset-11{margin-left:91.66666667%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-0{margin-left:0}@media (min-width:768px){.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9{float:left}.col-sm-12{width:100%}.col-sm-11{width:91.66666667%}.col-sm-10{width:83.33333333%}.col-sm-9{width:75%}.col-sm-8{width:66.66666667%}.col-sm-7{width:58.33333333%}.col-sm-6{width:50%}.col-sm-5{width:41.66666667%}.col-sm-4{width:33.33333333%}.col-sm-3{width:25%}.col-sm-2{width:16.66666667%}.col-sm-1{width:8.33333333%}.col-sm-pull-12{right:100%}.col-sm-pull-11{right:91.66666667%}.col-sm-pull-10{right:83.33333333%}.col-sm-pull-9{right:75%}.col-sm-pull-8{right:66.66666667%}.col-sm-pull-7{right:58.33333333%}.col-sm-pull-6{right:50%}.col-sm-pull-5{right:41.66666667%}.col-sm-pull-4{right:33.33333333%}.col-sm-pull-3{right:25%}.col-sm-pull-2{right:16.66666667%}.col-sm-pull-1{right:8.33333333%}.col-sm-pull-0{right:auto}.col-sm-push-12{left:100%}.col-sm-push-11{left:91.66666667%}.col-sm-push-10{left:83.33333333%}.col-sm-push-9{left:75%}.col-sm-push-8{left:66.66666667%}.col-sm-push-7{left:58.33333333%}.col-sm-push-6{left:50%}.col-sm-push-5{left:41.66666667%}.col-sm-push-4{left:33.33333333%}.col-sm-push-3{left:25%}.col-sm-push-2{left:16.66666667%}.col-sm-push-1{left:8.33333333%}.col-sm-push-0{left:auto}.col-sm-offset-12{margin-left:100%}.col-sm-offset-11{margin-left:91.66666667%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-0{margin-left:0}}@media (min-width:992px){.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9{float:left}.col-md-12{width:100%}.col-md-11{width:91.66666667%}.col-md-10{width:83.33333333%}.col-md-9{width:75%}.col-md-8{width:66.66666667%}.col-md-7{width:58.33333333%}.col-md-6{width:50%}.col-md-5{width:41.66666667%}.col-md-4{width:33.33333333%}.col-md-3{width:25%}.col-md-2{width:16.66666667%}.col-md-1{width:8.33333333%}.col-md-pull-12{right:100%}.col-md-pull-11{right:91.66666667%}.col-md-pull-10{right:83.33333333%}.col-md-pull-9{right:75%}.col-md-pull-8{right:66.66666667%}.col-md-pull-7{right:58.33333333%}.col-md-pull-6{right:50%}.col-md-pull-5{right:41.66666667%}.col-md-pull-4{right:33.33333333%}.col-md-pull-3{right:25%}.col-md-pull-2{right:16.66666667%}.col-md-pull-1{right:8.33333333%}.col-md-pull-0{right:auto}.col-md-push-12{left:100%}.col-md-push-11{left:91.66666667%}.col-md-push-10{left:83.33333333%}.col-md-push-9{left:75%}.col-md-push-8{left:66.66666667%}.col-md-push-7{left:58.33333333%}.col-md-push-6{left:50%}.col-md-push-5{left:41.66666667%}.col-md-push-4{left:33.33333333%}.col-md-push-3{left:25%}.col-md-push-2{left:16.66666667%}.col-md-push-1{left:8.33333333%}.col-md-push-0{left:auto}.col-md-offset-12{margin-left:100%}.col-md-offset-11{margin-left:91.66666667%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-9{margin-left:75%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-6{margin-left:50%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-3{margin-left:25%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-0{margin-left:0}}@media (min-width:1200px){.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9{float:left}.col-lg-12{width:100%}.col-lg-11{width:91.66666667%}.col-lg-10{width:83.33333333%}.col-lg-9{width:75%}.col-lg-8{width:66.66666667%}.col-lg-7{width:58.33333333%}.col-lg-6{width:50%}.col-lg-5{width:41.66666667%}.col-lg-4{width:33.33333333%}.col-lg-3{width:25%}.col-lg-2{width:16.66666667%}.col-lg-1{width:8.33333333%}.col-lg-pull-12{right:100%}.col-lg-pull-11{right:91.66666667%}.col-lg-pull-10{right:83.33333333%}.col-lg-pull-9{right:75%}.col-lg-pull-8{right:66.66666667%}.col-lg-pull-7{right:58.33333333%}.col-lg-pull-6{right:50%}.col-lg-pull-5{right:41.66666667%}.col-lg-pull-4{right:33.33333333%}.col-lg-pull-3{right:25%}.col-lg-pull-2{right:16.66666667%}.col-lg-pull-1{right:8.33333333%}.col-lg-pull-0{right:auto}.col-lg-push-12{left:100%}.col-lg-push-11{left:91.66666667%}.col-lg-push-10{left:83.33333333%}.col-lg-push-9{left:75%}.col-lg-push-8{left:66.66666667%}.col-lg-push-7{left:58.33333333%}.col-lg-push-6{left:50%}.col-lg-push-5{left:41.66666667%}.col-lg-push-4{left:33.33333333%}.col-lg-push-3{left:25%}.col-lg-push-2{left:16.66666667%}.col-lg-push-1{left:8.33333333%}.col-lg-push-0{left:auto}.col-lg-offset-12{margin-left:100%}.col-lg-offset-11{margin-left:91.66666667%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-0{margin-left:0}}table{background-color:transparent}caption{padding-top:8px;padding-bottom:8px;color:#777;text-align:left}th{}.table{width:100%;max-width:100%;margin-bottom:20px}.table&gt;tbody&gt;tr&gt;td,.table&gt;tbody&gt;tr&gt;th,.table&gt;tfoot&gt;tr&gt;td,.table&gt;tfoot&gt;tr&gt;th,.table&gt;thead&gt;tr&gt;td,.table&gt;thead&gt;tr&gt;th{padding:8px;line-height:1.42857143;vertical-align:top;border-top:1px solid #ddd}.table&gt;thead&gt;tr&gt;th{vertical-align:bottom;border-bottom:2px solid #ddd}.table&gt;caption+thead&gt;tr:first-child&gt;td,.table&gt;caption+thead&gt;tr:first-child&gt;th,.table&gt;colgroup+thead&gt;tr:first-child&gt;td,.table&gt;colgroup+thead&gt;tr:first-child&gt;th,.table&gt;thead:first-child&gt;tr:first-child&gt;td,.table&gt;thead:first-child&gt;tr:first-child&gt;th{border-top:0}.table&gt;tbody+tbody{border-top:2px solid #ddd}.table .table{background-color:#fff}.table-condensed&gt;tbody&gt;tr&gt;td,.table-condensed&gt;tbody&gt;tr&gt;th,.table-condensed&gt;tfoot&gt;tr&gt;td,.table-condensed&gt;tfoot&gt;tr&gt;th,.table-condensed&gt;thead&gt;tr&gt;td,.table-condensed&gt;thead&gt;tr&gt;th{padding:5px}.table-bordered{border:1px solid #ddd}.table-bordered&gt;tbody&gt;tr&gt;td,.table-bordered&gt;tbody&gt;tr&gt;th,.table-bordered&gt;tfoot&gt;tr&gt;td,.table-bordered&gt;tfoot&gt;tr&gt;th,.table-bordered&gt;thead&gt;tr&gt;td,.table-bordered&gt;thead&gt;tr&gt;th{border:1px solid #ddd}.table-bordered&gt;thead&gt;tr&gt;td,.table-bordered&gt;thead&gt;tr&gt;th{border-bottom-width:2px}.table-striped&gt;tbody&gt;tr:nth-of-type(odd){background-color:#f9f9f9}.table-hover&gt;tbody&gt;tr:hover{background-color:#f5f5f5}table col[class*=col-]{position:static;display:table-column;float:none}table td[class*=col-],table th[class*=col-]{position:static;display:table-cell;float:none}.table&gt;tbody&gt;tr.active&gt;td,.table&gt;tbody&gt;tr.active&gt;th,.table&gt;tbody&gt;tr&gt;td.active,.table&gt;tbody&gt;tr&gt;th.active,.table&gt;tfoot&gt;tr.active&gt;td,.table&gt;tfoot&gt;tr.active&gt;th,.table&gt;tfoot&gt;tr&gt;td.active,.table&gt;tfoot&gt;tr&gt;th.active,.table&gt;thead&gt;tr.active&gt;td,.table&gt;thead&gt;tr.active&gt;th,.table&gt;thead&gt;tr&gt;td.active,.table&gt;thead&gt;tr&gt;th.active{background-color:#f5f5f5}.table-hover&gt;tbody&gt;tr.active:hover&gt;td,.table-hover&gt;tbody&gt;tr.active:hover&gt;th,.table-hover&gt;tbody&gt;tr:hover&gt;.active,.table-hover&gt;tbody&gt;tr&gt;td.active:hover,.table-hover&gt;tbody&gt;tr&gt;th.active:hover{background-color:#e8e8e8}.table&gt;tbody&gt;tr.success&gt;td,.table&gt;tbody&gt;tr.success&gt;th,.table&gt;tbody&gt;tr&gt;td.success,.table&gt;tbody&gt;tr&gt;th.success,.table&gt;tfoot&gt;tr.success&gt;td,.table&gt;tfoot&gt;tr.success&gt;th,.table&gt;tfoot&gt;tr&gt;td.success,.table&gt;tfoot&gt;tr&gt;th.success,.table&gt;thead&gt;tr.success&gt;td,.table&gt;thead&gt;tr.success&gt;th,.table&gt;thead&gt;tr&gt;td.success,.table&gt;thead&gt;tr&gt;th.success{background-color:#dff0d8}.table-hover&gt;tbody&gt;tr.success:hover&gt;td,.table-hover&gt;tbody&gt;tr.success:hover&gt;th,.table-hover&gt;tbody&gt;tr:hover&gt;.success,.table-hover&gt;tbody&gt;tr&gt;td.success:hover,.table-hover&gt;tbody&gt;tr&gt;th.success:hover{background-color:#d0e9c6}.table&gt;tbody&gt;tr.info&gt;td,.table&gt;tbody&gt;tr.info&gt;th,.table&gt;tbody&gt;tr&gt;td.info,.table&gt;tbody&gt;tr&gt;th.info,.table&gt;tfoot&gt;tr.info&gt;td,.table&gt;tfoot&gt;tr.info&gt;th,.table&gt;tfoot&gt;tr&gt;td.info,.table&gt;tfoot&gt;tr&gt;th.info,.table&gt;thead&gt;tr.info&gt;td,.table&gt;thead&gt;tr.info&gt;th,.table&gt;thead&gt;tr&gt;td.info,.table&gt;thead&gt;tr&gt;th.info{background-color:#d9edf7}.table-hover&gt;tbody&gt;tr.info:hover&gt;td,.table-hover&gt;tbody&gt;tr.info:hover&gt;th,.table-hover&gt;tbody&gt;tr:hover&gt;.info,.table-hover&gt;tbody&gt;tr&gt;td.info:hover,.table-hover&gt;tbody&gt;tr&gt;th.info:hover{background-color:#c4e3f3}.table&gt;tbody&gt;tr.warning&gt;td,.table&gt;tbody&gt;tr.warning&gt;th,.table&gt;tbody&gt;tr&gt;td.warning,.table&gt;tbody&gt;tr&gt;th.warning,.table&gt;tfoot&gt;tr.warning&gt;td,.table&gt;tfoot&gt;tr.warning&gt;th,.table&gt;tfoot&gt;tr&gt;td.warning,.table&gt;tfoot&gt;tr&gt;th.warning,.table&gt;thead&gt;tr.warning&gt;td,.table&gt;thead&gt;tr.warning&gt;th,.table&gt;thead&gt;tr&gt;td.warning,.table&gt;thead&gt;tr&gt;th.warning{background-color:#fcf8e3}.table-hover&gt;tbody&gt;tr.warning:hover&gt;td,.table-hover&gt;tbody&gt;tr.warning:hover&gt;th,.table-hover&gt;tbody&gt;tr:hover&gt;.warning,.table-hover&gt;tbody&gt;tr&gt;td.warning:hover,.table-hover&gt;tbody&gt;tr&gt;th.warning:hover{background-color:#faf2cc}.table&gt;tbody&gt;tr.danger&gt;td,.table&gt;tbody&gt;tr.danger&gt;th,.table&gt;tbody&gt;tr&gt;td.danger,.table&gt;tbody&gt;tr&gt;th.danger,.table&gt;tfoot&gt;tr.danger&gt;td,.table&gt;tfoot&gt;tr.danger&gt;th,.table&gt;tfoot&gt;tr&gt;td.danger,.table&gt;tfoot&gt;tr&gt;th.danger,.table&gt;thead&gt;tr.danger&gt;td,.table&gt;thead&gt;tr.danger&gt;th,.table&gt;thead&gt;tr&gt;td.danger,.table&gt;thead&gt;tr&gt;th.danger{background-color:#f2dede}.table-hover&gt;tbody&gt;tr.danger:hover&gt;td,.table-hover&gt;tbody&gt;tr.danger:hover&gt;th,.table-hover&gt;tbody&gt;tr:hover&gt;.danger,.table-hover&gt;tbody&gt;tr&gt;td.danger:hover,.table-hover&gt;tbody&gt;tr&gt;th.danger:hover{background-color:#ebcccc}.table-responsive{min-height:.01%;overflow-x:auto}@media screen and (max-width:767px){.table-responsive{width:100%;margin-bottom:15px;overflow-y:hidden;-ms-overflow-style:-ms-autohiding-scrollbar;border:1px solid #ddd}.table-responsive&gt;.table{margin-bottom:0}.table-responsive&gt;.table&gt;tbody&gt;tr&gt;td,.table-responsive&gt;.table&gt;tbody&gt;tr&gt;th,.table-responsive&gt;.table&gt;tfoot&gt;tr&gt;td,.table-responsive&gt;.table&gt;tfoot&gt;tr&gt;th,.table-responsive&gt;.table&gt;thead&gt;tr&gt;td,.table-responsive&gt;.table&gt;thead&gt;tr&gt;th{white-space:nowrap}.table-responsive&gt;.table-bordered{border:0}.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;td:first-child,.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;th:first-child,.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;td:first-child,.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;th:first-child,.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;td:first-child,.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;th:first-child{border-left:0}.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;td:last-child,.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;th:last-child,.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;td:last-child,.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;th:last-child,.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;td:last-child,.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;th:last-child{border-right:0}.table-responsive&gt;.table-bordered&gt;tbody&gt;tr:last-child&gt;td,.table-responsive&gt;.table-bordered&gt;tbody&gt;tr:last-child&gt;th,.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr:last-child&gt;td,.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr:last-child&gt;th{border-bottom:0}}fieldset{min-width:0;padding:0;margin:0;border:0}legend{display:block;width:100%;padding:0;margin-bottom:20px;font-size:21px;line-height:inherit;color:#333;border:0;border-bottom:1px solid #e5e5e5}label{display:inline-block;max-width:100%;margin-bottom:5px;font-weight:700}input[type=search]{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}input[type=checkbox],input[type=radio]{margin:4px 0 0;margin-top:1px\9;line-height:normal}input[type=file]{display:block}input[type=range]{display:block;width:100%}select[multiple],select[size]{height:auto}input[type=file]:focus,input[type=checkbox]:focus,input[type=radio]:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}output{display:block;padding-top:7px;font-size:14px;line-height:1.42857143;color:#555}.form-control{display:block;width:100%;height:34px;padding:6px 12px;font-size:14px;line-height:1.42857143;color:#555;background-color:#fff;background-image:none;border:1px solid #ccc;border-radius:4px;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075);-webkit-transition:border-color ease-in-out .15s,-webkit-box-shadow ease-in-out .15s;-o-transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s}.form-control:focus{border-color:#66afe9;outline:0;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6);box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6)}.form-control::-moz-placeholder{color:#999;opacity:1}.form-control:-ms-input-placeholder{color:#999}.form-control::-webkit-input-placeholder{color:#999}.form-control[disabled],.form-control[readonly],fieldset[disabled] .form-control{background-color:#eee;opacity:1}.form-control[disabled],fieldset[disabled] .form-control{cursor:not-allowed}textarea.form-control{height:auto}input[type=search]{-webkit-appearance:none}@media screen and (-webkit-min-device-pixel-ratio:0){input[type=date].form-control,input[type=time].form-control,input[type=datetime-local].form-control,input[type=month].form-control{line-height:34px}.input-group-sm input[type=date],.input-group-sm input[type=time],.input-group-sm input[type=datetime-local],.input-group-sm input[type=month],input[type=date].input-sm,input[type=time].input-sm,input[type=datetime-local].input-sm,input[type=month].input-sm{line-height:30px}.input-group-lg input[type=date],.input-group-lg input[type=time],.input-group-lg input[type=datetime-local],.input-group-lg input[type=month],input[type=date].input-lg,input[type=time].input-lg,input[type=datetime-local].input-lg,input[type=month].input-lg{line-height:46px}}.form-group{margin-bottom:15px}.checkbox,.radio{position:relative;display:block;margin-top:10px;margin-bottom:10px}.checkbox label,.radio label{min-height:20px;padding-left:20px;margin-bottom:0;font-weight:400;cursor:pointer}.checkbox input[type=checkbox],.checkbox-inline input[type=checkbox],.radio input[type=radio],.radio-inline input[type=radio]{position:absolute;margin-top:4px\9;margin-left:-20px}.checkbox+.checkbox,.radio+.radio{margin-top:-5px}.checkbox-inline,.radio-inline{position:relative;display:inline-block;padding-left:20px;margin-bottom:0;font-weight:400;vertical-align:middle;cursor:pointer}.checkbox-inline+.checkbox-inline,.radio-inline+.radio-inline{margin-top:0;margin-left:10px}fieldset[disabled] input[type=checkbox],fieldset[disabled] input[type=radio],input[type=checkbox].disabled,input[type=checkbox][disabled],input[type=radio].disabled,input[type=radio][disabled]{cursor:not-allowed}.checkbox-inline.disabled,.radio-inline.disabled,fieldset[disabled] .checkbox-inline,fieldset[disabled] .radio-inline{cursor:not-allowed}.checkbox.disabled label,.radio.disabled label,fieldset[disabled] .checkbox label,fieldset[disabled] .radio label{cursor:not-allowed}.form-control-static{min-height:34px;padding-top:7px;padding-bottom:7px;margin-bottom:0}.form-control-static.input-lg,.form-control-static.input-sm{padding-right:0;padding-left:0}.input-sm{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}select.input-sm{height:30px;line-height:30px}select[multiple].input-sm,textarea.input-sm{height:auto}.form-group-sm .form-control{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}.form-group-sm select.form-control{height:30px;line-height:30px}.form-group-sm select[multiple].form-control,.form-group-sm textarea.form-control{height:auto}.form-group-sm .form-control-static{height:30px;min-height:32px;padding:6px 10px;font-size:12px;line-height:1.5}.input-lg{height:46px;padding:10px 16px;font-size:18px;line-height:1.3333333;border-radius:6px}select.input-lg{height:46px;line-height:46px}select[multiple].input-lg,textarea.input-lg{height:auto}.form-group-lg .form-control{height:46px;padding:10px 16px;font-size:18px;line-height:1.3333333;border-radius:6px}.form-group-lg select.form-control{height:46px;line-height:46px}.form-group-lg select[multiple].form-control,.form-group-lg textarea.form-control{height:auto}.form-group-lg .form-control-static{height:46px;min-height:38px;padding:11px 16px;font-size:18px;line-height:1.3333333}.has-feedback{position:relative}.has-feedback .form-control{padding-right:42.5px}.form-control-feedback{position:absolute;top:0;right:0;z-index:2;display:block;width:34px;height:34px;line-height:34px;text-align:center;pointer-events:none}.form-group-lg .form-control+.form-control-feedback,.input-group-lg+.form-control-feedback,.input-lg+.form-control-feedback{width:46px;height:46px;line-height:46px}.form-group-sm .form-control+.form-control-feedback,.input-group-sm+.form-control-feedback,.input-sm+.form-control-feedback{width:30px;height:30px;line-height:30px}.has-success .checkbox,.has-success .checkbox-inline,.has-success .control-label,.has-success .help-block,.has-success .radio,.has-success .radio-inline,.has-success.checkbox label,.has-success.checkbox-inline label,.has-success.radio label,.has-success.radio-inline label{color:#3c763d}.has-success .form-control{border-color:#3c763d;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-success .form-control:focus{border-color:#2b542c;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #67b168;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #67b168}.has-success .input-group-addon{color:#3c763d;background-color:#dff0d8;border-color:#3c763d}.has-success .form-control-feedback{color:#3c763d}.has-warning .checkbox,.has-warning .checkbox-inline,.has-warning .control-label,.has-warning .help-block,.has-warning .radio,.has-warning .radio-inline,.has-warning.checkbox label,.has-warning.checkbox-inline label,.has-warning.radio label,.has-warning.radio-inline label{color:#8a6d3b}.has-warning .form-control{border-color:#8a6d3b;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-warning .form-control:focus{border-color:#66512c;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #c0a16b;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #c0a16b}.has-warning .input-group-addon{color:#8a6d3b;background-color:#fcf8e3;border-color:#8a6d3b}.has-warning .form-control-feedback{color:#8a6d3b}.has-error .checkbox,.has-error .checkbox-inline,.has-error .control-label,.has-error .help-block,.has-error .radio,.has-error .radio-inline,.has-error.checkbox label,.has-error.checkbox-inline label,.has-error.radio label,.has-error.radio-inline label{color:#a94442}.has-error .form-control{border-color:#a94442;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-error .form-control:focus{border-color:#843534;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #ce8483;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #ce8483}.has-error .input-group-addon{color:#a94442;background-color:#f2dede;border-color:#a94442}.has-error .form-control-feedback{color:#a94442}.has-feedback label~.form-control-feedback{top:25px}.has-feedback label.sr-only~.form-control-feedback{top:0}.help-block{display:block;margin-top:5px;margin-bottom:10px;color:#737373}@media (min-width:768px){.form-inline .form-group{display:inline-block;margin-bottom:0;vertical-align:middle}.form-inline .form-control{display:inline-block;width:auto;vertical-align:middle}.form-inline .form-control-static{display:inline-block}.form-inline .input-group{display:inline-table;vertical-align:middle}.form-inline .input-group .form-control,.form-inline .input-group .input-group-addon,.form-inline .input-group .input-group-btn{width:auto}.form-inline .input-group&gt;.form-control{width:100%}.form-inline .control-label{margin-bottom:0;vertical-align:middle}.form-inline .checkbox,.form-inline .radio{display:inline-block;margin-top:0;margin-bottom:0;vertical-align:middle}.form-inline .checkbox label,.form-inline .radio label{padding-left:0}.form-inline .checkbox input[type=checkbox],.form-inline .radio input[type=radio]{position:relative;margin-left:0}.form-inline .has-feedback .form-control-feedback{top:0}}.form-horizontal .checkbox,.form-horizontal .checkbox-inline,.form-horizontal .radio,.form-horizontal .radio-inline{padding-top:7px;margin-top:0;margin-bottom:0}.form-horizontal .checkbox,.form-horizontal .radio{min-height:27px}.form-horizontal .form-group{margin-right:-15px;margin-left:-15px}@media (min-width:768px){.form-horizontal .control-label{padding-top:7px;margin-bottom:0;text-align:right}}.form-horizontal .has-feedback .form-control-feedback{right:15px}@media (min-width:768px){.form-horizontal .form-group-lg .control-label{padding-top:14.33px;font-size:18px}}@media (min-width:768px){.form-horizontal .form-group-sm .control-label{padding-top:6px;font-size:12px}}.btn{display:inline-block;padding:6px 12px;margin-bottom:0;font-size:14px;font-weight:400;line-height:1.42857143;text-align:center;white-space:nowrap;vertical-align:middle;-ms-touch-action:manipulation;touch-action:manipulation;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-image:none;border:1px solid transparent;border-radius:4px}.btn.active.focus,.btn.active:focus,.btn.focus,.btn:active.focus,.btn:active:focus,.btn:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}.btn.focus,.btn:focus,.btn:hover{color:#333;text-decoration:none}.btn.active,.btn:active{background-image:none;outline:0;-webkit-box-shadow:inset 0 3px 5px rgba(0,0,0,.125);box-shadow:inset 0 3px 5px rgba(0,0,0,.125)}.btn.disabled,.btn[disabled],fieldset[disabled] .btn{cursor:not-allowed;filter:alpha(opacity=65);-webkit-box-shadow:none;box-shadow:none;opacity:.65}a.btn.disabled,fieldset[disabled] a.btn{pointer-events:none}.btn-default{color:#333;background-color:#fff;border-color:#ccc}.btn-default.focus,.btn-default:focus{color:#333;background-color:#e6e6e6;border-color:#8c8c8c}.btn-default:hover{color:#333;background-color:#e6e6e6;border-color:#adadad}.btn-default.active,.btn-default:active,.open&gt;.dropdown-toggle.btn-default{color:#333;background-color:#e6e6e6;border-color:#adadad}.btn-default.active.focus,.btn-default.active:focus,.btn-default.active:hover,.btn-default:active.focus,.btn-default:active:focus,.btn-default:active:hover,.open&gt;.dropdown-toggle.btn-default.focus,.open&gt;.dropdown-toggle.btn-default:focus,.open&gt;.dropdown-toggle.btn-default:hover{color:#333;background-color:#d4d4d4;border-color:#8c8c8c}.btn-default.active,.btn-default:active,.open&gt;.dropdown-toggle.btn-default{background-image:none}.btn-default.disabled,.btn-default.disabled.active,.btn-default.disabled.focus,.btn-default.disabled:active,.btn-default.disabled:focus,.btn-default.disabled:hover,.btn-default[disabled],.btn-default[disabled].active,.btn-default[disabled].focus,.btn-default[disabled]:active,.btn-default[disabled]:focus,.btn-default[disabled]:hover,fieldset[disabled] .btn-default,fieldset[disabled] .btn-default.active,fieldset[disabled] .btn-default.focus,fieldset[disabled] .btn-default:active,fieldset[disabled] .btn-default:focus,fieldset[disabled] .btn-default:hover{background-color:#fff;border-color:#ccc}.btn-default .badge{color:#fff;background-color:#333}.btn-primary{color:#fff;background-color:#337ab7;border-color:#2e6da4}.btn-primary.focus,.btn-primary:focus{color:#fff;background-color:#286090;border-color:#122b40}.btn-primary:hover{color:#fff;background-color:#286090;border-color:#204d74}.btn-primary.active,.btn-primary:active,.open&gt;.dropdown-toggle.btn-primary{color:#fff;background-color:#286090;border-color:#204d74}.btn-primary.active.focus,.btn-primary.active:focus,.btn-primary.active:hover,.btn-primary:active.focus,.btn-primary:active:focus,.btn-primary:active:hover,.open&gt;.dropdown-toggle.btn-primary.focus,.open&gt;.dropdown-toggle.btn-primary:focus,.open&gt;.dropdown-toggle.btn-primary:hover{color:#fff;background-color:#204d74;border-color:#122b40}.btn-primary.active,.btn-primary:active,.open&gt;.dropdown-toggle.btn-primary{background-image:none}.btn-primary.disabled,.btn-primary.disabled.active,.btn-primary.disabled.focus,.btn-primary.disabled:active,.btn-primary.disabled:focus,.btn-primary.disabled:hover,.btn-primary[disabled],.btn-primary[disabled].active,.btn-primary[disabled].focus,.btn-primary[disabled]:active,.btn-primary[disabled]:focus,.btn-primary[disabled]:hover,fieldset[disabled] .btn-primary,fieldset[disabled] .btn-primary.active,fieldset[disabled] .btn-primary.focus,fieldset[disabled] .btn-primary:active,fieldset[disabled] .btn-primary:focus,fieldset[disabled] .btn-primary:hover{background-color:#337ab7;border-color:#2e6da4}.btn-primary .badge{color:#337ab7;background-color:#fff}.btn-success{color:#fff;background-color:#5cb85c;border-color:#4cae4c}.btn-success.focus,.btn-success:focus{color:#fff;background-color:#449d44;border-color:#255625}.btn-success:hover{color:#fff;background-color:#449d44;border-color:#398439}.btn-success.active,.btn-success:active,.open&gt;.dropdown-toggle.btn-success{color:#fff;background-color:#449d44;border-color:#398439}.btn-success.active.focus,.btn-success.active:focus,.btn-success.active:hover,.btn-success:active.focus,.btn-success:active:focus,.btn-success:active:hover,.open&gt;.dropdown-toggle.btn-success.focus,.open&gt;.dropdown-toggle.btn-success:focus,.open&gt;.dropdown-toggle.btn-success:hover{color:#fff;background-color:#398439;border-color:#255625}.btn-success.active,.btn-success:active,.open&gt;.dropdown-toggle.btn-success{background-image:none}.btn-success.disabled,.btn-success.disabled.active,.btn-success.disabled.focus,.btn-success.disabled:active,.btn-success.disabled:focus,.btn-success.disabled:hover,.btn-success[disabled],.btn-success[disabled].active,.btn-success[disabled].focus,.btn-success[disabled]:active,.btn-success[disabled]:focus,.btn-success[disabled]:hover,fieldset[disabled] .btn-success,fieldset[disabled] .btn-success.active,fieldset[disabled] .btn-success.focus,fieldset[disabled] .btn-success:active,fieldset[disabled] .btn-success:focus,fieldset[disabled] .btn-success:hover{background-color:#5cb85c;border-color:#4cae4c}.btn-success .badge{color:#5cb85c;background-color:#fff}.btn-info{color:#fff;background-color:#5bc0de;border-color:#46b8da}.btn-info.focus,.btn-info:focus{color:#fff;background-color:#31b0d5;border-color:#1b6d85}.btn-info:hover{color:#fff;background-color:#31b0d5;border-color:#269abc}.btn-info.active,.btn-info:active,.open&gt;.dropdown-toggle.btn-info{color:#fff;background-color:#31b0d5;border-color:#269abc}.btn-info.active.focus,.btn-info.active:focus,.btn-info.active:hover,.btn-info:active.focus,.btn-info:active:focus,.btn-info:active:hover,.open&gt;.dropdown-toggle.btn-info.focus,.open&gt;.dropdown-toggle.btn-info:focus,.open&gt;.dropdown-toggle.btn-info:hover{color:#fff;background-color:#269abc;border-color:#1b6d85}.btn-info.active,.btn-info:active,.open&gt;.dropdown-toggle.btn-info{background-image:none}.btn-info.disabled,.btn-info.disabled.active,.btn-info.disabled.focus,.btn-info.disabled:active,.btn-info.disabled:focus,.btn-info.disabled:hover,.btn-info[disabled],.btn-info[disabled].active,.btn-info[disabled].focus,.btn-info[disabled]:active,.btn-info[disabled]:focus,.btn-info[disabled]:hover,fieldset[disabled] .btn-info,fieldset[disabled] .btn-info.active,fieldset[disabled] .btn-info.focus,fieldset[disabled] .btn-info:active,fieldset[disabled] .btn-info:focus,fieldset[disabled] .btn-info:hover{background-color:#5bc0de;border-color:#46b8da}.btn-info .badge{color:#5bc0de;background-color:#fff}.btn-warning{color:#fff;background-color:#f0ad4e;border-color:#eea236}.btn-warning.focus,.btn-warning:focus{color:#fff;background-color:#ec971f;border-color:#985f0d}.btn-warning:hover{color:#fff;background-color:#ec971f;border-color:#d58512}.btn-warning.active,.btn-warning:active,.open&gt;.dropdown-toggle.btn-warning{color:#fff;background-color:#ec971f;border-color:#d58512}.btn-warning.active.focus,.btn-warning.active:focus,.btn-warning.active:hover,.btn-warning:active.focus,.btn-warning:active:focus,.btn-warning:active:hover,.open&gt;.dropdown-toggle.btn-warning.focus,.open&gt;.dropdown-toggle.btn-warning:focus,.open&gt;.dropdown-toggle.btn-warning:hover{color:#fff;background-color:#d58512;border-color:#985f0d}.btn-warning.active,.btn-warning:active,.open&gt;.dropdown-toggle.btn-warning{background-image:none}.btn-warning.disabled,.btn-warning.disabled.active,.btn-warning.disabled.focus,.btn-warning.disabled:active,.btn-warning.disabled:focus,.btn-warning.disabled:hover,.btn-warning[disabled],.btn-warning[disabled].active,.btn-warning[disabled].focus,.btn-warning[disabled]:active,.btn-warning[disabled]:focus,.btn-warning[disabled]:hover,fieldset[disabled] .btn-warning,fieldset[disabled] .btn-warning.active,fieldset[disabled] .btn-warning.focus,fieldset[disabled] .btn-warning:active,fieldset[disabled] .btn-warning:focus,fieldset[disabled] .btn-warning:hover{background-color:#f0ad4e;border-color:#eea236}.btn-warning .badge{color:#f0ad4e;background-color:#fff}.btn-danger{color:#fff;background-color:#d9534f;border-color:#d43f3a}.btn-danger.focus,.btn-danger:focus{color:#fff;background-color:#c9302c;border-color:#761c19}.btn-danger:hover{color:#fff;background-color:#c9302c;border-color:#ac2925}.btn-danger.active,.btn-danger:active,.open&gt;.dropdown-toggle.btn-danger{color:#fff;background-color:#c9302c;border-color:#ac2925}.btn-danger.active.focus,.btn-danger.active:focus,.btn-danger.active:hover,.btn-danger:active.focus,.btn-danger:active:focus,.btn-danger:active:hover,.open&gt;.dropdown-toggle.btn-danger.focus,.open&gt;.dropdown-toggle.btn-danger:focus,.open&gt;.dropdown-toggle.btn-danger:hover{color:#fff;background-color:#ac2925;border-color:#761c19}.btn-danger.active,.btn-danger:active,.open&gt;.dropdown-toggle.btn-danger{background-image:none}.btn-danger.disabled,.btn-danger.disabled.active,.btn-danger.disabled.focus,.btn-danger.disabled:active,.btn-danger.disabled:focus,.btn-danger.disabled:hover,.btn-danger[disabled],.btn-danger[disabled].active,.btn-danger[disabled].focus,.btn-danger[disabled]:active,.btn-danger[disabled]:focus,.btn-danger[disabled]:hover,fieldset[disabled] .btn-danger,fieldset[disabled] .btn-danger.active,fieldset[disabled] .btn-danger.focus,fieldset[disabled] .btn-danger:active,fieldset[disabled] .btn-danger:focus,fieldset[disabled] .btn-danger:hover{background-color:#d9534f;border-color:#d43f3a}.btn-danger .badge{color:#d9534f;background-color:#fff}.btn-link{font-weight:400;color:#337ab7;border-radius:0}.btn-link,.btn-link.active,.btn-link:active,.btn-link[disabled],fieldset[disabled] .btn-link{background-color:transparent;-webkit-box-shadow:none;box-shadow:none}.btn-link,.btn-link:active,.btn-link:focus,.btn-link:hover{border-color:transparent}.btn-link:focus,.btn-link:hover{color:#23527c;text-decoration:underline;background-color:transparent}.btn-link[disabled]:focus,.btn-link[disabled]:hover,fieldset[disabled] .btn-link:focus,fieldset[disabled] .btn-link:hover{color:#777;text-decoration:none}.btn-group-lg&gt;.btn,.btn-lg{padding:10px 16px;font-size:18px;line-height:1.3333333;border-radius:6px}.btn-group-sm&gt;.btn,.btn-sm{padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}.btn-group-xs&gt;.btn,.btn-xs{padding:1px 5px;font-size:12px;line-height:1.5;border-radius:3px}.btn-block{display:block;width:100%}.btn-block+.btn-block{margin-top:5px}input[type=button].btn-block,input[type=reset].btn-block,input[type=submit].btn-block{width:100%}.fade{opacity:0;-webkit-transition:opacity .15s linear;-o-transition:opacity .15s linear;transition:opacity .15s linear}.fade.in{opacity:1}.collapse{display:none}.collapse.in{display:block}tr.collapse.in{display:table-row}tbody.collapse.in{display:table-row-group}.collapsing{position:relative;height:0;overflow:hidden;-webkit-transition-timing-function:ease;-o-transition-timing-function:ease;transition-timing-function:ease;-webkit-transition-duration:.35s;-o-transition-duration:.35s;transition-duration:.35s;-webkit-transition-property:height,visibility;-o-transition-property:height,visibility;transition-property:height,visibility}.caret{display:inline-block;width:0;height:0;margin-left:2px;vertical-align:middle;border-top:4px dashed;border-top:4px solid\9;border-right:4px solid transparent;border-left:4px solid transparent}.dropdown,.dropup{position:relative}.dropdown-toggle:focus{outline:0}.dropdown-menu{position:absolute;top:100%;left:0;z-index:1000;display:none;float:left;min-width:160px;padding:5px 0;margin:2px 0 0;font-size:14px;text-align:left;list-style:none;background-color:#fff;-webkit-background-clip:padding-box;background-clip:padding-box;border:1px solid #ccc;border:1px solid rgba(0,0,0,.15);border-radius:4px;-webkit-box-shadow:0 6px 12px rgba(0,0,0,.175);box-shadow:0 6px 12px rgba(0,0,0,.175)}.dropdown-menu.pull-right{right:0;left:auto}.dropdown-menu .divider{height:1px;margin:9px 0;overflow:hidden;background-color:#e5e5e5}.dropdown-menu&gt;li&gt;a{display:block;padding:3px 20px;clear:both;font-weight:400;line-height:1.42857143;color:#333;white-space:nowrap}.dropdown-menu&gt;li&gt;a:focus,.dropdown-menu&gt;li&gt;a:hover{color:#262626;text-decoration:none;background-color:#f5f5f5}.dropdown-menu&gt;.active&gt;a,.dropdown-menu&gt;.active&gt;a:focus,.dropdown-menu&gt;.active&gt;a:hover{color:#fff;text-decoration:none;background-color:#337ab7;outline:0}.dropdown-menu&gt;.disabled&gt;a,.dropdown-menu&gt;.disabled&gt;a:focus,.dropdown-menu&gt;.disabled&gt;a:hover{color:#777}.dropdown-menu&gt;.disabled&gt;a:focus,.dropdown-menu&gt;.disabled&gt;a:hover{text-decoration:none;cursor:not-allowed;background-color:transparent;background-image:none;filter:progid:DXImageTransform.Microsoft.gradient(enabled=false)}.open&gt;.dropdown-menu{display:block}.open&gt;a{outline:0}.dropdown-menu-right{right:0;left:auto}.dropdown-menu-left{right:auto;left:0}.dropdown-header{display:block;padding:3px 20px;font-size:12px;line-height:1.42857143;color:#777;white-space:nowrap}.dropdown-backdrop{position:fixed;top:0;right:0;bottom:0;left:0;z-index:990}.pull-right&gt;.dropdown-menu{right:0;left:auto}.dropup .caret,.navbar-fixed-bottom .dropdown .caret{content:&#34;&#34;;border-top:0;border-bottom:4px dashed;border-bottom:4px solid\9}.dropup .dropdown-menu,.navbar-fixed-bottom .dropdown .dropdown-menu{top:auto;bottom:100%;margin-bottom:2px}@media (min-width:768px){.navbar-right .dropdown-menu{right:0;left:auto}.navbar-right .dropdown-menu-left{right:auto;left:0}}.btn-group,.btn-group-vertical{position:relative;display:inline-block;vertical-align:middle}.btn-group-vertical&gt;.btn,.btn-group&gt;.btn{position:relative;float:left}.btn-group-vertical&gt;.btn.active,.btn-group-vertical&gt;.btn:active,.btn-group-vertical&gt;.btn:focus,.btn-group-vertical&gt;.btn:hover,.btn-group&gt;.btn.active,.btn-group&gt;.btn:active,.btn-group&gt;.btn:focus,.btn-group&gt;.btn:hover{z-index:2}.btn-group .btn+.btn,.btn-group .btn+.btn-group,.btn-group .btn-group+.btn,.btn-group .btn-group+.btn-group{margin-left:-1px}.btn-toolbar{margin-left:-5px}.btn-toolbar .btn,.btn-toolbar .btn-group,.btn-toolbar .input-group{float:left}.btn-toolbar&gt;.btn,.btn-toolbar&gt;.btn-group,.btn-toolbar&gt;.input-group{margin-left:5px}.btn-group&gt;.btn:not(:first-child):not(:last-child):not(.dropdown-toggle){border-radius:0}.btn-group&gt;.btn:first-child{margin-left:0}.btn-group&gt;.btn:first-child:not(:last-child):not(.dropdown-toggle){border-top-right-radius:0;border-bottom-right-radius:0}.btn-group&gt;.btn:last-child:not(:first-child),.btn-group&gt;.dropdown-toggle:not(:first-child){border-top-left-radius:0;border-bottom-left-radius:0}.btn-group&gt;.btn-group{float:left}.btn-group&gt;.btn-group:not(:first-child):not(:last-child)&gt;.btn{border-radius:0}.btn-group&gt;.btn-group:first-child:not(:last-child)&gt;.btn:last-child,.btn-group&gt;.btn-group:first-child:not(:last-child)&gt;.dropdown-toggle{border-top-right-radius:0;border-bottom-right-radius:0}.btn-group&gt;.btn-group:last-child:not(:first-child)&gt;.btn:first-child{border-top-left-radius:0;border-bottom-left-radius:0}.btn-group .dropdown-toggle:active,.btn-group.open .dropdown-toggle{outline:0}.btn-group&gt;.btn+.dropdown-toggle{padding-right:8px;padding-left:8px}.btn-group&gt;.btn-lg+.dropdown-toggle{padding-right:12px;padding-left:12px}.btn-group.open .dropdown-toggle{-webkit-box-shadow:inset 0 3px 5px rgba(0,0,0,.125);box-shadow:inset 0 3px 5px rgba(0,0,0,.125)}.btn-group.open .dropdown-toggle.btn-link{-webkit-box-shadow:none;box-shadow:none}.btn .caret{margin-left:0}.btn-lg .caret{border-width:5px 5px 0;border-bottom-width:0}.dropup .btn-lg .caret{border-width:0 5px 5px}.btn-group-vertical&gt;.btn,.btn-group-vertical&gt;.btn-group,.btn-group-vertical&gt;.btn-group&gt;.btn{display:block;float:none;width:100%;max-width:100%}.btn-group-vertical&gt;.btn-group&gt;.btn{float:none}.btn-group-vertical&gt;.btn+.btn,.btn-group-vertical&gt;.btn+.btn-group,.btn-group-vertical&gt;.btn-group+.btn,.btn-group-vertical&gt;.btn-group+.btn-group{margin-top:-1px;margin-left:0}.btn-group-vertical&gt;.btn:not(:first-child):not(:last-child){border-radius:0}.btn-group-vertical&gt;.btn:first-child:not(:last-child){border-top-right-radius:4px;border-bottom-right-radius:0;border-bottom-left-radius:0}.btn-group-vertical&gt;.btn:last-child:not(:first-child){border-top-left-radius:0;border-top-right-radius:0;border-bottom-left-radius:4px}.btn-group-vertical&gt;.btn-group:not(:first-child):not(:last-child)&gt;.btn{border-radius:0}.btn-group-vertical&gt;.btn-group:first-child:not(:last-child)&gt;.btn:last-child,.btn-group-vertical&gt;.btn-group:first-child:not(:last-child)&gt;.dropdown-toggle{border-bottom-right-radius:0;border-bottom-left-radius:0}.btn-group-vertical&gt;.btn-group:last-child:not(:first-child)&gt;.btn:first-child{border-top-left-radius:0;border-top-right-radius:0}.btn-group-justified{display:table;width:100%;table-layout:fixed;border-collapse:separate}.btn-group-justified&gt;.btn,.btn-group-justified&gt;.btn-group{display:table-cell;float:none;width:1%}.btn-group-justified&gt;.btn-group .btn{width:100%}.btn-group-justified&gt;.btn-group .dropdown-menu{left:auto}[data-toggle=buttons]&gt;.btn input[type=checkbox],[data-toggle=buttons]&gt;.btn input[type=radio],[data-toggle=buttons]&gt;.btn-group&gt;.btn input[type=checkbox],[data-toggle=buttons]&gt;.btn-group&gt;.btn input[type=radio]{position:absolute;clip:rect(0,0,0,0);pointer-events:none}.input-group{position:relative;display:table;border-collapse:separate}.input-group[class*=col-]{float:none;padding-right:0;padding-left:0}.input-group .form-control{position:relative;z-index:2;float:left;width:100%;margin-bottom:0}.input-group-lg&gt;.form-control,.input-group-lg&gt;.input-group-addon,.input-group-lg&gt;.input-group-btn&gt;.btn{height:46px;padding:10px 16px;font-size:18px;line-height:1.3333333;border-radius:6px}select.input-group-lg&gt;.form-control,select.input-group-lg&gt;.input-group-addon,select.input-group-lg&gt;.input-group-btn&gt;.btn{height:46px;line-height:46px}select[multiple].input-group-lg&gt;.form-control,select[multiple].input-group-lg&gt;.input-group-addon,select[multiple].input-group-lg&gt;.input-group-btn&gt;.btn,textarea.input-group-lg&gt;.form-control,textarea.input-group-lg&gt;.input-group-addon,textarea.input-group-lg&gt;.input-group-btn&gt;.btn{height:auto}.input-group-sm&gt;.form-control,.input-group-sm&gt;.input-group-addon,.input-group-sm&gt;.input-group-btn&gt;.btn{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}select.input-group-sm&gt;.form-control,select.input-group-sm&gt;.input-group-addon,select.input-group-sm&gt;.input-group-btn&gt;.btn{height:30px;line-height:30px}select[multiple].input-group-sm&gt;.form-control,select[multiple].input-group-sm&gt;.input-group-addon,select[multiple].input-group-sm&gt;.input-group-btn&gt;.btn,textarea.input-group-sm&gt;.form-control,textarea.input-group-sm&gt;.input-group-addon,textarea.input-group-sm&gt;.input-group-btn&gt;.btn{height:auto}.input-group .form-control,.input-group-addon,.input-group-btn{display:table-cell}.input-group .form-control:not(:first-child):not(:last-child),.input-group-addon:not(:first-child):not(:last-child),.input-group-btn:not(:first-child):not(:last-child){border-radius:0}.input-group-addon,.input-group-btn{width:1%;white-space:nowrap;vertical-align:middle}.input-group-addon{padding:6px 12px;font-size:14px;font-weight:400;line-height:1;color:#555;text-align:center;background-color:#eee;border:1px solid #ccc;border-radius:4px}.input-group-addon.input-sm{padding:5px 10px;font-size:12px;border-radius:3px}.input-group-addon.input-lg{padding:10px 16px;font-size:18px;border-radius:6px}.input-group-addon input[type=checkbox],.input-group-addon input[type=radio]{margin-top:0}.input-group .form-control:first-child,.input-group-addon:first-child,.input-group-btn:first-child&gt;.btn,.input-group-btn:first-child&gt;.btn-group&gt;.btn,.input-group-btn:first-child&gt;.dropdown-toggle,.input-group-btn:last-child&gt;.btn-group:not(:last-child)&gt;.btn,.input-group-btn:last-child&gt;.btn:not(:last-child):not(.dropdown-toggle){border-top-right-radius:0;border-bottom-right-radius:0}.input-group-addon:first-child{border-right:0}.input-group .form-control:last-child,.input-group-addon:last-child,.input-group-btn:first-child&gt;.btn-group:not(:first-child)&gt;.btn,.input-group-btn:first-child&gt;.btn:not(:first-child),.input-group-btn:last-child&gt;.btn,.input-group-btn:last-child&gt;.btn-group&gt;.btn,.input-group-btn:last-child&gt;.dropdown-toggle{border-top-left-radius:0;border-bottom-left-radius:0}.input-group-addon:last-child{border-left:0}.input-group-btn{position:relative;font-size:0;white-space:nowrap}.input-group-btn&gt;.btn{position:relative}.input-group-btn&gt;.btn+.btn{margin-left:-1px}.input-group-btn&gt;.btn:active,.input-group-btn&gt;.btn:focus,.input-group-btn&gt;.btn:hover{z-index:2}.input-group-btn:first-child&gt;.btn,.input-group-btn:first-child&gt;.btn-group{margin-right:-1px}.input-group-btn:last-child&gt;.btn,.input-group-btn:last-child&gt;.btn-group{z-index:2;margin-left:-1px}.nav{padding-left:0;margin-bottom:0;list-style:none}.nav&gt;li{position:relative;display:block}.nav&gt;li&gt;a{position:relative;display:block;padding:10px 15px}.nav&gt;li&gt;a:focus,.nav&gt;li&gt;a:hover{text-decoration:none;background-color:#eee}.nav&gt;li.disabled&gt;a{color:#777}.nav&gt;li.disabled&gt;a:focus,.nav&gt;li.disabled&gt;a:hover{color:#777;text-decoration:none;cursor:not-allowed;background-color:transparent}.nav .open&gt;a,.nav .open&gt;a:focus,.nav .open&gt;a:hover{background-color:#eee;border-color:#337ab7}.nav .nav-divider{height:1px;margin:9px 0;overflow:hidden;background-color:#e5e5e5}.nav&gt;li&gt;a&gt;img{max-width:none}.nav-tabs{border-bottom:1px solid #ddd}.nav-tabs&gt;li{float:left;margin-bottom:-1px}.nav-tabs&gt;li&gt;a{margin-right:2px;line-height:1.42857143;border:1px solid transparent;border-radius:4px 4px 0 0}.nav-tabs&gt;li&gt;a:hover{border-color:#eee #eee #ddd}.nav-tabs&gt;li.active&gt;a,.nav-tabs&gt;li.active&gt;a:focus,.nav-tabs&gt;li.active&gt;a:hover{color:#555;cursor:default;background-color:#fff;border:1px solid #ddd;border-bottom-color:transparent}.nav-tabs.nav-justified{width:100%;border-bottom:0}.nav-tabs.nav-justified&gt;li{float:none}.nav-tabs.nav-justified&gt;li&gt;a{margin-bottom:5px;text-align:center}.nav-tabs.nav-justified&gt;.dropdown .dropdown-menu{top:auto;left:auto}@media (min-width:768px){.nav-tabs.nav-justified&gt;li{display:table-cell;width:1%}.nav-tabs.nav-justified&gt;li&gt;a{margin-bottom:0}}.nav-tabs.nav-justified&gt;li&gt;a{margin-right:0;border-radius:4px}.nav-tabs.nav-justified&gt;.active&gt;a,.nav-tabs.nav-justified&gt;.active&gt;a:focus,.nav-tabs.nav-justified&gt;.active&gt;a:hover{border:1px solid #ddd}@media (min-width:768px){.nav-tabs.nav-justified&gt;li&gt;a{border-bottom:1px solid #ddd;border-radius:4px 4px 0 0}.nav-tabs.nav-justified&gt;.active&gt;a,.nav-tabs.nav-justified&gt;.active&gt;a:focus,.nav-tabs.nav-justified&gt;.active&gt;a:hover{border-bottom-color:#fff}}.nav-pills&gt;li{float:left}.nav-pills&gt;li&gt;a{border-radius:4px}.nav-pills&gt;li+li{margin-left:2px}.nav-pills&gt;li.active&gt;a,.nav-pills&gt;li.active&gt;a:focus,.nav-pills&gt;li.active&gt;a:hover{color:#fff;background-color:#337ab7}.nav-stacked&gt;li{float:none}.nav-stacked&gt;li+li{margin-top:2px;margin-left:0}.nav-justified{width:100%}.nav-justified&gt;li{float:none}.nav-justified&gt;li&gt;a{margin-bottom:5px;text-align:center}.nav-justified&gt;.dropdown .dropdown-menu{top:auto;left:auto}@media (min-width:768px){.nav-justified&gt;li{display:table-cell;width:1%}.nav-justified&gt;li&gt;a{margin-bottom:0}}.nav-tabs-justified{border-bottom:0}.nav-tabs-justified&gt;li&gt;a{margin-right:0;border-radius:4px}.nav-tabs-justified&gt;.active&gt;a,.nav-tabs-justified&gt;.active&gt;a:focus,.nav-tabs-justified&gt;.active&gt;a:hover{border:1px solid #ddd}@media (min-width:768px){.nav-tabs-justified&gt;li&gt;a{border-bottom:1px solid #ddd;border-radius:4px 4px 0 0}.nav-tabs-justified&gt;.active&gt;a,.nav-tabs-justified&gt;.active&gt;a:focus,.nav-tabs-justified&gt;.active&gt;a:hover{border-bottom-color:#fff}}.tab-content&gt;.tab-pane{display:none}.tab-content&gt;.active{display:block}.nav-tabs .dropdown-menu{margin-top:-1px;border-top-left-radius:0;border-top-right-radius:0}.navbar{position:relative;min-height:50px;margin-bottom:20px;border:1px solid transparent}@media (min-width:768px){.navbar{border-radius:4px}}@media (min-width:768px){.navbar-header{float:left}}.navbar-collapse{padding-right:15px;padding-left:15px;overflow-x:visible;-webkit-overflow-scrolling:touch;border-top:1px solid transparent;-webkit-box-shadow:inset 0 1px 0 rgba(255,255,255,.1);box-shadow:inset 0 1px 0 rgba(255,255,255,.1)}.navbar-collapse.in{overflow-y:auto}@media (min-width:768px){.navbar-collapse{width:auto;border-top:0;-webkit-box-shadow:none;box-shadow:none}.navbar-collapse.collapse{display:block!important;height:auto!important;padding-bottom:0;overflow:visible!important}.navbar-collapse.in{overflow-y:visible}.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse,.navbar-static-top .navbar-collapse{padding-right:0;padding-left:0}}.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse{max-height:340px}@media (max-device-width:480px) and (orientation:landscape){.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse{max-height:200px}}.container-fluid&gt;.navbar-collapse,.container-fluid&gt;.navbar-header,.container&gt;.navbar-collapse,.container&gt;.navbar-header{margin-right:-15px;margin-left:-15px}@media (min-width:768px){.container-fluid&gt;.navbar-collapse,.container-fluid&gt;.navbar-header,.container&gt;.navbar-collapse,.container&gt;.navbar-header{margin-right:0;margin-left:0}}.navbar-static-top{z-index:1000;border-width:0 0 1px}@media (min-width:768px){.navbar-static-top{border-radius:0}}.navbar-fixed-bottom,.navbar-fixed-top{position:fixed;right:0;left:0;z-index:1030}@media (min-width:768px){.navbar-fixed-bottom,.navbar-fixed-top{border-radius:0}}.navbar-fixed-top{top:0;border-width:0 0 1px}.navbar-fixed-bottom{bottom:0;margin-bottom:0;border-width:1px 0 0}.navbar-brand{float:left;height:50px;padding:15px 15px;font-size:18px;line-height:20px}.navbar-brand:focus,.navbar-brand:hover{text-decoration:none}.navbar-brand&gt;img{display:block}@media (min-width:768px){.navbar&gt;.container .navbar-brand,.navbar&gt;.container-fluid .navbar-brand{margin-left:-15px}}.navbar-toggle{position:relative;float:right;padding:9px 10px;margin-top:8px;margin-right:15px;margin-bottom:8px;background-color:transparent;background-image:none;border:1px solid transparent;border-radius:4px}.navbar-toggle:focus{outline:0}.navbar-toggle .icon-bar{display:block;width:22px;height:2px;border-radius:1px}.navbar-toggle .icon-bar+.icon-bar{margin-top:4px}@media (min-width:768px){.navbar-toggle{display:none}}.navbar-nav{margin:7.5px -15px}.navbar-nav&gt;li&gt;a{padding-top:10px;padding-bottom:10px;line-height:20px}@media (max-width:767px){.navbar-nav .open .dropdown-menu{position:static;float:none;width:auto;margin-top:0;background-color:transparent;border:0;-webkit-box-shadow:none;box-shadow:none}.navbar-nav .open .dropdown-menu .dropdown-header,.navbar-nav .open .dropdown-menu&gt;li&gt;a{padding:5px 15px 5px 25px}.navbar-nav .open .dropdown-menu&gt;li&gt;a{line-height:20px}.navbar-nav .open .dropdown-menu&gt;li&gt;a:focus,.navbar-nav .open .dropdown-menu&gt;li&gt;a:hover{background-image:none}}@media (min-width:768px){.navbar-nav{float:left;margin:0}.navbar-nav&gt;li{float:left}.navbar-nav&gt;li&gt;a{padding-top:15px;padding-bottom:15px}}.navbar-form{padding:10px 15px;margin-top:8px;margin-right:-15px;margin-bottom:8px;margin-left:-15px;border-top:1px solid transparent;border-bottom:1px solid transparent;-webkit-box-shadow:inset 0 1px 0 rgba(255,255,255,.1),0 1px 0 rgba(255,255,255,.1);box-shadow:inset 0 1px 0 rgba(255,255,255,.1),0 1px 0 rgba(255,255,255,.1)}@media (min-width:768px){.navbar-form .form-group{display:inline-block;margin-bottom:0;vertical-align:middle}.navbar-form .form-control{display:inline-block;width:auto;vertical-align:middle}.navbar-form .form-control-static{display:inline-block}.navbar-form .input-group{display:inline-table;vertical-align:middle}.navbar-form .input-group .form-control,.navbar-form .input-group .input-group-addon,.navbar-form .input-group .input-group-btn{width:auto}.navbar-form .input-group&gt;.form-control{width:100%}.navbar-form .control-label{margin-bottom:0;vertical-align:middle}.navbar-form .checkbox,.navbar-form .radio{display:inline-block;margin-top:0;margin-bottom:0;vertical-align:middle}.navbar-form .checkbox label,.navbar-form .radio label{padding-left:0}.navbar-form .checkbox input[type=checkbox],.navbar-form .radio input[type=radio]{position:relative;margin-left:0}.navbar-form .has-feedback .form-control-feedback{top:0}}@media (max-width:767px){.navbar-form .form-group{margin-bottom:5px}.navbar-form .form-group:last-child{margin-bottom:0}}@media (min-width:768px){.navbar-form{width:auto;padding-top:0;padding-bottom:0;margin-right:0;margin-left:0;border:0;-webkit-box-shadow:none;box-shadow:none}}.navbar-nav&gt;li&gt;.dropdown-menu{margin-top:0;border-top-left-radius:0;border-top-right-radius:0}.navbar-fixed-bottom .navbar-nav&gt;li&gt;.dropdown-menu{margin-bottom:0;border-top-left-radius:4px;border-top-right-radius:4px;border-bottom-right-radius:0;border-bottom-left-radius:0}.navbar-btn{margin-top:8px;margin-bottom:8px}.navbar-btn.btn-sm{margin-top:10px;margin-bottom:10px}.navbar-btn.btn-xs{margin-top:14px;margin-bottom:14px}.navbar-text{margin-top:15px;margin-bottom:15px}@media (min-width:768px){.navbar-text{float:left;margin-right:15px;margin-left:15px}}@media (min-width:768px){.navbar-left{float:left!important}.navbar-right{float:right!important;margin-right:-15px}.navbar-right~.navbar-right{margin-right:0}}.navbar-default{background-color:#f8f8f8;border-color:#e7e7e7}.navbar-default .navbar-brand{color:#777}.navbar-default .navbar-brand:focus,.navbar-default .navbar-brand:hover{color:#5e5e5e;background-color:transparent}.navbar-default .navbar-text{color:#777}.navbar-default .navbar-nav&gt;li&gt;a{color:#777}.navbar-default .navbar-nav&gt;li&gt;a:focus,.navbar-default .navbar-nav&gt;li&gt;a:hover{color:#333;background-color:transparent}.navbar-default .navbar-nav&gt;.active&gt;a,.navbar-default .navbar-nav&gt;.active&gt;a:focus,.navbar-default .navbar-nav&gt;.active&gt;a:hover{color:#555;background-color:#e7e7e7}.navbar-default .navbar-nav&gt;.disabled&gt;a,.navbar-default .navbar-nav&gt;.disabled&gt;a:focus,.navbar-default .navbar-nav&gt;.disabled&gt;a:hover{color:#ccc;background-color:transparent}.navbar-default .navbar-toggle{border-color:#ddd}.navbar-default .navbar-toggle:focus,.navbar-default .navbar-toggle:hover{background-color:#ddd}.navbar-default .navbar-toggle .icon-bar{background-color:#888}.navbar-default .navbar-collapse,.navbar-default .navbar-form{border-color:#e7e7e7}.navbar-default .navbar-nav&gt;.open&gt;a,.navbar-default .navbar-nav&gt;.open&gt;a:focus,.navbar-default .navbar-nav&gt;.open&gt;a:hover{color:#555;background-color:#e7e7e7}@media (max-width:767px){.navbar-default .navbar-nav .open .dropdown-menu&gt;li&gt;a{color:#777}.navbar-default .navbar-nav .open .dropdown-menu&gt;li&gt;a:focus,.navbar-default .navbar-nav .open .dropdown-menu&gt;li&gt;a:hover{color:#333;background-color:transparent}.navbar-default .navbar-nav .open .dropdown-menu&gt;.active&gt;a,.navbar-default .navbar-nav .open .dropdown-menu&gt;.active&gt;a:focus,.navbar-default .navbar-nav .open .dropdown-menu&gt;.active&gt;a:hover{color:#555;background-color:#e7e7e7}.navbar-default .navbar-nav .open .dropdown-menu&gt;.disabled&gt;a,.navbar-default .navbar-nav .open .dropdown-menu&gt;.disabled&gt;a:focus,.navbar-default .navbar-nav .open .dropdown-menu&gt;.disabled&gt;a:hover{color:#ccc;background-color:transparent}}.navbar-default .navbar-link{color:#777}.navbar-default .navbar-link:hover{color:#333}.navbar-default .btn-link{color:#777}.navbar-default .btn-link:focus,.navbar-default .btn-link:hover{color:#333}.navbar-default .btn-link[disabled]:focus,.navbar-default .btn-link[disabled]:hover,fieldset[disabled] .navbar-default .btn-link:focus,fieldset[disabled] .navbar-default .btn-link:hover{color:#ccc}.navbar-inverse{background-color:#222;border-color:#080808}.navbar-inverse .navbar-brand{color:#9d9d9d}.navbar-inverse .navbar-brand:focus,.navbar-inverse .navbar-brand:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-text{color:#9d9d9d}.navbar-inverse .navbar-nav&gt;li&gt;a{color:#9d9d9d}.navbar-inverse .navbar-nav&gt;li&gt;a:focus,.navbar-inverse .navbar-nav&gt;li&gt;a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav&gt;.active&gt;a,.navbar-inverse .navbar-nav&gt;.active&gt;a:focus,.navbar-inverse .navbar-nav&gt;.active&gt;a:hover{color:#fff;background-color:#080808}.navbar-inverse .navbar-nav&gt;.disabled&gt;a,.navbar-inverse .navbar-nav&gt;.disabled&gt;a:focus,.navbar-inverse .navbar-nav&gt;.disabled&gt;a:hover{color:#444;background-color:transparent}.navbar-inverse .navbar-toggle{border-color:#333}.navbar-inverse .navbar-toggle:focus,.navbar-inverse .navbar-toggle:hover{background-color:#333}.navbar-inverse .navbar-toggle .icon-bar{background-color:#fff}.navbar-inverse .navbar-collapse,.navbar-inverse .navbar-form{border-color:#101010}.navbar-inverse .navbar-nav&gt;.open&gt;a,.navbar-inverse .navbar-nav&gt;.open&gt;a:focus,.navbar-inverse .navbar-nav&gt;.open&gt;a:hover{color:#fff;background-color:#080808}@media (max-width:767px){.navbar-inverse .navbar-nav .open .dropdown-menu&gt;.dropdown-header{border-color:#080808}.navbar-inverse .navbar-nav .open .dropdown-menu .divider{background-color:#080808}.navbar-inverse .navbar-nav .open .dropdown-menu&gt;li&gt;a{color:#9d9d9d}.navbar-inverse .navbar-nav .open .dropdown-menu&gt;li&gt;a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu&gt;li&gt;a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav .open .dropdown-menu&gt;.active&gt;a,.navbar-inverse .navbar-nav .open .dropdown-menu&gt;.active&gt;a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu&gt;.active&gt;a:hover{color:#fff;background-color:#080808}.navbar-inverse .navbar-nav .open .dropdown-menu&gt;.disabled&gt;a,.navbar-inverse .navbar-nav .open .dropdown-menu&gt;.disabled&gt;a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu&gt;.disabled&gt;a:hover{color:#444;background-color:transparent}}.navbar-inverse .navbar-link{color:#9d9d9d}.navbar-inverse .navbar-link:hover{color:#fff}.navbar-inverse .btn-link{color:#9d9d9d}.navbar-inverse .btn-link:focus,.navbar-inverse .btn-link:hover{color:#fff}.navbar-inverse .btn-link[disabled]:focus,.navbar-inverse .btn-link[disabled]:hover,fieldset[disabled] .navbar-inverse .btn-link:focus,fieldset[disabled] .navbar-inverse .btn-link:hover{color:#444}.breadcrumb{padding:8px 15px;margin-bottom:20px;list-style:none;background-color:#f5f5f5;border-radius:4px}.breadcrumb&gt;li{display:inline-block}.breadcrumb&gt;li+li:before{padding:0 5px;color:#ccc;content:&#34;/\00a0&#34;}.breadcrumb&gt;.active{color:#777}.pagination{display:inline-block;padding-left:0;margin:20px 0;border-radius:4px}.pagination&gt;li{display:inline}.pagination&gt;li&gt;a,.pagination&gt;li&gt;span{position:relative;float:left;padding:6px 12px;margin-left:-1px;line-height:1.42857143;color:#337ab7;text-decoration:none;background-color:#fff;border:1px solid #ddd}.pagination&gt;li:first-child&gt;a,.pagination&gt;li:first-child&gt;span{margin-left:0;border-top-left-radius:4px;border-bottom-left-radius:4px}.pagination&gt;li:last-child&gt;a,.pagination&gt;li:last-child&gt;span{border-top-right-radius:4px;border-bottom-right-radius:4px}.pagination&gt;li&gt;a:focus,.pagination&gt;li&gt;a:hover,.pagination&gt;li&gt;span:focus,.pagination&gt;li&gt;span:hover{z-index:3;color:#23527c;background-color:#eee;border-color:#ddd}.pagination&gt;.active&gt;a,.pagination&gt;.active&gt;a:focus,.pagination&gt;.active&gt;a:hover,.pagination&gt;.active&gt;span,.pagination&gt;.active&gt;span:focus,.pagination&gt;.active&gt;span:hover{z-index:2;color:#fff;cursor:default;background-color:#337ab7;border-color:#337ab7}.pagination&gt;.disabled&gt;a,.pagination&gt;.disabled&gt;a:focus,.pagination&gt;.disabled&gt;a:hover,.pagination&gt;.disabled&gt;span,.pagination&gt;.disabled&gt;span:focus,.pagination&gt;.disabled&gt;span:hover{color:#777;cursor:not-allowed;background-color:#fff;border-color:#ddd}.pagination-lg&gt;li&gt;a,.pagination-lg&gt;li&gt;span{padding:10px 16px;font-size:18px;line-height:1.3333333}.pagination-lg&gt;li:first-child&gt;a,.pagination-lg&gt;li:first-child&gt;span{border-top-left-radius:6px;border-bottom-left-radius:6px}.pagination-lg&gt;li:last-child&gt;a,.pagination-lg&gt;li:last-child&gt;span{border-top-right-radius:6px;border-bottom-right-radius:6px}.pagination-sm&gt;li&gt;a,.pagination-sm&gt;li&gt;span{padding:5px 10px;font-size:12px;line-height:1.5}.pagination-sm&gt;li:first-child&gt;a,.pagination-sm&gt;li:first-child&gt;span{border-top-left-radius:3px;border-bottom-left-radius:3px}.pagination-sm&gt;li:last-child&gt;a,.pagination-sm&gt;li:last-child&gt;span{border-top-right-radius:3px;border-bottom-right-radius:3px}.pager{padding-left:0;margin:20px 0;text-align:center;list-style:none}.pager li{display:inline}.pager li&gt;a,.pager li&gt;span{display:inline-block;padding:5px 14px;background-color:#fff;border:1px solid #ddd;border-radius:15px}.pager li&gt;a:focus,.pager li&gt;a:hover{text-decoration:none;background-color:#eee}.pager .next&gt;a,.pager .next&gt;span{float:right}.pager .previous&gt;a,.pager .previous&gt;span{float:left}.pager .disabled&gt;a,.pager .disabled&gt;a:focus,.pager .disabled&gt;a:hover,.pager .disabled&gt;span{color:#777;cursor:not-allowed;background-color:#fff}.label{display:inline;padding:.2em .6em .3em;font-size:75%;font-weight:700;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:.25em}a.label:focus,a.label:hover{color:#fff;text-decoration:none;cursor:pointer}.label:empty{display:none}.btn .label{position:relative;top:-1px}.label-default{background-color:#777}.label-default[href]:focus,.label-default[href]:hover{background-color:#5e5e5e}.label-primary{background-color:#337ab7}.label-primary[href]:focus,.label-primary[href]:hover{background-color:#286090}.label-success{background-color:#5cb85c}.label-success[href]:focus,.label-success[href]:hover{background-color:#449d44}.label-info{background-color:#5bc0de}.label-info[href]:focus,.label-info[href]:hover{background-color:#31b0d5}.label-warning{background-color:#f0ad4e}.label-warning[href]:focus,.label-warning[href]:hover{background-color:#ec971f}.label-danger{background-color:#d9534f}.label-danger[href]:focus,.label-danger[href]:hover{background-color:#c9302c}.badge{display:inline-block;min-width:10px;padding:3px 7px;font-size:12px;font-weight:700;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:middle;background-color:#777;border-radius:10px}.badge:empty{display:none}.btn .badge{position:relative;top:-1px}.btn-group-xs&gt;.btn .badge,.btn-xs .badge{top:0;padding:1px 5px}a.badge:focus,a.badge:hover{color:#fff;text-decoration:none;cursor:pointer}.list-group-item.active&gt;.badge,.nav-pills&gt;.active&gt;a&gt;.badge{color:#337ab7;background-color:#fff}.list-group-item&gt;.badge{float:right}.list-group-item&gt;.badge+.badge{margin-right:5px}.nav-pills&gt;li&gt;a&gt;.badge{margin-left:3px}.jumbotron{padding-top:30px;padding-bottom:30px;margin-bottom:30px;color:inherit;background-color:#eee}.jumbotron .h1,.jumbotron h1{color:inherit}.jumbotron p{margin-bottom:15px;font-size:21px;font-weight:200}.jumbotron&gt;hr{border-top-color:#d5d5d5}.container .jumbotron,.container-fluid .jumbotron{border-radius:6px}.jumbotron .container{max-width:100%}@media screen and (min-width:768px){.jumbotron{padding-top:48px;padding-bottom:48px}.container .jumbotron,.container-fluid .jumbotron{padding-right:60px;padding-left:60px}.jumbotron .h1,.jumbotron h1{font-size:63px}}.thumbnail{display:block;padding:4px;margin-bottom:20px;line-height:1.42857143;background-color:#fff;border:1px solid #ddd;border-radius:4px;-webkit-transition:border .2s ease-in-out;-o-transition:border .2s ease-in-out;transition:border .2s ease-in-out}.thumbnail a&gt;img,.thumbnail&gt;img{margin-right:auto;margin-left:auto}a.thumbnail.active,a.thumbnail:focus,a.thumbnail:hover{border-color:#337ab7}.thumbnail .caption{padding:9px;color:#333}.alert{padding:15px;margin-bottom:20px;border:1px solid transparent;border-radius:4px}.alert h4{margin-top:0;color:inherit}.alert .alert-link{font-weight:700}.alert&gt;p,.alert&gt;ul{margin-bottom:0}.alert&gt;p+p{margin-top:5px}.alert-dismissable,.alert-dismissible{padding-right:35px}.alert-dismissable .close,.alert-dismissible .close{position:relative;top:-2px;right:-21px;color:inherit}.alert-success{color:#3c763d;background-color:#dff0d8;border-color:#d6e9c6}.alert-success hr{border-top-color:#c9e2b3}.alert-success .alert-link{color:#2b542c}.alert-info{color:#31708f;background-color:#d9edf7;border-color:#bce8f1}.alert-info hr{border-top-color:#a6e1ec}.alert-info .alert-link{color:#245269}.alert-warning{color:#8a6d3b;background-color:#fcf8e3;border-color:#faebcc}.alert-warning hr{border-top-color:#f7e1b5}.alert-warning .alert-link{color:#66512c}.alert-danger{color:#a94442;background-color:#f2dede;border-color:#ebccd1}.alert-danger hr{border-top-color:#e4b9c0}.alert-danger .alert-link{color:#843534}@-webkit-keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}@-o-keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}@keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}.progress{height:20px;margin-bottom:20px;overflow:hidden;background-color:#f5f5f5;border-radius:4px;-webkit-box-shadow:inset 0 1px 2px rgba(0,0,0,.1);box-shadow:inset 0 1px 2px rgba(0,0,0,.1)}.progress-bar{float:left;width:0;height:100%;font-size:12px;line-height:20px;color:#fff;text-align:center;background-color:#337ab7;-webkit-box-shadow:inset 0 -1px 0 rgba(0,0,0,.15);box-shadow:inset 0 -1px 0 rgba(0,0,0,.15);-webkit-transition:width .6s ease;-o-transition:width .6s ease;transition:width .6s ease}.progress-bar-striped,.progress-striped .progress-bar{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);-webkit-background-size:40px 40px;background-size:40px 40px}.progress-bar.active,.progress.active .progress-bar{-webkit-animation:progress-bar-stripes 2s linear infinite;-o-animation:progress-bar-stripes 2s linear infinite;animation:progress-bar-stripes 2s linear infinite}.progress-bar-success{background-color:#5cb85c}.progress-striped .progress-bar-success{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-info{background-color:#5bc0de}.progress-striped .progress-bar-info{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-warning{background-color:#f0ad4e}.progress-striped .progress-bar-warning{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-danger{background-color:#d9534f}.progress-striped .progress-bar-danger{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.media{margin-top:15px}.media:first-child{margin-top:0}.media,.media-body{overflow:hidden;zoom:1}.media-body{width:10000px}.media-object{display:block}.media-object.img-thumbnail{max-width:none}.media-right,.media&gt;.pull-right{padding-left:10px}.media-left,.media&gt;.pull-left{padding-right:10px}.media-body,.media-left,.media-right{display:table-cell;vertical-align:top}.media-middle{vertical-align:middle}.media-bottom{vertical-align:bottom}.media-heading{margin-top:0;margin-bottom:5px}.media-list{padding-left:0;list-style:none}.list-group{padding-left:0;margin-bottom:20px}.list-group-item{position:relative;display:block;padding:10px 15px;margin-bottom:-1px;background-color:#fff;border:1px solid #ddd}.list-group-item:first-child{border-top-left-radius:4px;border-top-right-radius:4px}.list-group-item:last-child{margin-bottom:0;border-bottom-right-radius:4px;border-bottom-left-radius:4px}a.list-group-item,button.list-group-item{color:#555}a.list-group-item .list-group-item-heading,button.list-group-item .list-group-item-heading{color:#333}a.list-group-item:focus,a.list-group-item:hover,button.list-group-item:focus,button.list-group-item:hover{color:#555;text-decoration:none;background-color:#f5f5f5}button.list-group-item{width:100%;text-align:left}.list-group-item.disabled,.list-group-item.disabled:focus,.list-group-item.disabled:hover{color:#777;cursor:not-allowed;background-color:#eee}.list-group-item.disabled .list-group-item-heading,.list-group-item.disabled:focus .list-group-item-heading,.list-group-item.disabled:hover .list-group-item-heading{color:inherit}.list-group-item.disabled .list-group-item-text,.list-group-item.disabled:focus .list-group-item-text,.list-group-item.disabled:hover .list-group-item-text{color:#777}.list-group-item.active,.list-group-item.active:focus,.list-group-item.active:hover{z-index:2;color:#fff;background-color:#337ab7;border-color:#337ab7}.list-group-item.active .list-group-item-heading,.list-group-item.active .list-group-item-heading&gt;.small,.list-group-item.active .list-group-item-heading&gt;small,.list-group-item.active:focus .list-group-item-heading,.list-group-item.active:focus .list-group-item-heading&gt;.small,.list-group-item.active:focus .list-group-item-heading&gt;small,.list-group-item.active:hover .list-group-item-heading,.list-group-item.active:hover .list-group-item-heading&gt;.small,.list-group-item.active:hover .list-group-item-heading&gt;small{color:inherit}.list-group-item.active .list-group-item-text,.list-group-item.active:focus .list-group-item-text,.list-group-item.active:hover .list-group-item-text{color:#c7ddef}.list-group-item-success{color:#3c763d;background-color:#dff0d8}a.list-group-item-success,button.list-group-item-success{color:#3c763d}a.list-group-item-success .list-group-item-heading,button.list-group-item-success .list-group-item-heading{color:inherit}a.list-group-item-success:focus,a.list-group-item-success:hover,button.list-group-item-success:focus,button.list-group-item-success:hover{color:#3c763d;background-color:#d0e9c6}a.list-group-item-success.active,a.list-group-item-success.active:focus,a.list-group-item-success.active:hover,button.list-group-item-success.active,button.list-group-item-success.active:focus,button.list-group-item-success.active:hover{color:#fff;background-color:#3c763d;border-color:#3c763d}.list-group-item-info{color:#31708f;background-color:#d9edf7}a.list-group-item-info,button.list-group-item-info{color:#31708f}a.list-group-item-info .list-group-item-heading,button.list-group-item-info .list-group-item-heading{color:inherit}a.list-group-item-info:focus,a.list-group-item-info:hover,button.list-group-item-info:focus,button.list-group-item-info:hover{color:#31708f;background-color:#c4e3f3}a.list-group-item-info.active,a.list-group-item-info.active:focus,a.list-group-item-info.active:hover,button.list-group-item-info.active,button.list-group-item-info.active:focus,button.list-group-item-info.active:hover{color:#fff;background-color:#31708f;border-color:#31708f}.list-group-item-warning{color:#8a6d3b;background-color:#fcf8e3}a.list-group-item-warning,button.list-group-item-warning{color:#8a6d3b}a.list-group-item-warning .list-group-item-heading,button.list-group-item-warning .list-group-item-heading{color:inherit}a.list-group-item-warning:focus,a.list-group-item-warning:hover,button.list-group-item-warning:focus,button.list-group-item-warning:hover{color:#8a6d3b;background-color:#faf2cc}a.list-group-item-warning.active,a.list-group-item-warning.active:focus,a.list-group-item-warning.active:hover,button.list-group-item-warning.active,button.list-group-item-warning.active:focus,button.list-group-item-warning.active:hover{color:#fff;background-color:#8a6d3b;border-color:#8a6d3b}.list-group-item-danger{color:#a94442;background-color:#f2dede}a.list-group-item-danger,button.list-group-item-danger{color:#a94442}a.list-group-item-danger .list-group-item-heading,button.list-group-item-danger .list-group-item-heading{color:inherit}a.list-group-item-danger:focus,a.list-group-item-danger:hover,button.list-group-item-danger:focus,button.list-group-item-danger:hover{color:#a94442;background-color:#ebcccc}a.list-group-item-danger.active,a.list-group-item-danger.active:focus,a.list-group-item-danger.active:hover,button.list-group-item-danger.active,button.list-group-item-danger.active:focus,button.list-group-item-danger.active:hover{color:#fff;background-color:#a94442;border-color:#a94442}.list-group-item-heading{margin-top:0;margin-bottom:5px}.list-group-item-text{margin-bottom:0;line-height:1.3}.panel{margin-bottom:20px;background-color:#fff;border:1px solid transparent;border-radius:4px;-webkit-box-shadow:0 1px 1px rgba(0,0,0,.05);box-shadow:0 1px 1px rgba(0,0,0,.05)}.panel-body{padding:15px}.panel-heading{padding:10px 15px;border-bottom:1px solid transparent;border-top-left-radius:3px;border-top-right-radius:3px}.panel-heading&gt;.dropdown .dropdown-toggle{color:inherit}.panel-title{margin-top:0;margin-bottom:0;font-size:16px;color:inherit}.panel-title&gt;.small,.panel-title&gt;.small&gt;a,.panel-title&gt;a,.panel-title&gt;small,.panel-title&gt;small&gt;a{color:inherit}.panel-footer{padding:10px 15px;background-color:#f5f5f5;border-top:1px solid #ddd;border-bottom-right-radius:3px;border-bottom-left-radius:3px}.panel&gt;.list-group,.panel&gt;.panel-collapse&gt;.list-group{margin-bottom:0}.panel&gt;.list-group .list-group-item,.panel&gt;.panel-collapse&gt;.list-group .list-group-item{border-width:1px 0;border-radius:0}.panel&gt;.list-group:first-child .list-group-item:first-child,.panel&gt;.panel-collapse&gt;.list-group:first-child .list-group-item:first-child{border-top:0;border-top-left-radius:3px;border-top-right-radius:3px}.panel&gt;.list-group:last-child .list-group-item:last-child,.panel&gt;.panel-collapse&gt;.list-group:last-child .list-group-item:last-child{border-bottom:0;border-bottom-right-radius:3px;border-bottom-left-radius:3px}.panel&gt;.panel-heading+.panel-collapse&gt;.list-group .list-group-item:first-child{border-top-left-radius:0;border-top-right-radius:0}.panel-heading+.list-group .list-group-item:first-child{border-top-width:0}.list-group+.panel-footer{border-top-width:0}.panel&gt;.panel-collapse&gt;.table,.panel&gt;.table,.panel&gt;.table-responsive&gt;.table{margin-bottom:0}.panel&gt;.panel-collapse&gt;.table caption,.panel&gt;.table caption,.panel&gt;.table-responsive&gt;.table caption{padding-right:15px;padding-left:15px}.panel&gt;.table-responsive:first-child&gt;.table:first-child,.panel&gt;.table:first-child{border-top-left-radius:3px;border-top-right-radius:3px}.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child,.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child,.panel&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child,.panel&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child{border-top-left-radius:3px;border-top-right-radius:3px}.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child td:first-child,.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child th:first-child,.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child td:first-child,.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child th:first-child,.panel&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child td:first-child,.panel&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child th:first-child,.panel&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child td:first-child,.panel&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child th:first-child{border-top-left-radius:3px}.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child td:last-child,.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child th:last-child,.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child td:last-child,.panel&gt;.table-responsive:first-child&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child th:last-child,.panel&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child td:last-child,.panel&gt;.table:first-child&gt;tbody:first-child&gt;tr:first-child th:last-child,.panel&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child td:last-child,.panel&gt;.table:first-child&gt;thead:first-child&gt;tr:first-child th:last-child{border-top-right-radius:3px}.panel&gt;.table-responsive:last-child&gt;.table:last-child,.panel&gt;.table:last-child{border-bottom-right-radius:3px;border-bottom-left-radius:3px}.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child,.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child,.panel&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child,.panel&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child{border-bottom-right-radius:3px;border-bottom-left-radius:3px}.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child td:first-child,.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child th:first-child,.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child td:first-child,.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child th:first-child,.panel&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child td:first-child,.panel&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child th:first-child,.panel&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child td:first-child,.panel&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child th:first-child{border-bottom-left-radius:3px}.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child td:last-child,.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child th:last-child,.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child td:last-child,.panel&gt;.table-responsive:last-child&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child th:last-child,.panel&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child td:last-child,.panel&gt;.table:last-child&gt;tbody:last-child&gt;tr:last-child th:last-child,.panel&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child td:last-child,.panel&gt;.table:last-child&gt;tfoot:last-child&gt;tr:last-child th:last-child{border-bottom-right-radius:3px}.panel&gt;.panel-body+.table,.panel&gt;.panel-body+.table-responsive,.panel&gt;.table+.panel-body,.panel&gt;.table-responsive+.panel-body{border-top:1px solid #ddd}.panel&gt;.table&gt;tbody:first-child&gt;tr:first-child td,.panel&gt;.table&gt;tbody:first-child&gt;tr:first-child th{border-top:0}.panel&gt;.table-bordered,.panel&gt;.table-responsive&gt;.table-bordered{border:0}.panel&gt;.table-bordered&gt;tbody&gt;tr&gt;td:first-child,.panel&gt;.table-bordered&gt;tbody&gt;tr&gt;th:first-child,.panel&gt;.table-bordered&gt;tfoot&gt;tr&gt;td:first-child,.panel&gt;.table-bordered&gt;tfoot&gt;tr&gt;th:first-child,.panel&gt;.table-bordered&gt;thead&gt;tr&gt;td:first-child,.panel&gt;.table-bordered&gt;thead&gt;tr&gt;th:first-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;td:first-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;th:first-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;td:first-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;th:first-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;td:first-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;th:first-child{border-left:0}.panel&gt;.table-bordered&gt;tbody&gt;tr&gt;td:last-child,.panel&gt;.table-bordered&gt;tbody&gt;tr&gt;th:last-child,.panel&gt;.table-bordered&gt;tfoot&gt;tr&gt;td:last-child,.panel&gt;.table-bordered&gt;tfoot&gt;tr&gt;th:last-child,.panel&gt;.table-bordered&gt;thead&gt;tr&gt;td:last-child,.panel&gt;.table-bordered&gt;thead&gt;tr&gt;th:last-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;td:last-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr&gt;th:last-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;td:last-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr&gt;th:last-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;td:last-child,.panel&gt;.table-responsive&gt;.table-bordered&gt;thead&gt;tr&gt;th:last-child{border-right:0}.panel&gt;.table-bordered&gt;tbody&gt;tr:first-child&gt;td,.panel&gt;.table-bordered&gt;tbody&gt;tr:first-child&gt;th,.panel&gt;.table-bordered&gt;thead&gt;tr:first-child&gt;td,.panel&gt;.table-bordered&gt;thead&gt;tr:first-child&gt;th,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr:first-child&gt;td,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr:first-child&gt;th,.panel&gt;.table-responsive&gt;.table-bordered&gt;thead&gt;tr:first-child&gt;td,.panel&gt;.table-responsive&gt;.table-bordered&gt;thead&gt;tr:first-child&gt;th{border-bottom:0}.panel&gt;.table-bordered&gt;tbody&gt;tr:last-child&gt;td,.panel&gt;.table-bordered&gt;tbody&gt;tr:last-child&gt;th,.panel&gt;.table-bordered&gt;tfoot&gt;tr:last-child&gt;td,.panel&gt;.table-bordered&gt;tfoot&gt;tr:last-child&gt;th,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr:last-child&gt;td,.panel&gt;.table-responsive&gt;.table-bordered&gt;tbody&gt;tr:last-child&gt;th,.panel&gt;.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr:last-child&gt;td,.panel&gt;.table-responsive&gt;.table-bordered&gt;tfoot&gt;tr:last-child&gt;th{border-bottom:0}.panel&gt;.table-responsive{margin-bottom:0;border:0}.panel-group{margin-bottom:20px}.panel-group .panel{margin-bottom:0;border-radius:4px}.panel-group .panel+.panel{margin-top:5px}.panel-group .panel-heading{border-bottom:0}.panel-group .panel-heading+.panel-collapse&gt;.list-group,.panel-group .panel-heading+.panel-collapse&gt;.panel-body{border-top:1px solid #ddd}.panel-group .panel-footer{border-top:0}.panel-group .panel-footer+.panel-collapse .panel-body{border-bottom:1px solid #ddd}.panel-default{border-color:#ddd}.panel-default&gt;.panel-heading{color:#333;background-color:#f5f5f5;border-color:#ddd}.panel-default&gt;.panel-heading+.panel-collapse&gt;.panel-body{border-top-color:#ddd}.panel-default&gt;.panel-heading .badge{color:#f5f5f5;background-color:#333}.panel-default&gt;.panel-footer+.panel-collapse&gt;.panel-body{border-bottom-color:#ddd}.panel-primary{border-color:#337ab7}.panel-primary&gt;.panel-heading{color:#fff;background-color:#337ab7;border-color:#337ab7}.panel-primary&gt;.panel-heading+.panel-collapse&gt;.panel-body{border-top-color:#337ab7}.panel-primary&gt;.panel-heading .badge{color:#337ab7;background-color:#fff}.panel-primary&gt;.panel-footer+.panel-collapse&gt;.panel-body{border-bottom-color:#337ab7}.panel-success{border-color:#d6e9c6}.panel-success&gt;.panel-heading{color:#3c763d;background-color:#dff0d8;border-color:#d6e9c6}.panel-success&gt;.panel-heading+.panel-collapse&gt;.panel-body{border-top-color:#d6e9c6}.panel-success&gt;.panel-heading .badge{color:#dff0d8;background-color:#3c763d}.panel-success&gt;.panel-footer+.panel-collapse&gt;.panel-body{border-bottom-color:#d6e9c6}.panel-info{border-color:#bce8f1}.panel-info&gt;.panel-heading{color:#31708f;background-color:#d9edf7;border-color:#bce8f1}.panel-info&gt;.panel-heading+.panel-collapse&gt;.panel-body{border-top-color:#bce8f1}.panel-info&gt;.panel-heading .badge{color:#d9edf7;background-color:#31708f}.panel-info&gt;.panel-footer+.panel-collapse&gt;.panel-body{border-bottom-color:#bce8f1}.panel-warning{border-color:#faebcc}.panel-warning&gt;.panel-heading{color:#8a6d3b;background-color:#fcf8e3;border-color:#faebcc}.panel-warning&gt;.panel-heading+.panel-collapse&gt;.panel-body{border-top-color:#faebcc}.panel-warning&gt;.panel-heading .badge{color:#fcf8e3;background-color:#8a6d3b}.panel-warning&gt;.panel-footer+.panel-collapse&gt;.panel-body{border-bottom-color:#faebcc}.panel-danger{border-color:#ebccd1}.panel-danger&gt;.panel-heading{color:#a94442;background-color:#f2dede;border-color:#ebccd1}.panel-danger&gt;.panel-heading+.panel-collapse&gt;.panel-body{border-top-color:#ebccd1}.panel-danger&gt;.panel-heading .badge{color:#f2dede;background-color:#a94442}.panel-danger&gt;.panel-footer+.panel-collapse&gt;.panel-body{border-bottom-color:#ebccd1}.embed-responsive{position:relative;display:block;height:0;padding:0;overflow:hidden}.embed-responsive .embed-responsive-item,.embed-responsive embed,.embed-responsive iframe,.embed-responsive object,.embed-responsive video{position:absolute;top:0;bottom:0;left:0;width:100%;height:100%;border:0}.embed-responsive-16by9{padding-bottom:56.25%}.embed-responsive-4by3{padding-bottom:75%}.well{min-height:20px;padding:19px;margin-bottom:20px;background-color:#f5f5f5;border:1px solid #e3e3e3;border-radius:4px;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.05);box-shadow:inset 0 1px 1px rgba(0,0,0,.05)}.well blockquote{border-color:#ddd;border-color:rgba(0,0,0,.15)}.well-lg{padding:24px;border-radius:6px}.well-sm{padding:9px;border-radius:3px}.close{float:right;font-size:21px;font-weight:700;line-height:1;color:#000;text-shadow:0 1px 0 #fff;filter:alpha(opacity=20);opacity:.2}.close:focus,.close:hover{color:#000;text-decoration:none;cursor:pointer;filter:alpha(opacity=50);opacity:.5}button.close{-webkit-appearance:none;padding:0;cursor:pointer;background:0 0;border:0}.modal-open{overflow:hidden}.modal{position:fixed;top:0;right:0;bottom:0;left:0;z-index:1050;display:none;overflow:hidden;-webkit-overflow-scrolling:touch;outline:0}.modal.fade .modal-dialog{-webkit-transition:-webkit-transform .3s ease-out;-o-transition:-o-transform .3s ease-out;transition:transform .3s ease-out;-webkit-transform:translate(0,-25%);-ms-transform:translate(0,-25%);-o-transform:translate(0,-25%);transform:translate(0,-25%)}.modal.in .modal-dialog{-webkit-transform:translate(0,0);-ms-transform:translate(0,0);-o-transform:translate(0,0);transform:translate(0,0)}.modal-open .modal{overflow-x:hidden;overflow-y:auto}.modal-dialog{position:relative;width:auto;margin:10px}.modal-content{position:relative;background-color:#fff;-webkit-background-clip:padding-box;background-clip:padding-box;border:1px solid #999;border:1px solid rgba(0,0,0,.2);border-radius:6px;outline:0;-webkit-box-shadow:0 3px 9px rgba(0,0,0,.5);box-shadow:0 3px 9px rgba(0,0,0,.5)}.modal-backdrop{position:fixed;top:0;right:0;bottom:0;left:0;z-index:1040;background-color:#000}.modal-backdrop.fade{filter:alpha(opacity=0);opacity:0}.modal-backdrop.in{filter:alpha(opacity=50);opacity:.5}.modal-header{min-height:16.43px;padding:15px;border-bottom:1px solid #e5e5e5}.modal-header .close{margin-top:-2px}.modal-title{margin:0;line-height:1.42857143}.modal-body{position:relative;padding:15px}.modal-footer{padding:15px;text-align:right;border-top:1px solid #e5e5e5}.modal-footer .btn+.btn{margin-bottom:0;margin-left:5px}.modal-footer .btn-group .btn+.btn{margin-left:-1px}.modal-footer .btn-block+.btn-block{margin-left:0}.modal-scrollbar-measure{position:absolute;top:-9999px;width:50px;height:50px;overflow:scroll}@media (min-width:768px){.modal-dialog{width:600px;margin:30px auto}.modal-content{-webkit-box-shadow:0 5px 15px rgba(0,0,0,.5);box-shadow:0 5px 15px rgba(0,0,0,.5)}.modal-sm{width:300px}}@media (min-width:992px){.modal-lg{width:900px}}.tooltip{position:absolute;z-index:1070;display:block;font-family:&#34;Helvetica Neue&#34;,Helvetica,Arial,sans-serif;font-size:12px;font-style:normal;font-weight:400;line-height:1.42857143;text-align:left;text-align:start;text-decoration:none;text-shadow:none;text-transform:none;letter-spacing:normal;word-break:normal;word-spacing:normal;word-wrap:normal;white-space:normal;filter:alpha(opacity=0);opacity:0;line-break:auto}.tooltip.in{filter:alpha(opacity=90);opacity:.9}.tooltip.top{padding:5px 0;margin-top:-3px}.tooltip.right{padding:0 5px;margin-left:3px}.tooltip.bottom{padding:5px 0;margin-top:3px}.tooltip.left{padding:0 5px;margin-left:-3px}.tooltip-inner{max-width:200px;padding:3px 8px;color:#fff;text-align:center;background-color:#000;border-radius:4px}.tooltip-arrow{position:absolute;width:0;height:0;border-color:transparent;border-style:solid}.tooltip.top .tooltip-arrow{bottom:0;left:50%;margin-left:-5px;border-width:5px 5px 0;border-top-color:#000}.tooltip.top-left .tooltip-arrow{right:5px;bottom:0;margin-bottom:-5px;border-width:5px 5px 0;border-top-color:#000}.tooltip.top-right .tooltip-arrow{bottom:0;left:5px;margin-bottom:-5px;border-width:5px 5px 0;border-top-color:#000}.tooltip.right .tooltip-arrow{top:50%;left:0;margin-top:-5px;border-width:5px 5px 5px 0;border-right-color:#000}.tooltip.left .tooltip-arrow{top:50%;right:0;margin-top:-5px;border-width:5px 0 5px 5px;border-left-color:#000}.tooltip.bottom .tooltip-arrow{top:0;left:50%;margin-left:-5px;border-width:0 5px 5px;border-bottom-color:#000}.tooltip.bottom-left .tooltip-arrow{top:0;right:5px;margin-top:-5px;border-width:0 5px 5px;border-bottom-color:#000}.tooltip.bottom-right .tooltip-arrow{top:0;left:5px;margin-top:-5px;border-width:0 5px 5px;border-bottom-color:#000}.popover{position:absolute;top:0;left:0;z-index:1060;display:none;max-width:276px;padding:1px;font-family:&#34;Helvetica Neue&#34;,Helvetica,Arial,sans-serif;font-size:14px;font-style:normal;font-weight:400;line-height:1.42857143;text-align:left;text-align:start;text-decoration:none;text-shadow:none;text-transform:none;letter-spacing:normal;word-break:normal;word-spacing:normal;word-wrap:normal;white-space:normal;background-color:#fff;-webkit-background-clip:padding-box;background-clip:padding-box;border:1px solid #ccc;border:1px solid rgba(0,0,0,.2);border-radius:6px;-webkit-box-shadow:0 5px 10px rgba(0,0,0,.2);box-shadow:0 5px 10px rgba(0,0,0,.2);line-break:auto}.popover.top{margin-top:-10px}.popover.right{margin-left:10px}.popover.bottom{margin-top:10px}.popover.left{margin-left:-10px}.popover-title{padding:8px 14px;margin:0;font-size:14px;background-color:#f7f7f7;border-bottom:1px solid #ebebeb;border-radius:5px 5px 0 0}.popover-content{padding:9px 14px}.popover&gt;.arrow,.popover&gt;.arrow:after{position:absolute;display:block;width:0;height:0;border-color:transparent;border-style:solid}.popover&gt;.arrow{border-width:11px}.popover&gt;.arrow:after{content:&#34;&#34;;border-width:10px}.popover.top&gt;.arrow{bottom:-11px;left:50%;margin-left:-11px;border-top-color:#999;border-top-color:rgba(0,0,0,.25);border-bottom-width:0}.popover.top&gt;.arrow:after{bottom:1px;margin-left:-10px;content:&#34; &#34;;border-top-color:#fff;border-bottom-width:0}.popover.right&gt;.arrow{top:50%;left:-11px;margin-top:-11px;border-right-color:#999;border-right-color:rgba(0,0,0,.25);border-left-width:0}.popover.right&gt;.arrow:after{bottom:-10px;left:1px;content:&#34; &#34;;border-right-color:#fff;border-left-width:0}.popover.bottom&gt;.arrow{top:-11px;left:50%;margin-left:-11px;border-top-width:0;border-bottom-color:#999;border-bottom-color:rgba(0,0,0,.25)}.popover.bottom&gt;.arrow:after{top:1px;margin-left:-10px;content:&#34; &#34;;border-top-width:0;border-bottom-color:#fff}.popover.left&gt;.arrow{top:50%;right:-11px;margin-top:-11px;border-right-width:0;border-left-color:#999;border-left-color:rgba(0,0,0,.25)}.popover.left&gt;.arrow:after{right:1px;bottom:-10px;content:&#34; &#34;;border-right-width:0;border-left-color:#fff}.carousel{position:relative}.carousel-inner{position:relative;width:100%;overflow:hidden}.carousel-inner&gt;.item{position:relative;display:none;-webkit-transition:.6s ease-in-out left;-o-transition:.6s ease-in-out left;transition:.6s ease-in-out left}.carousel-inner&gt;.item&gt;a&gt;img,.carousel-inner&gt;.item&gt;img{line-height:1}@media all and (transform-3d),(-webkit-transform-3d){.carousel-inner&gt;.item{-webkit-transition:-webkit-transform .6s ease-in-out;-o-transition:-o-transform .6s ease-in-out;transition:transform .6s ease-in-out;-webkit-backface-visibility:hidden;backface-visibility:hidden;-webkit-perspective:1000px;perspective:1000px}.carousel-inner&gt;.item.active.right,.carousel-inner&gt;.item.next{left:0;-webkit-transform:translate3d(100%,0,0);transform:translate3d(100%,0,0)}.carousel-inner&gt;.item.active.left,.carousel-inner&gt;.item.prev{left:0;-webkit-transform:translate3d(-100%,0,0);transform:translate3d(-100%,0,0)}.carousel-inner&gt;.item.active,.carousel-inner&gt;.item.next.left,.carousel-inner&gt;.item.prev.right{left:0;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}}.carousel-inner&gt;.active,.carousel-inner&gt;.next,.carousel-inner&gt;.prev{display:block}.carousel-inner&gt;.active{left:0}.carousel-inner&gt;.next,.carousel-inner&gt;.prev{position:absolute;top:0;width:100%}.carousel-inner&gt;.next{left:100%}.carousel-inner&gt;.prev{left:-100%}.carousel-inner&gt;.next.left,.carousel-inner&gt;.prev.right{left:0}.carousel-inner&gt;.active.left{left:-100%}.carousel-inner&gt;.active.right{left:100%}.carousel-control{position:absolute;top:0;bottom:0;left:0;width:15%;font-size:20px;color:#fff;text-align:center;text-shadow:0 1px 2px rgba(0,0,0,.6);filter:alpha(opacity=50);opacity:.5}.carousel-control.left{background-image:-webkit-linear-gradient(left,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-image:-o-linear-gradient(left,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-image:-webkit-gradient(linear,left top,right top,from(rgba(0,0,0,.5)),to(rgba(0,0,0,.0001)));background-image:linear-gradient(to right,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr=&#39;#80000000&#39;, endColorstr=&#39;#00000000&#39;, GradientType=1);background-repeat:repeat-x}.carousel-control.right{right:0;left:auto;background-image:-webkit-linear-gradient(left,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-image:-o-linear-gradient(left,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-image:-webkit-gradient(linear,left top,right top,from(rgba(0,0,0,.0001)),to(rgba(0,0,0,.5)));background-image:linear-gradient(to right,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr=&#39;#00000000&#39;, endColorstr=&#39;#80000000&#39;, GradientType=1);background-repeat:repeat-x}.carousel-control:focus,.carousel-control:hover{color:#fff;text-decoration:none;filter:alpha(opacity=90);outline:0;opacity:.9}.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .icon-prev{position:absolute;top:50%;z-index:5;display:inline-block;margin-top:-10px}.carousel-control .glyphicon-chevron-left,.carousel-control .icon-prev{left:50%;margin-left:-10px}.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next{right:50%;margin-right:-10px}.carousel-control .icon-next,.carousel-control .icon-prev{width:20px;height:20px;font-family:serif;line-height:1}.carousel-control .icon-prev:before{content:&#39;\2039&#39;}.carousel-control .icon-next:before{content:&#39;\203a&#39;}.carousel-indicators{position:absolute;bottom:10px;left:50%;z-index:15;width:60%;padding-left:0;margin-left:-30%;text-align:center;list-style:none}.carousel-indicators li{display:inline-block;width:10px;height:10px;margin:1px;text-indent:-999px;cursor:pointer;background-color:#000\9;background-color:rgba(0,0,0,0);border:1px solid #fff;border-radius:10px}.carousel-indicators .active{width:12px;height:12px;margin:0;background-color:#fff}.carousel-caption{position:absolute;right:15%;bottom:20px;left:15%;z-index:10;padding-top:20px;padding-bottom:20px;color:#fff;text-align:center;text-shadow:0 1px 2px rgba(0,0,0,.6)}.carousel-caption .btn{text-shadow:none}@media screen and (min-width:768px){.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .icon-prev{width:30px;height:30px;margin-top:-15px;font-size:30px}.carousel-control .glyphicon-chevron-left,.carousel-control .icon-prev{margin-left:-15px}.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next{margin-right:-15px}.carousel-caption{right:20%;left:20%;padding-bottom:30px}.carousel-indicators{bottom:20px}}.btn-group-vertical&gt;.btn-group:after,.btn-group-vertical&gt;.btn-group:before,.btn-toolbar:after,.btn-toolbar:before,.clearfix:after,.clearfix:before,.container-fluid:after,.container-fluid:before,.container:after,.container:before,.dl-horizontal dd:after,.dl-horizontal dd:before,.form-horizontal .form-group:after,.form-horizontal .form-group:before,.modal-footer:after,.modal-footer:before,.nav:after,.nav:before,.navbar-collapse:after,.navbar-collapse:before,.navbar-header:after,.navbar-header:before,.navbar:after,.navbar:before,.pager:after,.pager:before,.panel-body:after,.panel-body:before,.row:after,.row:before{display:table;content:&#34; &#34;}.btn-group-vertical&gt;.btn-group:after,.btn-toolbar:after,.clearfix:after,.container-fluid:after,.container:after,.dl-horizontal dd:after,.form-horizontal .form-group:after,.modal-footer:after,.nav:after,.navbar-collapse:after,.navbar-header:after,.navbar:after,.pager:after,.panel-body:after,.row:after{clear:both}.center-block{display:block;margin-right:auto;margin-left:auto}.pull-right{float:right!important}.pull-left{float:left!important}.hide{display:none!important}.show{display:block!important}.invisible{visibility:hidden}.text-hide{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;border:0}.hidden{display:none!important}.affix{position:fixed}@-ms-viewport{width:device-width}.visible-lg,.visible-md,.visible-sm,.visible-xs{display:none!important}.visible-lg-block,.visible-lg-inline,.visible-lg-inline-block,.visible-md-block,.visible-md-inline,.visible-md-inline-block,.visible-sm-block,.visible-sm-inline,.visible-sm-inline-block,.visible-xs-block,.visible-xs-inline,.visible-xs-inline-block{display:none!important}@media (max-width:767px){.visible-xs{display:block!important}table.visible-xs{display:table!important}tr.visible-xs{display:table-row!important}td.visible-xs,th.visible-xs{display:table-cell!important}}@media (max-width:767px){.visible-xs-block{display:block!important}}@media (max-width:767px){.visible-xs-inline{display:inline!important}}@media (max-width:767px){.visible-xs-inline-block{display:inline-block!important}}@media (min-width:768px) and (max-width:991px){.visible-sm{display:block!important}table.visible-sm{display:table!important}tr.visible-sm{display:table-row!important}td.visible-sm,th.visible-sm{display:table-cell!important}}@media (min-width:768px) and (max-width:991px){.visible-sm-block{display:block!important}}@media (min-width:768px) and (max-width:991px){.visible-sm-inline{display:inline!important}}@media (min-width:768px) and (max-width:991px){.visible-sm-inline-block{display:inline-block!important}}@media (min-width:992px) and (max-width:1199px){.visible-md{display:block!important}table.visible-md{display:table!important}tr.visible-md{display:table-row!important}td.visible-md,th.visible-md{display:table-cell!important}}@media (min-width:992px) and (max-width:1199px){.visible-md-block{display:block!important}}@media (min-width:992px) and (max-width:1199px){.visible-md-inline{display:inline!important}}@media (min-width:992px) and (max-width:1199px){.visible-md-inline-block{display:inline-block!important}}@media (min-width:1200px){.visible-lg{display:block!important}table.visible-lg{display:table!important}tr.visible-lg{display:table-row!important}td.visible-lg,th.visible-lg{display:table-cell!important}}@media (min-width:1200px){.visible-lg-block{display:block!important}}@media (min-width:1200px){.visible-lg-inline{display:inline!important}}@media (min-width:1200px){.visible-lg-inline-block{display:inline-block!important}}@media (max-width:767px){.hidden-xs{display:none!important}}@media (min-width:768px) and (max-width:991px){.hidden-sm{display:none!important}}@media (min-width:992px) and (max-width:1199px){.hidden-md{display:none!important}}@media (min-width:1200px){.hidden-lg{display:none!important}}.visible-print{display:none!important}@media print{.visible-print{display:block!important}table.visible-print{display:table!important}tr.visible-print{display:table-row!important}td.visible-print,th.visible-print{display:table-cell!important}}.visible-print-block{display:none!important}@media print{.visible-print-block{display:block!important}}.visible-print-inline{display:none!important}@media print{.visible-print-inline{display:inline!important}}.visible-print-inline-block{display:none!important}@media print{.visible-print-inline-block{display:inline-block!important}}@media print{.hidden-print{display:none!important}}
&lt;/style&gt;
&lt;script&gt;/*!
 * Bootstrap v3.3.5 (http://getbootstrap.com)
 * Copyright 2011-2015 Twitter, Inc.
 * Licensed under the MIT license
 */
if(&#34;undefined&#34;==typeof jQuery)throw new Error(&#34;Bootstrap&#39;s JavaScript requires jQuery&#34;);+function(a){&#34;use strict&#34;;var b=a.fn.jquery.split(&#34; &#34;)[0].split(&#34;.&#34;);if(b[0]&lt;2&amp;&amp;b[1]&lt;9||1==b[0]&amp;&amp;9==b[1]&amp;&amp;b[2]&lt;1)throw new Error(&#34;Bootstrap&#39;s JavaScript requires jQuery version 1.9.1 or higher&#34;)}(jQuery),+function(a){&#34;use strict&#34;;function b(){var a=document.createElement(&#34;bootstrap&#34;),b={WebkitTransition:&#34;webkitTransitionEnd&#34;,MozTransition:&#34;transitionend&#34;,OTransition:&#34;oTransitionEnd otransitionend&#34;,transition:&#34;transitionend&#34;};for(var c in b)if(void 0!==a.style[c])return{end:b[c]};return!1}a.fn.emulateTransitionEnd=function(b){var c=!1,d=this;a(this).one(&#34;bsTransitionEnd&#34;,function(){c=!0});var e=function(){c||a(d).trigger(a.support.transition.end)};return setTimeout(e,b),this},a(function(){a.support.transition=b(),a.support.transition&amp;&amp;(a.event.special.bsTransitionEnd={bindType:a.support.transition.end,delegateType:a.support.transition.end,handle:function(b){return a(b.target).is(this)?b.handleObj.handler.apply(this,arguments):void 0}})})}(jQuery),+function(a){&#34;use strict&#34;;function b(b){return this.each(function(){var c=a(this),e=c.data(&#34;bs.alert&#34;);e||c.data(&#34;bs.alert&#34;,e=new d(this)),&#34;string&#34;==typeof b&amp;&amp;e[b].call(c)})}var c=&#39;[data-dismiss=&#34;alert&#34;]&#39;,d=function(b){a(b).on(&#34;click&#34;,c,this.close)};d.VERSION=&#34;3.3.5&#34;,d.TRANSITION_DURATION=150,d.prototype.close=function(b){function c(){g.detach().trigger(&#34;closed.bs.alert&#34;).remove()}var e=a(this),f=e.attr(&#34;data-target&#34;);f||(f=e.attr(&#34;href&#34;),f=f&amp;&amp;f.replace(/.*(?=#[^\s]*$)/,&#34;&#34;));var g=a(f);b&amp;&amp;b.preventDefault(),g.length||(g=e.closest(&#34;.alert&#34;)),g.trigger(b=a.Event(&#34;close.bs.alert&#34;)),b.isDefaultPrevented()||(g.removeClass(&#34;in&#34;),a.support.transition&amp;&amp;g.hasClass(&#34;fade&#34;)?g.one(&#34;bsTransitionEnd&#34;,c).emulateTransitionEnd(d.TRANSITION_DURATION):c())};var e=a.fn.alert;a.fn.alert=b,a.fn.alert.Constructor=d,a.fn.alert.noConflict=function(){return a.fn.alert=e,this},a(document).on(&#34;click.bs.alert.data-api&#34;,c,d.prototype.close)}(jQuery),+function(a){&#34;use strict&#34;;function b(b){return this.each(function(){var d=a(this),e=d.data(&#34;bs.button&#34;),f=&#34;object&#34;==typeof b&amp;&amp;b;e||d.data(&#34;bs.button&#34;,e=new c(this,f)),&#34;toggle&#34;==b?e.toggle():b&amp;&amp;e.setState(b)})}var c=function(b,d){this.$element=a(b),this.options=a.extend({},c.DEFAULTS,d),this.isLoading=!1};c.VERSION=&#34;3.3.5&#34;,c.DEFAULTS={loadingText:&#34;loading...&#34;},c.prototype.setState=function(b){var c=&#34;disabled&#34;,d=this.$element,e=d.is(&#34;input&#34;)?&#34;val&#34;:&#34;html&#34;,f=d.data();b+=&#34;Text&#34;,null==f.resetText&amp;&amp;d.data(&#34;resetText&#34;,d[e]()),setTimeout(a.proxy(function(){d[e](null==f[b]?this.options[b]:f[b]),&#34;loadingText&#34;==b?(this.isLoading=!0,d.addClass(c).attr(c,c)):this.isLoading&amp;&amp;(this.isLoading=!1,d.removeClass(c).removeAttr(c))},this),0)},c.prototype.toggle=function(){var a=!0,b=this.$element.closest(&#39;[data-toggle=&#34;buttons&#34;]&#39;);if(b.length){var c=this.$element.find(&#34;input&#34;);&#34;radio&#34;==c.prop(&#34;type&#34;)?(c.prop(&#34;checked&#34;)&amp;&amp;(a=!1),b.find(&#34;.active&#34;).removeClass(&#34;active&#34;),this.$element.addClass(&#34;active&#34;)):&#34;checkbox&#34;==c.prop(&#34;type&#34;)&amp;&amp;(c.prop(&#34;checked&#34;)!==this.$element.hasClass(&#34;active&#34;)&amp;&amp;(a=!1),this.$element.toggleClass(&#34;active&#34;)),c.prop(&#34;checked&#34;,this.$element.hasClass(&#34;active&#34;)),a&amp;&amp;c.trigger(&#34;change&#34;)}else this.$element.attr(&#34;aria-pressed&#34;,!this.$element.hasClass(&#34;active&#34;)),this.$element.toggleClass(&#34;active&#34;)};var d=a.fn.button;a.fn.button=b,a.fn.button.Constructor=c,a.fn.button.noConflict=function(){return a.fn.button=d,this},a(document).on(&#34;click.bs.button.data-api&#34;,&#39;[data-toggle^=&#34;button&#34;]&#39;,function(c){var d=a(c.target);d.hasClass(&#34;btn&#34;)||(d=d.closest(&#34;.btn&#34;)),b.call(d,&#34;toggle&#34;),a(c.target).is(&#39;input[type=&#34;radio&#34;]&#39;)||a(c.target).is(&#39;input[type=&#34;checkbox&#34;]&#39;)||c.preventDefault()}).on(&#34;focus.bs.button.data-api blur.bs.button.data-api&#34;,&#39;[data-toggle^=&#34;button&#34;]&#39;,function(b){a(b.target).closest(&#34;.btn&#34;).toggleClass(&#34;focus&#34;,/^focus(in)?$/.test(b.type))})}(jQuery),+function(a){&#34;use strict&#34;;function b(b){return this.each(function(){var d=a(this),e=d.data(&#34;bs.carousel&#34;),f=a.extend({},c.DEFAULTS,d.data(),&#34;object&#34;==typeof b&amp;&amp;b),g=&#34;string&#34;==typeof b?b:f.slide;e||d.data(&#34;bs.carousel&#34;,e=new c(this,f)),&#34;number&#34;==typeof b?e.to(b):g?e[g]():f.interval&amp;&amp;e.pause().cycle()})}var c=function(b,c){this.$element=a(b),this.$indicators=this.$element.find(&#34;.carousel-indicators&#34;),this.options=c,this.paused=null,this.sliding=null,this.interval=null,this.$active=null,this.$items=null,this.options.keyboard&amp;&amp;this.$element.on(&#34;keydown.bs.carousel&#34;,a.proxy(this.keydown,this)),&#34;hover&#34;==this.options.pause&amp;&amp;!(&#34;ontouchstart&#34;in document.documentElement)&amp;&amp;this.$element.on(&#34;mouseenter.bs.carousel&#34;,a.proxy(this.pause,this)).on(&#34;mouseleave.bs.carousel&#34;,a.proxy(this.cycle,this))};c.VERSION=&#34;3.3.5&#34;,c.TRANSITION_DURATION=600,c.DEFAULTS={interval:5e3,pause:&#34;hover&#34;,wrap:!0,keyboard:!0},c.prototype.keydown=function(a){if(!/input|textarea/i.test(a.target.tagName)){switch(a.which){case 37:this.prev();break;case 39:this.next();break;default:return}a.preventDefault()}},c.prototype.cycle=function(b){return b||(this.paused=!1),this.interval&amp;&amp;clearInterval(this.interval),this.options.interval&amp;&amp;!this.paused&amp;&amp;(this.interval=setInterval(a.proxy(this.next,this),this.options.interval)),this},c.prototype.getItemIndex=function(a){return this.$items=a.parent().children(&#34;.item&#34;),this.$items.index(a||this.$active)},c.prototype.getItemForDirection=function(a,b){var c=this.getItemIndex(b),d=&#34;prev&#34;==a&amp;&amp;0===c||&#34;next&#34;==a&amp;&amp;c==this.$items.length-1;if(d&amp;&amp;!this.options.wrap)return b;var e=&#34;prev&#34;==a?-1:1,f=(c+e)%this.$items.length;return this.$items.eq(f)},c.prototype.to=function(a){var b=this,c=this.getItemIndex(this.$active=this.$element.find(&#34;.item.active&#34;));return a&gt;this.$items.length-1||0&gt;a?void 0:this.sliding?this.$element.one(&#34;slid.bs.carousel&#34;,function(){b.to(a)}):c==a?this.pause().cycle():this.slide(a&gt;c?&#34;next&#34;:&#34;prev&#34;,this.$items.eq(a))},c.prototype.pause=function(b){return b||(this.paused=!0),this.$element.find(&#34;.next, .prev&#34;).length&amp;&amp;a.support.transition&amp;&amp;(this.$element.trigger(a.support.transition.end),this.cycle(!0)),this.interval=clearInterval(this.interval),this},c.prototype.next=function(){return this.sliding?void 0:this.slide(&#34;next&#34;)},c.prototype.prev=function(){return this.sliding?void 0:this.slide(&#34;prev&#34;)},c.prototype.slide=function(b,d){var e=this.$element.find(&#34;.item.active&#34;),f=d||this.getItemForDirection(b,e),g=this.interval,h=&#34;next&#34;==b?&#34;left&#34;:&#34;right&#34;,i=this;if(f.hasClass(&#34;active&#34;))return this.sliding=!1;var j=f[0],k=a.Event(&#34;slide.bs.carousel&#34;,{relatedTarget:j,direction:h});if(this.$element.trigger(k),!k.isDefaultPrevented()){if(this.sliding=!0,g&amp;&amp;this.pause(),this.$indicators.length){this.$indicators.find(&#34;.active&#34;).removeClass(&#34;active&#34;);var l=a(this.$indicators.children()[this.getItemIndex(f)]);l&amp;&amp;l.addClass(&#34;active&#34;)}var m=a.Event(&#34;slid.bs.carousel&#34;,{relatedTarget:j,direction:h});return a.support.transition&amp;&amp;this.$element.hasClass(&#34;slide&#34;)?(f.addClass(b),f[0].offsetWidth,e.addClass(h),f.addClass(h),e.one(&#34;bsTransitionEnd&#34;,function(){f.removeClass([b,h].join(&#34; &#34;)).addClass(&#34;active&#34;),e.removeClass([&#34;active&#34;,h].join(&#34; &#34;)),i.sliding=!1,setTimeout(function(){i.$element.trigger(m)},0)}).emulateTransitionEnd(c.TRANSITION_DURATION)):(e.removeClass(&#34;active&#34;),f.addClass(&#34;active&#34;),this.sliding=!1,this.$element.trigger(m)),g&amp;&amp;this.cycle(),this}};var d=a.fn.carousel;a.fn.carousel=b,a.fn.carousel.Constructor=c,a.fn.carousel.noConflict=function(){return a.fn.carousel=d,this};var e=function(c){var d,e=a(this),f=a(e.attr(&#34;data-target&#34;)||(d=e.attr(&#34;href&#34;))&amp;&amp;d.replace(/.*(?=#[^\s]+$)/,&#34;&#34;));if(f.hasClass(&#34;carousel&#34;)){var g=a.extend({},f.data(),e.data()),h=e.attr(&#34;data-slide-to&#34;);h&amp;&amp;(g.interval=!1),b.call(f,g),h&amp;&amp;f.data(&#34;bs.carousel&#34;).to(h),c.preventDefault()}};a(document).on(&#34;click.bs.carousel.data-api&#34;,&#34;[data-slide]&#34;,e).on(&#34;click.bs.carousel.data-api&#34;,&#34;[data-slide-to]&#34;,e),a(window).on(&#34;load&#34;,function(){a(&#39;[data-ride=&#34;carousel&#34;]&#39;).each(function(){var c=a(this);b.call(c,c.data())})})}(jQuery),+function(a){&#34;use strict&#34;;function b(b){var c,d=b.attr(&#34;data-target&#34;)||(c=b.attr(&#34;href&#34;))&amp;&amp;c.replace(/.*(?=#[^\s]+$)/,&#34;&#34;);return a(d)}function c(b){return this.each(function(){var c=a(this),e=c.data(&#34;bs.collapse&#34;),f=a.extend({},d.DEFAULTS,c.data(),&#34;object&#34;==typeof b&amp;&amp;b);!e&amp;&amp;f.toggle&amp;&amp;/show|hide/.test(b)&amp;&amp;(f.toggle=!1),e||c.data(&#34;bs.collapse&#34;,e=new d(this,f)),&#34;string&#34;==typeof b&amp;&amp;e[b]()})}var d=function(b,c){this.$element=a(b),this.options=a.extend({},d.DEFAULTS,c),this.$trigger=a(&#39;[data-toggle=&#34;collapse&#34;][href=&#34;#&#39;+b.id+&#39;&#34;],[data-toggle=&#34;collapse&#34;][data-target=&#34;#&#39;+b.id+&#39;&#34;]&#39;),this.transitioning=null,this.options.parent?this.$parent=this.getParent():this.addAriaAndCollapsedClass(this.$element,this.$trigger),this.options.toggle&amp;&amp;this.toggle()};d.VERSION=&#34;3.3.5&#34;,d.TRANSITION_DURATION=350,d.DEFAULTS={toggle:!0},d.prototype.dimension=function(){var a=this.$element.hasClass(&#34;width&#34;);return a?&#34;width&#34;:&#34;height&#34;},d.prototype.show=function(){if(!this.transitioning&amp;&amp;!this.$element.hasClass(&#34;in&#34;)){var b,e=this.$parent&amp;&amp;this.$parent.children(&#34;.panel&#34;).children(&#34;.in, .collapsing&#34;);if(!(e&amp;&amp;e.length&amp;&amp;(b=e.data(&#34;bs.collapse&#34;),b&amp;&amp;b.transitioning))){var f=a.Event(&#34;show.bs.collapse&#34;);if(this.$element.trigger(f),!f.isDefaultPrevented()){e&amp;&amp;e.length&amp;&amp;(c.call(e,&#34;hide&#34;),b||e.data(&#34;bs.collapse&#34;,null));var g=this.dimension();this.$element.removeClass(&#34;collapse&#34;).addClass(&#34;collapsing&#34;)[g](0).attr(&#34;aria-expanded&#34;,!0),this.$trigger.removeClass(&#34;collapsed&#34;).attr(&#34;aria-expanded&#34;,!0),this.transitioning=1;var h=function(){this.$element.removeClass(&#34;collapsing&#34;).addClass(&#34;collapse in&#34;)[g](&#34;&#34;),this.transitioning=0,this.$element.trigger(&#34;shown.bs.collapse&#34;)};if(!a.support.transition)return h.call(this);var i=a.camelCase([&#34;scroll&#34;,g].join(&#34;-&#34;));this.$element.one(&#34;bsTransitionEnd&#34;,a.proxy(h,this)).emulateTransitionEnd(d.TRANSITION_DURATION)[g](this.$element[0][i])}}}},d.prototype.hide=function(){if(!this.transitioning&amp;&amp;this.$element.hasClass(&#34;in&#34;)){var b=a.Event(&#34;hide.bs.collapse&#34;);if(this.$element.trigger(b),!b.isDefaultPrevented()){var c=this.dimension();this.$element[c](this.$element[c]())[0].offsetHeight,this.$element.addClass(&#34;collapsing&#34;).removeClass(&#34;collapse in&#34;).attr(&#34;aria-expanded&#34;,!1),this.$trigger.addClass(&#34;collapsed&#34;).attr(&#34;aria-expanded&#34;,!1),this.transitioning=1;var e=function(){this.transitioning=0,this.$element.removeClass(&#34;collapsing&#34;).addClass(&#34;collapse&#34;).trigger(&#34;hidden.bs.collapse&#34;)};return a.support.transition?void this.$element[c](0).one(&#34;bsTransitionEnd&#34;,a.proxy(e,this)).emulateTransitionEnd(d.TRANSITION_DURATION):e.call(this)}}},d.prototype.toggle=function(){this[this.$element.hasClass(&#34;in&#34;)?&#34;hide&#34;:&#34;show&#34;]()},d.prototype.getParent=function(){return a(this.options.parent).find(&#39;[data-toggle=&#34;collapse&#34;][data-parent=&#34;&#39;+this.options.parent+&#39;&#34;]&#39;).each(a.proxy(function(c,d){var e=a(d);this.addAriaAndCollapsedClass(b(e),e)},this)).end()},d.prototype.addAriaAndCollapsedClass=function(a,b){var c=a.hasClass(&#34;in&#34;);a.attr(&#34;aria-expanded&#34;,c),b.toggleClass(&#34;collapsed&#34;,!c).attr(&#34;aria-expanded&#34;,c)};var e=a.fn.collapse;a.fn.collapse=c,a.fn.collapse.Constructor=d,a.fn.collapse.noConflict=function(){return a.fn.collapse=e,this},a(document).on(&#34;click.bs.collapse.data-api&#34;,&#39;[data-toggle=&#34;collapse&#34;]&#39;,function(d){var e=a(this);e.attr(&#34;data-target&#34;)||d.preventDefault();var f=b(e),g=f.data(&#34;bs.collapse&#34;),h=g?&#34;toggle&#34;:e.data();c.call(f,h)})}(jQuery),+function(a){&#34;use strict&#34;;function b(b){var c=b.attr(&#34;data-target&#34;);c||(c=b.attr(&#34;href&#34;),c=c&amp;&amp;/#[A-Za-z]/.test(c)&amp;&amp;c.replace(/.*(?=#[^\s]*$)/,&#34;&#34;));var d=c&amp;&amp;a(c);return d&amp;&amp;d.length?d:b.parent()}function c(c){c&amp;&amp;3===c.which||(a(e).remove(),a(f).each(function(){var d=a(this),e=b(d),f={relatedTarget:this};e.hasClass(&#34;open&#34;)&amp;&amp;(c&amp;&amp;&#34;click&#34;==c.type&amp;&amp;/input|textarea/i.test(c.target.tagName)&amp;&amp;a.contains(e[0],c.target)||(e.trigger(c=a.Event(&#34;hide.bs.dropdown&#34;,f)),c.isDefaultPrevented()||(d.attr(&#34;aria-expanded&#34;,&#34;false&#34;),e.removeClass(&#34;open&#34;).trigger(&#34;hidden.bs.dropdown&#34;,f))))}))}function d(b){return this.each(function(){var c=a(this),d=c.data(&#34;bs.dropdown&#34;);d||c.data(&#34;bs.dropdown&#34;,d=new g(this)),&#34;string&#34;==typeof b&amp;&amp;d[b].call(c)})}var e=&#34;.dropdown-backdrop&#34;,f=&#39;[data-toggle=&#34;dropdown&#34;]&#39;,g=function(b){a(b).on(&#34;click.bs.dropdown&#34;,this.toggle)};g.VERSION=&#34;3.3.5&#34;,g.prototype.toggle=function(d){var e=a(this);if(!e.is(&#34;.disabled, :disabled&#34;)){var f=b(e),g=f.hasClass(&#34;open&#34;);if(c(),!g){&#34;ontouchstart&#34;in document.documentElement&amp;&amp;!f.closest(&#34;.navbar-nav&#34;).length&amp;&amp;a(document.createElement(&#34;div&#34;)).addClass(&#34;dropdown-backdrop&#34;).insertAfter(a(this)).on(&#34;click&#34;,c);var h={relatedTarget:this};if(f.trigger(d=a.Event(&#34;show.bs.dropdown&#34;,h)),d.isDefaultPrevented())return;e.trigger(&#34;focus&#34;).attr(&#34;aria-expanded&#34;,&#34;true&#34;),f.toggleClass(&#34;open&#34;).trigger(&#34;shown.bs.dropdown&#34;,h)}return!1}},g.prototype.keydown=function(c){if(/(38|40|27|32)/.test(c.which)&amp;&amp;!/input|textarea/i.test(c.target.tagName)){var d=a(this);if(c.preventDefault(),c.stopPropagation(),!d.is(&#34;.disabled, :disabled&#34;)){var e=b(d),g=e.hasClass(&#34;open&#34;);if(!g&amp;&amp;27!=c.which||g&amp;&amp;27==c.which)return 27==c.which&amp;&amp;e.find(f).trigger(&#34;focus&#34;),d.trigger(&#34;click&#34;);var h=&#34; li:not(.disabled):visible a&#34;,i=e.find(&#34;.dropdown-menu&#34;+h);if(i.length){var j=i.index(c.target);38==c.which&amp;&amp;j&gt;0&amp;&amp;j--,40==c.which&amp;&amp;j&lt;i.length-1&amp;&amp;j++,~j||(j=0),i.eq(j).trigger(&#34;focus&#34;)}}}};var h=a.fn.dropdown;a.fn.dropdown=d,a.fn.dropdown.Constructor=g,a.fn.dropdown.noConflict=function(){return a.fn.dropdown=h,this},a(document).on(&#34;click.bs.dropdown.data-api&#34;,c).on(&#34;click.bs.dropdown.data-api&#34;,&#34;.dropdown form&#34;,function(a){a.stopPropagation()}).on(&#34;click.bs.dropdown.data-api&#34;,f,g.prototype.toggle).on(&#34;keydown.bs.dropdown.data-api&#34;,f,g.prototype.keydown).on(&#34;keydown.bs.dropdown.data-api&#34;,&#34;.dropdown-menu&#34;,g.prototype.keydown)}(jQuery),+function(a){&#34;use strict&#34;;function b(b,d){return this.each(function(){var e=a(this),f=e.data(&#34;bs.modal&#34;),g=a.extend({},c.DEFAULTS,e.data(),&#34;object&#34;==typeof b&amp;&amp;b);f||e.data(&#34;bs.modal&#34;,f=new c(this,g)),&#34;string&#34;==typeof b?f[b](d):g.show&amp;&amp;f.show(d)})}var c=function(b,c){this.options=c,this.$body=a(document.body),this.$element=a(b),this.$dialog=this.$element.find(&#34;.modal-dialog&#34;),this.$backdrop=null,this.isShown=null,this.originalBodyPad=null,this.scrollbarWidth=0,this.ignoreBackdropClick=!1,this.options.remote&amp;&amp;this.$element.find(&#34;.modal-content&#34;).load(this.options.remote,a.proxy(function(){this.$element.trigger(&#34;loaded.bs.modal&#34;)},this))};c.VERSION=&#34;3.3.5&#34;,c.TRANSITION_DURATION=300,c.BACKDROP_TRANSITION_DURATION=150,c.DEFAULTS={backdrop:!0,keyboard:!0,show:!0},c.prototype.toggle=function(a){return this.isShown?this.hide():this.show(a)},c.prototype.show=function(b){var d=this,e=a.Event(&#34;show.bs.modal&#34;,{relatedTarget:b});this.$element.trigger(e),this.isShown||e.isDefaultPrevented()||(this.isShown=!0,this.checkScrollbar(),this.setScrollbar(),this.$body.addClass(&#34;modal-open&#34;),this.escape(),this.resize(),this.$element.on(&#34;click.dismiss.bs.modal&#34;,&#39;[data-dismiss=&#34;modal&#34;]&#39;,a.proxy(this.hide,this)),this.$dialog.on(&#34;mousedown.dismiss.bs.modal&#34;,function(){d.$element.one(&#34;mouseup.dismiss.bs.modal&#34;,function(b){a(b.target).is(d.$element)&amp;&amp;(d.ignoreBackdropClick=!0)})}),this.backdrop(function(){var e=a.support.transition&amp;&amp;d.$element.hasClass(&#34;fade&#34;);d.$element.parent().length||d.$element.appendTo(d.$body),d.$element.show().scrollTop(0),d.adjustDialog(),e&amp;&amp;d.$element[0].offsetWidth,d.$element.addClass(&#34;in&#34;),d.enforceFocus();var f=a.Event(&#34;shown.bs.modal&#34;,{relatedTarget:b});e?d.$dialog.one(&#34;bsTransitionEnd&#34;,function(){d.$element.trigger(&#34;focus&#34;).trigger(f)}).emulateTransitionEnd(c.TRANSITION_DURATION):d.$element.trigger(&#34;focus&#34;).trigger(f)}))},c.prototype.hide=function(b){b&amp;&amp;b.preventDefault(),b=a.Event(&#34;hide.bs.modal&#34;),this.$element.trigger(b),this.isShown&amp;&amp;!b.isDefaultPrevented()&amp;&amp;(this.isShown=!1,this.escape(),this.resize(),a(document).off(&#34;focusin.bs.modal&#34;),this.$element.removeClass(&#34;in&#34;).off(&#34;click.dismiss.bs.modal&#34;).off(&#34;mouseup.dismiss.bs.modal&#34;),this.$dialog.off(&#34;mousedown.dismiss.bs.modal&#34;),a.support.transition&amp;&amp;this.$element.hasClass(&#34;fade&#34;)?this.$element.one(&#34;bsTransitionEnd&#34;,a.proxy(this.hideModal,this)).emulateTransitionEnd(c.TRANSITION_DURATION):this.hideModal())},c.prototype.enforceFocus=function(){a(document).off(&#34;focusin.bs.modal&#34;).on(&#34;focusin.bs.modal&#34;,a.proxy(function(a){this.$element[0]===a.target||this.$element.has(a.target).length||this.$element.trigger(&#34;focus&#34;)},this))},c.prototype.escape=function(){this.isShown&amp;&amp;this.options.keyboard?this.$element.on(&#34;keydown.dismiss.bs.modal&#34;,a.proxy(function(a){27==a.which&amp;&amp;this.hide()},this)):this.isShown||this.$element.off(&#34;keydown.dismiss.bs.modal&#34;)},c.prototype.resize=function(){this.isShown?a(window).on(&#34;resize.bs.modal&#34;,a.proxy(this.handleUpdate,this)):a(window).off(&#34;resize.bs.modal&#34;)},c.prototype.hideModal=function(){var a=this;this.$element.hide(),this.backdrop(function(){a.$body.removeClass(&#34;modal-open&#34;),a.resetAdjustments(),a.resetScrollbar(),a.$element.trigger(&#34;hidden.bs.modal&#34;)})},c.prototype.removeBackdrop=function(){this.$backdrop&amp;&amp;this.$backdrop.remove(),this.$backdrop=null},c.prototype.backdrop=function(b){var d=this,e=this.$element.hasClass(&#34;fade&#34;)?&#34;fade&#34;:&#34;&#34;;if(this.isShown&amp;&amp;this.options.backdrop){var f=a.support.transition&amp;&amp;e;if(this.$backdrop=a(document.createElement(&#34;div&#34;)).addClass(&#34;modal-backdrop &#34;+e).appendTo(this.$body),this.$element.on(&#34;click.dismiss.bs.modal&#34;,a.proxy(function(a){return this.ignoreBackdropClick?void(this.ignoreBackdropClick=!1):void(a.target===a.currentTarget&amp;&amp;(&#34;static&#34;==this.options.backdrop?this.$element[0].focus():this.hide()))},this)),f&amp;&amp;this.$backdrop[0].offsetWidth,this.$backdrop.addClass(&#34;in&#34;),!b)return;f?this.$backdrop.one(&#34;bsTransitionEnd&#34;,b).emulateTransitionEnd(c.BACKDROP_TRANSITION_DURATION):b()}else if(!this.isShown&amp;&amp;this.$backdrop){this.$backdrop.removeClass(&#34;in&#34;);var g=function(){d.removeBackdrop(),b&amp;&amp;b()};a.support.transition&amp;&amp;this.$element.hasClass(&#34;fade&#34;)?this.$backdrop.one(&#34;bsTransitionEnd&#34;,g).emulateTransitionEnd(c.BACKDROP_TRANSITION_DURATION):g()}else b&amp;&amp;b()},c.prototype.handleUpdate=function(){this.adjustDialog()},c.prototype.adjustDialog=function(){var a=this.$element[0].scrollHeight&gt;document.documentElement.clientHeight;this.$element.css({paddingLeft:!this.bodyIsOverflowing&amp;&amp;a?this.scrollbarWidth:&#34;&#34;,paddingRight:this.bodyIsOverflowing&amp;&amp;!a?this.scrollbarWidth:&#34;&#34;})},c.prototype.resetAdjustments=function(){this.$element.css({paddingLeft:&#34;&#34;,paddingRight:&#34;&#34;})},c.prototype.checkScrollbar=function(){var a=window.innerWidth;if(!a){var b=document.documentElement.getBoundingClientRect();a=b.right-Math.abs(b.left)}this.bodyIsOverflowing=document.body.clientWidth&lt;a,this.scrollbarWidth=this.measureScrollbar()},c.prototype.setScrollbar=function(){var a=parseInt(this.$body.css(&#34;padding-right&#34;)||0,10);this.originalBodyPad=document.body.style.paddingRight||&#34;&#34;,this.bodyIsOverflowing&amp;&amp;this.$body.css(&#34;padding-right&#34;,a+this.scrollbarWidth)},c.prototype.resetScrollbar=function(){this.$body.css(&#34;padding-right&#34;,this.originalBodyPad)},c.prototype.measureScrollbar=function(){var a=document.createElement(&#34;div&#34;);a.className=&#34;modal-scrollbar-measure&#34;,this.$body.append(a);var b=a.offsetWidth-a.clientWidth;return this.$body[0].removeChild(a),b};var d=a.fn.modal;a.fn.modal=b,a.fn.modal.Constructor=c,a.fn.modal.noConflict=function(){return a.fn.modal=d,this},a(document).on(&#34;click.bs.modal.data-api&#34;,&#39;[data-toggle=&#34;modal&#34;]&#39;,function(c){var d=a(this),e=d.attr(&#34;href&#34;),f=a(d.attr(&#34;data-target&#34;)||e&amp;&amp;e.replace(/.*(?=#[^\s]+$)/,&#34;&#34;)),g=f.data(&#34;bs.modal&#34;)?&#34;toggle&#34;:a.extend({remote:!/#/.test(e)&amp;&amp;e},f.data(),d.data());d.is(&#34;a&#34;)&amp;&amp;c.preventDefault(),f.one(&#34;show.bs.modal&#34;,function(a){a.isDefaultPrevented()||f.one(&#34;hidden.bs.modal&#34;,function(){d.is(&#34;:visible&#34;)&amp;&amp;d.trigger(&#34;focus&#34;)})}),b.call(f,g,this)})}(jQuery),+function(a){&#34;use strict&#34;;function b(b){return this.each(function(){var d=a(this),e=d.data(&#34;bs.tooltip&#34;),f=&#34;object&#34;==typeof b&amp;&amp;b;(e||!/destroy|hide/.test(b))&amp;&amp;(e||d.data(&#34;bs.tooltip&#34;,e=new c(this,f)),&#34;string&#34;==typeof b&amp;&amp;e[b]())})}var c=function(a,b){this.type=null,this.options=null,this.enabled=null,this.timeout=null,this.hoverState=null,this.$element=null,this.inState=null,this.init(&#34;tooltip&#34;,a,b)};c.VERSION=&#34;3.3.5&#34;,c.TRANSITION_DURATION=150,c.DEFAULTS={animation:!0,placement:&#34;top&#34;,selector:!1,template:&#39;&lt;div class=&#34;tooltip&#34; role=&#34;tooltip&#34;&gt;&lt;div class=&#34;tooltip-arrow&#34;&gt;&lt;/div&gt;&lt;div class=&#34;tooltip-inner&#34;&gt;&lt;/div&gt;&lt;/div&gt;&#39;,trigger:&#34;hover focus&#34;,title:&#34;&#34;,delay:0,html:!1,container:!1,viewport:{selector:&#34;body&#34;,padding:0}},c.prototype.init=function(b,c,d){if(this.enabled=!0,this.type=b,this.$element=a(c),this.options=this.getOptions(d),this.$viewport=this.options.viewport&amp;&amp;a(a.isFunction(this.options.viewport)?this.options.viewport.call(this,this.$element):this.options.viewport.selector||this.options.viewport),this.inState={click:!1,hover:!1,focus:!1},this.$element[0]instanceof document.constructor&amp;&amp;!this.options.selector)throw new Error(&#34;`selector` option must be specified when initializing &#34;+this.type+&#34; on the window.document object!&#34;);for(var e=this.options.trigger.split(&#34; &#34;),f=e.length;f--;){var g=e[f];if(&#34;click&#34;==g)this.$element.on(&#34;click.&#34;+this.type,this.options.selector,a.proxy(this.toggle,this));else if(&#34;manual&#34;!=g){var h=&#34;hover&#34;==g?&#34;mouseenter&#34;:&#34;focusin&#34;,i=&#34;hover&#34;==g?&#34;mouseleave&#34;:&#34;focusout&#34;;this.$element.on(h+&#34;.&#34;+this.type,this.options.selector,a.proxy(this.enter,this)),this.$element.on(i+&#34;.&#34;+this.type,this.options.selector,a.proxy(this.leave,this))}}this.options.selector?this._options=a.extend({},this.options,{trigger:&#34;manual&#34;,selector:&#34;&#34;}):this.fixTitle()},c.prototype.getDefaults=function(){return c.DEFAULTS},c.prototype.getOptions=function(b){return b=a.extend({},this.getDefaults(),this.$element.data(),b),b.delay&amp;&amp;&#34;number&#34;==typeof b.delay&amp;&amp;(b.delay={show:b.delay,hide:b.delay}),b},c.prototype.getDelegateOptions=function(){var b={},c=this.getDefaults();return this._options&amp;&amp;a.each(this._options,function(a,d){c[a]!=d&amp;&amp;(b[a]=d)}),b},c.prototype.enter=function(b){var c=b instanceof this.constructor?b:a(b.currentTarget).data(&#34;bs.&#34;+this.type);return c||(c=new this.constructor(b.currentTarget,this.getDelegateOptions()),a(b.currentTarget).data(&#34;bs.&#34;+this.type,c)),b instanceof a.Event&amp;&amp;(c.inState[&#34;focusin&#34;==b.type?&#34;focus&#34;:&#34;hover&#34;]=!0),c.tip().hasClass(&#34;in&#34;)||&#34;in&#34;==c.hoverState?void(c.hoverState=&#34;in&#34;):(clearTimeout(c.timeout),c.hoverState=&#34;in&#34;,c.options.delay&amp;&amp;c.options.delay.show?void(c.timeout=setTimeout(function(){&#34;in&#34;==c.hoverState&amp;&amp;c.show()},c.options.delay.show)):c.show())},c.prototype.isInStateTrue=function(){for(var a in this.inState)if(this.inState[a])return!0;return!1},c.prototype.leave=function(b){var c=b instanceof this.constructor?b:a(b.currentTarget).data(&#34;bs.&#34;+this.type);return c||(c=new this.constructor(b.currentTarget,this.getDelegateOptions()),a(b.currentTarget).data(&#34;bs.&#34;+this.type,c)),b instanceof a.Event&amp;&amp;(c.inState[&#34;focusout&#34;==b.type?&#34;focus&#34;:&#34;hover&#34;]=!1),c.isInStateTrue()?void 0:(clearTimeout(c.timeout),c.hoverState=&#34;out&#34;,c.options.delay&amp;&amp;c.options.delay.hide?void(c.timeout=setTimeout(function(){&#34;out&#34;==c.hoverState&amp;&amp;c.hide()},c.options.delay.hide)):c.hide())},c.prototype.show=function(){var b=a.Event(&#34;show.bs.&#34;+this.type);if(this.hasContent()&amp;&amp;this.enabled){this.$element.trigger(b);var d=a.contains(this.$element[0].ownerDocument.documentElement,this.$element[0]);if(b.isDefaultPrevented()||!d)return;var e=this,f=this.tip(),g=this.getUID(this.type);this.setContent(),f.attr(&#34;id&#34;,g),this.$element.attr(&#34;aria-describedby&#34;,g),this.options.animation&amp;&amp;f.addClass(&#34;fade&#34;);var h=&#34;function&#34;==typeof this.options.placement?this.options.placement.call(this,f[0],this.$element[0]):this.options.placement,i=/\s?auto?\s?/i,j=i.test(h);j&amp;&amp;(h=h.replace(i,&#34;&#34;)||&#34;top&#34;),f.detach().css({top:0,left:0,display:&#34;block&#34;}).addClass(h).data(&#34;bs.&#34;+this.type,this),this.options.container?f.appendTo(this.options.container):f.insertAfter(this.$element),this.$element.trigger(&#34;inserted.bs.&#34;+this.type);var k=this.getPosition(),l=f[0].offsetWidth,m=f[0].offsetHeight;if(j){var n=h,o=this.getPosition(this.$viewport);h=&#34;bottom&#34;==h&amp;&amp;k.bottom+m&gt;o.bottom?&#34;top&#34;:&#34;top&#34;==h&amp;&amp;k.top-m&lt;o.top?&#34;bottom&#34;:&#34;right&#34;==h&amp;&amp;k.right+l&gt;o.width?&#34;left&#34;:&#34;left&#34;==h&amp;&amp;k.left-l&lt;o.left?&#34;right&#34;:h,f.removeClass(n).addClass(h)}var p=this.getCalculatedOffset(h,k,l,m);this.applyPlacement(p,h);var q=function(){var a=e.hoverState;e.$element.trigger(&#34;shown.bs.&#34;+e.type),e.hoverState=null,&#34;out&#34;==a&amp;&amp;e.leave(e)};a.support.transition&amp;&amp;this.$tip.hasClass(&#34;fade&#34;)?f.one(&#34;bsTransitionEnd&#34;,q).emulateTransitionEnd(c.TRANSITION_DURATION):q()}},c.prototype.applyPlacement=function(b,c){var d=this.tip(),e=d[0].offsetWidth,f=d[0].offsetHeight,g=parseInt(d.css(&#34;margin-top&#34;),10),h=parseInt(d.css(&#34;margin-left&#34;),10);isNaN(g)&amp;&amp;(g=0),isNaN(h)&amp;&amp;(h=0),b.top+=g,b.left+=h,a.offset.setOffset(d[0],a.extend({using:function(a){d.css({top:Math.round(a.top),left:Math.round(a.left)})}},b),0),d.addClass(&#34;in&#34;);var i=d[0].offsetWidth,j=d[0].offsetHeight;&#34;top&#34;==c&amp;&amp;j!=f&amp;&amp;(b.top=b.top+f-j);var k=this.getViewportAdjustedDelta(c,b,i,j);k.left?b.left+=k.left:b.top+=k.top;var l=/top|bottom/.test(c),m=l?2*k.left-e+i:2*k.top-f+j,n=l?&#34;offsetWidth&#34;:&#34;offsetHeight&#34;;d.offset(b),this.replaceArrow(m,d[0][n],l)},c.prototype.replaceArrow=function(a,b,c){this.arrow().css(c?&#34;left&#34;:&#34;top&#34;,50*(1-a/b)+&#34;%&#34;).css(c?&#34;top&#34;:&#34;left&#34;,&#34;&#34;)},c.prototype.setContent=function(){var a=this.tip(),b=this.getTitle();a.find(&#34;.tooltip-inner&#34;)[this.options.html?&#34;html&#34;:&#34;text&#34;](b),a.removeClass(&#34;fade in top bottom left right&#34;)},c.prototype.hide=function(b){function d(){&#34;in&#34;!=e.hoverState&amp;&amp;f.detach(),e.$element.removeAttr(&#34;aria-describedby&#34;).trigger(&#34;hidden.bs.&#34;+e.type),b&amp;&amp;b()}var e=this,f=a(this.$tip),g=a.Event(&#34;hide.bs.&#34;+this.type);return this.$element.trigger(g),g.isDefaultPrevented()?void 0:(f.removeClass(&#34;in&#34;),a.support.transition&amp;&amp;f.hasClass(&#34;fade&#34;)?f.one(&#34;bsTransitionEnd&#34;,d).emulateTransitionEnd(c.TRANSITION_DURATION):d(),this.hoverState=null,this)},c.prototype.fixTitle=function(){var a=this.$element;(a.attr(&#34;title&#34;)||&#34;string&#34;!=typeof a.attr(&#34;data-original-title&#34;))&amp;&amp;a.attr(&#34;data-original-title&#34;,a.attr(&#34;title&#34;)||&#34;&#34;).attr(&#34;title&#34;,&#34;&#34;)},c.prototype.hasContent=function(){return this.getTitle()},c.prototype.getPosition=function(b){b=b||this.$element;var c=b[0],d=&#34;BODY&#34;==c.tagName,e=c.getBoundingClientRect();null==e.width&amp;&amp;(e=a.extend({},e,{width:e.right-e.left,height:e.bottom-e.top}));var f=d?{top:0,left:0}:b.offset(),g={scroll:d?document.documentElement.scrollTop||document.body.scrollTop:b.scrollTop()},h=d?{width:a(window).width(),height:a(window).height()}:null;return a.extend({},e,g,h,f)},c.prototype.getCalculatedOffset=function(a,b,c,d){return&#34;bottom&#34;==a?{top:b.top+b.height,left:b.left+b.width/2-c/2}:&#34;top&#34;==a?{top:b.top-d,left:b.left+b.width/2-c/2}:&#34;left&#34;==a?{top:b.top+b.height/2-d/2,left:b.left-c}:{top:b.top+b.height/2-d/2,left:b.left+b.width}},c.prototype.getViewportAdjustedDelta=function(a,b,c,d){var e={top:0,left:0};if(!this.$viewport)return e;var f=this.options.viewport&amp;&amp;this.options.viewport.padding||0,g=this.getPosition(this.$viewport);if(/right|left/.test(a)){var h=b.top-f-g.scroll,i=b.top+f-g.scroll+d;h&lt;g.top?e.top=g.top-h:i&gt;g.top+g.height&amp;&amp;(e.top=g.top+g.height-i)}else{var j=b.left-f,k=b.left+f+c;j&lt;g.left?e.left=g.left-j:k&gt;g.right&amp;&amp;(e.left=g.left+g.width-k)}return e},c.prototype.getTitle=function(){var a,b=this.$element,c=this.options;return a=b.attr(&#34;data-original-title&#34;)||(&#34;function&#34;==typeof c.title?c.title.call(b[0]):c.title)},c.prototype.getUID=function(a){do a+=~~(1e6*Math.random());while(document.getElementById(a));return a},c.prototype.tip=function(){if(!this.$tip&amp;&amp;(this.$tip=a(this.options.template),1!=this.$tip.length))throw new Error(this.type+&#34; `template` option must consist of exactly 1 top-level element!&#34;);return this.$tip},c.prototype.arrow=function(){return this.$arrow=this.$arrow||this.tip().find(&#34;.tooltip-arrow&#34;)},c.prototype.enable=function(){this.enabled=!0},c.prototype.disable=function(){this.enabled=!1},c.prototype.toggleEnabled=function(){this.enabled=!this.enabled},c.prototype.toggle=function(b){var c=this;b&amp;&amp;(c=a(b.currentTarget).data(&#34;bs.&#34;+this.type),c||(c=new this.constructor(b.currentTarget,this.getDelegateOptions()),a(b.currentTarget).data(&#34;bs.&#34;+this.type,c))),b?(c.inState.click=!c.inState.click,c.isInStateTrue()?c.enter(c):c.leave(c)):c.tip().hasClass(&#34;in&#34;)?c.leave(c):c.enter(c)},c.prototype.destroy=function(){var a=this;clearTimeout(this.timeout),this.hide(function(){a.$element.off(&#34;.&#34;+a.type).removeData(&#34;bs.&#34;+a.type),a.$tip&amp;&amp;a.$tip.detach(),a.$tip=null,a.$arrow=null,a.$viewport=null})};var d=a.fn.tooltip;a.fn.tooltip=b,a.fn.tooltip.Constructor=c,a.fn.tooltip.noConflict=function(){return a.fn.tooltip=d,this}}(jQuery),+function(a){&#34;use strict&#34;;function b(b){return this.each(function(){var d=a(this),e=d.data(&#34;bs.popover&#34;),f=&#34;object&#34;==typeof b&amp;&amp;b;(e||!/destroy|hide/.test(b))&amp;&amp;(e||d.data(&#34;bs.popover&#34;,e=new c(this,f)),&#34;string&#34;==typeof b&amp;&amp;e[b]())})}var c=function(a,b){this.init(&#34;popover&#34;,a,b)};if(!a.fn.tooltip)throw new Error(&#34;Popover requires tooltip.js&#34;);c.VERSION=&#34;3.3.5&#34;,c.DEFAULTS=a.extend({},a.fn.tooltip.Constructor.DEFAULTS,{placement:&#34;right&#34;,trigger:&#34;click&#34;,content:&#34;&#34;,template:&#39;&lt;div class=&#34;popover&#34; role=&#34;tooltip&#34;&gt;&lt;div class=&#34;arrow&#34;&gt;&lt;/div&gt;&lt;h3 class=&#34;popover-title&#34;&gt;&lt;/h3&gt;&lt;div class=&#34;popover-content&#34;&gt;&lt;/div&gt;&lt;/div&gt;&#39;}),c.prototype=a.extend({},a.fn.tooltip.Constructor.prototype),c.prototype.constructor=c,c.prototype.getDefaults=function(){return c.DEFAULTS},c.prototype.setContent=function(){var a=this.tip(),b=this.getTitle(),c=this.getContent();a.find(&#34;.popover-title&#34;)[this.options.html?&#34;html&#34;:&#34;text&#34;](b),a.find(&#34;.popover-content&#34;).children().detach().end()[this.options.html?&#34;string&#34;==typeof c?&#34;html&#34;:&#34;append&#34;:&#34;text&#34;](c),a.removeClass(&#34;fade top bottom left right in&#34;),a.find(&#34;.popover-title&#34;).html()||a.find(&#34;.popover-title&#34;).hide()},c.prototype.hasContent=function(){return this.getTitle()||this.getContent()},c.prototype.getContent=function(){var a=this.$element,b=this.options;return a.attr(&#34;data-content&#34;)||(&#34;function&#34;==typeof b.content?b.content.call(a[0]):b.content)},c.prototype.arrow=function(){return this.$arrow=this.$arrow||this.tip().find(&#34;.arrow&#34;)};var d=a.fn.popover;a.fn.popover=b,a.fn.popover.Constructor=c,a.fn.popover.noConflict=function(){return a.fn.popover=d,this}}(jQuery),+function(a){&#34;use strict&#34;;function b(c,d){this.$body=a(document.body),this.$scrollElement=a(a(c).is(document.body)?window:c),this.options=a.extend({},b.DEFAULTS,d),this.selector=(this.options.target||&#34;&#34;)+&#34; .nav li &gt; a&#34;,this.offsets=[],this.targets=[],this.activeTarget=null,this.scrollHeight=0,this.$scrollElement.on(&#34;scroll.bs.scrollspy&#34;,a.proxy(this.process,this)),this.refresh(),this.process()}function c(c){return this.each(function(){var d=a(this),e=d.data(&#34;bs.scrollspy&#34;),f=&#34;object&#34;==typeof c&amp;&amp;c;e||d.data(&#34;bs.scrollspy&#34;,e=new b(this,f)),&#34;string&#34;==typeof c&amp;&amp;e[c]()})}b.VERSION=&#34;3.3.5&#34;,b.DEFAULTS={offset:10},b.prototype.getScrollHeight=function(){return this.$scrollElement[0].scrollHeight||Math.max(this.$body[0].scrollHeight,document.documentElement.scrollHeight)},b.prototype.refresh=function(){var b=this,c=&#34;offset&#34;,d=0;this.offsets=[],this.targets=[],this.scrollHeight=this.getScrollHeight(),a.isWindow(this.$scrollElement[0])||(c=&#34;position&#34;,d=this.$scrollElement.scrollTop()),this.$body.find(this.selector).map(function(){var b=a(this),e=b.data(&#34;target&#34;)||b.attr(&#34;href&#34;),f=/^#./.test(e)&amp;&amp;a(e);return f&amp;&amp;f.length&amp;&amp;f.is(&#34;:visible&#34;)&amp;&amp;[[f[c]().top+d,e]]||null}).sort(function(a,b){return a[0]-b[0]}).each(function(){b.offsets.push(this[0]),b.targets.push(this[1])})},b.prototype.process=function(){var a,b=this.$scrollElement.scrollTop()+this.options.offset,c=this.getScrollHeight(),d=this.options.offset+c-this.$scrollElement.height(),e=this.offsets,f=this.targets,g=this.activeTarget;if(this.scrollHeight!=c&amp;&amp;this.refresh(),b&gt;=d)return g!=(a=f[f.length-1])&amp;&amp;this.activate(a);if(g&amp;&amp;b&lt;e[0])return this.activeTarget=null,this.clear();for(a=e.length;a--;)g!=f[a]&amp;&amp;b&gt;=e[a]&amp;&amp;(void 0===e[a+1]||b&lt;e[a+1])&amp;&amp;this.activate(f[a])},b.prototype.activate=function(b){this.activeTarget=b,this.clear();var c=this.selector+&#39;[data-target=&#34;&#39;+b+&#39;&#34;],&#39;+this.selector+&#39;[href=&#34;&#39;+b+&#39;&#34;]&#39;,d=a(c).parents(&#34;li&#34;).addClass(&#34;active&#34;);d.parent(&#34;.dropdown-menu&#34;).length&amp;&amp;(d=d.closest(&#34;li.dropdown&#34;).addClass(&#34;active&#34;)),
d.trigger(&#34;activate.bs.scrollspy&#34;)},b.prototype.clear=function(){a(this.selector).parentsUntil(this.options.target,&#34;.active&#34;).removeClass(&#34;active&#34;)};var d=a.fn.scrollspy;a.fn.scrollspy=c,a.fn.scrollspy.Constructor=b,a.fn.scrollspy.noConflict=function(){return a.fn.scrollspy=d,this},a(window).on(&#34;load.bs.scrollspy.data-api&#34;,function(){a(&#39;[data-spy=&#34;scroll&#34;]&#39;).each(function(){var b=a(this);c.call(b,b.data())})})}(jQuery),+function(a){&#34;use strict&#34;;function b(b){return this.each(function(){var d=a(this),e=d.data(&#34;bs.tab&#34;);e||d.data(&#34;bs.tab&#34;,e=new c(this)),&#34;string&#34;==typeof b&amp;&amp;e[b]()})}var c=function(b){this.element=a(b)};c.VERSION=&#34;3.3.5&#34;,c.TRANSITION_DURATION=150,c.prototype.show=function(){var b=this.element,c=b.closest(&#34;ul:not(.dropdown-menu)&#34;),d=b.data(&#34;target&#34;);if(d||(d=b.attr(&#34;href&#34;),d=d&amp;&amp;d.replace(/.*(?=#[^\s]*$)/,&#34;&#34;)),!b.parent(&#34;li&#34;).hasClass(&#34;active&#34;)){var e=c.find(&#34;.active:last a&#34;),f=a.Event(&#34;hide.bs.tab&#34;,{relatedTarget:b[0]}),g=a.Event(&#34;show.bs.tab&#34;,{relatedTarget:e[0]});if(e.trigger(f),b.trigger(g),!g.isDefaultPrevented()&amp;&amp;!f.isDefaultPrevented()){var h=a(d);this.activate(b.closest(&#34;li&#34;),c),this.activate(h,h.parent(),function(){e.trigger({type:&#34;hidden.bs.tab&#34;,relatedTarget:b[0]}),b.trigger({type:&#34;shown.bs.tab&#34;,relatedTarget:e[0]})})}}},c.prototype.activate=function(b,d,e){function f(){g.removeClass(&#34;active&#34;).find(&#34;&gt; .dropdown-menu &gt; .active&#34;).removeClass(&#34;active&#34;).end().find(&#39;[data-toggle=&#34;tab&#34;]&#39;).attr(&#34;aria-expanded&#34;,!1),b.addClass(&#34;active&#34;).find(&#39;[data-toggle=&#34;tab&#34;]&#39;).attr(&#34;aria-expanded&#34;,!0),h?(b[0].offsetWidth,b.addClass(&#34;in&#34;)):b.removeClass(&#34;fade&#34;),b.parent(&#34;.dropdown-menu&#34;).length&amp;&amp;b.closest(&#34;li.dropdown&#34;).addClass(&#34;active&#34;).end().find(&#39;[data-toggle=&#34;tab&#34;]&#39;).attr(&#34;aria-expanded&#34;,!0),e&amp;&amp;e()}var g=d.find(&#34;&gt; .active&#34;),h=e&amp;&amp;a.support.transition&amp;&amp;(g.length&amp;&amp;g.hasClass(&#34;fade&#34;)||!!d.find(&#34;&gt; .fade&#34;).length);g.length&amp;&amp;h?g.one(&#34;bsTransitionEnd&#34;,f).emulateTransitionEnd(c.TRANSITION_DURATION):f(),g.removeClass(&#34;in&#34;)};var d=a.fn.tab;a.fn.tab=b,a.fn.tab.Constructor=c,a.fn.tab.noConflict=function(){return a.fn.tab=d,this};var e=function(c){c.preventDefault(),b.call(a(this),&#34;show&#34;)};a(document).on(&#34;click.bs.tab.data-api&#34;,&#39;[data-toggle=&#34;tab&#34;]&#39;,e).on(&#34;click.bs.tab.data-api&#34;,&#39;[data-toggle=&#34;pill&#34;]&#39;,e)}(jQuery),+function(a){&#34;use strict&#34;;function b(b){return this.each(function(){var d=a(this),e=d.data(&#34;bs.affix&#34;),f=&#34;object&#34;==typeof b&amp;&amp;b;e||d.data(&#34;bs.affix&#34;,e=new c(this,f)),&#34;string&#34;==typeof b&amp;&amp;e[b]()})}var c=function(b,d){this.options=a.extend({},c.DEFAULTS,d),this.$target=a(this.options.target).on(&#34;scroll.bs.affix.data-api&#34;,a.proxy(this.checkPosition,this)).on(&#34;click.bs.affix.data-api&#34;,a.proxy(this.checkPositionWithEventLoop,this)),this.$element=a(b),this.affixed=null,this.unpin=null,this.pinnedOffset=null,this.checkPosition()};c.VERSION=&#34;3.3.5&#34;,c.RESET=&#34;affix affix-top affix-bottom&#34;,c.DEFAULTS={offset:0,target:window},c.prototype.getState=function(a,b,c,d){var e=this.$target.scrollTop(),f=this.$element.offset(),g=this.$target.height();if(null!=c&amp;&amp;&#34;top&#34;==this.affixed)return c&gt;e?&#34;top&#34;:!1;if(&#34;bottom&#34;==this.affixed)return null!=c?e+this.unpin&lt;=f.top?!1:&#34;bottom&#34;:a-d&gt;=e+g?!1:&#34;bottom&#34;;var h=null==this.affixed,i=h?e:f.top,j=h?g:b;return null!=c&amp;&amp;c&gt;=e?&#34;top&#34;:null!=d&amp;&amp;i+j&gt;=a-d?&#34;bottom&#34;:!1},c.prototype.getPinnedOffset=function(){if(this.pinnedOffset)return this.pinnedOffset;this.$element.removeClass(c.RESET).addClass(&#34;affix&#34;);var a=this.$target.scrollTop(),b=this.$element.offset();return this.pinnedOffset=b.top-a},c.prototype.checkPositionWithEventLoop=function(){setTimeout(a.proxy(this.checkPosition,this),1)},c.prototype.checkPosition=function(){if(this.$element.is(&#34;:visible&#34;)){var b=this.$element.height(),d=this.options.offset,e=d.top,f=d.bottom,g=Math.max(a(document).height(),a(document.body).height());&#34;object&#34;!=typeof d&amp;&amp;(f=e=d),&#34;function&#34;==typeof e&amp;&amp;(e=d.top(this.$element)),&#34;function&#34;==typeof f&amp;&amp;(f=d.bottom(this.$element));var h=this.getState(g,b,e,f);if(this.affixed!=h){null!=this.unpin&amp;&amp;this.$element.css(&#34;top&#34;,&#34;&#34;);var i=&#34;affix&#34;+(h?&#34;-&#34;+h:&#34;&#34;),j=a.Event(i+&#34;.bs.affix&#34;);if(this.$element.trigger(j),j.isDefaultPrevented())return;this.affixed=h,this.unpin=&#34;bottom&#34;==h?this.getPinnedOffset():null,this.$element.removeClass(c.RESET).addClass(i).trigger(i.replace(&#34;affix&#34;,&#34;affixed&#34;)+&#34;.bs.affix&#34;)}&#34;bottom&#34;==h&amp;&amp;this.$element.offset({top:g-b-f})}};var d=a.fn.affix;a.fn.affix=b,a.fn.affix.Constructor=c,a.fn.affix.noConflict=function(){return a.fn.affix=d,this},a(window).on(&#34;load&#34;,function(){a(&#39;[data-spy=&#34;affix&#34;]&#39;).each(function(){var c=a(this),d=c.data();d.offset=d.offset||{},null!=d.offsetBottom&amp;&amp;(d.offset.bottom=d.offsetBottom),null!=d.offsetTop&amp;&amp;(d.offset.top=d.offsetTop),b.call(c,d)})})}(jQuery);&lt;/script&gt;
&lt;script&gt;/**
* @preserve HTML5 Shiv 3.7.2 | @afarkas @jdalton @jon_neal @rem | MIT/GPL2 Licensed
*/
// Only run this code in IE 8
if (!!window.navigator.userAgent.match(&#34;MSIE 8&#34;)) {
!function(a,b){function c(a,b){var c=a.createElement(&#34;p&#34;),d=a.getElementsByTagName(&#34;head&#34;)[0]||a.documentElement;return c.innerHTML=&#34;x&lt;style&gt;&#34;+b+&#34;&lt;/style&gt;&#34;,d.insertBefore(c.lastChild,d.firstChild)}function d(){var a=t.elements;return&#34;string&#34;==typeof a?a.split(&#34; &#34;):a}function e(a,b){var c=t.elements;&#34;string&#34;!=typeof c&amp;&amp;(c=c.join(&#34; &#34;)),&#34;string&#34;!=typeof a&amp;&amp;(a=a.join(&#34; &#34;)),t.elements=c+&#34; &#34;+a,j(b)}function f(a){var b=s[a[q]];return b||(b={},r++,a[q]=r,s[r]=b),b}function g(a,c,d){if(c||(c=b),l)return c.createElement(a);d||(d=f(c));var e;return e=d.cache[a]?d.cache[a].cloneNode():p.test(a)?(d.cache[a]=d.createElem(a)).cloneNode():d.createElem(a),!e.canHaveChildren||o.test(a)||e.tagUrn?e:d.frag.appendChild(e)}function h(a,c){if(a||(a=b),l)return a.createDocumentFragment();c=c||f(a);for(var e=c.frag.cloneNode(),g=0,h=d(),i=h.length;i&gt;g;g++)e.createElement(h[g]);return e}function i(a,b){b.cache||(b.cache={},b.createElem=a.createElement,b.createFrag=a.createDocumentFragment,b.frag=b.createFrag()),a.createElement=function(c){return t.shivMethods?g(c,a,b):b.createElem(c)},a.createDocumentFragment=Function(&#34;h,f&#34;,&#34;return function(){var n=f.cloneNode(),c=n.createElement;h.shivMethods&amp;&amp;(&#34;+d().join().replace(/[\w\-:]+/g,function(a){return b.createElem(a),b.frag.createElement(a),&#39;c(&#34;&#39;+a+&#39;&#34;)&#39;})+&#34;);return n}&#34;)(t,b.frag)}function j(a){a||(a=b);var d=f(a);return!t.shivCSS||k||d.hasCSS||(d.hasCSS=!!c(a,&#34;article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}mark{background:#FF0;color:#000}template{display:none}&#34;)),l||i(a,d),a}var k,l,m=&#34;3.7.2&#34;,n=a.html5||{},o=/^&lt;|^(?:button|map|select|textarea|object|iframe|option|optgroup)$/i,p=/^(?:a|b|code|div|fieldset|h1|h2|h3|h4|h5|h6|i|label|li|ol|p|q|span|strong|style|table|tbody|td|th|tr|ul)$/i,q=&#34;_html5shiv&#34;,r=0,s={};!function(){try{var a=b.createElement(&#34;a&#34;);a.innerHTML=&#34;&lt;xyz&gt;&lt;/xyz&gt;&#34;,k=&#34;hidden&#34;in a,l=1==a.childNodes.length||function(){b.createElement(&#34;a&#34;);var a=b.createDocumentFragment();return&#34;undefined&#34;==typeof a.cloneNode||&#34;undefined&#34;==typeof a.createDocumentFragment||&#34;undefined&#34;==typeof a.createElement}()}catch(c){k=!0,l=!0}}();var t={elements:n.elements||&#34;abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time video&#34;,version:m,shivCSS:n.shivCSS!==!1,supportsUnknownElements:l,shivMethods:n.shivMethods!==!1,type:&#34;default&#34;,shivDocument:j,createElement:g,createDocumentFragment:h,addElements:e};a.html5=t,j(b)}(this,document);
};
&lt;/script&gt;
&lt;script&gt;/*! Respond.js v1.4.2: min/max-width media query polyfill * Copyright 2013 Scott Jehl
 * Licensed under https://github.com/scottjehl/Respond/blob/master/LICENSE-MIT
 *  */

// Only run this code in IE 8
if (!!window.navigator.userAgent.match(&#34;MSIE 8&#34;)) {
!function(a){&#34;use strict&#34;;a.matchMedia=a.matchMedia||function(a){var b,c=a.documentElement,d=c.firstElementChild||c.firstChild,e=a.createElement(&#34;body&#34;),f=a.createElement(&#34;div&#34;);return f.id=&#34;mq-test-1&#34;,f.style.cssText=&#34;position:absolute;top:-100em&#34;,e.style.background=&#34;none&#34;,e.appendChild(f),function(a){return f.innerHTML=&#39;&amp;shy;&lt;style media=&#34;&#39;+a+&#39;&#34;&gt; #mq-test-1 { width: 42px; }&lt;/style&gt;&#39;,c.insertBefore(e,d),b=42===f.offsetWidth,c.removeChild(e),{matches:b,media:a}}}(a.document)}(this),function(a){&#34;use strict&#34;;function b(){u(!0)}var c={};a.respond=c,c.update=function(){};var d=[],e=function(){var b=!1;try{b=new a.XMLHttpRequest}catch(c){b=new a.ActiveXObject(&#34;Microsoft.XMLHTTP&#34;)}return function(){return b}}(),f=function(a,b){var c=e();c&amp;&amp;(c.open(&#34;GET&#34;,a,!0),c.onreadystatechange=function(){4!==c.readyState||200!==c.status&amp;&amp;304!==c.status||b(c.responseText)},4!==c.readyState&amp;&amp;c.send(null))};if(c.ajax=f,c.queue=d,c.regex={media:/@media[^\{]+\{([^\{\}]*\{[^\}\{]*\})+/gi,keyframes:/@(?:\-(?:o|moz|webkit)\-)?keyframes[^\{]+\{(?:[^\{\}]*\{[^\}\{]*\})+[^\}]*\}/gi,urls:/(url\()[&#39;&#34;]?([^\/\)&#39;&#34;][^:\)&#39;&#34;]+)[&#39;&#34;]?(\))/g,findStyles:/@media *([^\{]+)\{([\S\s]+?)$/,only:/(only\s+)?([a-zA-Z]+)\s?/,minw:/\([\s]*min\-width\s*:[\s]*([\s]*[0-9\.]+)(px|em)[\s]*\)/,maxw:/\([\s]*max\-width\s*:[\s]*([\s]*[0-9\.]+)(px|em)[\s]*\)/},c.mediaQueriesSupported=a.matchMedia&amp;&amp;null!==a.matchMedia(&#34;only all&#34;)&amp;&amp;a.matchMedia(&#34;only all&#34;).matches,!c.mediaQueriesSupported){var g,h,i,j=a.document,k=j.documentElement,l=[],m=[],n=[],o={},p=30,q=j.getElementsByTagName(&#34;head&#34;)[0]||k,r=j.getElementsByTagName(&#34;base&#34;)[0],s=q.getElementsByTagName(&#34;link&#34;),t=function(){var a,b=j.createElement(&#34;div&#34;),c=j.body,d=k.style.fontSize,e=c&amp;&amp;c.style.fontSize,f=!1;return b.style.cssText=&#34;position:absolute;font-size:1em;width:1em&#34;,c||(c=f=j.createElement(&#34;body&#34;),c.style.background=&#34;none&#34;),k.style.fontSize=&#34;100%&#34;,c.style.fontSize=&#34;100%&#34;,c.appendChild(b),f&amp;&amp;k.insertBefore(c,k.firstChild),a=b.offsetWidth,f?k.removeChild(c):c.removeChild(b),k.style.fontSize=d,e&amp;&amp;(c.style.fontSize=e),a=i=parseFloat(a)},u=function(b){var c=&#34;clientWidth&#34;,d=k[c],e=&#34;CSS1Compat&#34;===j.compatMode&amp;&amp;d||j.body[c]||d,f={},o=s[s.length-1],r=(new Date).getTime();if(b&amp;&amp;g&amp;&amp;p&gt;r-g)return a.clearTimeout(h),h=a.setTimeout(u,p),void 0;g=r;for(var v in l)if(l.hasOwnProperty(v)){var w=l[v],x=w.minw,y=w.maxw,z=null===x,A=null===y,B=&#34;em&#34;;x&amp;&amp;(x=parseFloat(x)*(x.indexOf(B)&gt;-1?i||t():1)),y&amp;&amp;(y=parseFloat(y)*(y.indexOf(B)&gt;-1?i||t():1)),w.hasquery&amp;&amp;(z&amp;&amp;A||!(z||e&gt;=x)||!(A||y&gt;=e))||(f[w.media]||(f[w.media]=[]),f[w.media].push(m[w.rules]))}for(var C in n)n.hasOwnProperty(C)&amp;&amp;n[C]&amp;&amp;n[C].parentNode===q&amp;&amp;q.removeChild(n[C]);n.length=0;for(var D in f)if(f.hasOwnProperty(D)){var E=j.createElement(&#34;style&#34;),F=f[D].join(&#34;\n&#34;);E.type=&#34;text/css&#34;,E.media=D,q.insertBefore(E,o.nextSibling),E.styleSheet?E.styleSheet.cssText=F:E.appendChild(j.createTextNode(F)),n.push(E)}},v=function(a,b,d){var e=a.replace(c.regex.keyframes,&#34;&#34;).match(c.regex.media),f=e&amp;&amp;e.length||0;b=b.substring(0,b.lastIndexOf(&#34;/&#34;));var g=function(a){return a.replace(c.regex.urls,&#34;$1&#34;+b+&#34;$2$3&#34;)},h=!f&amp;&amp;d;b.length&amp;&amp;(b+=&#34;/&#34;),h&amp;&amp;(f=1);for(var i=0;f&gt;i;i++){var j,k,n,o;h?(j=d,m.push(g(a))):(j=e[i].match(c.regex.findStyles)&amp;&amp;RegExp.$1,m.push(RegExp.$2&amp;&amp;g(RegExp.$2))),n=j.split(&#34;,&#34;),o=n.length;for(var p=0;o&gt;p;p++)k=n[p],l.push({media:k.split(&#34;(&#34;)[0].match(c.regex.only)&amp;&amp;RegExp.$2||&#34;all&#34;,rules:m.length-1,hasquery:k.indexOf(&#34;(&#34;)&gt;-1,minw:k.match(c.regex.minw)&amp;&amp;parseFloat(RegExp.$1)+(RegExp.$2||&#34;&#34;),maxw:k.match(c.regex.maxw)&amp;&amp;parseFloat(RegExp.$1)+(RegExp.$2||&#34;&#34;)})}u()},w=function(){if(d.length){var b=d.shift();f(b.href,function(c){v(c,b.href,b.media),o[b.href]=!0,a.setTimeout(function(){w()},0)})}},x=function(){for(var b=0;b&lt;s.length;b++){var c=s[b],e=c.href,f=c.media,g=c.rel&amp;&amp;&#34;stylesheet&#34;===c.rel.toLowerCase();e&amp;&amp;g&amp;&amp;!o[e]&amp;&amp;(c.styleSheet&amp;&amp;c.styleSheet.rawCssText?(v(c.styleSheet.rawCssText,e,f),o[e]=!0):(!/^([a-zA-Z:]*\/\/)/.test(e)&amp;&amp;!r||e.replace(RegExp.$1,&#34;&#34;).split(&#34;/&#34;)[0]===a.location.host)&amp;&amp;(&#34;//&#34;===e.substring(0,2)&amp;&amp;(e=a.location.protocol+e),d.push({href:e,media:f})))}w()};x(),c.update=x,c.getEmValue=t,a.addEventListener?a.addEventListener(&#34;resize&#34;,b,!1):a.attachEvent&amp;&amp;a.attachEvent(&#34;onresize&#34;,b)}}(this);
};
&lt;/script&gt;
&lt;style&gt;h1 {font-size: 34px;}
h1.title {font-size: 38px;}
h2 {font-size: 30px;}
h3 {font-size: 24px;}
h4 {font-size: 18px;}
h5 {font-size: 16px;}
h6 {font-size: 12px;}
code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
pre:not([class]) { background-color: white }&lt;/style&gt;
&lt;script&gt;

/**
 * jQuery Plugin: Sticky Tabs
 *
 * @author Aidan Lister &lt;aidan@php.net&gt;
 * adapted by Ruben Arslan to activate parent tabs too
 * http://www.aidanlister.com/2014/03/persisting-the-tab-state-in-bootstrap/
 */
(function($) {
  &#34;use strict&#34;;
  $.fn.rmarkdownStickyTabs = function() {
    var context = this;
    // Show the tab corresponding with the hash in the URL, or the first tab
    var showStuffFromHash = function() {
      var hash = window.location.hash;
      var selector = hash ? &#39;a[href=&#34;&#39; + hash + &#39;&#34;]&#39; : &#39;li.active &gt; a&#39;;
      var $selector = $(selector, context);
      if($selector.data(&#39;toggle&#39;) === &#34;tab&#34;) {
        $selector.tab(&#39;show&#39;);
        // walk up the ancestors of this element, show any hidden tabs
        $selector.parents(&#39;.section.tabset&#39;).each(function(i, elm) {
          var link = $(&#39;a[href=&#34;#&#39; + $(elm).attr(&#39;id&#39;) + &#39;&#34;]&#39;);
          if(link.data(&#39;toggle&#39;) === &#34;tab&#34;) {
            link.tab(&#34;show&#34;);
          }
        });
      }
    };


    // Set the correct tab when the page loads
    showStuffFromHash(context);

    // Set the correct tab when a user uses their back/forward button
    $(window).on(&#39;hashchange&#39;, function() {
      showStuffFromHash(context);
    });

    // Change the URL when tabs are clicked
    $(&#39;a&#39;, context).on(&#39;click&#39;, function(e) {
      history.pushState(null, null, this.href);
      showStuffFromHash(context);
    });

    return this;
  };
}(jQuery));

window.buildTabsets = function(tocID) {

  // build a tabset from a section div with the .tabset class
  function buildTabset(tabset) {

    // check for fade and pills options
    var fade = tabset.hasClass(&#34;tabset-fade&#34;);
    var pills = tabset.hasClass(&#34;tabset-pills&#34;);
    var navClass = pills ? &#34;nav-pills&#34; : &#34;nav-tabs&#34;;

    // determine the heading level of the tabset and tabs
    var match = tabset.attr(&#39;class&#39;).match(/level(\d) /);
    if (match === null)
      return;
    var tabsetLevel = Number(match[1]);
    var tabLevel = tabsetLevel + 1;

    // find all subheadings immediately below
    var tabs = tabset.find(&#34;div.section.level&#34; + tabLevel);
    if (!tabs.length)
      return;

    // create tablist and tab-content elements
    var tabList = $(&#39;&lt;ul class=&#34;nav &#39; + navClass + &#39;&#34; role=&#34;tablist&#34;&gt;&lt;/ul&gt;&#39;);
    $(tabs[0]).before(tabList);
    var tabContent = $(&#39;&lt;div class=&#34;tab-content&#34;&gt;&lt;/div&gt;&#39;);
    $(tabs[0]).before(tabContent);

    // build the tabset
    var activeTab = 0;
    tabs.each(function(i) {

      // get the tab div
      var tab = $(tabs[i]);

      // get the id then sanitize it for use with bootstrap tabs
      var id = tab.attr(&#39;id&#39;);

      // see if this is marked as the active tab
      if (tab.hasClass(&#39;active&#39;))
        activeTab = i;

      // remove any table of contents entries associated with
      // this ID (since we&#39;ll be removing the heading element)
      $(&#34;div#&#34; + tocID + &#34; li a[href=&#39;#&#34; + id + &#34;&#39;]&#34;).parent().remove();

      // sanitize the id for use with bootstrap tabs
      id = id.replace(/[.\/?&amp;!#&lt;&gt;]/g, &#39;&#39;).replace(/\s/g, &#39;_&#39;);
      tab.attr(&#39;id&#39;, id);

      // get the heading element within it, grab it&#39;s text, then remove it
      var heading = tab.find(&#39;h&#39; + tabLevel + &#39;:first&#39;);
      var headingText = heading.html();
      heading.remove();

      // build and append the tab list item
      var a = $(&#39;&lt;a role=&#34;tab&#34; data-toggle=&#34;tab&#34;&gt;&#39; + headingText + &#39;&lt;/a&gt;&#39;);
      a.attr(&#39;href&#39;, &#39;#&#39; + id);
      a.attr(&#39;aria-controls&#39;, id);
      var li = $(&#39;&lt;li role=&#34;presentation&#34;&gt;&lt;/li&gt;&#39;);
      li.append(a);
      tabList.append(li);

      // set it&#39;s attributes
      tab.attr(&#39;role&#39;, &#39;tabpanel&#39;);
      tab.addClass(&#39;tab-pane&#39;);
      tab.addClass(&#39;tabbed-pane&#39;);
      if (fade)
        tab.addClass(&#39;fade&#39;);

      // move it into the tab content div
      tab.detach().appendTo(tabContent);
    });

    // set active tab
    $(tabList.children(&#39;li&#39;)[activeTab]).addClass(&#39;active&#39;);
    var active = $(tabContent.children(&#39;div.section&#39;)[activeTab]);
    active.addClass(&#39;active&#39;);
    if (fade)
      active.addClass(&#39;in&#39;);

    if (tabset.hasClass(&#34;tabset-sticky&#34;))
      tabset.rmarkdownStickyTabs();
  }

  // convert section divs with the .tabset class to tabsets
  var tabsets = $(&#34;div.section.tabset&#34;);
  tabsets.each(function(i) {
    buildTabset($(tabsets[i]));
  });
};

&lt;/script&gt;
&lt;style type=&#34;text/css&#34;&gt;.hljs-literal {
color: #990073;
}
.hljs-number {
color: #099;
}
.hljs-comment {
color: #998;
font-style: italic;
}
.hljs-keyword {
color: #900;
font-weight: bold;
}
.hljs-string {
color: #d14;
}
&lt;/style&gt;
&lt;script src=&#34;data:application/javascript;base64,/*! highlight.js v9.12.0 | BSD3 License | git.io/hljslicense */
!function(e){var n="object"==typeof window&&window||"object"==typeof self&&self;"undefined"!=typeof exports?e(exports):n&&(n.hljs=e({}),"function"==typeof define&&define.amd&&define([],function(){return n.hljs}))}(function(e){function n(e){return e.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;")}function t(e){return e.nodeName.toLowerCase()}function r(e,n){var t=e&&e.exec(n);return t&&0===t.index}function a(e){return k.test(e)}function i(e){var n,t,r,i,o=e.className+" ";if(o+=e.parentNode?e.parentNode.className:"",t=B.exec(o))return w(t[1])?t[1]:"no-highlight";for(o=o.split(/\s+/),n=0,r=o.length;r>n;n++)if(i=o[n],a(i)||w(i))return i}function o(e){var n,t={},r=Array.prototype.slice.call(arguments,1);for(n in e)t[n]=e[n];return r.forEach(function(e){for(n in e)t[n]=e[n]}),t}function u(e){var n=[];return function r(e,a){for(var i=e.firstChild;i;i=i.nextSibling)3===i.nodeType?a+=i.nodeValue.length:1===i.nodeType&&(n.push({event:"start",offset:a,node:i}),a=r(i,a),t(i).match(/br|hr|img|input/)||n.push({event:"stop",offset:a,node:i}));return a}(e,0),n}function c(e,r,a){function i(){return e.length&&r.length?e[0].offset!==r[0].offset?e[0].offset<r[0].offset?e:r:"start"===r[0].event?e:r:e.length?e:r}function o(e){function r(e){return" "+e.nodeName+'="'+n(e.value).replace('"',"&quot;")+'"'}s+="<"+t(e)+E.map.call(e.attributes,r).join("")+">"}function u(e){s+="</"+t(e)+">"}function c(e){("start"===e.event?o:u)(e.node)}for(var l=0,s="",f=[];e.length||r.length;){var g=i();if(s+=n(a.substring(l,g[0].offset)),l=g[0].offset,g===e){f.reverse().forEach(u);do c(g.splice(0,1)[0]),g=i();while(g===e&&g.length&&g[0].offset===l);f.reverse().forEach(o)}else"start"===g[0].event?f.push(g[0].node):f.pop(),c(g.splice(0,1)[0])}return s+n(a.substr(l))}function l(e){return e.v&&!e.cached_variants&&(e.cached_variants=e.v.map(function(n){return o(e,{v:null},n)})),e.cached_variants||e.eW&&[o(e)]||[e]}function s(e){function n(e){return e&&e.source||e}function t(t,r){return new RegExp(n(t),"m"+(e.cI?"i":"")+(r?"g":""))}function r(a,i){if(!a.compiled){if(a.compiled=!0,a.k=a.k||a.bK,a.k){var o={},u=function(n,t){e.cI&&(t=t.toLowerCase()),t.split(" ").forEach(function(e){var t=e.split("|");o[t[0]]=[n,t[1]?Number(t[1]):1]})};"string"==typeof a.k?u("keyword",a.k):x(a.k).forEach(function(e){u(e,a.k[e])}),a.k=o}a.lR=t(a.l||/\w+/,!0),i&&(a.bK&&(a.b="\\b("+a.bK.split(" ").join("|")+")\\b"),a.b||(a.b=/\B|\b/),a.bR=t(a.b),a.e||a.eW||(a.e=/\B|\b/),a.e&&(a.eR=t(a.e)),a.tE=n(a.e)||"",a.eW&&i.tE&&(a.tE+=(a.e?"|":"")+i.tE)),a.i&&(a.iR=t(a.i)),null==a.r&&(a.r=1),a.c||(a.c=[]),a.c=Array.prototype.concat.apply([],a.c.map(function(e){return l("self"===e?a:e)})),a.c.forEach(function(e){r(e,a)}),a.starts&&r(a.starts,i);var c=a.c.map(function(e){return e.bK?"\\.?("+e.b+")\\.?":e.b}).concat([a.tE,a.i]).map(n).filter(Boolean);a.t=c.length?t(c.join("|"),!0):{exec:function(){return null}}}}r(e)}function f(e,t,a,i){function o(e,n){var t,a;for(t=0,a=n.c.length;a>t;t++)if(r(n.c[t].bR,e))return n.c[t]}function u(e,n){if(r(e.eR,n)){for(;e.endsParent&&e.parent;)e=e.parent;return e}return e.eW?u(e.parent,n):void 0}function c(e,n){return!a&&r(n.iR,e)}function l(e,n){var t=N.cI?n[0].toLowerCase():n[0];return e.k.hasOwnProperty(t)&&e.k[t]}function p(e,n,t,r){var a=r?"":I.classPrefix,i='<span class="'+a,o=t?"":C;return i+=e+'">',i+n+o}function h(){var e,t,r,a;if(!E.k)return n(k);for(a="",t=0,E.lR.lastIndex=0,r=E.lR.exec(k);r;)a+=n(k.substring(t,r.index)),e=l(E,r),e?(B+=e[1],a+=p(e[0],n(r[0]))):a+=n(r[0]),t=E.lR.lastIndex,r=E.lR.exec(k);return a+n(k.substr(t))}function d(){var e="string"==typeof E.sL;if(e&&!y[E.sL])return n(k);var t=e?f(E.sL,k,!0,x[E.sL]):g(k,E.sL.length?E.sL:void 0);return E.r>0&&(B+=t.r),e&&(x[E.sL]=t.top),p(t.language,t.value,!1,!0)}function b(){L+=null!=E.sL?d():h(),k=""}function v(e){L+=e.cN?p(e.cN,"",!0):"",E=Object.create(e,{parent:{value:E}})}function m(e,n){if(k+=e,null==n)return b(),0;var t=o(n,E);if(t)return t.skip?k+=n:(t.eB&&(k+=n),b(),t.rB||t.eB||(k=n)),v(t,n),t.rB?0:n.length;var r=u(E,n);if(r){var a=E;a.skip?k+=n:(a.rE||a.eE||(k+=n),b(),a.eE&&(k=n));do E.cN&&(L+=C),E.skip||(B+=E.r),E=E.parent;while(E!==r.parent);return r.starts&&v(r.starts,""),a.rE?0:n.length}if(c(n,E))throw new Error('Illegal lexeme "'+n+'" for mode "'+(E.cN||"<unnamed>")+'"');return k+=n,n.length||1}var N=w(e);if(!N)throw new Error('Unknown language: "'+e+'"');s(N);var R,E=i||N,x={},L="";for(R=E;R!==N;R=R.parent)R.cN&&(L=p(R.cN,"",!0)+L);var k="",B=0;try{for(var M,j,O=0;;){if(E.t.lastIndex=O,M=E.t.exec(t),!M)break;j=m(t.substring(O,M.index),M[0]),O=M.index+j}for(m(t.substr(O)),R=E;R.parent;R=R.parent)R.cN&&(L+=C);return{r:B,value:L,language:e,top:E}}catch(T){if(T.message&&-1!==T.message.indexOf("Illegal"))return{r:0,value:n(t)};throw T}}function g(e,t){t=t||I.languages||x(y);var r={r:0,value:n(e)},a=r;return t.filter(w).forEach(function(n){var t=f(n,e,!1);t.language=n,t.r>a.r&&(a=t),t.r>r.r&&(a=r,r=t)}),a.language&&(r.second_best=a),r}function p(e){return I.tabReplace||I.useBR?e.replace(M,function(e,n){return I.useBR&&"\n"===e?"<br>":I.tabReplace?n.replace(/\t/g,I.tabReplace):""}):e}function h(e,n,t){var r=n?L[n]:t,a=[e.trim()];return e.match(/\bhljs\b/)||a.push("hljs"),-1===e.indexOf(r)&&a.push(r),a.join(" ").trim()}function d(e){var n,t,r,o,l,s=i(e);a(s)||(I.useBR?(n=document.createElementNS("http://www.w3.org/1999/xhtml","div"),n.innerHTML=e.innerHTML.replace(/\n/g,"").replace(/<br[ \/]*>/g,"\n")):n=e,l=n.textContent,r=s?f(s,l,!0):g(l),t=u(n),t.length&&(o=document.createElementNS("http://www.w3.org/1999/xhtml","div"),o.innerHTML=r.value,r.value=c(t,u(o),l)),r.value=p(r.value),e.innerHTML=r.value,e.className=h(e.className,s,r.language),e.result={language:r.language,re:r.r},r.second_best&&(e.second_best={language:r.second_best.language,re:r.second_best.r}))}function b(e){I=o(I,e)}function v(){if(!v.called){v.called=!0;var e=document.querySelectorAll("pre code");E.forEach.call(e,d)}}function m(){addEventListener("DOMContentLoaded",v,!1),addEventListener("load",v,!1)}function N(n,t){var r=y[n]=t(e);r.aliases&&r.aliases.forEach(function(e){L[e]=n})}function R(){return x(y)}function w(e){return e=(e||"").toLowerCase(),y[e]||y[L[e]]}var E=[],x=Object.keys,y={},L={},k=/^(no-?highlight|plain|text)$/i,B=/\blang(?:uage)?-([\w-]+)\b/i,M=/((^(<[^>]+>|\t|)+|(?:\n)))/gm,C="</span>",I={classPrefix:"hljs-",tabReplace:null,useBR:!1,languages:void 0};return e.highlight=f,e.highlightAuto=g,e.fixMarkup=p,e.highlightBlock=d,e.configure=b,e.initHighlighting=v,e.initHighlightingOnLoad=m,e.registerLanguage=N,e.listLanguages=R,e.getLanguage=w,e.inherit=o,e.IR="[a-zA-Z]\\w*",e.UIR="[a-zA-Z_]\\w*",e.NR="\\b\\d+(\\.\\d+)?",e.CNR="(-?)(\\b0[xX][a-fA-F0-9]+|(\\b\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)",e.BNR="\\b(0b[01]+)",e.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|-|-=|/=|/|:|;|<<|<<=|<=|<|===|==|=|>>>=|>>=|>=|>>>|>>|>|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~",e.BE={b:"\\\\[\\s\\S]",r:0},e.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[e.BE]},e.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[e.BE]},e.PWM={b:/\b(a|an|the|are|I'm|isn't|don't|doesn't|won't|but|just|should|pretty|simply|enough|gonna|going|wtf|so|such|will|you|your|they|like|more)\b/},e.C=function(n,t,r){var a=e.inherit({cN:"comment",b:n,e:t,c:[]},r||{});return a.c.push(e.PWM),a.c.push({cN:"doctag",b:"(?:TODO|FIXME|NOTE|BUG|XXX):",r:0}),a},e.CLCM=e.C("//","$"),e.CBCM=e.C("/\\*","\\*/"),e.HCM=e.C("#","$"),e.NM={cN:"number",b:e.NR,r:0},e.CNM={cN:"number",b:e.CNR,r:0},e.BNM={cN:"number",b:e.BNR,r:0},e.CSSNM={cN:"number",b:e.NR+"(%|em|ex|ch|rem|vw|vh|vmin|vmax|cm|mm|in|pt|pc|px|deg|grad|rad|turn|s|ms|Hz|kHz|dpi|dpcm|dppx)?",r:0},e.RM={cN:"regexp",b:/\//,e:/\/[gimuy]*/,i:/\n/,c:[e.BE,{b:/\[/,e:/\]/,r:0,c:[e.BE]}]},e.TM={cN:"title",b:e.IR,r:0},e.UTM={cN:"title",b:e.UIR,r:0},e.METHOD_GUARD={b:"\\.\\s*"+e.UIR,r:0},e});hljs.registerLanguage("sql",function(e){var t=e.C("--","$");return{cI:!0,i:/[<>{}*#]/,c:[{bK:"begin end start commit rollback savepoint lock alter create drop rename call delete do handler insert load replace select truncate update set show pragma grant merge describe use explain help declare prepare execute deallocate release unlock purge reset change stop analyze cache flush optimize repair kill install uninstall checksum restore check backup revoke comment",e:/;/,eW:!0,l:/[\w\.]+/,k:{keyword:"abort abs absolute acc acce accep accept access accessed accessible account acos action activate add addtime admin administer advanced advise aes_decrypt aes_encrypt after agent aggregate ali alia alias allocate allow alter always analyze ancillary and any anydata anydataset anyschema anytype apply archive archived archivelog are as asc ascii asin assembly assertion associate asynchronous at atan atn2 attr attri attrib attribu attribut attribute attributes audit authenticated authentication authid authors auto autoallocate autodblink autoextend automatic availability avg backup badfile basicfile before begin beginning benchmark between bfile bfile_base big bigfile bin binary_double binary_float binlog bit_and bit_count bit_length bit_or bit_xor bitmap blob_base block blocksize body both bound buffer_cache buffer_pool build bulk by byte byteordermark bytes cache caching call calling cancel capacity cascade cascaded case cast catalog category ceil ceiling chain change changed char_base char_length character_length characters characterset charindex charset charsetform charsetid check checksum checksum_agg child choose chr chunk class cleanup clear client clob clob_base clone close cluster_id cluster_probability cluster_set clustering coalesce coercibility col collate collation collect colu colum column column_value columns columns_updated comment commit compact compatibility compiled complete composite_limit compound compress compute concat concat_ws concurrent confirm conn connec connect connect_by_iscycle connect_by_isleaf connect_by_root connect_time connection consider consistent constant constraint constraints constructor container content contents context contributors controlfile conv convert convert_tz corr corr_k corr_s corresponding corruption cos cost count count_big counted covar_pop covar_samp cpu_per_call cpu_per_session crc32 create creation critical cross cube cume_dist curdate current current_date current_time current_timestamp current_user cursor curtime customdatum cycle data database databases datafile datafiles datalength date_add date_cache date_format date_sub dateadd datediff datefromparts datename datepart datetime2fromparts day day_to_second dayname dayofmonth dayofweek dayofyear days db_role_change dbtimezone ddl deallocate declare decode decompose decrement decrypt deduplicate def defa defau defaul default defaults deferred defi defin define degrees delayed delegate delete delete_all delimited demand dense_rank depth dequeue des_decrypt des_encrypt des_key_file desc descr descri describ describe descriptor deterministic diagnostics difference dimension direct_load directory disable disable_all disallow disassociate discardfile disconnect diskgroup distinct distinctrow distribute distributed div do document domain dotnet double downgrade drop dumpfile duplicate duration each edition editionable editions element ellipsis else elsif elt empty enable enable_all enclosed encode encoding encrypt end end-exec endian enforced engine engines enqueue enterprise entityescaping eomonth error errors escaped evalname evaluate event eventdata events except exception exceptions exchange exclude excluding execu execut execute exempt exists exit exp expire explain export export_set extended extent external external_1 external_2 externally extract failed failed_login_attempts failover failure far fast feature_set feature_value fetch field fields file file_name_convert filesystem_like_logging final finish first first_value fixed flash_cache flashback floor flush following follows for forall force form forma format found found_rows freelist freelists freepools fresh from from_base64 from_days ftp full function general generated get get_format get_lock getdate getutcdate global global_name globally go goto grant grants greatest group group_concat group_id grouping grouping_id groups gtid_subtract guarantee guard handler hash hashkeys having hea head headi headin heading heap help hex hierarchy high high_priority hosts hour http id ident_current ident_incr ident_seed identified identity idle_time if ifnull ignore iif ilike ilm immediate import in include including increment index indexes indexing indextype indicator indices inet6_aton inet6_ntoa inet_aton inet_ntoa infile initial initialized initially initrans inmemory inner innodb input insert install instance instantiable instr interface interleaved intersect into invalidate invisible is is_free_lock is_ipv4 is_ipv4_compat is_not is_not_null is_used_lock isdate isnull isolation iterate java join json json_exists keep keep_duplicates key keys kill language large last last_day last_insert_id last_value lax lcase lead leading least leaves left len lenght length less level levels library like like2 like4 likec limit lines link list listagg little ln load load_file lob lobs local localtime localtimestamp locate locator lock locked log log10 log2 logfile logfiles logging logical logical_reads_per_call logoff logon logs long loop low low_priority lower lpad lrtrim ltrim main make_set makedate maketime managed management manual map mapping mask master master_pos_wait match matched materialized max maxextents maximize maxinstances maxlen maxlogfiles maxloghistory maxlogmembers maxsize maxtrans md5 measures median medium member memcompress memory merge microsecond mid migration min minextents minimum mining minus minute minvalue missing mod mode model modification modify module monitoring month months mount move movement multiset mutex name name_const names nan national native natural nav nchar nclob nested never new newline next nextval no no_write_to_binlog noarchivelog noaudit nobadfile nocheck nocompress nocopy nocycle nodelay nodiscardfile noentityescaping noguarantee nokeep nologfile nomapping nomaxvalue nominimize nominvalue nomonitoring none noneditionable nonschema noorder nopr nopro noprom nopromp noprompt norely noresetlogs noreverse normal norowdependencies noschemacheck noswitch not nothing notice notrim novalidate now nowait nth_value nullif nulls num numb numbe nvarchar nvarchar2 object ocicoll ocidate ocidatetime ociduration ociinterval ociloblocator ocinumber ociref ocirefcursor ocirowid ocistring ocitype oct octet_length of off offline offset oid oidindex old on online only opaque open operations operator optimal optimize option optionally or oracle oracle_date oradata ord ordaudio orddicom orddoc order ordimage ordinality ordvideo organization orlany orlvary out outer outfile outline output over overflow overriding package pad parallel parallel_enable parameters parent parse partial partition partitions pascal passing password password_grace_time password_lock_time password_reuse_max password_reuse_time password_verify_function patch path patindex pctincrease pctthreshold pctused pctversion percent percent_rank percentile_cont percentile_disc performance period period_add period_diff permanent physical pi pipe pipelined pivot pluggable plugin policy position post_transaction pow power pragma prebuilt precedes preceding precision prediction prediction_cost prediction_details prediction_probability prediction_set prepare present preserve prior priority private private_sga privileges procedural procedure procedure_analyze processlist profiles project prompt protection public publishingservername purge quarter query quick quiesce quota quotename radians raise rand range rank raw read reads readsize rebuild record records recover recovery recursive recycle redo reduced ref reference referenced references referencing refresh regexp_like register regr_avgx regr_avgy regr_count regr_intercept regr_r2 regr_slope regr_sxx regr_sxy reject rekey relational relative relaylog release release_lock relies_on relocate rely rem remainder rename repair repeat replace replicate replication required reset resetlogs resize resource respect restore restricted result result_cache resumable resume retention return returning returns reuse reverse revoke right rlike role roles rollback rolling rollup round row row_count rowdependencies rowid rownum rows rtrim rules safe salt sample save savepoint sb1 sb2 sb4 scan schema schemacheck scn scope scroll sdo_georaster sdo_topo_geometry search sec_to_time second section securefile security seed segment select self sequence sequential serializable server servererror session session_user sessions_per_user set sets settings sha sha1 sha2 share shared shared_pool short show shrink shutdown si_averagecolor si_colorhistogram si_featurelist si_positionalcolor si_stillimage si_texture siblings sid sign sin size size_t sizes skip slave sleep smalldatetimefromparts smallfile snapshot some soname sort soundex source space sparse spfile split sql sql_big_result sql_buffer_result sql_cache sql_calc_found_rows sql_small_result sql_variant_property sqlcode sqldata sqlerror sqlname sqlstate sqrt square standalone standby start starting startup statement static statistics stats_binomial_test stats_crosstab stats_ks_test stats_mode stats_mw_test stats_one_way_anova stats_t_test_ stats_t_test_indep stats_t_test_one stats_t_test_paired stats_wsr_test status std stddev stddev_pop stddev_samp stdev stop storage store stored str str_to_date straight_join strcmp strict string struct stuff style subdate subpartition subpartitions substitutable substr substring subtime subtring_index subtype success sum suspend switch switchoffset switchover sync synchronous synonym sys sys_xmlagg sysasm sysaux sysdate sysdatetimeoffset sysdba sysoper system system_user sysutcdatetime table tables tablespace tan tdo template temporary terminated tertiary_weights test than then thread through tier ties time time_format time_zone timediff timefromparts timeout timestamp timestampadd timestampdiff timezone_abbr timezone_minute timezone_region to to_base64 to_date to_days to_seconds todatetimeoffset trace tracking transaction transactional translate translation treat trigger trigger_nestlevel triggers trim truncate try_cast try_convert try_parse type ub1 ub2 ub4 ucase unarchived unbounded uncompress under undo unhex unicode uniform uninstall union unique unix_timestamp unknown unlimited unlock unpivot unrecoverable unsafe unsigned until untrusted unusable unused update updated upgrade upped upper upsert url urowid usable usage use use_stored_outlines user user_data user_resources users using utc_date utc_timestamp uuid uuid_short validate validate_password_strength validation valist value values var var_samp varcharc vari varia variab variabl variable variables variance varp varraw varrawc varray verify version versions view virtual visible void wait wallet warning warnings week weekday weekofyear wellformed when whene whenev wheneve whenever where while whitespace with within without work wrapped xdb xml xmlagg xmlattributes xmlcast xmlcolattval xmlelement xmlexists xmlforest xmlindex xmlnamespaces xmlpi xmlquery xmlroot xmlschema xmlserialize xmltable xmltype xor year year_to_month years yearweek",literal:"true false null",built_in:"array bigint binary bit blob boolean char character date dec decimal float int int8 integer interval number numeric real record serial serial8 smallint text varchar varying void"},c:[{cN:"string",b:"'",e:"'",c:[e.BE,{b:"''"}]},{cN:"string",b:'"',e:'"',c:[e.BE,{b:'""'}]},{cN:"string",b:"`",e:"`",c:[e.BE]},e.CNM,e.CBCM,t]},e.CBCM,t]}});hljs.registerLanguage("r",function(e){var r="([a-zA-Z]|\\.[a-zA-Z.])[a-zA-Z0-9._]*";return{c:[e.HCM,{b:r,l:r,k:{keyword:"function if in break next repeat else for return switch while try tryCatch stop warning require library attach detach source setMethod setGeneric setGroupGeneric setClass ...",literal:"NULL NA TRUE FALSE T F Inf NaN NA_integer_|10 NA_real_|10 NA_character_|10 NA_complex_|10"},r:0},{cN:"number",b:"0[xX][0-9a-fA-F]+[Li]?\\b",r:0},{cN:"number",b:"\\d+(?:[eE][+\\-]?\\d*)?L\\b",r:0},{cN:"number",b:"\\d+\\.(?!\\d)(?:i\\b)?",r:0},{cN:"number",b:"\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",r:0},{b:"`",e:"`",r:0},{cN:"string",c:[e.BE],v:[{b:'"',e:'"'},{b:"'",e:"'"}]}]}});hljs.registerLanguage("perl",function(e){var t="getpwent getservent quotemeta msgrcv scalar kill dbmclose undef lc ma syswrite tr send umask sysopen shmwrite vec qx utime local oct semctl localtime readpipe do return format read sprintf dbmopen pop getpgrp not getpwnam rewinddir qqfileno qw endprotoent wait sethostent bless s|0 opendir continue each sleep endgrent shutdown dump chomp connect getsockname die socketpair close flock exists index shmgetsub for endpwent redo lstat msgctl setpgrp abs exit select print ref gethostbyaddr unshift fcntl syscall goto getnetbyaddr join gmtime symlink semget splice x|0 getpeername recv log setsockopt cos last reverse gethostbyname getgrnam study formline endhostent times chop length gethostent getnetent pack getprotoent getservbyname rand mkdir pos chmod y|0 substr endnetent printf next open msgsnd readdir use unlink getsockopt getpriority rindex wantarray hex system getservbyport endservent int chr untie rmdir prototype tell listen fork shmread ucfirst setprotoent else sysseek link getgrgid shmctl waitpid unpack getnetbyname reset chdir grep split require caller lcfirst until warn while values shift telldir getpwuid my getprotobynumber delete and sort uc defined srand accept package seekdir getprotobyname semop our rename seek if q|0 chroot sysread setpwent no crypt getc chown sqrt write setnetent setpriority foreach tie sin msgget map stat getlogin unless elsif truncate exec keys glob tied closedirioctl socket readlink eval xor readline binmode setservent eof ord bind alarm pipe atan2 getgrent exp time push setgrent gt lt or ne m|0 break given say state when",r={cN:"subst",b:"[$@]\\{",e:"\\}",k:t},s={b:"->{",e:"}"},n={v:[{b:/\$\d/},{b:/[\$%@](\^\w\b|#\w+(::\w+)*|{\w+}|\w+(::\w*)*)/},{b:/[\$%@][^\s\w{]/,r:0}]},i=[e.BE,r,n],o=[n,e.HCM,e.C("^\\=\\w","\\=cut",{eW:!0}),s,{cN:"string",c:i,v:[{b:"q[qwxr]?\\s*\\(",e:"\\)",r:5},{b:"q[qwxr]?\\s*\\[",e:"\\]",r:5},{b:"q[qwxr]?\\s*\\{",e:"\\}",r:5},{b:"q[qwxr]?\\s*\\|",e:"\\|",r:5},{b:"q[qwxr]?\\s*\\<",e:"\\>",r:5},{b:"qw\\s+q",e:"q",r:5},{b:"'",e:"'",c:[e.BE]},{b:'"',e:'"'},{b:"`",e:"`",c:[e.BE]},{b:"{\\w+}",c:[],r:0},{b:"-?\\w+\\s*\\=\\>",c:[],r:0}]},{cN:"number",b:"(\\b0[0-7_]+)|(\\b0x[0-9a-fA-F_]+)|(\\b[1-9][0-9_]*(\\.[0-9_]+)?)|[0_]\\b",r:0},{b:"(\\/\\/|"+e.RSR+"|\\b(split|return|print|reverse|grep)\\b)\\s*",k:"split return print reverse grep",r:0,c:[e.HCM,{cN:"regexp",b:"(s|tr|y)/(\\\\.|[^/])*/(\\\\.|[^/])*/[a-z]*",r:10},{cN:"regexp",b:"(m|qr)?/",e:"/[a-z]*",c:[e.BE],r:0}]},{cN:"function",bK:"sub",e:"(\\s*\\(.*?\\))?[;{]",eE:!0,r:5,c:[e.TM]},{b:"-\\w\\b",r:0},{b:"^__DATA__$",e:"^__END__$",sL:"mojolicious",c:[{b:"^@@.*",e:"$",cN:"comment"}]}];return r.c=o,s.c=o,{aliases:["pl","pm"],l:/[\w\.]+/,k:t,c:o}});hljs.registerLanguage("ini",function(e){var b={cN:"string",c:[e.BE],v:[{b:"'''",e:"'''",r:10},{b:'"""',e:'"""',r:10},{b:'"',e:'"'},{b:"'",e:"'"}]};return{aliases:["toml"],cI:!0,i:/\S/,c:[e.C(";","$"),e.HCM,{cN:"section",b:/^\s*\[+/,e:/\]+/},{b:/^[a-z0-9\[\]_-]+\s*=\s*/,e:"$",rB:!0,c:[{cN:"attr",b:/[a-z0-9\[\]_-]+/},{b:/=/,eW:!0,r:0,c:[{cN:"literal",b:/\bon|off|true|false|yes|no\b/},{cN:"variable",v:[{b:/\$[\w\d"][\w\d_]*/},{b:/\$\{(.*?)}/}]},b,{cN:"number",b:/([\+\-]+)?[\d]+_[\d_]+/},e.NM]}]}]}});hljs.registerLanguage("diff",function(e){return{aliases:["patch"],c:[{cN:"meta",r:10,v:[{b:/^@@ +\-\d+,\d+ +\+\d+,\d+ +@@$/},{b:/^\*\*\* +\d+,\d+ +\*\*\*\*$/},{b:/^\-\-\- +\d+,\d+ +\-\-\-\-$/}]},{cN:"comment",v:[{b:/Index: /,e:/$/},{b:/={3,}/,e:/$/},{b:/^\-{3}/,e:/$/},{b:/^\*{3} /,e:/$/},{b:/^\+{3}/,e:/$/},{b:/\*{5}/,e:/\*{5}$/}]},{cN:"addition",b:"^\\+",e:"$"},{cN:"deletion",b:"^\\-",e:"$"},{cN:"addition",b:"^\\!",e:"$"}]}});hljs.registerLanguage("go",function(e){var t={keyword:"break default func interface select case map struct chan else goto package switch const fallthrough if range type continue for import return var go defer bool byte complex64 complex128 float32 float64 int8 int16 int32 int64 string uint8 uint16 uint32 uint64 int uint uintptr rune",literal:"true false iota nil",built_in:"append cap close complex copy imag len make new panic print println real recover delete"};return{aliases:["golang"],k:t,i:"</",c:[e.CLCM,e.CBCM,{cN:"string",v:[e.QSM,{b:"'",e:"[^\\\\]'"},{b:"`",e:"`"}]},{cN:"number",v:[{b:e.CNR+"[dflsi]",r:1},e.CNM]},{b:/:=/},{cN:"function",bK:"func",e:/\s*\{/,eE:!0,c:[e.TM,{cN:"params",b:/\(/,e:/\)/,k:t,i:/["']/}]}]}});hljs.registerLanguage("bash",function(e){var t={cN:"variable",v:[{b:/\$[\w\d#@][\w\d_]*/},{b:/\$\{(.*?)}/}]},s={cN:"string",b:/"/,e:/"/,c:[e.BE,t,{cN:"variable",b:/\$\(/,e:/\)/,c:[e.BE]}]},a={cN:"string",b:/'/,e:/'/};return{aliases:["sh","zsh"],l:/\b-?[a-z\._]+\b/,k:{keyword:"if then else elif fi for while in do done case esac function",literal:"true false",built_in:"break cd continue eval exec exit export getopts hash pwd readonly return shift test times trap umask unset alias bind builtin caller command declare echo enable help let local logout mapfile printf read readarray source type typeset ulimit unalias set shopt autoload bg bindkey bye cap chdir clone comparguments compcall compctl compdescribe compfiles compgroups compquote comptags comptry compvalues dirs disable disown echotc echoti emulate fc fg float functions getcap getln history integer jobs kill limit log noglob popd print pushd pushln rehash sched setcap setopt stat suspend ttyctl unfunction unhash unlimit unsetopt vared wait whence where which zcompile zformat zftp zle zmodload zparseopts zprof zpty zregexparse zsocket zstyle ztcp",_:"-ne -eq -lt -gt -f -d -e -s -l -a"},c:[{cN:"meta",b:/^#![^\n]+sh\s*$/,r:10},{cN:"function",b:/\w[\w\d_]*\s*\(\s*\)\s*\{/,rB:!0,c:[e.inherit(e.TM,{b:/\w[\w\d_]*/})],r:0},e.HCM,s,a,t]}});hljs.registerLanguage("python",function(e){var r={keyword:"and elif is global as in if from raise for except finally print import pass return exec else break not with class assert yield try while continue del or def lambda async await nonlocal|10 None True False",built_in:"Ellipsis NotImplemented"},b={cN:"meta",b:/^(>>>|\.\.\.) /},c={cN:"subst",b:/\{/,e:/\}/,k:r,i:/#/},a={cN:"string",c:[e.BE],v:[{b:/(u|b)?r?'''/,e:/'''/,c:[b],r:10},{b:/(u|b)?r?"""/,e:/"""/,c:[b],r:10},{b:/(fr|rf|f)'''/,e:/'''/,c:[b,c]},{b:/(fr|rf|f)"""/,e:/"""/,c:[b,c]},{b:/(u|r|ur)'/,e:/'/,r:10},{b:/(u|r|ur)"/,e:/"/,r:10},{b:/(b|br)'/,e:/'/},{b:/(b|br)"/,e:/"/},{b:/(fr|rf|f)'/,e:/'/,c:[c]},{b:/(fr|rf|f)"/,e:/"/,c:[c]},e.ASM,e.QSM]},s={cN:"number",r:0,v:[{b:e.BNR+"[lLjJ]?"},{b:"\\b(0o[0-7]+)[lLjJ]?"},{b:e.CNR+"[lLjJ]?"}]},i={cN:"params",b:/\(/,e:/\)/,c:["self",b,s,a]};return c.c=[a,s,b],{aliases:["py","gyp"],k:r,i:/(<\/|->|\?)|=>/,c:[b,s,a,e.HCM,{v:[{cN:"function",bK:"def"},{cN:"class",bK:"class"}],e:/:/,i:/[${=;\n,]/,c:[e.UTM,i,{b:/->/,eW:!0,k:"None"}]},{cN:"meta",b:/^[\t ]*@/,e:/$/},{b:/\b(print|exec)\(/}]}});hljs.registerLanguage("julia",function(e){var r={keyword:"in isa where baremodule begin break catch ccall const continue do else elseif end export false finally for function global if import importall let local macro module quote return true try using while type immutable abstract bitstype typealias ",literal:"true false ARGS C_NULL DevNull ENDIAN_BOM ENV I Inf Inf16 Inf32 Inf64 InsertionSort JULIA_HOME LOAD_PATH MergeSort NaN NaN16 NaN32 NaN64 PROGRAM_FILE QuickSort RoundDown RoundFromZero RoundNearest RoundNearestTiesAway RoundNearestTiesUp RoundToZero RoundUp STDERR STDIN STDOUT VERSION catalan e|0 eu|0 eulergamma golden im nothing pi γ π φ ",built_in:"ANY AbstractArray AbstractChannel AbstractFloat AbstractMatrix AbstractRNG AbstractSerializer AbstractSet AbstractSparseArray AbstractSparseMatrix AbstractSparseVector AbstractString AbstractUnitRange AbstractVecOrMat AbstractVector Any ArgumentError Array AssertionError Associative Base64DecodePipe Base64EncodePipe Bidiagonal BigFloat BigInt BitArray BitMatrix BitVector Bool BoundsError BufferStream CachingPool CapturedException CartesianIndex CartesianRange Cchar Cdouble Cfloat Channel Char Cint Cintmax_t Clong Clonglong ClusterManager Cmd CodeInfo Colon Complex Complex128 Complex32 Complex64 CompositeException Condition ConjArray ConjMatrix ConjVector Cptrdiff_t Cshort Csize_t Cssize_t Cstring Cuchar Cuint Cuintmax_t Culong Culonglong Cushort Cwchar_t Cwstring DataType Date DateFormat DateTime DenseArray DenseMatrix DenseVecOrMat DenseVector Diagonal Dict DimensionMismatch Dims DirectIndexString Display DivideError DomainError EOFError EachLine Enum Enumerate ErrorException Exception ExponentialBackOff Expr Factorization FileMonitor Float16 Float32 Float64 Function Future GlobalRef GotoNode HTML Hermitian IO IOBuffer IOContext IOStream IPAddr IPv4 IPv6 IndexCartesian IndexLinear IndexStyle InexactError InitError Int Int128 Int16 Int32 Int64 Int8 IntSet Integer InterruptException InvalidStateException Irrational KeyError LabelNode LinSpace LineNumberNode LoadError LowerTriangular MIME Matrix MersenneTwister Method MethodError MethodTable Module NTuple NewvarNode NullException Nullable Number ObjectIdDict OrdinalRange OutOfMemoryError OverflowError Pair ParseError PartialQuickSort PermutedDimsArray Pipe PollingFileWatcher ProcessExitedException Ptr QuoteNode RandomDevice Range RangeIndex Rational RawFD ReadOnlyMemoryError Real ReentrantLock Ref Regex RegexMatch RemoteChannel RemoteException RevString RoundingMode RowVector SSAValue SegmentationFault SerializationState Set SharedArray SharedMatrix SharedVector Signed SimpleVector Slot SlotNumber SparseMatrixCSC SparseVector StackFrame StackOverflowError StackTrace StepRange StepRangeLen StridedArray StridedMatrix StridedVecOrMat StridedVector String SubArray SubString SymTridiagonal Symbol Symmetric SystemError TCPSocket Task Text TextDisplay Timer Tridiagonal Tuple Type TypeError TypeMapEntry TypeMapLevel TypeName TypeVar TypedSlot UDPSocket UInt UInt128 UInt16 UInt32 UInt64 UInt8 UndefRefError UndefVarError UnicodeError UniformScaling Union UnionAll UnitRange Unsigned UpperTriangular Val Vararg VecElement VecOrMat Vector VersionNumber Void WeakKeyDict WeakRef WorkerConfig WorkerPool "},t="[A-Za-z_\\u00A1-\\uFFFF][A-Za-z_0-9\\u00A1-\\uFFFF]*",a={l:t,k:r,i:/<\//},n={cN:"number",b:/(\b0x[\d_]*(\.[\d_]*)?|0x\.\d[\d_]*)p[-+]?\d+|\b0[box][a-fA-F0-9][a-fA-F0-9_]*|(\b\d[\d_]*(\.[\d_]*)?|\.\d[\d_]*)([eEfF][-+]?\d+)?/,r:0},o={cN:"string",b:/'(.|\\[xXuU][a-zA-Z0-9]+)'/},i={cN:"subst",b:/\$\(/,e:/\)/,k:r},l={cN:"variable",b:"\\$"+t},c={cN:"string",c:[e.BE,i,l],v:[{b:/\w*"""/,e:/"""\w*/,r:10},{b:/\w*"/,e:/"\w*/}]},s={cN:"string",c:[e.BE,i,l],b:"`",e:"`"},d={cN:"meta",b:"@"+t},u={cN:"comment",v:[{b:"#=",e:"=#",r:10},{b:"#",e:"$"}]};return a.c=[n,o,c,s,d,u,e.HCM,{cN:"keyword",b:"\\b(((abstract|primitive)\\s+)type|(mutable\\s+)?struct)\\b"},{b:/<:/}],i.c=a.c,a});hljs.registerLanguage("coffeescript",function(e){var c={keyword:"in if for while finally new do return else break catch instanceof throw try this switch continue typeof delete debugger super yield import export from as default await then unless until loop of by when and or is isnt not",literal:"true false null undefined yes no on off",built_in:"npm require console print module global window document"},n="[A-Za-z$_][0-9A-Za-z$_]*",r={cN:"subst",b:/#\{/,e:/}/,k:c},i=[e.BNM,e.inherit(e.CNM,{starts:{e:"(\\s*/)?",r:0}}),{cN:"string",v:[{b:/'''/,e:/'''/,c:[e.BE]},{b:/'/,e:/'/,c:[e.BE]},{b:/"""/,e:/"""/,c:[e.BE,r]},{b:/"/,e:/"/,c:[e.BE,r]}]},{cN:"regexp",v:[{b:"///",e:"///",c:[r,e.HCM]},{b:"//[gim]*",r:0},{b:/\/(?![ *])(\\\/|.)*?\/[gim]*(?=\W|$)/}]},{b:"@"+n},{sL:"javascript",eB:!0,eE:!0,v:[{b:"```",e:"```"},{b:"`",e:"`"}]}];r.c=i;var s=e.inherit(e.TM,{b:n}),t="(\\(.*\\))?\\s*\\B[-=]>",o={cN:"params",b:"\\([^\\(]",rB:!0,c:[{b:/\(/,e:/\)/,k:c,c:["self"].concat(i)}]};return{aliases:["coffee","cson","iced"],k:c,i:/\/\*/,c:i.concat([e.C("###","###"),e.HCM,{cN:"function",b:"^\\s*"+n+"\\s*=\\s*"+t,e:"[-=]>",rB:!0,c:[s,o]},{b:/[:\(,=]\s*/,r:0,c:[{cN:"function",b:t,e:"[-=]>",rB:!0,c:[o]}]},{cN:"class",bK:"class",e:"$",i:/[:="\[\]]/,c:[{bK:"extends",eW:!0,i:/[:="\[\]]/,c:[s]},s]},{b:n+":",e:":",rB:!0,rE:!0,r:0}])}});hljs.registerLanguage("cpp",function(t){var e={cN:"keyword",b:"\\b[a-z\\d_]*_t\\b"},r={cN:"string",v:[{b:'(u8?|U)?L?"',e:'"',i:"\\n",c:[t.BE]},{b:'(u8?|U)?R"',e:'"',c:[t.BE]},{b:"'\\\\?.",e:"'",i:"."}]},s={cN:"number",v:[{b:"\\b(0b[01']+)"},{b:"(-?)\\b([\\d']+(\\.[\\d']*)?|\\.[\\d']+)(u|U|l|L|ul|UL|f|F|b|B)"},{b:"(-?)(\\b0[xX][a-fA-F0-9']+|(\\b[\\d']+(\\.[\\d']*)?|\\.[\\d']+)([eE][-+]?[\\d']+)?)"}],r:0},i={cN:"meta",b:/#\s*[a-z]+\b/,e:/$/,k:{"meta-keyword":"if else elif endif define undef warning error line pragma ifdef ifndef include"},c:[{b:/\\\n/,r:0},t.inherit(r,{cN:"meta-string"}),{cN:"meta-string",b:/<[^\n>]*>/,e:/$/,i:"\\n"},t.CLCM,t.CBCM]},a=t.IR+"\\s*\\(",c={keyword:"int float while private char catch import module export virtual operator sizeof dynamic_cast|10 typedef const_cast|10 const for static_cast|10 union namespace unsigned long volatile static protected bool template mutable if public friend do goto auto void enum else break extern using asm case typeid short reinterpret_cast|10 default double register explicit signed typename try this switch continue inline delete alignof constexpr decltype noexcept static_assert thread_local restrict _Bool complex _Complex _Imaginary atomic_bool atomic_char atomic_schar atomic_uchar atomic_short atomic_ushort atomic_int atomic_uint atomic_long atomic_ulong atomic_llong atomic_ullong new throw return and or not",built_in:"std string cin cout cerr clog stdin stdout stderr stringstream istringstream ostringstream auto_ptr deque list queue stack vector map set bitset multiset multimap unordered_set unordered_map unordered_multiset unordered_multimap array shared_ptr abort abs acos asin atan2 atan calloc ceil cosh cos exit exp fabs floor fmod fprintf fputs free frexp fscanf isalnum isalpha iscntrl isdigit isgraph islower isprint ispunct isspace isupper isxdigit tolower toupper labs ldexp log10 log malloc realloc memchr memcmp memcpy memset modf pow printf putchar puts scanf sinh sin snprintf sprintf sqrt sscanf strcat strchr strcmp strcpy strcspn strlen strncat strncmp strncpy strpbrk strrchr strspn strstr tanh tan vfprintf vprintf vsprintf endl initializer_list unique_ptr",literal:"true false nullptr NULL"},n=[e,t.CLCM,t.CBCM,s,r];return{aliases:["c","cc","h","c++","h++","hpp"],k:c,i:"</",c:n.concat([i,{b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:c,c:["self",e]},{b:t.IR+"::",k:c},{v:[{b:/=/,e:/;/},{b:/\(/,e:/\)/},{bK:"new throw return else",e:/;/}],k:c,c:n.concat([{b:/\(/,e:/\)/,k:c,c:n.concat(["self"]),r:0}]),r:0},{cN:"function",b:"("+t.IR+"[\\*&\\s]+)+"+a,rB:!0,e:/[{;=]/,eE:!0,k:c,i:/[^\w\s\*&]/,c:[{b:a,rB:!0,c:[t.TM],r:0},{cN:"params",b:/\(/,e:/\)/,k:c,r:0,c:[t.CLCM,t.CBCM,r,s,e]},t.CLCM,t.CBCM,i]},{cN:"class",bK:"class struct",e:/[{;:]/,c:[{b:/</,e:/>/,c:["self"]},t.TM]}]),exports:{preprocessor:i,strings:r,k:c}}});hljs.registerLanguage("ruby",function(e){var b="[a-zA-Z_]\\w*[!?=]?|[-+~]\\@|<<|>>|=~|===?|<=>|[<>]=?|\\*\\*|[-/+%^&*~`|]|\\[\\]=?",r={keyword:"and then defined module in return redo if BEGIN retry end for self when next until do begin unless END rescue else break undef not super class case require yield alias while ensure elsif or include attr_reader attr_writer attr_accessor",literal:"true false nil"},c={cN:"doctag",b:"@[A-Za-z]+"},a={b:"#<",e:">"},s=[e.C("#","$",{c:[c]}),e.C("^\\=begin","^\\=end",{c:[c],r:10}),e.C("^__END__","\\n$")],n={cN:"subst",b:"#\\{",e:"}",k:r},t={cN:"string",c:[e.BE,n],v:[{b:/'/,e:/'/},{b:/"/,e:/"/},{b:/`/,e:/`/},{b:"%[qQwWx]?\\(",e:"\\)"},{b:"%[qQwWx]?\\[",e:"\\]"},{b:"%[qQwWx]?{",e:"}"},{b:"%[qQwWx]?<",e:">"},{b:"%[qQwWx]?/",e:"/"},{b:"%[qQwWx]?%",e:"%"},{b:"%[qQwWx]?-",e:"-"},{b:"%[qQwWx]?\\|",e:"\\|"},{b:/\B\?(\\\d{1,3}|\\x[A-Fa-f0-9]{1,2}|\\u[A-Fa-f0-9]{4}|\\?\S)\b/},{b:/<<(-?)\w+$/,e:/^\s*\w+$/}]},i={cN:"params",b:"\\(",e:"\\)",endsParent:!0,k:r},d=[t,a,{cN:"class",bK:"class module",e:"$|;",i:/=/,c:[e.inherit(e.TM,{b:"[A-Za-z_]\\w*(::\\w+)*(\\?|\\!)?"}),{b:"<\\s*",c:[{b:"("+e.IR+"::)?"+e.IR}]}].concat(s)},{cN:"function",bK:"def",e:"$|;",c:[e.inherit(e.TM,{b:b}),i].concat(s)},{b:e.IR+"::"},{cN:"symbol",b:e.UIR+"(\\!|\\?)?:",r:0},{cN:"symbol",b:":(?!\\s)",c:[t,{b:b}],r:0},{cN:"number",b:"(\\b0[0-7_]+)|(\\b0x[0-9a-fA-F_]+)|(\\b[1-9][0-9_]*(\\.[0-9_]+)?)|[0_]\\b",r:0},{b:"(\\$\\W)|((\\$|\\@\\@?)(\\w+))"},{cN:"params",b:/\|/,e:/\|/,k:r},{b:"("+e.RSR+"|unless)\\s*",k:"unless",c:[a,{cN:"regexp",c:[e.BE,n],i:/\n/,v:[{b:"/",e:"/[a-z]*"},{b:"%r{",e:"}[a-z]*"},{b:"%r\\(",e:"\\)[a-z]*"},{b:"%r!",e:"![a-z]*"},{b:"%r\\[",e:"\\][a-z]*"}]}].concat(s),r:0}].concat(s);n.c=d,i.c=d;var l="[>?]>",o="[\\w#]+\\(\\w+\\):\\d+:\\d+>",u="(\\w+-)?\\d+\\.\\d+\\.\\d(p\\d+)?[^>]+>",w=[{b:/^\s*=>/,starts:{e:"$",c:d}},{cN:"meta",b:"^("+l+"|"+o+"|"+u+")",starts:{e:"$",c:d}}];return{aliases:["rb","gemspec","podspec","thor","irb"],k:r,i:/\/\*/,c:s.concat(w).concat(d)}});hljs.registerLanguage("yaml",function(e){var b="true false yes no null",a="^[ \\-]*",r="[a-zA-Z_][\\w\\-]*",t={cN:"attr",v:[{b:a+r+":"},{b:a+'"'+r+'":'},{b:a+"'"+r+"':"}]},c={cN:"template-variable",v:[{b:"{{",e:"}}"},{b:"%{",e:"}"}]},l={cN:"string",r:0,v:[{b:/'/,e:/'/},{b:/"/,e:/"/},{b:/\S+/}],c:[e.BE,c]};return{cI:!0,aliases:["yml","YAML","yaml"],c:[t,{cN:"meta",b:"^---s*$",r:10},{cN:"string",b:"[\\|>] *$",rE:!0,c:l.c,e:t.v[0].b},{b:"<%[%=-]?",e:"[%-]?%>",sL:"ruby",eB:!0,eE:!0,r:0},{cN:"type",b:"!!"+e.UIR},{cN:"meta",b:"&"+e.UIR+"$"},{cN:"meta",b:"\\*"+e.UIR+"$"},{cN:"bullet",b:"^ *-",r:0},e.HCM,{bK:b,k:{literal:b}},e.CNM,l]}});hljs.registerLanguage("css",function(e){var c="[a-zA-Z-][a-zA-Z0-9_-]*",t={b:/[A-Z\_\.\-]+\s*:/,rB:!0,e:";",eW:!0,c:[{cN:"attribute",b:/\S/,e:":",eE:!0,starts:{eW:!0,eE:!0,c:[{b:/[\w-]+\(/,rB:!0,c:[{cN:"built_in",b:/[\w-]+/},{b:/\(/,e:/\)/,c:[e.ASM,e.QSM]}]},e.CSSNM,e.QSM,e.ASM,e.CBCM,{cN:"number",b:"#[0-9A-Fa-f]+"},{cN:"meta",b:"!important"}]}}]};return{cI:!0,i:/[=\/|'\$]/,c:[e.CBCM,{cN:"selector-id",b:/#[A-Za-z0-9_-]+/},{cN:"selector-class",b:/\.[A-Za-z0-9_-]+/},{cN:"selector-attr",b:/\[/,e:/\]/,i:"$"},{cN:"selector-pseudo",b:/:(:)?[a-zA-Z0-9\_\-\+\(\)"'.]+/},{b:"@(font-face|page)",l:"[a-z-]+",k:"font-face page"},{b:"@",e:"[{;]",i:/:/,c:[{cN:"keyword",b:/\w+/},{b:/\s/,eW:!0,eE:!0,r:0,c:[e.ASM,e.QSM,e.CSSNM]}]},{cN:"selector-tag",b:c,r:0},{b:"{",e:"}",i:/\S/,c:[e.CBCM,t]}]}});hljs.registerLanguage("fortran",function(e){var t={cN:"params",b:"\\(",e:"\\)"},n={literal:".False. .True.",keyword:"kind do while private call intrinsic where elsewhere type endtype endmodule endselect endinterface end enddo endif if forall endforall only contains default return stop then public subroutine|10 function program .and. .or. .not. .le. .eq. .ge. .gt. .lt. goto save else use module select case access blank direct exist file fmt form formatted iostat name named nextrec number opened rec recl sequential status unformatted unit continue format pause cycle exit c_null_char c_alert c_backspace c_form_feed flush wait decimal round iomsg synchronous nopass non_overridable pass protected volatile abstract extends import non_intrinsic value deferred generic final enumerator class associate bind enum c_int c_short c_long c_long_long c_signed_char c_size_t c_int8_t c_int16_t c_int32_t c_int64_t c_int_least8_t c_int_least16_t c_int_least32_t c_int_least64_t c_int_fast8_t c_int_fast16_t c_int_fast32_t c_int_fast64_t c_intmax_t C_intptr_t c_float c_double c_long_double c_float_complex c_double_complex c_long_double_complex c_bool c_char c_null_ptr c_null_funptr c_new_line c_carriage_return c_horizontal_tab c_vertical_tab iso_c_binding c_loc c_funloc c_associated  c_f_pointer c_ptr c_funptr iso_fortran_env character_storage_size error_unit file_storage_size input_unit iostat_end iostat_eor numeric_storage_size output_unit c_f_procpointer ieee_arithmetic ieee_support_underflow_control ieee_get_underflow_mode ieee_set_underflow_mode newunit contiguous recursive pad position action delim readwrite eor advance nml interface procedure namelist include sequence elemental pure integer real character complex logical dimension allocatable|10 parameter external implicit|10 none double precision assign intent optional pointer target in out common equivalence data",built_in:"alog alog10 amax0 amax1 amin0 amin1 amod cabs ccos cexp clog csin csqrt dabs dacos dasin datan datan2 dcos dcosh ddim dexp dint dlog dlog10 dmax1 dmin1 dmod dnint dsign dsin dsinh dsqrt dtan dtanh float iabs idim idint idnint ifix isign max0 max1 min0 min1 sngl algama cdabs cdcos cdexp cdlog cdsin cdsqrt cqabs cqcos cqexp cqlog cqsin cqsqrt dcmplx dconjg derf derfc dfloat dgamma dimag dlgama iqint qabs qacos qasin qatan qatan2 qcmplx qconjg qcos qcosh qdim qerf qerfc qexp qgamma qimag qlgama qlog qlog10 qmax1 qmin1 qmod qnint qsign qsin qsinh qsqrt qtan qtanh abs acos aimag aint anint asin atan atan2 char cmplx conjg cos cosh exp ichar index int log log10 max min nint sign sin sinh sqrt tan tanh print write dim lge lgt lle llt mod nullify allocate deallocate adjustl adjustr all allocated any associated bit_size btest ceiling count cshift date_and_time digits dot_product eoshift epsilon exponent floor fraction huge iand ibclr ibits ibset ieor ior ishft ishftc lbound len_trim matmul maxexponent maxloc maxval merge minexponent minloc minval modulo mvbits nearest pack present product radix random_number random_seed range repeat reshape rrspacing scale scan selected_int_kind selected_real_kind set_exponent shape size spacing spread sum system_clock tiny transpose trim ubound unpack verify achar iachar transfer dble entry dprod cpu_time command_argument_count get_command get_command_argument get_environment_variable is_iostat_end ieee_arithmetic ieee_support_underflow_control ieee_get_underflow_mode ieee_set_underflow_mode is_iostat_eor move_alloc new_line selected_char_kind same_type_as extends_type_ofacosh asinh atanh bessel_j0 bessel_j1 bessel_jn bessel_y0 bessel_y1 bessel_yn erf erfc erfc_scaled gamma log_gamma hypot norm2 atomic_define atomic_ref execute_command_line leadz trailz storage_size merge_bits bge bgt ble blt dshiftl dshiftr findloc iall iany iparity image_index lcobound ucobound maskl maskr num_images parity popcnt poppar shifta shiftl shiftr this_image"};return{cI:!0,aliases:["f90","f95"],k:n,i:/\/\*/,c:[e.inherit(e.ASM,{cN:"string",r:0}),e.inherit(e.QSM,{cN:"string",r:0}),{cN:"function",bK:"subroutine function program",i:"[${=\\n]",c:[e.UTM,t]},e.C("!","$",{r:0}),{cN:"number",b:"(?=\\b|\\+|\\-|\\.)(?=\\.\\d|\\d)(?:\\d+)?(?:\\.?\\d*)(?:[de][+-]?\\d+)?\\b\\.?",r:0}]}});hljs.registerLanguage("awk",function(e){var r={cN:"variable",v:[{b:/\$[\w\d#@][\w\d_]*/},{b:/\$\{(.*?)}/}]},b="BEGIN END if else while do for in break continue delete next nextfile function func exit|10",n={cN:"string",c:[e.BE],v:[{b:/(u|b)?r?'''/,e:/'''/,r:10},{b:/(u|b)?r?"""/,e:/"""/,r:10},{b:/(u|r|ur)'/,e:/'/,r:10},{b:/(u|r|ur)"/,e:/"/,r:10},{b:/(b|br)'/,e:/'/},{b:/(b|br)"/,e:/"/},e.ASM,e.QSM]};return{k:{keyword:b},c:[r,n,e.RM,e.HCM,e.NM]}});hljs.registerLanguage("makefile",function(e){var i={cN:"variable",v:[{b:"\\$\\("+e.UIR+"\\)",c:[e.BE]},{b:/\$[@%<?\^\+\*]/}]},r={cN:"string",b:/"/,e:/"/,c:[e.BE,i]},a={cN:"variable",b:/\$\([\w-]+\s/,e:/\)/,k:{built_in:"subst patsubst strip findstring filter filter-out sort word wordlist firstword lastword dir notdir suffix basename addsuffix addprefix join wildcard realpath abspath error warning shell origin flavor foreach if or and call eval file value"},c:[i]},n={b:"^"+e.UIR+"\\s*[:+?]?=",i:"\\n",rB:!0,c:[{b:"^"+e.UIR,e:"[:+?]?=",eE:!0}]},t={cN:"meta",b:/^\.PHONY:/,e:/$/,k:{"meta-keyword":".PHONY"},l:/[\.\w]+/},l={cN:"section",b:/^[^\s]+:/,e:/$/,c:[i]};return{aliases:["mk","mak"],k:"define endef undefine ifdef ifndef ifeq ifneq else endif include -include sinclude override export unexport private vpath",l:/[\w-]+/,c:[e.HCM,i,r,a,n,t,l]}});hljs.registerLanguage("java",function(e){var a="[À-ʸa-zA-Z_$][À-ʸa-zA-Z_$0-9]*",t=a+"(<"+a+"(\\s*,\\s*"+a+")*>)?",r="false synchronized int abstract float private char boolean static null if const for true while long strictfp finally protected import native final void enum else break transient catch instanceof byte super volatile case assert short package default double public try this switch continue throws protected public private module requires exports do",s="\\b(0[bB]([01]+[01_]+[01]+|[01]+)|0[xX]([a-fA-F0-9]+[a-fA-F0-9_]+[a-fA-F0-9]+|[a-fA-F0-9]+)|(([\\d]+[\\d_]+[\\d]+|[\\d]+)(\\.([\\d]+[\\d_]+[\\d]+|[\\d]+))?|\\.([\\d]+[\\d_]+[\\d]+|[\\d]+))([eE][-+]?\\d+)?)[lLfF]?",c={cN:"number",b:s,r:0};return{aliases:["jsp"],k:r,i:/<\/|#/,c:[e.C("/\\*\\*","\\*/",{r:0,c:[{b:/\w+@/,r:0},{cN:"doctag",b:"@[A-Za-z]+"}]}),e.CLCM,e.CBCM,e.ASM,e.QSM,{cN:"class",bK:"class interface",e:/[{;=]/,eE:!0,k:"class interface",i:/[:"\[\]]/,c:[{bK:"extends implements"},e.UTM]},{bK:"new throw return else",r:0},{cN:"function",b:"("+t+"\\s+)+"+e.UIR+"\\s*\\(",rB:!0,e:/[{;=]/,eE:!0,k:r,c:[{b:e.UIR+"\\s*\\(",rB:!0,r:0,c:[e.UTM]},{cN:"params",b:/\(/,e:/\)/,k:r,r:0,c:[e.ASM,e.QSM,e.CNM,e.CBCM]},e.CLCM,e.CBCM]},c,{cN:"meta",b:"@[A-Za-z]+"}]}});hljs.registerLanguage("stan",function(e){return{c:[e.HCM,e.CLCM,e.CBCM,{b:e.UIR,l:e.UIR,k:{name:"for in while repeat until if then else",symbol:"bernoulli bernoulli_logit binomial binomial_logit beta_binomial hypergeometric categorical categorical_logit ordered_logistic neg_binomial neg_binomial_2 neg_binomial_2_log poisson poisson_log multinomial normal exp_mod_normal skew_normal student_t cauchy double_exponential logistic gumbel lognormal chi_square inv_chi_square scaled_inv_chi_square exponential inv_gamma weibull frechet rayleigh wiener pareto pareto_type_2 von_mises uniform multi_normal multi_normal_prec multi_normal_cholesky multi_gp multi_gp_cholesky multi_student_t gaussian_dlm_obs dirichlet lkj_corr lkj_corr_cholesky wishart inv_wishart","selector-tag":"int real vector simplex unit_vector ordered positive_ordered row_vector matrix cholesky_factor_corr cholesky_factor_cov corr_matrix cov_matrix",title:"functions model data parameters quantities transformed generated",literal:"true false"},r:0},{cN:"number",b:"0[xX][0-9a-fA-F]+[Li]?\\b",r:0},{cN:"number",b:"0[xX][0-9a-fA-F]+[Li]?\\b",r:0},{cN:"number",b:"\\d+(?:[eE][+\\-]?\\d*)?L\\b",r:0},{cN:"number",b:"\\d+\\.(?!\\d)(?:i\\b)?",r:0},{cN:"number",b:"\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",r:0}]}});hljs.registerLanguage("javascript",function(e){var r="[A-Za-z$_][0-9A-Za-z$_]*",t={keyword:"in of if for while finally var new function do return void else break catch instanceof with throw case default try this switch continue typeof delete let yield const export super debugger as async await static import from as",literal:"true false null undefined NaN Infinity",built_in:"eval isFinite isNaN parseFloat parseInt decodeURI decodeURIComponent encodeURI encodeURIComponent escape unescape Object Function Boolean Error EvalError InternalError RangeError ReferenceError StopIteration SyntaxError TypeError URIError Number Math Date String RegExp Array Float32Array Float64Array Int16Array Int32Array Int8Array Uint16Array Uint32Array Uint8Array Uint8ClampedArray ArrayBuffer DataView JSON Intl arguments require module console window document Symbol Set Map WeakSet WeakMap Proxy Reflect Promise"},a={cN:"number",v:[{b:"\\b(0[bB][01]+)"},{b:"\\b(0[oO][0-7]+)"},{b:e.CNR}],r:0},n={cN:"subst",b:"\\$\\{",e:"\\}",k:t,c:[]},c={cN:"string",b:"`",e:"`",c:[e.BE,n]};n.c=[e.ASM,e.QSM,c,a,e.RM];var s=n.c.concat([e.CBCM,e.CLCM]);return{aliases:["js","jsx"],k:t,c:[{cN:"meta",r:10,b:/^\s*['"]use (strict|asm)['"]/},{cN:"meta",b:/^#!/,e:/$/},e.ASM,e.QSM,c,e.CLCM,e.CBCM,a,{b:/[{,]\s*/,r:0,c:[{b:r+"\\s*:",rB:!0,r:0,c:[{cN:"attr",b:r,r:0}]}]},{b:"("+e.RSR+"|\\b(case|return|throw)\\b)\\s*",k:"return throw case",c:[e.CLCM,e.CBCM,e.RM,{cN:"function",b:"(\\(.*?\\)|"+r+")\\s*=>",rB:!0,e:"\\s*=>",c:[{cN:"params",v:[{b:r},{b:/\(\s*\)/},{b:/\(/,e:/\)/,eB:!0,eE:!0,k:t,c:s}]}]},{b:/</,e:/(\/\w+|\w+\/)>/,sL:"xml",c:[{b:/<\w+\s*\/>/,skip:!0},{b:/<\w+/,e:/(\/\w+|\w+\/)>/,skip:!0,c:[{b:/<\w+\s*\/>/,skip:!0},"self"]}]}],r:0},{cN:"function",bK:"function",e:/\{/,eE:!0,c:[e.inherit(e.TM,{b:r}),{cN:"params",b:/\(/,e:/\)/,eB:!0,eE:!0,c:s}],i:/\[|%/},{b:/\$[(.]/},e.METHOD_GUARD,{cN:"class",bK:"class",e:/[{;=]/,eE:!0,i:/[:"\[\]]/,c:[{bK:"extends"},e.UTM]},{bK:"constructor",e:/\{/,eE:!0}],i:/#(?!!)/}});hljs.registerLanguage("tex",function(c){var e={cN:"tag",b:/\\/,r:0,c:[{cN:"name",v:[{b:/[a-zA-Zа-яА-я]+[*]?/},{b:/[^a-zA-Zа-яА-я0-9]/}],starts:{eW:!0,r:0,c:[{cN:"string",v:[{b:/\[/,e:/\]/},{b:/\{/,e:/\}/}]},{b:/\s*=\s*/,eW:!0,r:0,c:[{cN:"number",b:/-?\d*\.?\d+(pt|pc|mm|cm|in|dd|cc|ex|em)?/}]}]}}]};return{c:[e,{cN:"formula",c:[e],r:0,v:[{b:/\$\$/,e:/\$\$/},{b:/\$/,e:/\$/}]},c.C("%","$",{r:0})]}});hljs.registerLanguage("xml",function(s){var e="[A-Za-z0-9\\._:-]+",t={eW:!0,i:/</,r:0,c:[{cN:"attr",b:e,r:0},{b:/=\s*/,r:0,c:[{cN:"string",endsParent:!0,v:[{b:/"/,e:/"/},{b:/'/,e:/'/},{b:/[^\s"'=<>`]+/}]}]}]};return{aliases:["html","xhtml","rss","atom","xjb","xsd","xsl","plist"],cI:!0,c:[{cN:"meta",b:"<!DOCTYPE",e:">",r:10,c:[{b:"\\[",e:"\\]"}]},s.C("<!--","-->",{r:10}),{b:"<\\!\\[CDATA\\[",e:"\\]\\]>",r:10},{b:/<\?(php)?/,e:/\?>/,sL:"php",c:[{b:"/\\*",e:"\\*/",skip:!0}]},{cN:"tag",b:"<style(?=\\s|>|$)",e:">",k:{name:"style"},c:[t],starts:{e:"</style>",rE:!0,sL:["css","xml"]}},{cN:"tag",b:"<script(?=\\s|>|$)",e:">",k:{name:"script"},c:[t],starts:{e:"</script>",rE:!0,sL:["actionscript","javascript","handlebars","xml"]}},{cN:"meta",v:[{b:/<\?xml/,e:/\?>/,r:10},{b:/<\?\w+/,e:/\?>/}]},{cN:"tag",b:"</?",e:"/?>",c:[{cN:"name",b:/[^\/><\s]+/,r:0},t]}]}});hljs.registerLanguage("markdown",function(e){return{aliases:["md","mkdown","mkd"],c:[{cN:"section",v:[{b:"^#{1,6}",e:"$"},{b:"^.+?\\n[=-]{2,}$"}]},{b:"<",e:">",sL:"xml",r:0},{cN:"bullet",b:"^([*+-]|(\\d+\\.))\\s+"},{cN:"strong",b:"[*_]{2}.+?[*_]{2}"},{cN:"emphasis",v:[{b:"\\*.+?\\*"},{b:"_.+?_",r:0}]},{cN:"quote",b:"^>\\s+",e:"$"},{cN:"code",v:[{b:"^```w*s*$",e:"^```s*$"},{b:"`.+?`"},{b:"^( {4}|	)",e:"$",r:0}]},{b:"^[-\\*]{3,}",e:"$"},{b:"\\[.+?\\][\\(\\[].*?[\\)\\]]",rB:!0,c:[{cN:"string",b:"\\[",e:"\\]",eB:!0,rE:!0,r:0},{cN:"link",b:"\\]\\(",e:"\\)",eB:!0,eE:!0},{cN:"symbol",b:"\\]\\[",e:"\\]",eB:!0,eE:!0}],r:10},{b:/^\[[^\n]+\]:/,rB:!0,c:[{cN:"symbol",b:/\[/,e:/\]/,eB:!0,eE:!0},{cN:"link",b:/:\s*/,e:/$/,eB:!0}]}]}});hljs.registerLanguage("json",function(e){var i={literal:"true false null"},n=[e.QSM,e.CNM],r={e:",",eW:!0,eE:!0,c:n,k:i},t={b:"{",e:"}",c:[{cN:"attr",b:/"/,e:/"/,c:[e.BE],i:"\\n"},e.inherit(r,{b:/:/})],i:"\\S"},c={b:"\\[",e:"\\]",c:[e.inherit(r)],i:"\\S"};return n.splice(n.length,0,t,c),{c:n,k:i,i:"\\S"}});&#34;&gt;&lt;/script&gt;

&lt;style type=&#34;text/css&#34;&gt;
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
&lt;/style&gt;

&lt;style type=&#34;text/css&#34;&gt;code{white-space: pre;}&lt;/style&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState &amp;&amp; document.readyState === &#34;complete&#34;) {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
&lt;/script&gt;









&lt;style type=&#34;text/css&#34;&gt;
.main-container {
max-width: 940px;
margin-left: auto;
margin-right: auto;
}
img {
max-width:100%;
}
.tabbed-pane {
padding-top: 12px;
}
.html-widget {
margin-bottom: 20px;
}
button.code-folding-btn:focus {
outline: none;
}
summary {
display: list-item;
}
details &gt; summary &gt; p:only-child {
display: inline;
}
pre code {
padding: 0;
}
&lt;/style&gt;



&lt;!-- tabsets --&gt;

&lt;style type=&#34;text/css&#34;&gt;
.tabset-dropdown &gt; .nav-tabs {
display: inline-table;
max-height: 500px;
min-height: 44px;
overflow-y: auto;
border: 1px solid #ddd;
border-radius: 4px;
}
.tabset-dropdown &gt; .nav-tabs &gt; li.active:before, .tabset-dropdown &gt; .nav-tabs.nav-tabs-open:before {
content: &#34;\e259&#34;;
font-family: &#39;Glyphicons Halflings&#39;;
display: inline-block;
padding: 10px;
border-right: 1px solid #ddd;
}
.tabset-dropdown &gt; .nav-tabs.nav-tabs-open &gt; li.active:before {
content: &#34;\e258&#34;;
font-family: &#39;Glyphicons Halflings&#39;;
border: none;
}
.tabset-dropdown &gt; .nav-tabs &gt; li.active {
display: block;
}
.tabset-dropdown &gt; .nav-tabs &gt; li &gt; a,
.tabset-dropdown &gt; .nav-tabs &gt; li &gt; a:focus,
.tabset-dropdown &gt; .nav-tabs &gt; li &gt; a:hover {
border: none;
display: inline-block;
border-radius: 4px;
background-color: transparent;
}
.tabset-dropdown &gt; .nav-tabs.nav-tabs-open &gt; li {
display: block;
float: none;
}
.tabset-dropdown &gt; .nav-tabs &gt; li {
display: none;
}
&lt;/style&gt;

&lt;!-- code folding --&gt;




&lt;/head&gt;

&lt;body&gt;


&lt;div class=&#34;container-fluid main-container&#34;&gt;




&lt;div id=&#34;header&#34;&gt;



&lt;h1 class=&#34;title toc-ignore&#34;&gt;Rejection sampler for Efron’s double
Poisson distribution&lt;/h1&gt;
&lt;h4 class=&#34;date&#34;&gt;2023-01-25&lt;/h4&gt;

&lt;/div&gt;


&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\def\Pr{{\text{Pr}}}
\def\E{{\text{E}}}
\def\Var{{\text{Var}}}
\def\Cov{{\text{Cov}}}
\def\bm{\mathbf}
\def\bs{\boldsymbol}
\]&lt;/span&gt; For a project I am working on, we are using &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; to fit generalized random effects
location-scale models to a bunch of count data. We’re interested in
using the double-Poisson distribution, as described by &lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron (1986)&lt;/a&gt;, but it’s
turning out to be a bit tricky. The double-Poisson distribution is not
implemented in Stan, so we’ve had to write our own distribution
function. That’s fine and not particularly difficult. What’s more
challenging is that also we need to also write a Stan function to
generate random samples from the double-Poisson, so that we can generate
posterior predictive checks.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; In this post, I’ll look at how to approach
this problem using a rejection sampler.&lt;/p&gt;
&lt;p&gt;To implement a rejection sampler, we need to find a distribution 1)
from which it is easy to draw random samples and 2) that approximates
the double-Poisson. Specifically, we need to find a density &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt; and a constant &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; that satisfies the following criterion,
with &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; denoting the
double-Poisson density: &lt;span class=&#34;math display&#34;&gt;\[
\sup_x \frac{f(x)}{g(x)} \leq k,
\]&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; ranging over the
non-negative integers. Equivalently, we seek &lt;span class=&#34;math display&#34;&gt;\[
\sup_x \ d(x) \leq \ln k, \quad \text{where} \quad d(x) = \ln f(x) - \ln
g(x).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.2307/2289002&#34;&gt;Efron (1986)&lt;/a&gt; gives the
following expression for the density of the double-Poisson distribution
with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and inverse-disperson
&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;: &lt;span class=&#34;math display&#34;&gt;\[
f(x | \mu, \theta) = \frac{\theta^{1/2} e^{-\theta \mu}}{c(\mu,\theta)}
\left(\frac{e^{-x} x^x}{x!}\right) \left(\frac{e \mu}{x}\right)^{\theta
x},
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(c(\mu,\theta)\)&lt;/span&gt; is a
scaling constant to ensure that the density sums to one, which is
closely approximated by &lt;span class=&#34;math display&#34;&gt;\[
c(\mu, \theta) \approx 1 + \frac{1 - \theta}{12 \mu \theta}\left(1 +
\frac{1}{\mu \theta}\right).
\]&lt;/span&gt; We then have &lt;span class=&#34;math display&#34;&gt;\[
\ln f(x | \mu, \theta) = \frac{1}{2} \ln \theta - \theta \mu - c(\mu,
\theta) - (1 - \theta - \theta \ln \mu) x + (1 - \theta) x \ln(x) - \ln
\left(x!\right),
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(x \ln (x)\)&lt;/span&gt; is
evaluated as 0.&lt;/p&gt;
&lt;p&gt;Finding an approximating distribution is tricky because the
double-Poisson admits both over-dispersion (where &lt;span class=&#34;math inline&#34;&gt;\(\Var(X) &amp;gt; \E(X)\)&lt;/span&gt;) and under-dispersion
(where &lt;span class=&#34;math inline&#34;&gt;\(\Var(X) &amp;lt; \E(X)\)&lt;/span&gt;). In
contrast, many other readily available distributions such as the
negative binomial only allow for over-dispersion relative to the
Poisson.&lt;/p&gt;
&lt;div id=&#34;over-dispersion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Over-dispersion&lt;/h1&gt;
&lt;p&gt;Let us consider using a negative binomial distribution for &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt;, for the case where the
double-Poisson is over-dispersed with &lt;span class=&#34;math inline&#34;&gt;\(\theta
&amp;lt; 1\)&lt;/span&gt;. The negative binomial density is &lt;span class=&#34;math display&#34;&gt;\[
g(x | p, r) = {{x + r - 1}\choose{x}} (1 - p)^x p^r
\]&lt;/span&gt; with log density &lt;span class=&#34;math display&#34;&gt;\[
\ln g(x | p, r) = \ln \left((x + r - 1)!\right) - \ln \left((r -
1)!\right) - \ln \left(x!\right) + x \ln(1 - p) + r \ln (p).
\]&lt;/span&gt; The difference function is thus &lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
d(x) &amp;amp;= \ln f(x | \mu, \theta) - \ln g(x | p, r) \\
&amp;amp;= \frac{1}{2} \ln \theta - \theta \mu - r \ln p \\
&amp;amp; \qquad + \left[\theta \ln \mu - (1 - \theta) - \ln (1 - p)\right]
x \\
&amp;amp; \qquad \qquad + (1 - \theta) x \ln(x) - \left[\ln \left((x + r -
1)!\right) - \ln \left((r - 1)!\right)\right] \\
&amp;amp; = (1 - \theta) x \ln(x) + b x - \ln \Gamma(x + r - 1) + c
\end{aligned}
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(b = \theta \ln \mu - (1 -
\theta) - \ln (1 - p)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c =
\frac{1}{2} \ln \theta - \theta \mu - r \ln p + \ln \Gamma(r -
1)\)&lt;/span&gt;. The first derivative of &lt;span class=&#34;math inline&#34;&gt;\(d(x)\)&lt;/span&gt; with respect to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is then &lt;span class=&#34;math display&#34;&gt;\[
d&amp;#39;(x) = (1 - \theta) \ln x - \psi_0(x + r - 1) + \theta \ln \mu -
\ln(1 - p),
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\psi_0()\)&lt;/span&gt; is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Digamma_function&#34;&gt;digamma
function&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s assume that we want &lt;span class=&#34;math inline&#34;&gt;\(d&amp;#39;(\mu) =
0\)&lt;/span&gt;. This implies that &lt;span class=&#34;math display&#34;&gt;\[
\ln(1 - p) = \ln \mu - \psi_0(\mu + r - 1)
\]&lt;/span&gt; and thus &lt;span class=&#34;math display&#34;&gt;\[
\ln p = \ln\left[1 - \mu \exp \psi_0(\mu + r - 1)\right]
\]&lt;/span&gt; We can then write &lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
d(\mu) &amp;amp;= (1 - \theta) \mu \ln \mu + b \mu - \ln \Gamma(\mu + r - 1)
+ c \\
&amp;amp;= (1 - \theta) \mu \ln \mu + \theta \mu \ln \mu - \mu (1 - \theta)
- \mu\ln (1 - p) - \ln \Gamma(\mu + r - 1) + \frac{1}{2} \ln \theta -
\theta \mu - r \ln p + \ln \Gamma(r - 1) \\
&amp;amp;= \mu \ln \mu - \mu - \mu \ln(1 - p) - \ln \Gamma(\mu + r - 1) +
\frac{1}{2} \ln \theta - r \ln p + \ln \Gamma(r - 1) \\
&amp;amp;= \mu \psi_0(\mu + r - 1) - r \ln\left[1 - \mu \exp \psi_0(\mu + r
- 1)\right] - \ln \Gamma(\mu + r - 1) + \ln \Gamma(r - 1)  - \mu +
\frac{1}{2} \ln \theta.
\end{aligned}
\]&lt;/span&gt; Now, we would like to find a value of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; so that the approximating distribution
is as similar as possible to &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;.
One way to approach this is to minimize &lt;span class=&#34;math inline&#34;&gt;\(d(\mu)\)&lt;/span&gt; with respect to &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;. Let’s therefore look at the derivative
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial r} d(\mu) = \mu \psi_1(\mu + r -
1)\left(\frac{1 - (\mu - r)\exp \psi_0(\mu + r - 1)}{1 - \mu \exp
\psi_0(\mu + r - 1)}\right) - \ln\left[1 - \mu \exp \psi_0(\mu + r -
1)\right] - \psi_0(\mu + r - 1) + \psi_0(r - 1).
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes footnotes-end-of-document&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The incredible &lt;a href=&#34;https://cran.r-project.org/package=gamlss.dist&#34;&gt;&lt;code&gt;gamlss.dist&lt;/code&gt;
package&lt;/a&gt; does include a sampler for the double-Poisson distribution.
It appears to be implemented using the standard inversion method, by
applying the double-Poisson quantile function to a random sample from a
uniform distribution.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;




&lt;/div&gt;

&lt;script&gt;

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $(&#39;tr.odd&#39;).parent(&#39;tbody&#39;).parent(&#39;table&#39;).addClass(&#39;table table-condensed&#39;);
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


&lt;/script&gt;

&lt;!-- tabsets --&gt;

&lt;script&gt;
$(document).ready(function () {
  window.buildTabsets(&#34;TOC&#34;);
});

$(document).ready(function () {
  $(&#39;.tabset-dropdown &gt; .nav-tabs &gt; li&#39;).click(function () {
    $(this).parent().toggleClass(&#39;nav-tabs-open&#39;);
  });
});
&lt;/script&gt;

&lt;!-- code folding --&gt;


&lt;!-- dynamically load mathjax for compatibility with self-contained --&gt;
&lt;script&gt;
  (function () {
    var script = document.createElement(&#34;script&#34;);
    script.type = &#34;text/javascript&#34;;
    script.src  = &#34;https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;;
    document.getElementsByTagName(&#34;head&#34;)[0].appendChild(script);
  })();
&lt;/script&gt;

&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    
  </channel>
</rss>
